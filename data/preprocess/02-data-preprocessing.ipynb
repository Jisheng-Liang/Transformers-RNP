{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('lang_rna.csv')\n",
    "df.head()\n",
    "row, col = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASFHLDHLKNYHRRFCRPSRAPNIPTKQGQNMLEILQDCFEEQNSTESLSCSTPKEKDIYVQSTGKERQASHSESVPISSRRKEASLQVPAKPSDPADEPVQANEVHQKILSTDVVSKSTPDSTKTSSKGVKGHHGASDELYLPGGSPVVLLGARVSGSQKAISSGGQKRVTSRRSADMQSSNTDISFKTRKRLNFEDKVISNTAEIESSASQVEDSISEEQEGTSSETSQKRDDLSSEIQPQSKKSFSELYLETVNRKSKCSSVVRHTAAVPSPPYPPNDMKLLEDEFIIDGPDRSFSSQPWVVIPRKGHHMPFPENIAVPQGKKSREKPHRLSEKTLVSNTQTDKTGPVEEAQLSVEEKLGTTLTNELENDCRSTENKTHSENAKKPSARKRTVKQKQRRPSKPNIAQELSMGQNETENRNMSKIGQDKLQINSKRNMEDHEEVRNEPTPKKPVPALGNKKEKDSTQANKEKSRKKCFSRESKRKSVPKEVTLASRRGRRTSQHPSEWWLVKPSEGSVDGNSSKENESSILYPNRKKQTKRNHVSENTEKKPVPSKRKKKEISSRELKSLNVKGSGGNDDISTSQRKPLQNIDADPTQKSLHCSGPTRGSEDQNSDMISQNVHLKTRSEQHRSKTQMESTSNSEVCKHSVWEESGPSRFKNLEMPGRSNSEVGDEKDQKSLDLKTRSSNMVPNRNLHHKLVLPSNSPNVRRSNRIRLKPLEYWRGERIDAQESSSGRLVLEIVSPASESVKRKAKRNLDKVNKETNKKRIHLDNPTKTKIKVSLDIPLGDPFQATLAKDPETREIVPMDLIRPRDTYHFFVEQHGLKVYKTLNTTFFSTGKLVLGPHEEKGKQHVGQDILVFYVNFGDLLCTLHETPYMLTTGDSFYVPSGNHYNIKNLLNVESCLLFTQIKR MASFHLDHLKNYHRRFCRPSRAPNIPTKQGQNMLEILQDCFEEQNSTESLSCSTPKEKDIYVQSTGKERQASHSESVPISSRRKEASLQVPAKPSDPADEPVQANEVHQKILSTDVVSKSTPDSTKTSSKGVKGHHGASDELYLPGGSPVVLLGARVSGSQKAISSGGQKRVTSRRSADMQSSNTDISFKTRKRLNFEDKVISNTAEIESSASQVEDSISEEQEGTSSETSQKRDDLSSEIQPQSKKSFSELYLETVNRKSKCSSVVRHTAAVPSPPYPPNDMKLLEDEFIIDGPDRSFSSQPWVVIPRKGHHMPFPENIAVPQGKKSREKPHRLSEKTLVSNTQTDKTGPVEEAQLSVEEKLGTTLTNELENDCRSTENKTHSENAKKPSARKRTVKQKQRRPSKPNIAQELSMGQNETENRNMSKIGQDKLQINSKRNMEDHEEVRNEPTPKKPVPALGNKKEKDSTQANKEKSRKKCFSRESKRKSVPKEVTLASRRGRRTSQHPSEWWLVKPSEGSVDGNSSKENESSILYPNRKKQTKRNHVSENTEKKPVPSKRKKKEISSRELKSLNVKGSGGNDDISTSQRKPLQNIDADPTQKSLHCSGPTRGSEDQNSDMISQNVHLKTRSEQHRSKTQMESTSNSEVCKHSVWEESGPSRFKNLEMPGRSNSEVGDEKDQKSLDLKTRSSNMVPNRNLHHKLVLPSNSPNVRRSNRIRLKPLEYWRGERIDYQESSSGRLVLEIVSPASESVKRKAKRNLDKVNKETNKKRIHLDNPTKTKIKVSLDIPLGDPFQATLAKDPETREIVPMDLIRPRDTYHFFVEQHGLKVYKTLNTTFFSTGKLVLGPHEEKGKQHVGQDILVFYVNFGDLLCTLHETPYMLTTGDSFYVPSGNHYNIKNLLNVESCLLFTQIKR\n"
     ]
    }
   ],
   "source": [
    "# prepare for running hh-suite (see utils/runHHblits.py)\n",
    "for i in range(row):\n",
    "    seq_1 = df.iloc[i,2]\n",
    "    seq_2 = df.iloc[i,4]\n",
    "    entry_id = df.iloc[i,0]\n",
    "    # label = fasta.readline().strip()\n",
    "    # print(i)\n",
    "    new_1 = open(\"fasta/pro_mut_\" + str(entry_id) + \".fasta\", \"w+\")\n",
    "    new_2 = open(\"fasta/pro_ori_\" + str(entry_id) + \".fasta\", \"w+\")\n",
    "    new_1.write(\">\" + str(entry_id) + '\\n')\n",
    "    new_1.write(seq_1)\n",
    "    new_2.write(\">\" + str(entry_id) + '\\n')\n",
    "    new_2.write(seq_2)\n",
    "    if i == (row-1):\n",
    "        print(seq_1,seq_2)\n",
    "    # line = fasta.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# fetch name list\n",
    "import os\n",
    "hhm_path = 'hhm/'\n",
    "# pdb_path = 'data/pdb_example/'\n",
    "hhm_path_files = os.listdir(hhm_path)  \n",
    "name_list = []\n",
    "for fi in hhm_path_files: \n",
    "    hhm_name = fi.split('.')[0]\n",
    "    name_list.append(hhm_name)\n",
    "print(len(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mean space-hhblits\n",
    "import numpy as np\n",
    "import os\n",
    "output_path = '../hhblits/'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for uniprot_id in name_list:\n",
    "    # fetch length\n",
    "    with open(hhm_path + uniprot_id + '.hhm') as hhm_file:\n",
    "        hhm_line = hhm_file.readline()\n",
    "        while hhm_line:\n",
    "            if(hhm_line[0:4] == 'LENG'):\n",
    "                hhm_seq_len = int(hhm_line.split()[1])\n",
    "                break\n",
    "            hhm_line = hhm_file.readline()\n",
    "    # fetch 30d feature from .hhm    \n",
    "    with open(hhm_path + uniprot_id + '.hhm') as hhm_file:     \n",
    "        hhm_matrix = np.zeros([hhm_seq_len, 30], float)\n",
    "        hhm_line = hhm_file.readline()\n",
    "        idxx = 0\n",
    "        while(hhm_line[0] != '#'):\n",
    "            hhm_line = hhm_file.readline()\n",
    "        for i in range(0,5):\n",
    "            hhm_line = hhm_file.readline()\n",
    "        while hhm_line:\n",
    "            if(len(hhm_line.split()) == 23):\n",
    "                idxx += 1\n",
    "                if(idxx == hhm_seq_len + 1):\n",
    "                    break\n",
    "                each_item = hhm_line.split()[2:22]\n",
    "                for idx, s in enumerate(each_item):\n",
    "                    if(s == '*'):\n",
    "                        each_item[idx] = '99999'                            \n",
    "                for j in range(0, 20):\n",
    "                    try:\n",
    "                        hhm_matrix[idxx - 1, j] = int(each_item[j])                      \n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            elif(len(hhm_line.split()) == 10):\n",
    "                each_item = hhm_line.split()[0:10]\n",
    "                for idx, s in enumerate(each_item):\n",
    "                    if(s == '*'):\n",
    "                        each_item[idx] = '99999'                             \n",
    "                for j in range(20, 30):\n",
    "                    try:\n",
    "                        hhm_matrix[idxx - 1, j] = int(each_item[j - 20])                        \n",
    "                    except IndexError:\n",
    "                        pass                            \n",
    "            hhm_line = hhm_file.readline()\n",
    "        #print(hhm_matrix.shape) # # seq_len*30\n",
    "        #print(hhm_matrix)\n",
    "    \n",
    "    with open(os.path.join(output_path,uniprot_id + '.hhm'),'w+') as out_file:\n",
    "        np.savetxt(out_file, hhm_matrix, fmt='%.6f')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3803, 41)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/pro_mut_0.hhm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/lstm/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     os\u001b[39m.\u001b[39;49mrename(src, real_dst)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/pro_mut_0.hhm' -> 'new/pro_mut_133.hhm'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m mut_new \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpro_mut_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(idx) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.hhm\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     13\u001b[0m ori_new \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpro_ori_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(idx) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.hhm\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m shutil\u001b[39m.\u001b[39;49mmove((\u001b[39m'\u001b[39;49m\u001b[39mdata/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mmut_old),(\u001b[39m'\u001b[39;49m\u001b[39mnew/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mmut_new))\n\u001b[1;32m     15\u001b[0m shutil\u001b[39m.\u001b[39mmove((\u001b[39m'\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mori_old),(\u001b[39m'\u001b[39m\u001b[39mnew/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mori_new))\n",
      "File \u001b[0;32m~/.conda/envs/lstm/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         copy_function(src, real_dst)\n\u001b[1;32m    837\u001b[0m         os\u001b[39m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[39mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m~/.conda/envs/lstm/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/.conda/envs/lstm/lib/python3.10/shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m     os\u001b[39m.\u001b[39msymlink(os\u001b[39m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(src, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dst, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m                 \u001b[39m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/pro_mut_0.hhm'"
     ]
    }
   ],
   "source": [
    "# rename \n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "df = pd.read_csv('final.csv')\n",
    "print(df.shape)\n",
    "for i in range(df.shape[0]):\n",
    "    idx = df.iloc[i,0]\n",
    "\n",
    "    mut_old = 'pro_mut_' + str(i) + '.hhm'\n",
    "    ori_old = 'pro_ori_' + str(i) + '.hhm'\n",
    "\n",
    "    mut_new = 'pro_mut_' + str(idx) + '.hhm'\n",
    "    ori_new = 'pro_ori_' + str(idx) + '.hhm'\n",
    "    shutil.move(('data/'+mut_old),('new/'+mut_new))\n",
    "    shutil.move(('data/'+ori_old),('new/'+ori_new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cea085641e72410502974b25165e6310c4e74f3895213c724f4183725c7e9270"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
