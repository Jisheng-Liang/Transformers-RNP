{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from dataset import pro_encoder, na_encoder, hhblits_encoder\n",
    "from model import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 64\n",
    "root_dir = \"./\"\n",
    "data_csv = \"final_rna.csv\"\n",
    "hhblits_dir = \"new/\"\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random_split\n",
    "# df = pd.read_csv(data_csv)\n",
    "# df = df.sample(frac=1.0)\n",
    "# df.to_csv('random_rna.csv')\n",
    "# row = df.shape[0]\n",
    "# print(row)\n",
    "# idx_tr = round(row*0.8);idx_ts = round(row*0.1)\n",
    "# num_spl = [idx_tr,idx_tr+idx_ts,idx_tr+2*idx_ts]\n",
    "# df.iloc[0:num_spl[0],:].to_csv('train.csv',index=False)\n",
    "# df.iloc[num_spl[0]:num_spl[1],:].to_csv('val.csv',index=False)\n",
    "# df.iloc[num_spl[1]:num_spl[2],:].to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in ['train','val','test']:\n",
    "    filename = i+'.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    pro_ori = pro_encoder(df,'origin'); pro_ori = torch.tensor(pro_ori, dtype=torch.float)\n",
    "    pro_mut = pro_encoder(df,'mutant'); pro_mut = torch.tensor(pro_mut, dtype=torch.float)\n",
    "    na = na_encoder(df); na = torch.tensor(na, dtype=torch.float)\n",
    "    hhb_ori, hhb_mut = hhblits_encoder(hhblits_dir,df)\n",
    "    hhb_ori, hhb_mut = torch.tensor(hhb_ori, dtype=torch.float), torch.tensor(hhb_mut, dtype=torch.float)\n",
    "    y = df['ddG(kcal/mol)'].values.tolist(); y = torch.tensor(y, dtype=torch.float)\n",
    "    dataset.append(TensorDataset(pro_ori, pro_mut, hhb_ori, hhb_mut, na, y))\n",
    "\n",
    "train_dataset = dataset[0]; val_dataset = dataset[1]; test_dataset = dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 112 112\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),len(val_dataset), len(test_dataset))\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# MLPRegressor = MLPRegressor().to(device)\n",
    "\n",
    "# optimizer = Adam(MLPRegressor.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "# MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "#     min_val_loss = float(\"inf\")\n",
    "#     log = []\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         total_loss = 0.\n",
    "#         best_model = None\n",
    "#         model.train()\n",
    "#         for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             X_ori = X_ori.to(device)\n",
    "#             X_mut = X_mut.to(device)\n",
    "#             X_muthhb = X_muthhb.to(device)\n",
    "#             X_orihhb = X_orihhb.to(device)\n",
    "#             X_na = X_na.to(device)\n",
    "#             y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#             y = y.to(device)\n",
    "#             loss = loss_fn(y_preds.ravel(), y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()*len(X_ori)\n",
    "#         total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "#         # validate\n",
    "#         model.eval()\n",
    "#         val_losses = 0.\n",
    "#         with torch.no_grad():\n",
    "#             for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "#                 X_ori = X_ori.to(device)\n",
    "#                 X_mut = X_mut.to(device)\n",
    "#                 X_muthhb = X_muthhb.to(device)\n",
    "#                 X_orihhb = X_orihhb.to(device)\n",
    "#                 X_na = X_na.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#                 val_loss = loss_fn(preds.ravel(), y)\n",
    "#                 val_losses += val_loss.item()*len(X_ori)\n",
    "#         val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "#         log.append([epoch,total_mse,val_mse])\n",
    "#         print('| epoch {:3d} | lr {:02.5f} '\n",
    "#                       'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "#                       format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "#         if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "#             min_val_loss = val_loss\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), './result/mlp_best_all.pth')\n",
    "#         scheduler.step()\n",
    "#     f = open('./result/mlp_log.txt','w')\n",
    "#     for i in log:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#     f.close()\n",
    "# TrainModel(MLPRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# test_mse = 0.\n",
    "# test_result = []\n",
    "# model = MLPRegressor.to(device)\n",
    "# model.load_state_dict(torch.load('./result/mlp_best_all.pth'))\n",
    "# model.eval()\n",
    "# for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "#     X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "#     X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "#     X_na = X_na.to(device)\n",
    "#     y = y.to(device)\n",
    "#     preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#     loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "#     test_result.append(y.tolist())\n",
    "#     test_result.append(preds.tolist())\n",
    "#     test_result.append(loss.tolist())\n",
    "#     test_mse += loss.item()*len(X_ori)\n",
    "# test_mse = test_mse/len(test_dataset)\n",
    "# test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "# file_name = 'result/mlp_test_'+'result.txt'\n",
    "# f = open(file_name,'w')\n",
    "# for i in test_result:\n",
    "#     f.write(str(i)+'\\n')\n",
    "# f.close()\n",
    "# print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# CNNRegressor = CNNRegressor().to(device)\n",
    "\n",
    "# optimizer = Adam(CNNRegressor.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "# CNNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "#     min_val_loss = float(\"inf\")\n",
    "#     log = []\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         total_loss = 0.\n",
    "#         best_model = None\n",
    "#         model.train()\n",
    "#         for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             X_ori = X_ori.to(device)\n",
    "#             X_mut = X_mut.to(device)\n",
    "#             X_muthhb = X_muthhb.to(device)\n",
    "#             X_orihhb = X_orihhb.to(device)\n",
    "#             X_na = X_na.to(device)\n",
    "#             y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#             y = y.to(device)\n",
    "#             loss = loss_fn(y_preds.ravel(), y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()*len(X_ori)\n",
    "#         total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "#         # validate\n",
    "#         model.eval()\n",
    "#         val_losses = 0.\n",
    "#         with torch.no_grad():\n",
    "#             for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "#                 X_ori = X_ori.to(device)\n",
    "#                 X_mut = X_mut.to(device)\n",
    "#                 X_muthhb = X_muthhb.to(device)\n",
    "#                 X_orihhb = X_orihhb.to(device)\n",
    "#                 X_na = X_na.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#                 val_loss = loss_fn(preds.ravel(), y)\n",
    "#                 val_losses += val_loss.item()*len(X_ori)\n",
    "#         val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "#         log.append([epoch,total_mse,val_mse])\n",
    "#         print('| epoch {:3d} | lr {:02.5f} '\n",
    "#                       'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "#                       format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "#         if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "#             min_val_loss = val_loss\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), './result/cnn_best_all.pth')\n",
    "#         scheduler.step()\n",
    "#     f = open('./result/cnn_log.txt','w')\n",
    "#     for i in log:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#     f.close()\n",
    "# TrainModel(CNNRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# test_mse = 0.\n",
    "# test_result = []\n",
    "# model = CNNRegressor.to(device)\n",
    "# model.load_state_dict(torch.load('result/cnn_best_all.pth'))\n",
    "# model.eval()\n",
    "# for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "#     X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "#     X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "#     X_na = X_na.to(device)\n",
    "#     y = y.to(device)\n",
    "#     preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#     loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "#     test_result.append(y.tolist())\n",
    "#     test_result.append(preds.tolist())\n",
    "#     test_result.append(loss.tolist())\n",
    "#     test_mse += loss.item()*len(X_ori)\n",
    "# test_mse = test_mse/len(test_dataset)\n",
    "# test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "# file_name = 'result/cnn_test_result.txt'\n",
    "# f = open(file_name,'w')\n",
    "# for i in test_result:\n",
    "#     f.write(str(i)+'\\n')\n",
    "# f.close()\n",
    "# print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# LSTMRegressor = LSTMRegressor().to(device)\n",
    "\n",
    "# optimizer = Adam(LSTMRegressor.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "# LSTMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "#     min_val_loss = float(\"inf\")\n",
    "#     log = []\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         total_loss = 0.\n",
    "#         best_model = None\n",
    "#         model.train()\n",
    "#         for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             X_ori = X_ori.to(device)\n",
    "#             X_mut = X_mut.to(device)\n",
    "#             X_muthhb = X_muthhb.to(device)\n",
    "#             X_orihhb = X_orihhb.to(device)\n",
    "#             X_na = X_na.to(device)\n",
    "#             y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "#             y = y.to(device)\n",
    "#             loss = loss_fn(y_preds.ravel(), y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()*len(X_ori)\n",
    "#         total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "#         # validate\n",
    "#         model.eval()\n",
    "#         val_losses = 0.\n",
    "#         with torch.no_grad():\n",
    "#             for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "#                 X_ori = X_ori.to(device)\n",
    "#                 X_mut = X_mut.to(device)\n",
    "#                 X_muthhb = X_muthhb.to(device)\n",
    "#                 X_orihhb = X_orihhb.to(device)\n",
    "#                 X_na = X_na.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "#                 val_loss = loss_fn(preds.ravel(), y)\n",
    "#                 val_losses += val_loss.item()*len(X_ori)\n",
    "#         val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "#         log.append([epoch,total_mse,val_mse])\n",
    "#         print('| epoch {:3d} | lr {:02.5f} '\n",
    "#                       'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "#                       format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "#         if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "#             min_val_loss = val_loss\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), 'result/lstm_best_all.pth')\n",
    "#         scheduler.step()\n",
    "#     f = open('result/lstm_log.txt','w')\n",
    "#     for i in log:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#     f.close()\n",
    "# TrainModel(LSTMRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# test_mse = 0.\n",
    "# test_result = []\n",
    "# model = LSTMRegressor.to(device)\n",
    "# model.load_state_dict(torch.load('result/lstm_best_all.pth'))\n",
    "# model.eval()\n",
    "# for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "#     X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "#     X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "#     X_na = X_na.to(device)\n",
    "#     y = y.to(device)\n",
    "#     preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "#     loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "#     test_result.append(y.tolist())\n",
    "#     test_result.append(preds.tolist())\n",
    "#     test_result.append(loss.tolist())\n",
    "#     test_mse += loss.item()*len(X_ori)\n",
    "# test_mse = test_mse/len(test_dataset)\n",
    "# test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "# file_name = 'result/lstm_test_result.txt'\n",
    "# f = open(file_name,'w')\n",
    "# for i in test_result:\n",
    "#     f.write(str(i)+'\\n')\n",
    "# f.close()\n",
    "# print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# BLSTMRegressor = BLSTMRegressor().to(device)\n",
    "\n",
    "# optimizer = Adam(BLSTMRegressor.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "# BLSTMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "#     min_val_loss = float(\"inf\")\n",
    "#     log = []\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         total_loss = 0.\n",
    "#         best_model = None\n",
    "#         model.train()\n",
    "#         for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             X_ori = X_ori.to(device)\n",
    "#             X_mut = X_mut.to(device)\n",
    "#             X_muthhb = X_muthhb.to(device)\n",
    "#             X_orihhb = X_orihhb.to(device)\n",
    "#             X_na = X_na.to(device)\n",
    "#             y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "#             y = y.to(device)\n",
    "#             loss = loss_fn(y_preds.ravel(), y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()*len(X_ori)\n",
    "#         total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "#         # validate\n",
    "#         model.eval()\n",
    "#         val_losses = 0.\n",
    "#         with torch.no_grad():\n",
    "#             for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "#                 X_ori = X_ori.to(device)\n",
    "#                 X_mut = X_mut.to(device)\n",
    "#                 X_muthhb = X_muthhb.to(device)\n",
    "#                 X_orihhb = X_orihhb.to(device)\n",
    "#                 X_na = X_na.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "#                 val_loss = loss_fn(preds.ravel(), y)\n",
    "#                 val_losses += val_loss.item()*len(X_ori)\n",
    "#         val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "#         log.append([epoch,total_mse,val_mse])\n",
    "#         print('| epoch {:3d} | lr {:02.5f} '\n",
    "#                       'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "#                       format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "#         if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "#             min_val_loss = val_loss\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), 'result/blstm_best_all.pth')\n",
    "#         scheduler.step()\n",
    "#     f = open('result/blstm_log.txt','w')\n",
    "#     for i in log:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#     f.close()\n",
    "# TrainModel(BLSTMRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# test_mse = 0.\n",
    "# test_result = []\n",
    "# model = BLSTMRegressor.to(device)\n",
    "# model.load_state_dict(torch.load('result/blstm_best_all.pth'))\n",
    "# model.eval()\n",
    "# for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "#     X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "#     X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "#     X_na = X_na.to(device)\n",
    "#     y = y.to(device)\n",
    "#     preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "#     loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "#     test_result.append(y.tolist())\n",
    "#     test_result.append(preds.tolist())\n",
    "#     test_result.append(loss.tolist())\n",
    "#     test_mse += loss.item()*len(X_ori)\n",
    "# test_mse = test_mse/len(test_dataset)\n",
    "# test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "# file_name = 'result/blstm_test_result.txt'\n",
    "# f = open(file_name,'w')\n",
    "# for i in test_result:\n",
    "#     f.write(str(i)+'\\n')\n",
    "# f.close()\n",
    "# print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trans(\n",
       "  (transencoder1): TransformerEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (token_embeddings): Linear(in_features=20, out_features=60, bias=True)\n",
       "      (layer_norm): LayerNorm((60,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (layer_norm_1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (1): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (2): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (3): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (4): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (5): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (6): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (7): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (8): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (9): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (output_linear): Linear(in_features=60, out_features=60, bias=True)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (linear_1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "          (linear_2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "          (gelu): GELU(approximate=none)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transencoder2): TransformerEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (token_embeddings): Linear(in_features=20, out_features=60, bias=True)\n",
       "      (layer_norm): LayerNorm((60,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (layer_norm_1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (1): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (2): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (3): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (4): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (5): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (6): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (7): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (8): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (9): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (output_linear): Linear(in_features=60, out_features=60, bias=True)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (linear_1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "          (linear_2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "          (gelu): GELU(approximate=none)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transencoder3): TransformerEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (token_embeddings): Linear(in_features=30, out_features=60, bias=True)\n",
       "      (layer_norm): LayerNorm((60,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (layer_norm_1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (1): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (2): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (3): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (4): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (5): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (6): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (7): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (8): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (9): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (output_linear): Linear(in_features=60, out_features=60, bias=True)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (linear_1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "          (linear_2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "          (gelu): GELU(approximate=none)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transencoder4): TransformerEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (token_embeddings): Linear(in_features=30, out_features=60, bias=True)\n",
       "      (layer_norm): LayerNorm((60,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (layer_norm_1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (1): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (2): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (3): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (4): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (5): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (6): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (7): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (8): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (9): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (output_linear): Linear(in_features=60, out_features=60, bias=True)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (linear_1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "          (linear_2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "          (gelu): GELU(approximate=none)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transencoder5): TransformerEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (token_embeddings): Linear(in_features=4, out_features=60, bias=True)\n",
       "      (layer_norm): LayerNorm((60,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (layer_norm_1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (1): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (2): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (3): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (4): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (5): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (6): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (7): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (8): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "            (9): AttentionHead(\n",
       "              (q): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (k): Linear(in_features=60, out_features=6, bias=True)\n",
       "              (v): Linear(in_features=60, out_features=6, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (output_linear): Linear(in_features=60, out_features=60, bias=True)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (linear_1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "          (linear_2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "          (gelu): GELU(approximate=none)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder1): Linear(in_features=60, out_features=10, bias=True)\n",
       "  (decoder11): Linear(in_features=60, out_features=10, bias=True)\n",
       "  (decoder2): Linear(in_features=60, out_features=10, bias=True)\n",
       "  (decoder22): Linear(in_features=60, out_features=10, bias=True)\n",
       "  (decoder3): Linear(in_features=60, out_features=10, bias=True)\n",
       "  (act): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear1): Linear(in_features=41000, out_features=8192, bias=True)\n",
       "  (linear2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  (linear3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (linear4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (linear5): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "Trans = Trans().to(device)\n",
    "\n",
    "optimizer = Adam(Trans.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | lr 0.00100 train_loss 436.76062 | val_loss 2.42099 | val_rmse 1.55595\n",
      "| epoch   2 | lr 0.00100 train_loss 2.24020 | val_loss 2.67586 | val_rmse 1.63580\n",
      "| epoch   3 | lr 0.00100 train_loss 2.18292 | val_loss 2.29104 | val_rmse 1.51362\n",
      "| epoch   4 | lr 0.00100 train_loss 2.25928 | val_loss 2.41600 | val_rmse 1.55435\n",
      "| epoch   5 | lr 0.00100 train_loss 1.93946 | val_loss 2.12584 | val_rmse 1.45803\n",
      "| epoch   6 | lr 0.00100 train_loss 1.96247 | val_loss 2.80894 | val_rmse 1.67599\n",
      "| epoch   7 | lr 0.00100 train_loss 1.93121 | val_loss 2.31464 | val_rmse 1.52139\n",
      "| epoch   8 | lr 0.00100 train_loss 1.69356 | val_loss 2.06610 | val_rmse 1.43739\n",
      "| epoch   9 | lr 0.00100 train_loss 1.71400 | val_loss 2.29989 | val_rmse 1.51654\n",
      "| epoch  10 | lr 0.00100 train_loss 1.54046 | val_loss 1.97603 | val_rmse 1.40571\n",
      "| epoch  11 | lr 0.00100 train_loss 1.45072 | val_loss 2.10653 | val_rmse 1.45139\n",
      "| epoch  12 | lr 0.00100 train_loss 1.41211 | val_loss 2.03643 | val_rmse 1.42703\n",
      "| epoch  13 | lr 0.00100 train_loss 1.33567 | val_loss 2.22306 | val_rmse 1.49099\n",
      "| epoch  14 | lr 0.00100 train_loss 1.33125 | val_loss 1.76996 | val_rmse 1.33040\n",
      "| epoch  15 | lr 0.00100 train_loss 1.38662 | val_loss 1.87448 | val_rmse 1.36912\n",
      "| epoch  16 | lr 0.00100 train_loss 1.24829 | val_loss 1.86994 | val_rmse 1.36746\n",
      "| epoch  17 | lr 0.00100 train_loss 1.15614 | val_loss 1.67165 | val_rmse 1.29292\n",
      "| epoch  18 | lr 0.00100 train_loss 1.16670 | val_loss 1.84252 | val_rmse 1.35739\n",
      "| epoch  19 | lr 0.00100 train_loss 1.26662 | val_loss 2.16453 | val_rmse 1.47123\n",
      "| epoch  20 | lr 0.00100 train_loss 1.16043 | val_loss 1.94262 | val_rmse 1.39378\n",
      "| epoch  21 | lr 0.00100 train_loss 1.05368 | val_loss 1.72188 | val_rmse 1.31220\n",
      "| epoch  22 | lr 0.00100 train_loss 0.96060 | val_loss 1.58816 | val_rmse 1.26022\n",
      "| epoch  23 | lr 0.00100 train_loss 1.02729 | val_loss 1.85508 | val_rmse 1.36201\n",
      "| epoch  24 | lr 0.00100 train_loss 1.01105 | val_loss 1.89520 | val_rmse 1.37666\n",
      "| epoch  25 | lr 0.00100 train_loss 0.97428 | val_loss 1.61874 | val_rmse 1.27230\n",
      "| epoch  26 | lr 0.00100 train_loss 1.11760 | val_loss 1.69419 | val_rmse 1.30161\n",
      "| epoch  27 | lr 0.00100 train_loss 0.98171 | val_loss 1.59442 | val_rmse 1.26270\n",
      "| epoch  28 | lr 0.00100 train_loss 0.92297 | val_loss 1.44280 | val_rmse 1.20117\n",
      "| epoch  29 | lr 0.00100 train_loss 0.94387 | val_loss 1.53865 | val_rmse 1.24042\n",
      "| epoch  30 | lr 0.00100 train_loss 0.83814 | val_loss 1.64175 | val_rmse 1.28131\n",
      "| epoch  31 | lr 0.00100 train_loss 0.79610 | val_loss 1.55960 | val_rmse 1.24884\n",
      "| epoch  32 | lr 0.00100 train_loss 0.87625 | val_loss 1.44820 | val_rmse 1.20341\n",
      "| epoch  33 | lr 0.00100 train_loss 0.83976 | val_loss 1.47413 | val_rmse 1.21414\n",
      "| epoch  34 | lr 0.00100 train_loss 0.83193 | val_loss 1.47304 | val_rmse 1.21369\n",
      "| epoch  35 | lr 0.00100 train_loss 0.80024 | val_loss 1.44721 | val_rmse 1.20300\n",
      "| epoch  36 | lr 0.00100 train_loss 0.76999 | val_loss 1.54583 | val_rmse 1.24331\n",
      "| epoch  37 | lr 0.00100 train_loss 0.75302 | val_loss 1.73645 | val_rmse 1.31774\n",
      "| epoch  38 | lr 0.00100 train_loss 0.77954 | val_loss 1.57796 | val_rmse 1.25617\n",
      "| epoch  39 | lr 0.00100 train_loss 0.72605 | val_loss 1.60298 | val_rmse 1.26609\n",
      "| epoch  40 | lr 0.00100 train_loss 0.75501 | val_loss 1.54969 | val_rmse 1.24487\n",
      "| epoch  41 | lr 0.00100 train_loss 0.76469 | val_loss 1.54718 | val_rmse 1.24386\n",
      "| epoch  42 | lr 0.00100 train_loss 0.68161 | val_loss 1.55642 | val_rmse 1.24757\n",
      "| epoch  43 | lr 0.00100 train_loss 0.71790 | val_loss 1.59233 | val_rmse 1.26188\n",
      "| epoch  44 | lr 0.00100 train_loss 0.66659 | val_loss 1.54233 | val_rmse 1.24191\n",
      "| epoch  45 | lr 0.00100 train_loss 0.66166 | val_loss 1.50571 | val_rmse 1.22708\n",
      "| epoch  46 | lr 0.00100 train_loss 0.69128 | val_loss 1.60999 | val_rmse 1.26885\n",
      "| epoch  47 | lr 0.00100 train_loss 0.65516 | val_loss 1.42856 | val_rmse 1.19522\n",
      "| epoch  48 | lr 0.00100 train_loss 0.62684 | val_loss 1.51561 | val_rmse 1.23110\n",
      "| epoch  49 | lr 0.00100 train_loss 0.64398 | val_loss 1.67186 | val_rmse 1.29301\n",
      "| epoch  50 | lr 0.00100 train_loss 0.67516 | val_loss 1.53544 | val_rmse 1.23913\n",
      "| epoch  51 | lr 0.00010 train_loss 0.64034 | val_loss 1.57697 | val_rmse 1.25578\n",
      "| epoch  52 | lr 0.00010 train_loss 0.58420 | val_loss 1.59236 | val_rmse 1.26189\n",
      "| epoch  53 | lr 0.00010 train_loss 0.57082 | val_loss 1.57214 | val_rmse 1.25385\n",
      "| epoch  54 | lr 0.00010 train_loss 0.57339 | val_loss 1.57096 | val_rmse 1.25338\n",
      "| epoch  55 | lr 0.00010 train_loss 0.57003 | val_loss 1.57382 | val_rmse 1.25452\n",
      "| epoch  56 | lr 0.00010 train_loss 0.55521 | val_loss 1.55147 | val_rmse 1.24558\n",
      "| epoch  57 | lr 0.00010 train_loss 0.53981 | val_loss 1.52399 | val_rmse 1.23450\n",
      "| epoch  58 | lr 0.00010 train_loss 0.55685 | val_loss 1.53689 | val_rmse 1.23971\n",
      "| epoch  59 | lr 0.00010 train_loss 0.55211 | val_loss 1.51702 | val_rmse 1.23167\n",
      "| epoch  60 | lr 0.00010 train_loss 0.53844 | val_loss 1.52994 | val_rmse 1.23691\n",
      "| epoch  61 | lr 0.00010 train_loss 0.54201 | val_loss 1.55369 | val_rmse 1.24647\n",
      "| epoch  62 | lr 0.00010 train_loss 0.55478 | val_loss 1.52618 | val_rmse 1.23539\n",
      "| epoch  63 | lr 0.00010 train_loss 0.53916 | val_loss 1.53550 | val_rmse 1.23915\n",
      "| epoch  64 | lr 0.00010 train_loss 0.54986 | val_loss 1.50587 | val_rmse 1.22714\n",
      "| epoch  65 | lr 0.00010 train_loss 0.55913 | val_loss 1.49857 | val_rmse 1.22416\n",
      "| epoch  66 | lr 0.00010 train_loss 0.52465 | val_loss 1.51081 | val_rmse 1.22915\n",
      "| epoch  67 | lr 0.00010 train_loss 0.55804 | val_loss 1.49522 | val_rmse 1.22279\n",
      "| epoch  68 | lr 0.00010 train_loss 0.53788 | val_loss 1.52179 | val_rmse 1.23361\n",
      "| epoch  69 | lr 0.00010 train_loss 0.53947 | val_loss 1.50717 | val_rmse 1.22767\n",
      "| epoch  70 | lr 0.00010 train_loss 0.54112 | val_loss 1.51944 | val_rmse 1.23266\n",
      "| epoch  71 | lr 0.00010 train_loss 0.52656 | val_loss 1.50730 | val_rmse 1.22772\n",
      "| epoch  72 | lr 0.00010 train_loss 0.51482 | val_loss 1.51275 | val_rmse 1.22994\n",
      "| epoch  73 | lr 0.00010 train_loss 0.52429 | val_loss 1.51513 | val_rmse 1.23091\n",
      "| epoch  74 | lr 0.00010 train_loss 0.50134 | val_loss 1.53800 | val_rmse 1.24016\n",
      "| epoch  75 | lr 0.00010 train_loss 0.52914 | val_loss 1.51884 | val_rmse 1.23241\n",
      "| epoch  76 | lr 0.00010 train_loss 0.50791 | val_loss 1.51092 | val_rmse 1.22919\n",
      "| epoch  77 | lr 0.00010 train_loss 0.52728 | val_loss 1.53759 | val_rmse 1.24000\n",
      "| epoch  78 | lr 0.00010 train_loss 0.52952 | val_loss 1.54917 | val_rmse 1.24466\n",
      "| epoch  79 | lr 0.00010 train_loss 0.52611 | val_loss 1.56032 | val_rmse 1.24913\n",
      "| epoch  80 | lr 0.00010 train_loss 0.53022 | val_loss 1.49824 | val_rmse 1.22403\n",
      "| epoch  81 | lr 0.00010 train_loss 0.52844 | val_loss 1.49828 | val_rmse 1.22404\n",
      "| epoch  82 | lr 0.00010 train_loss 0.51961 | val_loss 1.51905 | val_rmse 1.23250\n",
      "| epoch  83 | lr 0.00010 train_loss 0.52616 | val_loss 1.45504 | val_rmse 1.20625\n",
      "| epoch  84 | lr 0.00010 train_loss 0.52558 | val_loss 1.47157 | val_rmse 1.21308\n",
      "| epoch  85 | lr 0.00010 train_loss 0.52649 | val_loss 1.46611 | val_rmse 1.21083\n",
      "| epoch  86 | lr 0.00010 train_loss 0.52008 | val_loss 1.45341 | val_rmse 1.20558\n",
      "| epoch  87 | lr 0.00010 train_loss 0.51933 | val_loss 1.44803 | val_rmse 1.20334\n",
      "| epoch  88 | lr 0.00010 train_loss 0.50870 | val_loss 1.45236 | val_rmse 1.20514\n",
      "| epoch  89 | lr 0.00010 train_loss 0.49529 | val_loss 1.46283 | val_rmse 1.20947\n",
      "| epoch  90 | lr 0.00010 train_loss 0.49156 | val_loss 1.45055 | val_rmse 1.20439\n",
      "| epoch  91 | lr 0.00010 train_loss 0.52351 | val_loss 1.47891 | val_rmse 1.21610\n",
      "| epoch  92 | lr 0.00010 train_loss 0.52645 | val_loss 1.48652 | val_rmse 1.21923\n",
      "| epoch  93 | lr 0.00010 train_loss 0.51379 | val_loss 1.48337 | val_rmse 1.21794\n",
      "| epoch  94 | lr 0.00010 train_loss 0.50679 | val_loss 1.46664 | val_rmse 1.21105\n",
      "| epoch  95 | lr 0.00010 train_loss 0.50632 | val_loss 1.48053 | val_rmse 1.21677\n",
      "| epoch  96 | lr 0.00010 train_loss 0.53691 | val_loss 1.47451 | val_rmse 1.21430\n",
      "| epoch  97 | lr 0.00010 train_loss 0.51128 | val_loss 1.49818 | val_rmse 1.22400\n",
      "| epoch  98 | lr 0.00010 train_loss 0.48449 | val_loss 1.48376 | val_rmse 1.21810\n",
      "| epoch  99 | lr 0.00010 train_loss 0.48404 | val_loss 1.49283 | val_rmse 1.22181\n",
      "| epoch 100 | lr 0.00010 train_loss 0.48759 | val_loss 1.48039 | val_rmse 1.21671\n",
      "| epoch 101 | lr 0.00010 train_loss 0.49345 | val_loss 1.49725 | val_rmse 1.22362\n",
      "| epoch 102 | lr 0.00010 train_loss 0.50195 | val_loss 1.47699 | val_rmse 1.21532\n",
      "| epoch 103 | lr 0.00010 train_loss 0.50870 | val_loss 1.48171 | val_rmse 1.21725\n",
      "| epoch 104 | lr 0.00010 train_loss 0.49466 | val_loss 1.48667 | val_rmse 1.21929\n",
      "| epoch 105 | lr 0.00010 train_loss 0.48454 | val_loss 1.46334 | val_rmse 1.20969\n",
      "| epoch 106 | lr 0.00010 train_loss 0.48274 | val_loss 1.47815 | val_rmse 1.21579\n",
      "| epoch 107 | lr 0.00010 train_loss 0.49799 | val_loss 1.47703 | val_rmse 1.21533\n",
      "| epoch 108 | lr 0.00010 train_loss 0.46537 | val_loss 1.44559 | val_rmse 1.20233\n",
      "| epoch 109 | lr 0.00010 train_loss 0.48304 | val_loss 1.47389 | val_rmse 1.21404\n",
      "| epoch 110 | lr 0.00010 train_loss 0.50092 | val_loss 1.42136 | val_rmse 1.19221\n",
      "| epoch 111 | lr 0.00010 train_loss 0.51179 | val_loss 1.42280 | val_rmse 1.19281\n",
      "| epoch 112 | lr 0.00010 train_loss 0.50319 | val_loss 1.42594 | val_rmse 1.19413\n",
      "| epoch 113 | lr 0.00010 train_loss 0.49584 | val_loss 1.40343 | val_rmse 1.18466\n",
      "| epoch 114 | lr 0.00010 train_loss 0.48668 | val_loss 1.43759 | val_rmse 1.19900\n",
      "| epoch 115 | lr 0.00010 train_loss 0.47937 | val_loss 1.43713 | val_rmse 1.19880\n",
      "| epoch 116 | lr 0.00010 train_loss 0.48347 | val_loss 1.40246 | val_rmse 1.18425\n",
      "| epoch 117 | lr 0.00010 train_loss 0.47060 | val_loss 1.40310 | val_rmse 1.18452\n",
      "| epoch 118 | lr 0.00010 train_loss 0.47979 | val_loss 1.41556 | val_rmse 1.18978\n",
      "| epoch 119 | lr 0.00010 train_loss 0.48637 | val_loss 1.41530 | val_rmse 1.18966\n",
      "| epoch 120 | lr 0.00010 train_loss 0.48223 | val_loss 1.41978 | val_rmse 1.19155\n",
      "| epoch 121 | lr 0.00010 train_loss 0.47231 | val_loss 1.41844 | val_rmse 1.19098\n",
      "| epoch 122 | lr 0.00010 train_loss 0.49179 | val_loss 1.42274 | val_rmse 1.19279\n",
      "| epoch 123 | lr 0.00010 train_loss 0.47109 | val_loss 1.41797 | val_rmse 1.19078\n",
      "| epoch 124 | lr 0.00010 train_loss 0.46860 | val_loss 1.42422 | val_rmse 1.19341\n",
      "| epoch 125 | lr 0.00010 train_loss 0.46114 | val_loss 1.42988 | val_rmse 1.19578\n",
      "| epoch 126 | lr 0.00010 train_loss 0.44366 | val_loss 1.44626 | val_rmse 1.20260\n",
      "| epoch 127 | lr 0.00010 train_loss 0.47414 | val_loss 1.42525 | val_rmse 1.19384\n",
      "| epoch 128 | lr 0.00010 train_loss 0.45388 | val_loss 1.41887 | val_rmse 1.19116\n",
      "| epoch 129 | lr 0.00010 train_loss 0.46580 | val_loss 1.43306 | val_rmse 1.19710\n",
      "| epoch 130 | lr 0.00010 train_loss 0.48007 | val_loss 1.42344 | val_rmse 1.19308\n",
      "| epoch 131 | lr 0.00010 train_loss 0.49261 | val_loss 1.39615 | val_rmse 1.18159\n",
      "| epoch 132 | lr 0.00010 train_loss 0.46264 | val_loss 1.38709 | val_rmse 1.17775\n",
      "| epoch 133 | lr 0.00010 train_loss 0.47925 | val_loss 1.40021 | val_rmse 1.18331\n",
      "| epoch 134 | lr 0.00010 train_loss 0.45728 | val_loss 1.39322 | val_rmse 1.18035\n",
      "| epoch 135 | lr 0.00010 train_loss 0.47392 | val_loss 1.40905 | val_rmse 1.18703\n",
      "| epoch 136 | lr 0.00010 train_loss 0.44621 | val_loss 1.40195 | val_rmse 1.18404\n",
      "| epoch 137 | lr 0.00010 train_loss 0.45529 | val_loss 1.39915 | val_rmse 1.18286\n",
      "| epoch 138 | lr 0.00010 train_loss 0.48252 | val_loss 1.39292 | val_rmse 1.18022\n",
      "| epoch 139 | lr 0.00010 train_loss 0.46286 | val_loss 1.38839 | val_rmse 1.17830\n",
      "| epoch 140 | lr 0.00010 train_loss 0.46428 | val_loss 1.38854 | val_rmse 1.17836\n",
      "| epoch 141 | lr 0.00010 train_loss 0.47782 | val_loss 1.40658 | val_rmse 1.18599\n",
      "| epoch 142 | lr 0.00010 train_loss 0.44979 | val_loss 1.40360 | val_rmse 1.18474\n",
      "| epoch 143 | lr 0.00010 train_loss 0.47766 | val_loss 1.38740 | val_rmse 1.17788\n",
      "| epoch 144 | lr 0.00010 train_loss 0.48192 | val_loss 1.39179 | val_rmse 1.17974\n",
      "| epoch 145 | lr 0.00010 train_loss 0.46358 | val_loss 1.40178 | val_rmse 1.18397\n",
      "| epoch 146 | lr 0.00010 train_loss 0.46074 | val_loss 1.39319 | val_rmse 1.18033\n",
      "| epoch 147 | lr 0.00010 train_loss 0.47326 | val_loss 1.41462 | val_rmse 1.18938\n",
      "| epoch 148 | lr 0.00010 train_loss 0.45946 | val_loss 1.41139 | val_rmse 1.18802\n",
      "| epoch 149 | lr 0.00010 train_loss 0.44189 | val_loss 1.42117 | val_rmse 1.19213\n",
      "| epoch 150 | lr 0.00010 train_loss 0.44776 | val_loss 1.41001 | val_rmse 1.18744\n",
      "| epoch 151 | lr 0.00010 train_loss 0.43940 | val_loss 1.39989 | val_rmse 1.18317\n",
      "| epoch 152 | lr 0.00010 train_loss 0.48437 | val_loss 1.41736 | val_rmse 1.19053\n",
      "| epoch 153 | lr 0.00010 train_loss 0.45441 | val_loss 1.44256 | val_rmse 1.20107\n",
      "| epoch 154 | lr 0.00010 train_loss 0.43040 | val_loss 1.43945 | val_rmse 1.19977\n",
      "| epoch 155 | lr 0.00010 train_loss 0.46301 | val_loss 1.42088 | val_rmse 1.19201\n",
      "| epoch 156 | lr 0.00010 train_loss 0.44196 | val_loss 1.41262 | val_rmse 1.18854\n",
      "| epoch 157 | lr 0.00010 train_loss 0.48011 | val_loss 1.40756 | val_rmse 1.18641\n",
      "| epoch 158 | lr 0.00010 train_loss 0.44917 | val_loss 1.41219 | val_rmse 1.18836\n",
      "| epoch 159 | lr 0.00010 train_loss 0.45952 | val_loss 1.41284 | val_rmse 1.18863\n",
      "| epoch 160 | lr 0.00010 train_loss 0.44101 | val_loss 1.40004 | val_rmse 1.18323\n",
      "| epoch 161 | lr 0.00010 train_loss 0.45159 | val_loss 1.39112 | val_rmse 1.17946\n",
      "| epoch 162 | lr 0.00010 train_loss 0.44244 | val_loss 1.39673 | val_rmse 1.18183\n",
      "| epoch 163 | lr 0.00010 train_loss 0.41998 | val_loss 1.38270 | val_rmse 1.17588\n",
      "| epoch 164 | lr 0.00010 train_loss 0.44049 | val_loss 1.37786 | val_rmse 1.17382\n",
      "| epoch 165 | lr 0.00010 train_loss 0.43482 | val_loss 1.38826 | val_rmse 1.17824\n",
      "| epoch 166 | lr 0.00010 train_loss 0.44638 | val_loss 1.38373 | val_rmse 1.17632\n",
      "| epoch 167 | lr 0.00010 train_loss 0.45145 | val_loss 1.38832 | val_rmse 1.17827\n",
      "| epoch 168 | lr 0.00010 train_loss 0.43998 | val_loss 1.39566 | val_rmse 1.18138\n",
      "| epoch 169 | lr 0.00010 train_loss 0.44330 | val_loss 1.40002 | val_rmse 1.18322\n",
      "| epoch 170 | lr 0.00010 train_loss 0.43596 | val_loss 1.41740 | val_rmse 1.19055\n",
      "| epoch 171 | lr 0.00010 train_loss 0.43174 | val_loss 1.40748 | val_rmse 1.18637\n",
      "| epoch 172 | lr 0.00010 train_loss 0.46275 | val_loss 1.38375 | val_rmse 1.17633\n",
      "| epoch 173 | lr 0.00010 train_loss 0.45994 | val_loss 1.36361 | val_rmse 1.16774\n",
      "| epoch 174 | lr 0.00010 train_loss 0.42575 | val_loss 1.37055 | val_rmse 1.17070\n",
      "| epoch 175 | lr 0.00010 train_loss 0.46207 | val_loss 1.36141 | val_rmse 1.16679\n",
      "| epoch 176 | lr 0.00010 train_loss 0.41910 | val_loss 1.36764 | val_rmse 1.16946\n",
      "| epoch 177 | lr 0.00010 train_loss 0.43808 | val_loss 1.36496 | val_rmse 1.16832\n",
      "| epoch 178 | lr 0.00010 train_loss 0.42722 | val_loss 1.36167 | val_rmse 1.16691\n",
      "| epoch 179 | lr 0.00010 train_loss 0.42298 | val_loss 1.34525 | val_rmse 1.15985\n",
      "| epoch 180 | lr 0.00010 train_loss 0.41103 | val_loss 1.36000 | val_rmse 1.16619\n",
      "| epoch 181 | lr 0.00010 train_loss 0.43120 | val_loss 1.35042 | val_rmse 1.16207\n",
      "| epoch 182 | lr 0.00010 train_loss 0.44225 | val_loss 1.35664 | val_rmse 1.16475\n",
      "| epoch 183 | lr 0.00010 train_loss 0.43078 | val_loss 1.34925 | val_rmse 1.16157\n",
      "| epoch 184 | lr 0.00010 train_loss 0.42210 | val_loss 1.37604 | val_rmse 1.17305\n",
      "| epoch 185 | lr 0.00010 train_loss 0.43658 | val_loss 1.36111 | val_rmse 1.16666\n",
      "| epoch 186 | lr 0.00010 train_loss 0.41596 | val_loss 1.38601 | val_rmse 1.17729\n",
      "| epoch 187 | lr 0.00010 train_loss 0.41874 | val_loss 1.36815 | val_rmse 1.16968\n",
      "| epoch 188 | lr 0.00010 train_loss 0.41497 | val_loss 1.35733 | val_rmse 1.16504\n",
      "| epoch 189 | lr 0.00010 train_loss 0.41935 | val_loss 1.36807 | val_rmse 1.16964\n",
      "| epoch 190 | lr 0.00010 train_loss 0.39682 | val_loss 1.36299 | val_rmse 1.16747\n",
      "| epoch 191 | lr 0.00010 train_loss 0.40337 | val_loss 1.36645 | val_rmse 1.16895\n",
      "| epoch 192 | lr 0.00010 train_loss 0.41927 | val_loss 1.35534 | val_rmse 1.16419\n",
      "| epoch 193 | lr 0.00010 train_loss 0.42254 | val_loss 1.36466 | val_rmse 1.16819\n",
      "| epoch 194 | lr 0.00010 train_loss 0.41958 | val_loss 1.38387 | val_rmse 1.17638\n",
      "| epoch 195 | lr 0.00010 train_loss 0.44921 | val_loss 1.36872 | val_rmse 1.16992\n",
      "| epoch 196 | lr 0.00010 train_loss 0.41100 | val_loss 1.37132 | val_rmse 1.17103\n",
      "| epoch 197 | lr 0.00010 train_loss 0.40881 | val_loss 1.35110 | val_rmse 1.16237\n",
      "| epoch 198 | lr 0.00010 train_loss 0.41410 | val_loss 1.35551 | val_rmse 1.16426\n",
      "| epoch 199 | lr 0.00010 train_loss 0.40992 | val_loss 1.36615 | val_rmse 1.16882\n",
      "| epoch 200 | lr 0.00010 train_loss 0.42185 | val_loss 1.36359 | val_rmse 1.16773\n",
      "| epoch 201 | lr 0.00010 train_loss 0.44513 | val_loss 1.35796 | val_rmse 1.16532\n",
      "| epoch 202 | lr 0.00010 train_loss 0.42258 | val_loss 1.35327 | val_rmse 1.16330\n",
      "| epoch 203 | lr 0.00010 train_loss 0.41410 | val_loss 1.32339 | val_rmse 1.15039\n",
      "| epoch 204 | lr 0.00010 train_loss 0.42541 | val_loss 1.34696 | val_rmse 1.16059\n",
      "| epoch 205 | lr 0.00010 train_loss 0.40367 | val_loss 1.35038 | val_rmse 1.16206\n",
      "| epoch 206 | lr 0.00010 train_loss 0.41551 | val_loss 1.36208 | val_rmse 1.16708\n",
      "| epoch 207 | lr 0.00010 train_loss 0.40211 | val_loss 1.35361 | val_rmse 1.16345\n",
      "| epoch 208 | lr 0.00010 train_loss 0.39755 | val_loss 1.33672 | val_rmse 1.15616\n",
      "| epoch 209 | lr 0.00010 train_loss 0.40847 | val_loss 1.35102 | val_rmse 1.16233\n",
      "| epoch 210 | lr 0.00010 train_loss 0.41383 | val_loss 1.37209 | val_rmse 1.17136\n",
      "| epoch 211 | lr 0.00010 train_loss 0.41953 | val_loss 1.34325 | val_rmse 1.15899\n",
      "| epoch 212 | lr 0.00010 train_loss 0.41855 | val_loss 1.39550 | val_rmse 1.18131\n",
      "| epoch 213 | lr 0.00010 train_loss 0.42130 | val_loss 1.34897 | val_rmse 1.16145\n",
      "| epoch 214 | lr 0.00010 train_loss 0.39293 | val_loss 1.36439 | val_rmse 1.16807\n",
      "| epoch 215 | lr 0.00010 train_loss 0.39734 | val_loss 1.36364 | val_rmse 1.16775\n",
      "| epoch 216 | lr 0.00010 train_loss 0.39914 | val_loss 1.35208 | val_rmse 1.16279\n",
      "| epoch 217 | lr 0.00010 train_loss 0.46338 | val_loss 1.32999 | val_rmse 1.15325\n",
      "| epoch 218 | lr 0.00010 train_loss 0.44110 | val_loss 1.32362 | val_rmse 1.15049\n",
      "| epoch 219 | lr 0.00010 train_loss 0.40972 | val_loss 1.35068 | val_rmse 1.16219\n",
      "| epoch 220 | lr 0.00010 train_loss 0.41264 | val_loss 1.34692 | val_rmse 1.16057\n",
      "| epoch 221 | lr 0.00010 train_loss 0.39652 | val_loss 1.38630 | val_rmse 1.17741\n",
      "| epoch 222 | lr 0.00010 train_loss 0.42123 | val_loss 1.38803 | val_rmse 1.17815\n",
      "| epoch 223 | lr 0.00010 train_loss 0.40336 | val_loss 1.38728 | val_rmse 1.17783\n",
      "| epoch 224 | lr 0.00010 train_loss 0.40858 | val_loss 1.37679 | val_rmse 1.17337\n",
      "| epoch 225 | lr 0.00010 train_loss 0.39712 | val_loss 1.37417 | val_rmse 1.17225\n",
      "| epoch 226 | lr 0.00010 train_loss 0.40888 | val_loss 1.37560 | val_rmse 1.17286\n",
      "| epoch 227 | lr 0.00010 train_loss 0.42201 | val_loss 1.32913 | val_rmse 1.15288\n",
      "| epoch 228 | lr 0.00010 train_loss 0.39938 | val_loss 1.34517 | val_rmse 1.15982\n",
      "| epoch 229 | lr 0.00010 train_loss 0.39699 | val_loss 1.30966 | val_rmse 1.14441\n",
      "| epoch 230 | lr 0.00010 train_loss 0.39015 | val_loss 1.33499 | val_rmse 1.15542\n",
      "| epoch 231 | lr 0.00010 train_loss 0.39754 | val_loss 1.33848 | val_rmse 1.15693\n",
      "| epoch 232 | lr 0.00010 train_loss 0.41760 | val_loss 1.36918 | val_rmse 1.17012\n",
      "| epoch 233 | lr 0.00010 train_loss 0.39065 | val_loss 1.37089 | val_rmse 1.17085\n",
      "| epoch 234 | lr 0.00010 train_loss 0.40939 | val_loss 1.35937 | val_rmse 1.16592\n",
      "| epoch 235 | lr 0.00010 train_loss 0.38822 | val_loss 1.37666 | val_rmse 1.17331\n",
      "| epoch 236 | lr 0.00010 train_loss 0.38148 | val_loss 1.39645 | val_rmse 1.18171\n",
      "| epoch 237 | lr 0.00010 train_loss 0.38101 | val_loss 1.38429 | val_rmse 1.17656\n",
      "| epoch 238 | lr 0.00010 train_loss 0.37910 | val_loss 1.40422 | val_rmse 1.18500\n",
      "| epoch 239 | lr 0.00010 train_loss 0.39721 | val_loss 1.37543 | val_rmse 1.17279\n",
      "| epoch 240 | lr 0.00010 train_loss 0.40123 | val_loss 1.37052 | val_rmse 1.17069\n",
      "| epoch 241 | lr 0.00010 train_loss 0.37139 | val_loss 1.39566 | val_rmse 1.18138\n",
      "| epoch 242 | lr 0.00010 train_loss 0.39743 | val_loss 1.43146 | val_rmse 1.19644\n",
      "| epoch 243 | lr 0.00010 train_loss 0.40363 | val_loss 1.37661 | val_rmse 1.17329\n",
      "| epoch 244 | lr 0.00010 train_loss 0.39719 | val_loss 1.36387 | val_rmse 1.16785\n",
      "| epoch 245 | lr 0.00010 train_loss 0.38614 | val_loss 1.42444 | val_rmse 1.19350\n",
      "| epoch 246 | lr 0.00010 train_loss 0.39661 | val_loss 1.41140 | val_rmse 1.18802\n",
      "| epoch 247 | lr 0.00010 train_loss 0.40103 | val_loss 1.43843 | val_rmse 1.19935\n",
      "| epoch 248 | lr 0.00010 train_loss 0.38060 | val_loss 1.40817 | val_rmse 1.18667\n",
      "| epoch 249 | lr 0.00010 train_loss 0.38556 | val_loss 1.40122 | val_rmse 1.18373\n",
      "| epoch 250 | lr 0.00010 train_loss 0.42161 | val_loss 1.41776 | val_rmse 1.19070\n",
      "| epoch 251 | lr 0.00010 train_loss 0.39061 | val_loss 1.43418 | val_rmse 1.19757\n",
      "| epoch 252 | lr 0.00010 train_loss 0.40908 | val_loss 1.41328 | val_rmse 1.18881\n",
      "| epoch 253 | lr 0.00010 train_loss 0.40914 | val_loss 1.40631 | val_rmse 1.18588\n",
      "| epoch 254 | lr 0.00010 train_loss 0.38933 | val_loss 1.39356 | val_rmse 1.18049\n",
      "| epoch 255 | lr 0.00010 train_loss 0.37546 | val_loss 1.34714 | val_rmse 1.16066\n",
      "| epoch 256 | lr 0.00010 train_loss 0.37761 | val_loss 1.43424 | val_rmse 1.19760\n",
      "| epoch 257 | lr 0.00010 train_loss 0.38988 | val_loss 1.42618 | val_rmse 1.19423\n",
      "| epoch 258 | lr 0.00010 train_loss 0.43928 | val_loss 1.44626 | val_rmse 1.20260\n",
      "| epoch 259 | lr 0.00010 train_loss 0.38172 | val_loss 1.39713 | val_rmse 1.18200\n",
      "| epoch 260 | lr 0.00010 train_loss 0.37883 | val_loss 1.39451 | val_rmse 1.18089\n",
      "| epoch 261 | lr 0.00010 train_loss 0.35741 | val_loss 1.38752 | val_rmse 1.17793\n",
      "| epoch 262 | lr 0.00010 train_loss 0.38541 | val_loss 1.39366 | val_rmse 1.18053\n",
      "| epoch 263 | lr 0.00010 train_loss 0.39226 | val_loss 1.37960 | val_rmse 1.17457\n",
      "| epoch 264 | lr 0.00010 train_loss 0.38802 | val_loss 1.39970 | val_rmse 1.18309\n",
      "| epoch 265 | lr 0.00010 train_loss 0.38443 | val_loss 1.38226 | val_rmse 1.17570\n",
      "| epoch 266 | lr 0.00010 train_loss 0.37446 | val_loss 1.39274 | val_rmse 1.18014\n",
      "| epoch 267 | lr 0.00010 train_loss 0.37300 | val_loss 1.37727 | val_rmse 1.17357\n",
      "| epoch 268 | lr 0.00010 train_loss 0.36673 | val_loss 1.38115 | val_rmse 1.17522\n",
      "| epoch 269 | lr 0.00010 train_loss 0.39280 | val_loss 1.35684 | val_rmse 1.16484\n",
      "| epoch 270 | lr 0.00010 train_loss 0.38387 | val_loss 1.34365 | val_rmse 1.15916\n",
      "| epoch 271 | lr 0.00010 train_loss 0.39817 | val_loss 1.35646 | val_rmse 1.16467\n",
      "| epoch 272 | lr 0.00010 train_loss 0.35882 | val_loss 1.40341 | val_rmse 1.18465\n",
      "| epoch 273 | lr 0.00010 train_loss 0.38709 | val_loss 1.40937 | val_rmse 1.18717\n",
      "| epoch 274 | lr 0.00010 train_loss 0.36725 | val_loss 1.37426 | val_rmse 1.17229\n",
      "| epoch 275 | lr 0.00010 train_loss 0.36169 | val_loss 1.38657 | val_rmse 1.17753\n",
      "| epoch 276 | lr 0.00010 train_loss 0.39099 | val_loss 1.37983 | val_rmse 1.17466\n",
      "| epoch 277 | lr 0.00010 train_loss 0.37849 | val_loss 1.40421 | val_rmse 1.18499\n",
      "| epoch 278 | lr 0.00010 train_loss 0.42036 | val_loss 1.44454 | val_rmse 1.20189\n",
      "| epoch 279 | lr 0.00010 train_loss 0.41307 | val_loss 1.48484 | val_rmse 1.21854\n",
      "| epoch 280 | lr 0.00010 train_loss 0.40619 | val_loss 1.35554 | val_rmse 1.16428\n",
      "| epoch 281 | lr 0.00010 train_loss 0.34572 | val_loss 1.35026 | val_rmse 1.16201\n",
      "| epoch 282 | lr 0.00010 train_loss 0.36857 | val_loss 1.34853 | val_rmse 1.16126\n",
      "| epoch 283 | lr 0.00010 train_loss 0.36879 | val_loss 1.36570 | val_rmse 1.16863\n",
      "| epoch 284 | lr 0.00010 train_loss 0.39341 | val_loss 1.36015 | val_rmse 1.16626\n",
      "| epoch 285 | lr 0.00010 train_loss 0.36169 | val_loss 1.38002 | val_rmse 1.17474\n",
      "| epoch 286 | lr 0.00010 train_loss 0.36922 | val_loss 1.35576 | val_rmse 1.16437\n",
      "| epoch 287 | lr 0.00010 train_loss 0.37133 | val_loss 1.36152 | val_rmse 1.16684\n",
      "| epoch 288 | lr 0.00010 train_loss 0.37835 | val_loss 1.37323 | val_rmse 1.17185\n",
      "| epoch 289 | lr 0.00010 train_loss 0.34951 | val_loss 1.35200 | val_rmse 1.16275\n",
      "| epoch 290 | lr 0.00010 train_loss 0.34732 | val_loss 1.36602 | val_rmse 1.16877\n",
      "| epoch 291 | lr 0.00010 train_loss 0.35291 | val_loss 1.36920 | val_rmse 1.17013\n",
      "| epoch 292 | lr 0.00010 train_loss 0.36485 | val_loss 1.37800 | val_rmse 1.17388\n",
      "| epoch 293 | lr 0.00010 train_loss 0.35968 | val_loss 1.34728 | val_rmse 1.16072\n",
      "| epoch 294 | lr 0.00010 train_loss 0.35879 | val_loss 1.34029 | val_rmse 1.15771\n",
      "| epoch 295 | lr 0.00010 train_loss 0.34622 | val_loss 1.35149 | val_rmse 1.16254\n",
      "| epoch 296 | lr 0.00010 train_loss 0.37414 | val_loss 1.34756 | val_rmse 1.16084\n",
      "| epoch 297 | lr 0.00010 train_loss 0.35908 | val_loss 1.37726 | val_rmse 1.17357\n",
      "| epoch 298 | lr 0.00010 train_loss 0.36174 | val_loss 1.37676 | val_rmse 1.17335\n",
      "| epoch 299 | lr 0.00010 train_loss 0.37329 | val_loss 1.38710 | val_rmse 1.17775\n",
      "| epoch 300 | lr 0.00010 train_loss 0.36729 | val_loss 1.35211 | val_rmse 1.16280\n",
      "| epoch 301 | lr 0.00010 train_loss 0.36894 | val_loss 1.40430 | val_rmse 1.18503\n",
      "| epoch 302 | lr 0.00010 train_loss 0.37813 | val_loss 1.38704 | val_rmse 1.17773\n",
      "| epoch 303 | lr 0.00010 train_loss 0.36653 | val_loss 1.35037 | val_rmse 1.16206\n",
      "| epoch 304 | lr 0.00010 train_loss 0.37087 | val_loss 1.33933 | val_rmse 1.15729\n",
      "| epoch 305 | lr 0.00010 train_loss 0.35682 | val_loss 1.36809 | val_rmse 1.16965\n",
      "| epoch 306 | lr 0.00010 train_loss 0.38179 | val_loss 1.37496 | val_rmse 1.17258\n",
      "| epoch 307 | lr 0.00010 train_loss 0.35729 | val_loss 1.39219 | val_rmse 1.17991\n",
      "| epoch 308 | lr 0.00010 train_loss 0.35043 | val_loss 1.38205 | val_rmse 1.17561\n",
      "| epoch 309 | lr 0.00010 train_loss 0.34968 | val_loss 1.37252 | val_rmse 1.17155\n",
      "| epoch 310 | lr 0.00010 train_loss 0.38490 | val_loss 1.43266 | val_rmse 1.19694\n",
      "| epoch 311 | lr 0.00010 train_loss 0.36781 | val_loss 1.41756 | val_rmse 1.19061\n",
      "| epoch 312 | lr 0.00010 train_loss 0.35742 | val_loss 1.36122 | val_rmse 1.16671\n",
      "| epoch 313 | lr 0.00010 train_loss 0.34487 | val_loss 1.34199 | val_rmse 1.15844\n",
      "| epoch 314 | lr 0.00010 train_loss 0.35667 | val_loss 1.34490 | val_rmse 1.15970\n",
      "| epoch 315 | lr 0.00010 train_loss 0.35177 | val_loss 1.36314 | val_rmse 1.16754\n",
      "| epoch 316 | lr 0.00010 train_loss 0.34417 | val_loss 1.36091 | val_rmse 1.16658\n",
      "| epoch 317 | lr 0.00010 train_loss 0.35831 | val_loss 1.39160 | val_rmse 1.17966\n",
      "| epoch 318 | lr 0.00010 train_loss 0.34657 | val_loss 1.39079 | val_rmse 1.17932\n",
      "| epoch 319 | lr 0.00010 train_loss 0.36829 | val_loss 1.37351 | val_rmse 1.17197\n",
      "| epoch 320 | lr 0.00010 train_loss 0.33829 | val_loss 1.39287 | val_rmse 1.18020\n",
      "| epoch 321 | lr 0.00010 train_loss 0.37226 | val_loss 1.40562 | val_rmse 1.18559\n",
      "| epoch 322 | lr 0.00010 train_loss 0.34804 | val_loss 1.36936 | val_rmse 1.17020\n",
      "| epoch 323 | lr 0.00010 train_loss 0.34169 | val_loss 1.38527 | val_rmse 1.17697\n",
      "| epoch 324 | lr 0.00010 train_loss 0.37800 | val_loss 1.43273 | val_rmse 1.19697\n",
      "| epoch 325 | lr 0.00010 train_loss 0.37422 | val_loss 1.44477 | val_rmse 1.20198\n",
      "| epoch 326 | lr 0.00010 train_loss 0.36378 | val_loss 1.45032 | val_rmse 1.20429\n",
      "| epoch 327 | lr 0.00010 train_loss 0.35746 | val_loss 1.45821 | val_rmse 1.20756\n",
      "| epoch 328 | lr 0.00010 train_loss 0.36047 | val_loss 1.40226 | val_rmse 1.18417\n"
     ]
    }
   ],
   "source": [
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "    min_val_loss = float(\"inf\")\n",
    "    log = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.\n",
    "        best_model = None\n",
    "        model.train()\n",
    "        for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            X_ori = X_ori.to(device)\n",
    "            X_mut = X_mut.to(device)\n",
    "            X_muthhb = X_muthhb.to(device)\n",
    "            X_orihhb = X_orihhb.to(device)\n",
    "            X_na = X_na.to(device)\n",
    "            y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "            y = y.to(device)\n",
    "            loss = loss_fn(y_preds.ravel(), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*len(X_ori)\n",
    "        total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_losses = 0.\n",
    "        with torch.no_grad():\n",
    "            for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "                X_ori = X_ori.to(device)\n",
    "                X_mut = X_mut.to(device)\n",
    "                X_muthhb = X_muthhb.to(device)\n",
    "                X_orihhb = X_orihhb.to(device)\n",
    "                X_na = X_na.to(device)\n",
    "                y = y.to(device)\n",
    "                preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "                val_loss = loss_fn(preds.ravel(), y)\n",
    "                val_losses += val_loss.item()*len(X_ori)\n",
    "        val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "        log.append([epoch,total_mse,val_mse])\n",
    "        print('| epoch {:3d} | lr {:02.5f} '\n",
    "                      'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "                      format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "        if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "            min_val_loss = val_loss\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), 'result/trans_best_all.pth')\n",
    "        scheduler.step()\n",
    "    f = open('result/trans_log.txt','w')\n",
    "    for i in log:\n",
    "        f.write(str(i)+'\\n')\n",
    "    f.close()\n",
    "TrainModel(Trans, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.028423179456882\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_mse = 0.\n",
    "test_result = []\n",
    "model = Trans\n",
    "model.load_state_dict(torch.load('result/trans_best_all.pth'))\n",
    "model.eval()\n",
    "for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "    X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "    X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "    X_na = X_na.to(device)\n",
    "    y = y.to(device)\n",
    "    preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "    loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "    test_result.append(y.tolist())\n",
    "    test_result.append(preds.tolist())\n",
    "    test_result.append(loss.tolist())\n",
    "    test_mse += loss.item()*len(X_ori)\n",
    "test_mse = test_mse/len(test_dataset)\n",
    "test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "file_name = 'result/trans_test_result.txt'\n",
    "f = open(file_name,'w')\n",
    "for i in test_result:\n",
    "    f.write(str(i)+'\\n')\n",
    "f.close()\n",
    "print(test_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cea085641e72410502974b25165e6310c4e74f3895213c724f4183725c7e9270"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
