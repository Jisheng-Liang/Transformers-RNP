{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from dataset import pro_encoder, na_encoder, hhblits_encoder\n",
    "from model import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 128\n",
    "root_dir = \"./\"\n",
    "data_csv = \"final_rna.csv\"\n",
    "hhblits_dir = \"new/\"\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random_split\n",
    "# df = pd.read_csv(data_csv)\n",
    "# df = df.sample(frac=1.0)\n",
    "# df.to_csv('random_rna.csv')\n",
    "# row = df.shape[0]\n",
    "# print(row)\n",
    "# idx_tr = round(row*0.8);idx_ts = round(row*0.1)\n",
    "# num_spl = [idx_tr,idx_tr+idx_ts,idx_tr+2*idx_ts]\n",
    "# df.iloc[0:num_spl[0],:].to_csv('train.csv',index=False)\n",
    "# df.iloc[num_spl[0]:num_spl[1],:].to_csv('val.csv',index=False)\n",
    "# df.iloc[num_spl[1]:num_spl[2],:].to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in ['train','val','test']:\n",
    "    filename = i+'.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    pro_ori = pro_encoder(df,'origin'); pro_ori = torch.tensor(pro_ori, dtype=torch.float)\n",
    "    pro_mut = pro_encoder(df,'mutant'); pro_mut = torch.tensor(pro_mut, dtype=torch.float)\n",
    "    na = na_encoder(df); na = torch.tensor(na, dtype=torch.float)\n",
    "    hhb_ori, hhb_mut = hhblits_encoder(hhblits_dir,df)\n",
    "    hhb_ori, hhb_mut = torch.tensor(hhb_ori, dtype=torch.float), torch.tensor(hhb_mut, dtype=torch.float)\n",
    "    y = df['ddG(kcal/mol)'].values.tolist(); y = torch.tensor(y, dtype=torch.float)\n",
    "    dataset.append(TensorDataset(pro_ori, pro_mut, hhb_ori, hhb_mut, na, y))\n",
    "\n",
    "train_dataset = dataset[0]; val_dataset = dataset[1]; test_dataset = dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 112 112\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),len(val_dataset), len(test_dataset))\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# MLPRegressor = MLPRegressor().to(device)\n",
    "\n",
    "# optimizer = Adam(MLPRegressor.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "# MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "#     min_val_loss = float(\"inf\")\n",
    "#     log = []\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         total_loss = 0.\n",
    "#         best_model = None\n",
    "#         model.train()\n",
    "#         for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             X_ori = X_ori.to(device)\n",
    "#             X_mut = X_mut.to(device)\n",
    "#             X_muthhb = X_muthhb.to(device)\n",
    "#             X_orihhb = X_orihhb.to(device)\n",
    "#             X_na = X_na.to(device)\n",
    "#             y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#             y = y.to(device)\n",
    "#             loss = loss_fn(y_preds.ravel(), y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()*len(X_ori)\n",
    "#         total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "#         # validate\n",
    "#         model.eval()\n",
    "#         val_losses = 0.\n",
    "#         with torch.no_grad():\n",
    "#             for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "#                 X_ori = X_ori.to(device)\n",
    "#                 X_mut = X_mut.to(device)\n",
    "#                 X_muthhb = X_muthhb.to(device)\n",
    "#                 X_orihhb = X_orihhb.to(device)\n",
    "#                 X_na = X_na.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#                 val_loss = loss_fn(preds.ravel(), y)\n",
    "#                 val_losses += val_loss.item()*len(X_ori)\n",
    "#         val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "#         log.append([epoch,total_mse,val_mse])\n",
    "#         print('| epoch {:3d} | lr {:02.5f} '\n",
    "#                       'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "#                       format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "#         if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "#             min_val_loss = val_loss\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), 'result/mlp_best_all.pth')\n",
    "#         scheduler.step()\n",
    "#     f = open('result/mlp_log.txt','w')\n",
    "#     for i in log:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#     f.close()\n",
    "# TrainModel(MLPRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# test_mse = 0.\n",
    "# test_result = []\n",
    "# model = MLPRegressor\n",
    "# model.load_state_dict(torch.load('./result/mlp_best_all.pth'))\n",
    "# MLPRegressor.eval()\n",
    "# for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "#     X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "#     X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "#     X_na = X_na.to(device)\n",
    "#     y = y.to(device)\n",
    "#     preds = MLPRegressor(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "#     loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "#     test_result.append(y.tolist())\n",
    "#     test_result.append(preds.tolist())\n",
    "#     test_result.append(loss.tolist())\n",
    "#     test_mse += loss.item()*len(X_ori)\n",
    "# test_mse = test_mse/len(test_dataset)\n",
    "# test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "# file_name = 'result/test'+'_mlp_'+'result.txt'\n",
    "# f = open(file_name,'w')\n",
    "# for i in test_result:\n",
    "#     f.write(str(i)+'\\n')\n",
    "# f.close()\n",
    "# print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNRegressor(\n",
       "  (hidden1): Conv1d(20, 256, kernel_size=(3,), stride=(1,))\n",
       "  (hidden2): Conv1d(20, 256, kernel_size=(3,), stride=(1,))\n",
       "  (hidden3): Conv1d(30, 256, kernel_size=(3,), stride=(1,))\n",
       "  (hidden4): Conv1d(30, 256, kernel_size=(3,), stride=(1,))\n",
       "  (hidden5): Conv1d(4, 256, kernel_size=(3,), stride=(1,))\n",
       "  (hidden11): Conv1d(256, 10, kernel_size=(3,), stride=(1,))\n",
       "  (hidden22): Conv1d(256, 10, kernel_size=(3,), stride=(1,))\n",
       "  (hidden33): Conv1d(256, 10, kernel_size=(3,), stride=(1,))\n",
       "  (hidden44): Conv1d(256, 10, kernel_size=(3,), stride=(1,))\n",
       "  (hidden55): Conv1d(256, 10, kernel_size=(3,), stride=(1,))\n",
       "  (act): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear1): Linear(in_features=40800, out_features=8192, bias=True)\n",
       "  (linear2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  (linear3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (linear4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (linear5): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "CNNRegressor = CNNRegressor().to(device)\n",
    "\n",
    "optimizer = Adam(CNNRegressor.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "CNNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1513],\n",
      "        [1.1440],\n",
      "        [1.1471],\n",
      "        [1.1665],\n",
      "        [1.1526],\n",
      "        [1.1304],\n",
      "        [1.1335],\n",
      "        [1.1209],\n",
      "        [1.1116],\n",
      "        [1.1394],\n",
      "        [1.1546],\n",
      "        [1.0946],\n",
      "        [1.1445],\n",
      "        [1.1381],\n",
      "        [1.1559],\n",
      "        [1.1473],\n",
      "        [1.1641],\n",
      "        [1.1567],\n",
      "        [1.1471],\n",
      "        [1.1385],\n",
      "        [1.1438],\n",
      "        [1.1165],\n",
      "        [1.1311],\n",
      "        [1.0743],\n",
      "        [1.1358],\n",
      "        [1.1192],\n",
      "        [1.0888],\n",
      "        [1.1004],\n",
      "        [1.1409],\n",
      "        [1.0788],\n",
      "        [1.1611],\n",
      "        [1.1557],\n",
      "        [1.1499],\n",
      "        [1.1638],\n",
      "        [1.1179],\n",
      "        [1.0953],\n",
      "        [1.1609],\n",
      "        [1.1080],\n",
      "        [1.1398],\n",
      "        [1.1617],\n",
      "        [1.1087],\n",
      "        [1.0848],\n",
      "        [1.1336],\n",
      "        [1.1040],\n",
      "        [1.1180],\n",
      "        [1.1508],\n",
      "        [1.1170],\n",
      "        [1.1120],\n",
      "        [1.1311],\n",
      "        [1.1598],\n",
      "        [1.1314],\n",
      "        [1.1531],\n",
      "        [1.0928],\n",
      "        [1.1247],\n",
      "        [0.4410],\n",
      "        [1.1423],\n",
      "        [1.1205],\n",
      "        [1.1052],\n",
      "        [1.1167],\n",
      "        [1.1529],\n",
      "        [1.1248],\n",
      "        [1.1418],\n",
      "        [1.1143],\n",
      "        [1.1608],\n",
      "        [1.0734],\n",
      "        [1.1612],\n",
      "        [1.1021],\n",
      "        [1.1222],\n",
      "        [1.1558],\n",
      "        [1.0993],\n",
      "        [1.1659],\n",
      "        [1.1199],\n",
      "        [1.1505],\n",
      "        [1.1161],\n",
      "        [1.1160],\n",
      "        [1.1312],\n",
      "        [1.1278],\n",
      "        [1.1175],\n",
      "        [1.1270],\n",
      "        [1.1391],\n",
      "        [1.1230],\n",
      "        [1.1236],\n",
      "        [1.1530],\n",
      "        [1.1503],\n",
      "        [1.1587],\n",
      "        [1.1490],\n",
      "        [1.1591],\n",
      "        [1.1481],\n",
      "        [1.1352],\n",
      "        [1.1278],\n",
      "        [1.1298],\n",
      "        [1.1388],\n",
      "        [1.1645],\n",
      "        [1.1417],\n",
      "        [1.1376],\n",
      "        [1.1617],\n",
      "        [1.0978],\n",
      "        [1.1087],\n",
      "        [1.1552],\n",
      "        [1.1609],\n",
      "        [1.1296],\n",
      "        [1.1643],\n",
      "        [1.1496],\n",
      "        [1.1309],\n",
      "        [1.1334],\n",
      "        [1.1624],\n",
      "        [1.1641],\n",
      "        [1.1348],\n",
      "        [1.1329],\n",
      "        [1.1344],\n",
      "        [1.1591],\n",
      "        [1.1602],\n",
      "        [1.1485],\n",
      "        [1.1454],\n",
      "        [1.1503],\n",
      "        [1.1549],\n",
      "        [1.1549],\n",
      "        [1.0551],\n",
      "        [1.1335],\n",
      "        [1.1385],\n",
      "        [1.0855],\n",
      "        [1.1300],\n",
      "        [1.1449],\n",
      "        [1.1182],\n",
      "        [1.1376],\n",
      "        [1.1561],\n",
      "        [1.1660],\n",
      "        [1.1192]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1385],\n",
      "        [1.1564],\n",
      "        [1.1537],\n",
      "        [1.0885],\n",
      "        [1.1352],\n",
      "        [1.1458],\n",
      "        [1.1176],\n",
      "        [1.1251],\n",
      "        [1.1307],\n",
      "        [1.1250],\n",
      "        [1.1397],\n",
      "        [1.1394],\n",
      "        [1.1209],\n",
      "        [1.1184],\n",
      "        [1.0860],\n",
      "        [1.1223],\n",
      "        [1.1347],\n",
      "        [1.1311],\n",
      "        [1.1426],\n",
      "        [1.1277],\n",
      "        [1.1426],\n",
      "        [1.1106],\n",
      "        [1.1063],\n",
      "        [1.1539],\n",
      "        [1.1430],\n",
      "        [1.1513],\n",
      "        [1.1422],\n",
      "        [1.1404],\n",
      "        [1.0702],\n",
      "        [1.0965],\n",
      "        [1.1429],\n",
      "        [1.1523],\n",
      "        [1.1335],\n",
      "        [1.1068],\n",
      "        [1.1036],\n",
      "        [1.1524],\n",
      "        [1.1293],\n",
      "        [1.1562],\n",
      "        [1.1334],\n",
      "        [1.1299],\n",
      "        [1.1149],\n",
      "        [1.1299],\n",
      "        [1.1258],\n",
      "        [1.1022],\n",
      "        [1.1474],\n",
      "        [1.1339],\n",
      "        [1.1479],\n",
      "        [1.1470],\n",
      "        [1.1289],\n",
      "        [1.0875],\n",
      "        [1.1235],\n",
      "        [1.1190],\n",
      "        [1.1176],\n",
      "        [1.1492],\n",
      "        [1.1185],\n",
      "        [1.1408],\n",
      "        [1.0838],\n",
      "        [1.1384],\n",
      "        [1.1247],\n",
      "        [1.1307],\n",
      "        [1.1453],\n",
      "        [1.1417],\n",
      "        [1.0814],\n",
      "        [1.1414],\n",
      "        [1.1331],\n",
      "        [1.1124],\n",
      "        [1.1168],\n",
      "        [1.1484],\n",
      "        [1.1528],\n",
      "        [1.1164],\n",
      "        [1.1448],\n",
      "        [1.1026],\n",
      "        [1.1342],\n",
      "        [1.0780],\n",
      "        [1.1378],\n",
      "        [1.1153],\n",
      "        [1.1291],\n",
      "        [1.1333],\n",
      "        [1.1184],\n",
      "        [1.1437],\n",
      "        [1.1070],\n",
      "        [1.1557],\n",
      "        [1.0817],\n",
      "        [1.1352],\n",
      "        [1.1419],\n",
      "        [1.1171],\n",
      "        [1.1210],\n",
      "        [1.1420],\n",
      "        [1.1122],\n",
      "        [1.1220],\n",
      "        [1.1283],\n",
      "        [1.1563],\n",
      "        [1.1061],\n",
      "        [1.1491],\n",
      "        [1.1170],\n",
      "        [1.0698],\n",
      "        [1.1107],\n",
      "        [1.1003],\n",
      "        [1.1402],\n",
      "        [1.0829],\n",
      "        [1.1458],\n",
      "        [1.0758],\n",
      "        [1.1143],\n",
      "        [1.1300],\n",
      "        [1.1078],\n",
      "        [1.0860],\n",
      "        [1.1378],\n",
      "        [1.1529],\n",
      "        [1.1532],\n",
      "        [1.1433],\n",
      "        [1.1492],\n",
      "        [1.1304],\n",
      "        [1.1420],\n",
      "        [1.1428],\n",
      "        [1.1145],\n",
      "        [1.1291],\n",
      "        [1.1104],\n",
      "        [1.1300],\n",
      "        [1.1291],\n",
      "        [1.1559],\n",
      "        [1.1351],\n",
      "        [1.1206],\n",
      "        [1.0718],\n",
      "        [1.1109],\n",
      "        [1.1522],\n",
      "        [1.1564],\n",
      "        [1.1528],\n",
      "        [1.1175]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1333],\n",
      "        [1.1379],\n",
      "        [1.1503],\n",
      "        [1.0909],\n",
      "        [1.1200],\n",
      "        [1.1264],\n",
      "        [1.1482],\n",
      "        [1.1225],\n",
      "        [1.1038],\n",
      "        [1.0843],\n",
      "        [1.1231],\n",
      "        [1.1401],\n",
      "        [1.1349],\n",
      "        [1.1328],\n",
      "        [1.1111],\n",
      "        [1.1500],\n",
      "        [1.1421],\n",
      "        [1.1369],\n",
      "        [1.0798],\n",
      "        [1.1210],\n",
      "        [1.1366],\n",
      "        [1.0861],\n",
      "        [1.1389],\n",
      "        [1.1252],\n",
      "        [1.1437],\n",
      "        [1.1132],\n",
      "        [1.1327],\n",
      "        [1.1405],\n",
      "        [1.1076],\n",
      "        [1.1261],\n",
      "        [1.1226],\n",
      "        [1.1028],\n",
      "        [1.1434],\n",
      "        [1.1177],\n",
      "        [1.1270],\n",
      "        [1.1504],\n",
      "        [1.1334],\n",
      "        [1.1275],\n",
      "        [1.1204],\n",
      "        [1.1347],\n",
      "        [1.1378],\n",
      "        [1.0912],\n",
      "        [1.1039],\n",
      "        [1.1126],\n",
      "        [1.1145],\n",
      "        [1.0901],\n",
      "        [1.1418],\n",
      "        [1.1217],\n",
      "        [1.1114],\n",
      "        [1.1269],\n",
      "        [1.1253],\n",
      "        [1.1213],\n",
      "        [1.1187],\n",
      "        [1.0925],\n",
      "        [1.1274],\n",
      "        [1.1253],\n",
      "        [1.0983],\n",
      "        [1.1140],\n",
      "        [1.0897],\n",
      "        [1.1281],\n",
      "        [1.1333],\n",
      "        [1.1501],\n",
      "        [1.1243],\n",
      "        [1.1338],\n",
      "        [1.1310],\n",
      "        [1.1269],\n",
      "        [1.1171],\n",
      "        [1.1436],\n",
      "        [1.1017],\n",
      "        [1.1013],\n",
      "        [1.1015],\n",
      "        [1.0987],\n",
      "        [1.0678],\n",
      "        [1.0939],\n",
      "        [1.1398],\n",
      "        [1.1338],\n",
      "        [1.1452],\n",
      "        [1.1157],\n",
      "        [1.0784],\n",
      "        [1.1283],\n",
      "        [1.1450],\n",
      "        [1.1261],\n",
      "        [1.1264],\n",
      "        [1.1176],\n",
      "        [1.0763],\n",
      "        [1.1330],\n",
      "        [1.1214],\n",
      "        [1.1391],\n",
      "        [1.1093],\n",
      "        [1.1045],\n",
      "        [1.1266],\n",
      "        [1.0440],\n",
      "        [1.1464],\n",
      "        [1.1041],\n",
      "        [1.1332],\n",
      "        [1.1046],\n",
      "        [1.1279],\n",
      "        [1.0948],\n",
      "        [1.0668],\n",
      "        [1.1287],\n",
      "        [1.1235],\n",
      "        [1.1121],\n",
      "        [1.1453],\n",
      "        [1.1300],\n",
      "        [1.0865],\n",
      "        [1.0877],\n",
      "        [1.1277],\n",
      "        [1.0953],\n",
      "        [1.1239],\n",
      "        [1.1357],\n",
      "        [1.1006],\n",
      "        [1.1389],\n",
      "        [1.1209],\n",
      "        [1.1273],\n",
      "        [1.1211],\n",
      "        [1.1159],\n",
      "        [1.0952],\n",
      "        [1.1392],\n",
      "        [1.1478],\n",
      "        [1.1127],\n",
      "        [1.1460],\n",
      "        [1.1442],\n",
      "        [1.1248],\n",
      "        [1.1241],\n",
      "        [1.1192],\n",
      "        [1.1280],\n",
      "        [1.1136],\n",
      "        [1.1030]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1371],\n",
      "        [1.1093],\n",
      "        [1.0887],\n",
      "        [1.1234],\n",
      "        [1.0972],\n",
      "        [1.1287],\n",
      "        [1.0929],\n",
      "        [1.1019],\n",
      "        [1.1518],\n",
      "        [1.0951],\n",
      "        [1.1527],\n",
      "        [1.0688],\n",
      "        [1.1450],\n",
      "        [1.0919],\n",
      "        [1.1105],\n",
      "        [1.1037],\n",
      "        [1.1268],\n",
      "        [1.1406],\n",
      "        [1.1424],\n",
      "        [1.1098],\n",
      "        [1.1160],\n",
      "        [1.1147],\n",
      "        [1.1098],\n",
      "        [1.1034],\n",
      "        [1.1452],\n",
      "        [1.1336],\n",
      "        [1.1351],\n",
      "        [1.1385],\n",
      "        [1.1396],\n",
      "        [1.1413],\n",
      "        [1.1240],\n",
      "        [1.1184],\n",
      "        [1.1027],\n",
      "        [1.1533],\n",
      "        [1.1480],\n",
      "        [1.1146],\n",
      "        [1.1316],\n",
      "        [1.1140],\n",
      "        [1.1215],\n",
      "        [1.1505],\n",
      "        [1.1390],\n",
      "        [1.1179],\n",
      "        [1.1386],\n",
      "        [1.1007],\n",
      "        [1.1275],\n",
      "        [1.0982],\n",
      "        [1.1269],\n",
      "        [1.0845],\n",
      "        [1.1512],\n",
      "        [1.0860],\n",
      "        [1.1427],\n",
      "        [1.1217],\n",
      "        [1.1314],\n",
      "        [1.1427],\n",
      "        [1.1174],\n",
      "        [1.1347],\n",
      "        [1.1394],\n",
      "        [1.1041],\n",
      "        [1.1164],\n",
      "        [1.1272],\n",
      "        [1.1028],\n",
      "        [1.1043],\n",
      "        [1.0910],\n",
      "        [1.0545],\n",
      "        [1.0669],\n",
      "        [1.1093],\n",
      "        [1.1258],\n",
      "        [1.1077],\n",
      "        [1.0707],\n",
      "        [1.1464],\n",
      "        [1.0918],\n",
      "        [1.1155],\n",
      "        [1.1458],\n",
      "        [1.1411],\n",
      "        [1.1409],\n",
      "        [1.1416],\n",
      "        [1.1186],\n",
      "        [1.1084],\n",
      "        [1.1504],\n",
      "        [1.0828],\n",
      "        [1.1320],\n",
      "        [1.1156],\n",
      "        [0.3621],\n",
      "        [1.1491],\n",
      "        [1.1215],\n",
      "        [1.1411],\n",
      "        [1.1290],\n",
      "        [1.1419],\n",
      "        [1.1440],\n",
      "        [1.0967],\n",
      "        [1.1184],\n",
      "        [1.0961],\n",
      "        [1.1097],\n",
      "        [1.1509],\n",
      "        [1.1359],\n",
      "        [1.1190],\n",
      "        [0.3422],\n",
      "        [1.1199],\n",
      "        [1.1256],\n",
      "        [1.1381],\n",
      "        [1.1493],\n",
      "        [1.0815],\n",
      "        [1.1260],\n",
      "        [1.0779],\n",
      "        [1.0981],\n",
      "        [1.1372],\n",
      "        [1.0991],\n",
      "        [1.0917],\n",
      "        [1.1245],\n",
      "        [1.1085],\n",
      "        [1.1363],\n",
      "        [1.1458],\n",
      "        [1.1359],\n",
      "        [1.0912],\n",
      "        [1.1002],\n",
      "        [1.1196],\n",
      "        [1.1399],\n",
      "        [1.1294],\n",
      "        [1.0727],\n",
      "        [1.1530],\n",
      "        [1.1424],\n",
      "        [1.1515],\n",
      "        [1.1429],\n",
      "        [1.1420],\n",
      "        [1.1150],\n",
      "        [1.1030],\n",
      "        [1.1137],\n",
      "        [1.1183]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1398],\n",
      "        [1.0798],\n",
      "        [1.1560],\n",
      "        [1.1211],\n",
      "        [1.1573],\n",
      "        [1.0607],\n",
      "        [1.1535],\n",
      "        [1.1180],\n",
      "        [1.1552],\n",
      "        [1.1445],\n",
      "        [1.1133],\n",
      "        [1.1434],\n",
      "        [1.0934],\n",
      "        [1.0686],\n",
      "        [1.0931],\n",
      "        [1.1481],\n",
      "        [1.1289],\n",
      "        [1.1005],\n",
      "        [1.1360],\n",
      "        [1.1257],\n",
      "        [1.1406],\n",
      "        [1.1342],\n",
      "        [1.1581],\n",
      "        [1.0933],\n",
      "        [1.1406],\n",
      "        [1.1258],\n",
      "        [1.1400],\n",
      "        [1.0949],\n",
      "        [1.0827],\n",
      "        [1.1403],\n",
      "        [1.1014],\n",
      "        [1.1373],\n",
      "        [1.0990],\n",
      "        [1.1335],\n",
      "        [1.0739],\n",
      "        [1.1322],\n",
      "        [1.1271],\n",
      "        [1.1067],\n",
      "        [1.1467],\n",
      "        [1.1396],\n",
      "        [1.1115],\n",
      "        [1.1469],\n",
      "        [1.1135],\n",
      "        [1.1441],\n",
      "        [1.1157],\n",
      "        [1.1042],\n",
      "        [1.1230],\n",
      "        [1.1293],\n",
      "        [1.1357],\n",
      "        [1.1539],\n",
      "        [1.1199],\n",
      "        [1.1366],\n",
      "        [1.0846],\n",
      "        [1.1505],\n",
      "        [1.1525],\n",
      "        [1.1432],\n",
      "        [1.1488],\n",
      "        [1.1433],\n",
      "        [1.1426],\n",
      "        [1.0785],\n",
      "        [1.1437],\n",
      "        [1.1142],\n",
      "        [1.1147],\n",
      "        [1.1362],\n",
      "        [1.1285],\n",
      "        [1.1355],\n",
      "        [1.1022],\n",
      "        [1.1515],\n",
      "        [1.1366],\n",
      "        [1.1491],\n",
      "        [1.1024],\n",
      "        [1.1551],\n",
      "        [1.1527],\n",
      "        [1.0991],\n",
      "        [1.1466],\n",
      "        [1.1068],\n",
      "        [1.1454],\n",
      "        [1.1327],\n",
      "        [1.1118],\n",
      "        [1.1491],\n",
      "        [1.1007],\n",
      "        [1.1242],\n",
      "        [1.1160],\n",
      "        [1.1189],\n",
      "        [1.1422],\n",
      "        [1.1191],\n",
      "        [1.0801],\n",
      "        [1.0917],\n",
      "        [1.1275],\n",
      "        [1.1430],\n",
      "        [1.1220],\n",
      "        [1.1480],\n",
      "        [1.1072],\n",
      "        [1.1207],\n",
      "        [1.1174],\n",
      "        [1.1161],\n",
      "        [1.1557],\n",
      "        [1.1506],\n",
      "        [1.1093],\n",
      "        [1.1564],\n",
      "        [1.1080],\n",
      "        [1.1391],\n",
      "        [1.1058],\n",
      "        [1.1208],\n",
      "        [1.1234],\n",
      "        [1.1432],\n",
      "        [1.1474],\n",
      "        [1.1137],\n",
      "        [1.1335],\n",
      "        [1.0935],\n",
      "        [1.1374],\n",
      "        [1.1266],\n",
      "        [1.1292],\n",
      "        [1.1114],\n",
      "        [1.1557],\n",
      "        [1.1575],\n",
      "        [1.1392],\n",
      "        [1.1569],\n",
      "        [1.1335],\n",
      "        [1.0970],\n",
      "        [1.0832],\n",
      "        [1.1445],\n",
      "        [1.0874],\n",
      "        [1.1363],\n",
      "        [1.0705],\n",
      "        [1.0968],\n",
      "        [1.1324],\n",
      "        [1.1249]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1361],\n",
      "        [1.0738],\n",
      "        [1.1329],\n",
      "        [1.1563],\n",
      "        [1.1088],\n",
      "        [1.1264],\n",
      "        [1.1112],\n",
      "        [1.0691],\n",
      "        [1.1386],\n",
      "        [1.1601],\n",
      "        [1.1586],\n",
      "        [1.1112],\n",
      "        [1.1473],\n",
      "        [1.1046],\n",
      "        [1.1368],\n",
      "        [1.1587],\n",
      "        [1.1364],\n",
      "        [1.1536],\n",
      "        [1.1369],\n",
      "        [1.1535],\n",
      "        [1.1262],\n",
      "        [1.1461],\n",
      "        [1.1188],\n",
      "        [1.1451],\n",
      "        [1.1113],\n",
      "        [1.1586],\n",
      "        [1.1227],\n",
      "        [1.1594],\n",
      "        [1.0945],\n",
      "        [1.1464],\n",
      "        [1.1245],\n",
      "        [1.1160],\n",
      "        [1.0989],\n",
      "        [1.1479],\n",
      "        [1.1420],\n",
      "        [1.1555],\n",
      "        [1.1008],\n",
      "        [1.0960],\n",
      "        [1.1080],\n",
      "        [1.1192],\n",
      "        [1.1510],\n",
      "        [1.1301],\n",
      "        [1.1437],\n",
      "        [1.0933],\n",
      "        [1.1087],\n",
      "        [1.1400],\n",
      "        [1.1518],\n",
      "        [1.1144],\n",
      "        [1.0929],\n",
      "        [1.1581],\n",
      "        [1.1240],\n",
      "        [1.1091],\n",
      "        [1.1317],\n",
      "        [1.1165],\n",
      "        [1.1322],\n",
      "        [1.0752],\n",
      "        [1.1467],\n",
      "        [1.1035],\n",
      "        [1.1363],\n",
      "        [1.0757],\n",
      "        [1.1519],\n",
      "        [1.1221],\n",
      "        [1.1076],\n",
      "        [1.1254],\n",
      "        [1.1549],\n",
      "        [1.1303],\n",
      "        [1.0757],\n",
      "        [1.1201],\n",
      "        [1.1375],\n",
      "        [1.1301],\n",
      "        [1.0660],\n",
      "        [1.1230],\n",
      "        [1.1349],\n",
      "        [1.1259],\n",
      "        [1.1436],\n",
      "        [1.1306],\n",
      "        [1.1416],\n",
      "        [1.1344],\n",
      "        [1.1127],\n",
      "        [1.1385],\n",
      "        [1.1158],\n",
      "        [1.0966],\n",
      "        [1.1326],\n",
      "        [1.1588],\n",
      "        [1.1440],\n",
      "        [1.1374],\n",
      "        [1.1231],\n",
      "        [1.1468],\n",
      "        [1.1221],\n",
      "        [1.1237],\n",
      "        [1.0727],\n",
      "        [1.1392],\n",
      "        [1.1150],\n",
      "        [1.1329],\n",
      "        [1.1338],\n",
      "        [1.0931],\n",
      "        [1.1325],\n",
      "        [1.1254],\n",
      "        [1.1074],\n",
      "        [1.1020],\n",
      "        [1.1260],\n",
      "        [1.1531],\n",
      "        [1.1451],\n",
      "        [1.1509],\n",
      "        [1.1200],\n",
      "        [1.1456],\n",
      "        [1.1468],\n",
      "        [1.1292],\n",
      "        [1.1475],\n",
      "        [1.1324],\n",
      "        [1.1503],\n",
      "        [1.1551],\n",
      "        [1.1317],\n",
      "        [1.1345],\n",
      "        [1.1343],\n",
      "        [1.1101],\n",
      "        [1.1492],\n",
      "        [1.1567],\n",
      "        [1.0845],\n",
      "        [1.1430],\n",
      "        [1.1200],\n",
      "        [1.1207],\n",
      "        [1.0803],\n",
      "        [1.1408],\n",
      "        [1.1460],\n",
      "        [1.1323],\n",
      "        [1.1479],\n",
      "        [1.1603]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1347],\n",
      "        [1.1292],\n",
      "        [1.1256],\n",
      "        [1.1272],\n",
      "        [1.1112],\n",
      "        [1.1467],\n",
      "        [1.1018],\n",
      "        [1.1391],\n",
      "        [1.1096],\n",
      "        [1.1240],\n",
      "        [1.1428],\n",
      "        [1.1186],\n",
      "        [1.1114],\n",
      "        [1.1281],\n",
      "        [1.1081],\n",
      "        [1.1206],\n",
      "        [1.1407],\n",
      "        [1.0916],\n",
      "        [1.0925],\n",
      "        [1.0906],\n",
      "        [1.1526],\n",
      "        [1.1019],\n",
      "        [1.1220],\n",
      "        [1.1154],\n",
      "        [1.1372],\n",
      "        [1.1194],\n",
      "        [1.1003],\n",
      "        [1.1321],\n",
      "        [1.1475],\n",
      "        [1.1531],\n",
      "        [1.1316],\n",
      "        [1.1532],\n",
      "        [1.1255],\n",
      "        [1.1356],\n",
      "        [1.1407],\n",
      "        [1.1437],\n",
      "        [1.0888],\n",
      "        [1.1372],\n",
      "        [1.1458],\n",
      "        [1.1243],\n",
      "        [1.1216],\n",
      "        [1.1449],\n",
      "        [1.1301],\n",
      "        [1.1246],\n",
      "        [1.0759],\n",
      "        [1.1435],\n",
      "        [1.1417],\n",
      "        [1.1444],\n",
      "        [1.1456],\n",
      "        [1.1229],\n",
      "        [1.1414],\n",
      "        [1.1063],\n",
      "        [1.1181],\n",
      "        [1.1459],\n",
      "        [1.1307],\n",
      "        [1.1328],\n",
      "        [1.1143],\n",
      "        [1.1172],\n",
      "        [1.1411],\n",
      "        [1.1233],\n",
      "        [1.1559],\n",
      "        [1.1473],\n",
      "        [1.0694],\n",
      "        [1.1341],\n",
      "        [1.1223],\n",
      "        [1.1292],\n",
      "        [1.1564],\n",
      "        [1.1480],\n",
      "        [1.1215],\n",
      "        [1.1351],\n",
      "        [1.1147],\n",
      "        [1.0889],\n",
      "        [1.1241],\n",
      "        [1.1220],\n",
      "        [1.1441],\n",
      "        [1.1370],\n",
      "        [1.1261],\n",
      "        [1.1371],\n",
      "        [1.1560],\n",
      "        [1.1412],\n",
      "        [1.1180],\n",
      "        [1.1506],\n",
      "        [1.1407],\n",
      "        [1.1163],\n",
      "        [1.0806],\n",
      "        [1.1527],\n",
      "        [1.1272],\n",
      "        [1.1514],\n",
      "        [1.0943],\n",
      "        [1.1563],\n",
      "        [1.1191],\n",
      "        [1.1210],\n",
      "        [1.1418],\n",
      "        [1.1426],\n",
      "        [1.1343],\n",
      "        [1.0945],\n",
      "        [1.1522],\n",
      "        [1.1333],\n",
      "        [1.1522],\n",
      "        [1.1383],\n",
      "        [1.1481],\n",
      "        [1.1273],\n",
      "        [1.1081],\n",
      "        [1.1242],\n",
      "        [1.1299],\n",
      "        [1.1005],\n",
      "        [1.1380],\n",
      "        [1.1037],\n",
      "        [1.1390],\n",
      "        [1.1166],\n",
      "        [1.1463],\n",
      "        [1.1532],\n",
      "        [1.1328],\n",
      "        [1.1176],\n",
      "        [1.1449],\n",
      "        [1.1221],\n",
      "        [1.1229],\n",
      "        [1.1415],\n",
      "        [1.0892],\n",
      "        [1.1087],\n",
      "        [1.1249],\n",
      "        [1.1030],\n",
      "        [1.0888],\n",
      "        [1.1312],\n",
      "        [1.1186],\n",
      "        [1.1239],\n",
      "        [1.1432],\n",
      "        [1.1208]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1341],\n",
      "        [1.1332],\n",
      "        [1.1098],\n",
      "        [1.0920]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   1 | lr 0.00100 train_loss 2.12701 | val_loss 2.28881 | val_rmse 1.51288\n",
      "tensor([[1.1217],\n",
      "        [1.1058],\n",
      "        [1.0976],\n",
      "        [1.1332],\n",
      "        [1.1281],\n",
      "        [1.1010],\n",
      "        [1.1171],\n",
      "        [1.1131],\n",
      "        [1.0915],\n",
      "        [1.1160],\n",
      "        [1.1090],\n",
      "        [1.1219],\n",
      "        [1.1121],\n",
      "        [1.0713],\n",
      "        [1.1262],\n",
      "        [1.0947],\n",
      "        [1.1046],\n",
      "        [1.1312],\n",
      "        [1.1144],\n",
      "        [1.1208],\n",
      "        [1.1152],\n",
      "        [1.0958],\n",
      "        [1.1038],\n",
      "        [1.1302],\n",
      "        [1.1139],\n",
      "        [1.0975],\n",
      "        [1.0857],\n",
      "        [1.1253],\n",
      "        [1.0839],\n",
      "        [1.0923],\n",
      "        [1.1077],\n",
      "        [1.1186],\n",
      "        [1.1157],\n",
      "        [1.0909],\n",
      "        [1.1329],\n",
      "        [1.0376],\n",
      "        [1.0789],\n",
      "        [1.1153],\n",
      "        [1.1085],\n",
      "        [1.1117],\n",
      "        [1.0873],\n",
      "        [1.1239],\n",
      "        [1.1150],\n",
      "        [1.0605],\n",
      "        [1.0985],\n",
      "        [1.1310],\n",
      "        [1.0725],\n",
      "        [1.0644],\n",
      "        [1.1179],\n",
      "        [1.1175],\n",
      "        [1.1262],\n",
      "        [1.0897],\n",
      "        [1.1311],\n",
      "        [1.0886],\n",
      "        [1.1105],\n",
      "        [1.0861],\n",
      "        [0.5985],\n",
      "        [1.1254],\n",
      "        [1.1154],\n",
      "        [1.1292],\n",
      "        [1.1130],\n",
      "        [1.1201],\n",
      "        [1.0625],\n",
      "        [1.1270],\n",
      "        [1.1239],\n",
      "        [1.1270],\n",
      "        [1.1101],\n",
      "        [1.1027],\n",
      "        [1.1188],\n",
      "        [1.0967],\n",
      "        [1.1263],\n",
      "        [1.1059],\n",
      "        [1.1030],\n",
      "        [1.0949],\n",
      "        [1.1287],\n",
      "        [1.1305],\n",
      "        [1.0973],\n",
      "        [1.1340],\n",
      "        [1.1228],\n",
      "        [1.0368],\n",
      "        [1.1282],\n",
      "        [1.1304],\n",
      "        [1.1315],\n",
      "        [1.1134],\n",
      "        [1.0784],\n",
      "        [1.1028],\n",
      "        [1.1199],\n",
      "        [1.1226],\n",
      "        [1.1239],\n",
      "        [1.1126],\n",
      "        [1.0380],\n",
      "        [1.1160],\n",
      "        [1.0730],\n",
      "        [1.1118],\n",
      "        [1.1332],\n",
      "        [1.1298],\n",
      "        [1.0978],\n",
      "        [1.0973],\n",
      "        [1.1045],\n",
      "        [1.0675],\n",
      "        [1.1225],\n",
      "        [1.1231],\n",
      "        [1.0565],\n",
      "        [1.1058],\n",
      "        [1.1228],\n",
      "        [1.1077],\n",
      "        [1.1209],\n",
      "        [1.0694],\n",
      "        [1.0554],\n",
      "        [1.0964],\n",
      "        [1.1105],\n",
      "        [1.0856],\n",
      "        [1.1256],\n",
      "        [1.1011],\n",
      "        [1.0888],\n",
      "        [1.1099],\n",
      "        [1.1169],\n",
      "        [1.1246],\n",
      "        [1.1105],\n",
      "        [1.1162],\n",
      "        [1.0472],\n",
      "        [1.1285],\n",
      "        [1.1299],\n",
      "        [1.1334],\n",
      "        [1.0945],\n",
      "        [1.1111],\n",
      "        [1.1295],\n",
      "        [1.0996]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1014],\n",
      "        [1.0928],\n",
      "        [1.0692],\n",
      "        [1.0882],\n",
      "        [1.0906],\n",
      "        [1.1079],\n",
      "        [1.0969],\n",
      "        [1.0986],\n",
      "        [1.1151],\n",
      "        [1.0569],\n",
      "        [1.0524],\n",
      "        [1.0878],\n",
      "        [1.1135],\n",
      "        [1.0791],\n",
      "        [1.0887],\n",
      "        [1.0716],\n",
      "        [1.0858],\n",
      "        [1.0918],\n",
      "        [1.0998],\n",
      "        [1.0851],\n",
      "        [1.1044],\n",
      "        [1.0954],\n",
      "        [1.0866],\n",
      "        [1.0758],\n",
      "        [1.1098],\n",
      "        [1.0611],\n",
      "        [1.1047],\n",
      "        [1.0862],\n",
      "        [1.0939],\n",
      "        [1.0916],\n",
      "        [1.0698],\n",
      "        [1.0979],\n",
      "        [1.0826],\n",
      "        [1.1027],\n",
      "        [1.0867],\n",
      "        [1.0908],\n",
      "        [1.1000],\n",
      "        [1.0526],\n",
      "        [1.1111],\n",
      "        [1.1111],\n",
      "        [1.1006],\n",
      "        [1.0576],\n",
      "        [1.0998],\n",
      "        [1.0979],\n",
      "        [1.0607],\n",
      "        [1.1011],\n",
      "        [1.1077],\n",
      "        [1.0809],\n",
      "        [1.0521],\n",
      "        [0.6714],\n",
      "        [1.1038],\n",
      "        [0.9833],\n",
      "        [1.1164],\n",
      "        [1.1083],\n",
      "        [1.0062],\n",
      "        [1.0815],\n",
      "        [1.0539],\n",
      "        [1.1029],\n",
      "        [1.1151],\n",
      "        [1.0870],\n",
      "        [1.1149],\n",
      "        [1.1094],\n",
      "        [1.0819],\n",
      "        [1.1083],\n",
      "        [1.1138],\n",
      "        [1.1091],\n",
      "        [1.0946],\n",
      "        [1.1107],\n",
      "        [1.0554],\n",
      "        [1.1128],\n",
      "        [1.0901],\n",
      "        [1.0854],\n",
      "        [1.0919],\n",
      "        [1.1040],\n",
      "        [1.0502],\n",
      "        [1.0544],\n",
      "        [1.1009],\n",
      "        [1.0822],\n",
      "        [1.0843],\n",
      "        [1.0671],\n",
      "        [1.0709],\n",
      "        [1.1078],\n",
      "        [1.0870],\n",
      "        [1.0883],\n",
      "        [1.0712],\n",
      "        [1.1079],\n",
      "        [1.0873],\n",
      "        [1.1111],\n",
      "        [1.0490],\n",
      "        [1.0523],\n",
      "        [1.0560],\n",
      "        [1.1094],\n",
      "        [1.0963],\n",
      "        [1.0973],\n",
      "        [1.1042],\n",
      "        [1.0727],\n",
      "        [1.0650],\n",
      "        [1.1049],\n",
      "        [1.0806],\n",
      "        [1.0853],\n",
      "        [1.0991],\n",
      "        [1.1060],\n",
      "        [1.0524],\n",
      "        [1.0851],\n",
      "        [1.1054],\n",
      "        [1.1026],\n",
      "        [1.0989],\n",
      "        [1.0896],\n",
      "        [1.0603],\n",
      "        [1.0758],\n",
      "        [1.0640],\n",
      "        [1.1076],\n",
      "        [1.0895],\n",
      "        [1.0629],\n",
      "        [1.0948],\n",
      "        [1.0636],\n",
      "        [1.1032],\n",
      "        [1.1142],\n",
      "        [1.1124],\n",
      "        [1.0823],\n",
      "        [1.0787],\n",
      "        [1.1016],\n",
      "        [1.0898],\n",
      "        [1.0867],\n",
      "        [1.1144],\n",
      "        [1.0964],\n",
      "        [1.0505],\n",
      "        [1.0657]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0845],\n",
      "        [1.0877],\n",
      "        [1.0761],\n",
      "        [1.0620],\n",
      "        [1.0711],\n",
      "        [1.0595],\n",
      "        [1.0898],\n",
      "        [1.0979],\n",
      "        [1.0684],\n",
      "        [1.0459],\n",
      "        [1.0544],\n",
      "        [1.0823],\n",
      "        [1.0603],\n",
      "        [1.0608],\n",
      "        [1.0846],\n",
      "        [1.0477],\n",
      "        [1.0978],\n",
      "        [1.0710],\n",
      "        [1.0599],\n",
      "        [1.0984],\n",
      "        [1.0440],\n",
      "        [1.0326],\n",
      "        [1.0427],\n",
      "        [1.0788],\n",
      "        [1.0704],\n",
      "        [1.0810],\n",
      "        [1.0934],\n",
      "        [1.0369],\n",
      "        [1.0380],\n",
      "        [1.0681],\n",
      "        [1.0848],\n",
      "        [1.0833],\n",
      "        [1.0992],\n",
      "        [1.0554],\n",
      "        [1.0478],\n",
      "        [1.0877],\n",
      "        [1.0719],\n",
      "        [1.0971],\n",
      "        [1.0523],\n",
      "        [1.0745],\n",
      "        [1.0711],\n",
      "        [1.0917],\n",
      "        [1.0816],\n",
      "        [1.0523],\n",
      "        [1.0957],\n",
      "        [1.0850],\n",
      "        [1.0862],\n",
      "        [1.0848],\n",
      "        [1.0766],\n",
      "        [1.0153],\n",
      "        [1.0693],\n",
      "        [1.0696],\n",
      "        [1.0708],\n",
      "        [1.0971],\n",
      "        [1.0831],\n",
      "        [1.0763],\n",
      "        [1.0949],\n",
      "        [1.0784],\n",
      "        [1.0992],\n",
      "        [0.4842],\n",
      "        [1.0901],\n",
      "        [1.0823],\n",
      "        [1.0722],\n",
      "        [1.0917],\n",
      "        [1.0466],\n",
      "        [1.0684],\n",
      "        [1.0622],\n",
      "        [1.0941],\n",
      "        [1.0589],\n",
      "        [1.0809],\n",
      "        [1.0722],\n",
      "        [1.0523],\n",
      "        [1.0927],\n",
      "        [1.0826],\n",
      "        [1.0356],\n",
      "        [1.0335],\n",
      "        [1.0510],\n",
      "        [1.0859],\n",
      "        [1.0901],\n",
      "        [1.0787],\n",
      "        [1.0441],\n",
      "        [1.0820],\n",
      "        [1.0711],\n",
      "        [1.0832],\n",
      "        [1.0626],\n",
      "        [1.0304],\n",
      "        [1.0427],\n",
      "        [1.0865],\n",
      "        [1.0899],\n",
      "        [1.0834],\n",
      "        [1.0780],\n",
      "        [1.0257],\n",
      "        [1.0436],\n",
      "        [1.0817],\n",
      "        [1.0378],\n",
      "        [1.0445],\n",
      "        [1.0438],\n",
      "        [1.0623],\n",
      "        [1.0759],\n",
      "        [1.0922],\n",
      "        [1.0748],\n",
      "        [1.0572],\n",
      "        [1.0882],\n",
      "        [1.0337],\n",
      "        [1.0991],\n",
      "        [1.0785],\n",
      "        [1.0896],\n",
      "        [1.0721],\n",
      "        [1.0933],\n",
      "        [1.0883],\n",
      "        [1.0995],\n",
      "        [1.0962],\n",
      "        [1.0852],\n",
      "        [1.0373],\n",
      "        [1.0878],\n",
      "        [1.0963],\n",
      "        [1.0608],\n",
      "        [1.0664],\n",
      "        [1.0628],\n",
      "        [1.0956],\n",
      "        [1.0931],\n",
      "        [1.0932],\n",
      "        [1.0290],\n",
      "        [1.0667],\n",
      "        [1.0164],\n",
      "        [1.0727],\n",
      "        [1.0812],\n",
      "        [1.0619]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0620],\n",
      "        [1.0538],\n",
      "        [1.0475],\n",
      "        [1.0711],\n",
      "        [1.0744],\n",
      "        [1.0486],\n",
      "        [1.0343],\n",
      "        [1.0737],\n",
      "        [1.0591],\n",
      "        [1.0405],\n",
      "        [1.0498],\n",
      "        [1.0421],\n",
      "        [1.0172],\n",
      "        [1.0679],\n",
      "        [1.0446],\n",
      "        [1.0536],\n",
      "        [1.0263],\n",
      "        [1.0692],\n",
      "        [1.0565],\n",
      "        [1.0118],\n",
      "        [1.0571],\n",
      "        [1.0847],\n",
      "        [1.0750],\n",
      "        [1.0541],\n",
      "        [1.0723],\n",
      "        [1.0505],\n",
      "        [1.0481],\n",
      "        [1.0563],\n",
      "        [1.0603],\n",
      "        [1.0571],\n",
      "        [1.0744],\n",
      "        [1.0433],\n",
      "        [1.0818],\n",
      "        [1.0474],\n",
      "        [1.0799],\n",
      "        [1.0367],\n",
      "        [1.0755],\n",
      "        [1.0340],\n",
      "        [1.0730],\n",
      "        [0.9843],\n",
      "        [1.0475],\n",
      "        [1.0837],\n",
      "        [1.0700],\n",
      "        [1.0284],\n",
      "        [1.0243],\n",
      "        [1.0698],\n",
      "        [1.0835],\n",
      "        [1.0673],\n",
      "        [1.0404],\n",
      "        [1.0673],\n",
      "        [1.0694],\n",
      "        [1.0098],\n",
      "        [1.0115],\n",
      "        [1.0583],\n",
      "        [1.0358],\n",
      "        [1.0447],\n",
      "        [1.0625],\n",
      "        [1.0702],\n",
      "        [1.0514],\n",
      "        [1.0785],\n",
      "        [1.0825],\n",
      "        [1.0668],\n",
      "        [1.0412],\n",
      "        [1.0696],\n",
      "        [1.0796],\n",
      "        [1.0842],\n",
      "        [1.0582],\n",
      "        [1.0584],\n",
      "        [1.0840],\n",
      "        [1.0418],\n",
      "        [1.0560],\n",
      "        [1.0591],\n",
      "        [1.0611],\n",
      "        [1.0271],\n",
      "        [1.0629],\n",
      "        [1.0687],\n",
      "        [1.0617],\n",
      "        [1.0522],\n",
      "        [1.0731],\n",
      "        [1.0796],\n",
      "        [1.0212],\n",
      "        [1.0059],\n",
      "        [1.0597],\n",
      "        [1.0104],\n",
      "        [1.0816],\n",
      "        [1.0833],\n",
      "        [0.9985],\n",
      "        [1.0413],\n",
      "        [1.0266],\n",
      "        [1.0192],\n",
      "        [1.0510],\n",
      "        [1.0718],\n",
      "        [1.0793],\n",
      "        [1.0502],\n",
      "        [1.0215],\n",
      "        [1.0586],\n",
      "        [1.0400],\n",
      "        [1.0586],\n",
      "        [1.0497],\n",
      "        [1.0466],\n",
      "        [1.0596],\n",
      "        [1.0533],\n",
      "        [1.0745],\n",
      "        [1.0736],\n",
      "        [1.0271],\n",
      "        [1.0624],\n",
      "        [1.0782],\n",
      "        [1.0863],\n",
      "        [1.0395],\n",
      "        [1.0254],\n",
      "        [1.0495],\n",
      "        [1.0848],\n",
      "        [1.0601],\n",
      "        [1.0549],\n",
      "        [1.0562],\n",
      "        [1.0579],\n",
      "        [1.0592],\n",
      "        [1.0540],\n",
      "        [1.0592],\n",
      "        [1.0623],\n",
      "        [1.0415],\n",
      "        [1.0849],\n",
      "        [1.0740],\n",
      "        [1.0820],\n",
      "        [1.0654],\n",
      "        [1.0736],\n",
      "        [1.0223],\n",
      "        [1.0356]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0458],\n",
      "        [1.0250],\n",
      "        [1.0351],\n",
      "        [1.0331],\n",
      "        [1.0314],\n",
      "        [1.0324],\n",
      "        [1.0320],\n",
      "        [1.0637],\n",
      "        [1.0395],\n",
      "        [1.0608],\n",
      "        [1.0223],\n",
      "        [1.0637],\n",
      "        [1.0244],\n",
      "        [1.0677],\n",
      "        [1.0375],\n",
      "        [1.0451],\n",
      "        [1.0582],\n",
      "        [1.0368],\n",
      "        [1.0699],\n",
      "        [1.0358],\n",
      "        [1.0398],\n",
      "        [0.4204],\n",
      "        [1.0274],\n",
      "        [1.0505],\n",
      "        [1.0658],\n",
      "        [1.0473],\n",
      "        [1.0380],\n",
      "        [1.0591],\n",
      "        [1.0626],\n",
      "        [1.0450],\n",
      "        [1.0298],\n",
      "        [1.0613],\n",
      "        [1.0243],\n",
      "        [1.0559],\n",
      "        [1.0258],\n",
      "        [1.0591],\n",
      "        [1.0102],\n",
      "        [1.0734],\n",
      "        [1.0645],\n",
      "        [1.0342],\n",
      "        [1.0242],\n",
      "        [1.0635],\n",
      "        [1.0608],\n",
      "        [1.0261],\n",
      "        [1.0584],\n",
      "        [1.0162],\n",
      "        [1.0518],\n",
      "        [1.0029],\n",
      "        [1.0392],\n",
      "        [1.0404],\n",
      "        [1.0527],\n",
      "        [1.0463],\n",
      "        [1.0459],\n",
      "        [1.0447],\n",
      "        [1.0418],\n",
      "        [1.0328],\n",
      "        [1.0747],\n",
      "        [1.0332],\n",
      "        [1.0600],\n",
      "        [1.0609],\n",
      "        [1.0392],\n",
      "        [1.0433],\n",
      "        [1.0746],\n",
      "        [1.0533],\n",
      "        [1.0624],\n",
      "        [1.0398],\n",
      "        [1.0359],\n",
      "        [1.0355],\n",
      "        [1.0608],\n",
      "        [0.7428],\n",
      "        [1.0471],\n",
      "        [1.0347],\n",
      "        [1.0284],\n",
      "        [1.0472],\n",
      "        [1.0302],\n",
      "        [1.0636],\n",
      "        [1.0511],\n",
      "        [1.0250],\n",
      "        [1.0592],\n",
      "        [1.0416],\n",
      "        [1.0492],\n",
      "        [1.0451],\n",
      "        [1.0640],\n",
      "        [1.0181],\n",
      "        [0.7808],\n",
      "        [1.0646],\n",
      "        [1.0538],\n",
      "        [1.0604],\n",
      "        [1.0635],\n",
      "        [1.0495],\n",
      "        [1.0622],\n",
      "        [0.9890],\n",
      "        [1.0319],\n",
      "        [1.0267],\n",
      "        [1.0098],\n",
      "        [1.0651],\n",
      "        [1.0655],\n",
      "        [1.0547],\n",
      "        [1.0404],\n",
      "        [1.0709],\n",
      "        [1.0455],\n",
      "        [1.0382],\n",
      "        [1.0672],\n",
      "        [1.0728],\n",
      "        [1.0625],\n",
      "        [1.0689],\n",
      "        [1.0332],\n",
      "        [1.0707],\n",
      "        [1.0467],\n",
      "        [1.0344],\n",
      "        [1.0742],\n",
      "        [1.0741],\n",
      "        [1.0638],\n",
      "        [1.0647],\n",
      "        [1.0221],\n",
      "        [2.5915],\n",
      "        [1.0547],\n",
      "        [1.0603],\n",
      "        [1.0517],\n",
      "        [1.0202],\n",
      "        [1.0473],\n",
      "        [1.0331],\n",
      "        [0.9983],\n",
      "        [1.0229],\n",
      "        [1.0604],\n",
      "        [1.0565],\n",
      "        [1.0537],\n",
      "        [1.0512]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0457],\n",
      "        [1.0640],\n",
      "        [1.0554],\n",
      "        [1.0268],\n",
      "        [1.0238],\n",
      "        [1.0068],\n",
      "        [1.0547],\n",
      "        [1.0539],\n",
      "        [1.0551],\n",
      "        [1.0664],\n",
      "        [1.0567],\n",
      "        [1.0640],\n",
      "        [1.0430],\n",
      "        [1.0369],\n",
      "        [1.0435],\n",
      "        [1.0571],\n",
      "        [1.0544],\n",
      "        [0.4005],\n",
      "        [1.0529],\n",
      "        [1.0542],\n",
      "        [1.0528],\n",
      "        [1.0412],\n",
      "        [1.0382],\n",
      "        [1.0354],\n",
      "        [1.0271],\n",
      "        [1.0254],\n",
      "        [1.0085],\n",
      "        [1.0497],\n",
      "        [1.0262],\n",
      "        [1.0534],\n",
      "        [1.0350],\n",
      "        [1.0260],\n",
      "        [1.0491],\n",
      "        [1.0386],\n",
      "        [1.0483],\n",
      "        [1.0254],\n",
      "        [1.0241],\n",
      "        [1.0301],\n",
      "        [1.0394],\n",
      "        [1.0457],\n",
      "        [1.0652],\n",
      "        [1.0212],\n",
      "        [1.0687],\n",
      "        [1.0341],\n",
      "        [1.0672],\n",
      "        [1.0590],\n",
      "        [1.0669],\n",
      "        [1.0428],\n",
      "        [1.0197],\n",
      "        [1.0584],\n",
      "        [1.0646],\n",
      "        [1.0419],\n",
      "        [1.0628],\n",
      "        [1.0508],\n",
      "        [1.0259],\n",
      "        [1.0603],\n",
      "        [1.0460],\n",
      "        [1.0317],\n",
      "        [0.9911],\n",
      "        [1.0393],\n",
      "        [0.9975],\n",
      "        [1.0567],\n",
      "        [1.0052],\n",
      "        [1.0697],\n",
      "        [1.0456],\n",
      "        [1.0360],\n",
      "        [1.0292],\n",
      "        [1.0432],\n",
      "        [1.0577],\n",
      "        [1.0515],\n",
      "        [1.0524],\n",
      "        [1.0556],\n",
      "        [1.0182],\n",
      "        [1.0601],\n",
      "        [1.0409],\n",
      "        [1.0272],\n",
      "        [1.0390],\n",
      "        [1.0380],\n",
      "        [1.0307],\n",
      "        [1.0503],\n",
      "        [1.0472],\n",
      "        [1.0524],\n",
      "        [1.0492],\n",
      "        [1.0485],\n",
      "        [1.0208],\n",
      "        [0.9892],\n",
      "        [1.0051],\n",
      "        [0.9867],\n",
      "        [1.0314],\n",
      "        [1.0524],\n",
      "        [1.0404],\n",
      "        [1.0341],\n",
      "        [0.9996],\n",
      "        [1.0389],\n",
      "        [1.0284],\n",
      "        [1.0386],\n",
      "        [1.0238],\n",
      "        [1.0677],\n",
      "        [1.0323],\n",
      "        [1.0691],\n",
      "        [1.0026],\n",
      "        [1.0644],\n",
      "        [1.0217],\n",
      "        [1.0627],\n",
      "        [1.0346],\n",
      "        [1.0104],\n",
      "        [1.0530],\n",
      "        [1.0544],\n",
      "        [1.0590],\n",
      "        [1.0587],\n",
      "        [1.0074],\n",
      "        [1.0632],\n",
      "        [1.0361],\n",
      "        [1.0548],\n",
      "        [1.0168],\n",
      "        [1.0674],\n",
      "        [1.0502],\n",
      "        [1.0446],\n",
      "        [1.0311],\n",
      "        [1.0606],\n",
      "        [0.9909],\n",
      "        [1.0487],\n",
      "        [1.0340],\n",
      "        [1.0667],\n",
      "        [1.0394],\n",
      "        [1.0455],\n",
      "        [1.0198],\n",
      "        [1.0413]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0496],\n",
      "        [1.0500],\n",
      "        [1.0153],\n",
      "        [1.0581],\n",
      "        [1.0328],\n",
      "        [1.0447],\n",
      "        [1.0344],\n",
      "        [1.0551],\n",
      "        [1.0275],\n",
      "        [1.0190],\n",
      "        [1.0076],\n",
      "        [1.0536],\n",
      "        [1.0609],\n",
      "        [0.9531],\n",
      "        [1.0033],\n",
      "        [1.0347],\n",
      "        [1.0230],\n",
      "        [1.0004],\n",
      "        [1.0457],\n",
      "        [1.0409],\n",
      "        [1.0350],\n",
      "        [1.0216],\n",
      "        [1.0398],\n",
      "        [1.0212],\n",
      "        [1.0393],\n",
      "        [1.0601],\n",
      "        [1.0491],\n",
      "        [1.0311],\n",
      "        [1.0271],\n",
      "        [1.0441],\n",
      "        [1.0500],\n",
      "        [1.0263],\n",
      "        [0.9889],\n",
      "        [1.0171],\n",
      "        [1.0514],\n",
      "        [1.0367],\n",
      "        [1.0240],\n",
      "        [1.0338],\n",
      "        [1.0435],\n",
      "        [1.0311],\n",
      "        [1.0369],\n",
      "        [0.9850],\n",
      "        [1.0548],\n",
      "        [1.0356],\n",
      "        [1.0049],\n",
      "        [1.0193],\n",
      "        [1.0355],\n",
      "        [0.9969],\n",
      "        [1.0556],\n",
      "        [1.0596],\n",
      "        [1.0088],\n",
      "        [0.9979],\n",
      "        [1.0400],\n",
      "        [1.0180],\n",
      "        [1.0214],\n",
      "        [1.0301],\n",
      "        [1.0312],\n",
      "        [1.0606],\n",
      "        [1.0565],\n",
      "        [1.0122],\n",
      "        [1.0484],\n",
      "        [1.0095],\n",
      "        [1.0147],\n",
      "        [1.0107],\n",
      "        [0.9915],\n",
      "        [1.0293],\n",
      "        [1.0078],\n",
      "        [1.0260],\n",
      "        [1.0260],\n",
      "        [1.0389],\n",
      "        [1.0524],\n",
      "        [0.9760],\n",
      "        [1.0334],\n",
      "        [1.0197],\n",
      "        [1.0432],\n",
      "        [1.0270],\n",
      "        [1.0450],\n",
      "        [1.0598],\n",
      "        [1.0418],\n",
      "        [1.0461],\n",
      "        [1.0266],\n",
      "        [1.0481],\n",
      "        [1.0117],\n",
      "        [1.0383],\n",
      "        [1.0603],\n",
      "        [1.0356],\n",
      "        [1.0346],\n",
      "        [1.0428],\n",
      "        [1.0162],\n",
      "        [1.0482],\n",
      "        [1.0283],\n",
      "        [1.0579],\n",
      "        [1.0569],\n",
      "        [1.0600],\n",
      "        [1.0262],\n",
      "        [1.0405],\n",
      "        [1.0537],\n",
      "        [1.0305],\n",
      "        [1.0584],\n",
      "        [1.0534],\n",
      "        [1.0264],\n",
      "        [1.0355],\n",
      "        [1.0352],\n",
      "        [1.0005],\n",
      "        [0.9937],\n",
      "        [1.0386],\n",
      "        [1.0099],\n",
      "        [1.0464],\n",
      "        [1.0268],\n",
      "        [1.0480],\n",
      "        [1.0416],\n",
      "        [1.0570],\n",
      "        [0.9845],\n",
      "        [1.0197],\n",
      "        [1.0253],\n",
      "        [1.0087],\n",
      "        [0.9957],\n",
      "        [1.0329],\n",
      "        [1.0555],\n",
      "        [1.0314],\n",
      "        [1.0358],\n",
      "        [1.0605],\n",
      "        [1.0135],\n",
      "        [1.0558],\n",
      "        [1.0604],\n",
      "        [1.0496],\n",
      "        [1.0605],\n",
      "        [1.0304]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.9999],\n",
      "        [1.0243],\n",
      "        [1.0138],\n",
      "        [1.0018]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   2 | lr 0.00100 train_loss 2.12304 | val_loss 2.31747 | val_rmse 1.52232\n",
      "tensor([[1.0275],\n",
      "        [1.0428],\n",
      "        [1.0441],\n",
      "        [1.0190],\n",
      "        [1.0121],\n",
      "        [1.0173],\n",
      "        [1.0281],\n",
      "        [1.0125],\n",
      "        [1.0075],\n",
      "        [1.0163],\n",
      "        [0.9874],\n",
      "        [1.0475],\n",
      "        [0.9977],\n",
      "        [1.0296],\n",
      "        [1.0174],\n",
      "        [1.0405],\n",
      "        [1.0427],\n",
      "        [1.0313],\n",
      "        [0.9558],\n",
      "        [1.0260],\n",
      "        [1.0118],\n",
      "        [0.9985],\n",
      "        [1.0373],\n",
      "        [1.0383],\n",
      "        [1.0375],\n",
      "        [0.9988],\n",
      "        [1.0259],\n",
      "        [1.0269],\n",
      "        [1.0342],\n",
      "        [1.0176],\n",
      "        [1.0058],\n",
      "        [1.0377],\n",
      "        [1.0364],\n",
      "        [1.0319],\n",
      "        [0.9757],\n",
      "        [1.0002],\n",
      "        [1.0335],\n",
      "        [0.9718],\n",
      "        [1.0454],\n",
      "        [1.0390],\n",
      "        [1.0017],\n",
      "        [1.0447],\n",
      "        [0.9989],\n",
      "        [1.0054],\n",
      "        [1.0198],\n",
      "        [1.0194],\n",
      "        [1.0239],\n",
      "        [1.0223],\n",
      "        [1.0194],\n",
      "        [1.0291],\n",
      "        [1.0274],\n",
      "        [0.9961],\n",
      "        [0.9958],\n",
      "        [1.0181],\n",
      "        [1.0082],\n",
      "        [1.0117],\n",
      "        [0.9847],\n",
      "        [1.0453],\n",
      "        [1.0185],\n",
      "        [0.9905],\n",
      "        [1.0075],\n",
      "        [1.0468],\n",
      "        [1.0220],\n",
      "        [1.0419],\n",
      "        [0.9998],\n",
      "        [0.9940],\n",
      "        [0.9811],\n",
      "        [1.0181],\n",
      "        [0.9947],\n",
      "        [1.0105],\n",
      "        [1.0288],\n",
      "        [1.0341],\n",
      "        [1.0401],\n",
      "        [1.0011],\n",
      "        [0.9983],\n",
      "        [1.0125],\n",
      "        [1.0207],\n",
      "        [0.9859],\n",
      "        [1.0313],\n",
      "        [1.0420],\n",
      "        [0.9918],\n",
      "        [1.0028],\n",
      "        [0.9925],\n",
      "        [1.0083],\n",
      "        [1.0067],\n",
      "        [1.0238],\n",
      "        [1.0053],\n",
      "        [1.0188],\n",
      "        [1.0354],\n",
      "        [1.0244],\n",
      "        [1.0324],\n",
      "        [1.0262],\n",
      "        [1.0012],\n",
      "        [1.0250],\n",
      "        [0.9679],\n",
      "        [1.0185],\n",
      "        [1.0207],\n",
      "        [1.0468],\n",
      "        [1.0021],\n",
      "        [1.0080],\n",
      "        [0.9950],\n",
      "        [1.0323],\n",
      "        [0.9831],\n",
      "        [1.0242],\n",
      "        [1.0251],\n",
      "        [1.0381],\n",
      "        [1.0057],\n",
      "        [0.9899],\n",
      "        [1.0217],\n",
      "        [1.0220],\n",
      "        [1.0322],\n",
      "        [1.0398],\n",
      "        [1.0230],\n",
      "        [1.0288],\n",
      "        [1.0438],\n",
      "        [1.0088],\n",
      "        [1.0271],\n",
      "        [0.9915],\n",
      "        [1.0346],\n",
      "        [1.0123],\n",
      "        [1.0374],\n",
      "        [1.0051],\n",
      "        [0.9944],\n",
      "        [1.0074],\n",
      "        [1.0243],\n",
      "        [1.0113],\n",
      "        [1.0315],\n",
      "        [1.0309]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0340],\n",
      "        [1.0249],\n",
      "        [1.0178],\n",
      "        [0.9989],\n",
      "        [1.0331],\n",
      "        [0.9971],\n",
      "        [1.0260],\n",
      "        [0.9988],\n",
      "        [1.0403],\n",
      "        [1.0095],\n",
      "        [1.0103],\n",
      "        [1.0255],\n",
      "        [1.0040],\n",
      "        [1.0096],\n",
      "        [1.0157],\n",
      "        [1.0232],\n",
      "        [1.0167],\n",
      "        [1.0120],\n",
      "        [1.0262],\n",
      "        [1.0336],\n",
      "        [1.0299],\n",
      "        [0.9867],\n",
      "        [1.0299],\n",
      "        [1.0046],\n",
      "        [0.9976],\n",
      "        [1.0275],\n",
      "        [1.0360],\n",
      "        [1.0247],\n",
      "        [1.0151],\n",
      "        [1.0357],\n",
      "        [1.0051],\n",
      "        [1.0111],\n",
      "        [1.0132],\n",
      "        [1.0126],\n",
      "        [1.0419],\n",
      "        [1.0221],\n",
      "        [1.0399],\n",
      "        [1.0248],\n",
      "        [1.0202],\n",
      "        [1.0413],\n",
      "        [1.0248],\n",
      "        [1.0113],\n",
      "        [0.9830],\n",
      "        [1.0295],\n",
      "        [0.9939],\n",
      "        [1.0131],\n",
      "        [1.0071],\n",
      "        [1.0284],\n",
      "        [1.0079],\n",
      "        [1.0325],\n",
      "        [1.0191],\n",
      "        [1.0323],\n",
      "        [1.0064],\n",
      "        [1.0342],\n",
      "        [1.0217],\n",
      "        [0.9916],\n",
      "        [1.0292],\n",
      "        [0.9959],\n",
      "        [0.9962],\n",
      "        [0.9905],\n",
      "        [1.0108],\n",
      "        [1.0200],\n",
      "        [1.0172],\n",
      "        [1.0293],\n",
      "        [1.0414],\n",
      "        [1.0102],\n",
      "        [1.0227],\n",
      "        [1.0285],\n",
      "        [0.9927],\n",
      "        [1.0388],\n",
      "        [1.0079],\n",
      "        [1.0002],\n",
      "        [1.0240],\n",
      "        [1.0152],\n",
      "        [1.0419],\n",
      "        [1.0419],\n",
      "        [1.0100],\n",
      "        [1.0361],\n",
      "        [1.0218],\n",
      "        [1.0377],\n",
      "        [1.0271],\n",
      "        [1.0319],\n",
      "        [1.0237],\n",
      "        [1.0137],\n",
      "        [0.9973],\n",
      "        [1.0220],\n",
      "        [1.0417],\n",
      "        [0.9887],\n",
      "        [1.0293],\n",
      "        [1.0418],\n",
      "        [0.9913],\n",
      "        [1.0119],\n",
      "        [1.0359],\n",
      "        [1.0003],\n",
      "        [1.0350],\n",
      "        [1.0207],\n",
      "        [0.9950],\n",
      "        [1.0151],\n",
      "        [1.0307],\n",
      "        [1.0278],\n",
      "        [1.0114],\n",
      "        [1.0127],\n",
      "        [0.9916],\n",
      "        [1.0057],\n",
      "        [1.0130],\n",
      "        [1.0036],\n",
      "        [1.0220],\n",
      "        [1.0249],\n",
      "        [0.9260],\n",
      "        [1.0296],\n",
      "        [0.9993],\n",
      "        [0.9931],\n",
      "        [1.0050],\n",
      "        [1.0253],\n",
      "        [0.9893],\n",
      "        [1.0430],\n",
      "        [1.0188],\n",
      "        [1.0180],\n",
      "        [1.0072],\n",
      "        [0.9668],\n",
      "        [1.0167],\n",
      "        [1.0345],\n",
      "        [1.0367],\n",
      "        [1.0374],\n",
      "        [1.0218],\n",
      "        [1.0152],\n",
      "        [1.0272],\n",
      "        [1.0251]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0222],\n",
      "        [1.0169],\n",
      "        [1.0379],\n",
      "        [1.0027],\n",
      "        [0.9922],\n",
      "        [1.0363],\n",
      "        [0.9878],\n",
      "        [1.0242],\n",
      "        [0.9913],\n",
      "        [0.9984],\n",
      "        [1.0246],\n",
      "        [1.0217],\n",
      "        [1.0288],\n",
      "        [1.0091],\n",
      "        [1.0075],\n",
      "        [1.0247],\n",
      "        [0.9878],\n",
      "        [1.0300],\n",
      "        [1.0163],\n",
      "        [1.0026],\n",
      "        [1.0250],\n",
      "        [1.0062],\n",
      "        [0.9937],\n",
      "        [1.0264],\n",
      "        [1.0132],\n",
      "        [0.9767],\n",
      "        [1.0068],\n",
      "        [1.0375],\n",
      "        [0.9866],\n",
      "        [1.0024],\n",
      "        [1.0351],\n",
      "        [1.0176],\n",
      "        [1.0305],\n",
      "        [1.0037],\n",
      "        [1.0087],\n",
      "        [0.9992],\n",
      "        [1.0373],\n",
      "        [0.9726],\n",
      "        [0.9908],\n",
      "        [0.9853],\n",
      "        [1.0305],\n",
      "        [1.0334],\n",
      "        [1.0080],\n",
      "        [1.0239],\n",
      "        [1.0342],\n",
      "        [1.0200],\n",
      "        [1.0133],\n",
      "        [1.0342],\n",
      "        [1.0268],\n",
      "        [1.0064],\n",
      "        [0.9871],\n",
      "        [1.0241],\n",
      "        [1.0258],\n",
      "        [1.0222],\n",
      "        [1.0254],\n",
      "        [1.0285],\n",
      "        [1.0089],\n",
      "        [1.0254],\n",
      "        [1.0017],\n",
      "        [0.9962],\n",
      "        [1.0153],\n",
      "        [1.0156],\n",
      "        [1.0341],\n",
      "        [1.0225],\n",
      "        [1.0264],\n",
      "        [1.0111],\n",
      "        [0.9458],\n",
      "        [1.0293],\n",
      "        [0.9475],\n",
      "        [0.9551],\n",
      "        [1.0094],\n",
      "        [1.0189],\n",
      "        [0.9934],\n",
      "        [1.0144],\n",
      "        [1.0341],\n",
      "        [1.0160],\n",
      "        [1.0015],\n",
      "        [1.0025],\n",
      "        [0.9955],\n",
      "        [1.0008],\n",
      "        [1.0089],\n",
      "        [1.0031],\n",
      "        [1.0233],\n",
      "        [0.9919],\n",
      "        [1.0307],\n",
      "        [1.0110],\n",
      "        [0.9499],\n",
      "        [1.0335],\n",
      "        [0.9879],\n",
      "        [1.0023],\n",
      "        [1.0326],\n",
      "        [1.0317],\n",
      "        [1.0097],\n",
      "        [1.0206],\n",
      "        [1.0116],\n",
      "        [1.0145],\n",
      "        [1.0080],\n",
      "        [1.0289],\n",
      "        [0.9813],\n",
      "        [1.0254],\n",
      "        [0.9740],\n",
      "        [1.0145],\n",
      "        [0.9928],\n",
      "        [1.0100],\n",
      "        [1.0113],\n",
      "        [1.0082],\n",
      "        [0.9916],\n",
      "        [1.0149],\n",
      "        [1.0214],\n",
      "        [1.0155],\n",
      "        [1.0280],\n",
      "        [1.0304],\n",
      "        [1.0312],\n",
      "        [0.9734],\n",
      "        [1.0113],\n",
      "        [1.0296],\n",
      "        [0.9889],\n",
      "        [1.0296],\n",
      "        [1.0157],\n",
      "        [1.0277],\n",
      "        [1.0006],\n",
      "        [1.0327],\n",
      "        [1.0361],\n",
      "        [1.0203],\n",
      "        [1.0032],\n",
      "        [1.0275],\n",
      "        [1.0190],\n",
      "        [0.9876]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0317],\n",
      "        [0.9753],\n",
      "        [1.0228],\n",
      "        [1.0230],\n",
      "        [1.0041],\n",
      "        [1.0315],\n",
      "        [1.0151],\n",
      "        [1.0314],\n",
      "        [1.0039],\n",
      "        [0.9867],\n",
      "        [1.0198],\n",
      "        [1.0054],\n",
      "        [1.0171],\n",
      "        [0.9970],\n",
      "        [1.0219],\n",
      "        [0.9769],\n",
      "        [1.0290],\n",
      "        [0.9699],\n",
      "        [1.0092],\n",
      "        [1.0165],\n",
      "        [0.9968],\n",
      "        [1.0037],\n",
      "        [0.9868],\n",
      "        [1.0201],\n",
      "        [1.0291],\n",
      "        [1.0114],\n",
      "        [0.9529],\n",
      "        [1.0049],\n",
      "        [1.0070],\n",
      "        [1.0224],\n",
      "        [1.0056],\n",
      "        [1.0134],\n",
      "        [1.0143],\n",
      "        [1.0337],\n",
      "        [0.9871],\n",
      "        [1.0127],\n",
      "        [1.0101],\n",
      "        [0.9541],\n",
      "        [1.0229],\n",
      "        [0.9954],\n",
      "        [1.0158],\n",
      "        [1.0323],\n",
      "        [0.9705],\n",
      "        [1.0054],\n",
      "        [1.0316],\n",
      "        [0.9356],\n",
      "        [0.9899],\n",
      "        [1.0314],\n",
      "        [1.0193],\n",
      "        [1.0132],\n",
      "        [1.0329],\n",
      "        [1.0031],\n",
      "        [1.0275],\n",
      "        [0.9914],\n",
      "        [1.0197],\n",
      "        [1.0293],\n",
      "        [0.9956],\n",
      "        [1.0109],\n",
      "        [1.0138],\n",
      "        [1.0264],\n",
      "        [1.0319],\n",
      "        [1.0220],\n",
      "        [0.9846],\n",
      "        [0.9936],\n",
      "        [1.0185],\n",
      "        [0.9793],\n",
      "        [1.0211],\n",
      "        [0.9799],\n",
      "        [1.0018],\n",
      "        [1.0149],\n",
      "        [1.0088],\n",
      "        [1.0221],\n",
      "        [1.0018],\n",
      "        [0.9949],\n",
      "        [1.0133],\n",
      "        [1.0244],\n",
      "        [1.0054],\n",
      "        [0.9786],\n",
      "        [0.9669],\n",
      "        [1.0224],\n",
      "        [0.9923],\n",
      "        [1.0295],\n",
      "        [1.0296],\n",
      "        [1.0315],\n",
      "        [1.0170],\n",
      "        [1.0028],\n",
      "        [0.9913],\n",
      "        [1.0266],\n",
      "        [1.0100],\n",
      "        [1.0242],\n",
      "        [0.9988],\n",
      "        [1.0228],\n",
      "        [1.0345],\n",
      "        [0.9864],\n",
      "        [1.0060],\n",
      "        [0.9999],\n",
      "        [1.0179],\n",
      "        [1.0254],\n",
      "        [1.0285],\n",
      "        [1.0278],\n",
      "        [0.9668],\n",
      "        [1.0190],\n",
      "        [1.0000],\n",
      "        [1.0230],\n",
      "        [1.0217],\n",
      "        [1.0183],\n",
      "        [1.0037],\n",
      "        [1.0114],\n",
      "        [1.0264],\n",
      "        [0.9429],\n",
      "        [1.0170],\n",
      "        [1.0229],\n",
      "        [1.0173],\n",
      "        [0.9974],\n",
      "        [1.0287],\n",
      "        [1.0275],\n",
      "        [0.9961],\n",
      "        [0.9709],\n",
      "        [1.0136],\n",
      "        [1.0043],\n",
      "        [1.0251],\n",
      "        [1.0336],\n",
      "        [1.0212],\n",
      "        [0.9665],\n",
      "        [0.9802],\n",
      "        [0.9937],\n",
      "        [1.0253],\n",
      "        [1.0084]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0021],\n",
      "        [1.0227],\n",
      "        [0.9939],\n",
      "        [1.0201],\n",
      "        [1.0314],\n",
      "        [1.0100],\n",
      "        [0.9589],\n",
      "        [1.0023],\n",
      "        [1.0134],\n",
      "        [1.0154],\n",
      "        [0.9909],\n",
      "        [0.9577],\n",
      "        [1.0312],\n",
      "        [1.0004],\n",
      "        [0.9782],\n",
      "        [0.9946],\n",
      "        [1.0043],\n",
      "        [1.0113],\n",
      "        [0.9848],\n",
      "        [1.0079],\n",
      "        [0.9966],\n",
      "        [0.9925],\n",
      "        [0.9906],\n",
      "        [1.0019],\n",
      "        [1.0294],\n",
      "        [1.0164],\n",
      "        [0.9936],\n",
      "        [0.9697],\n",
      "        [1.0130],\n",
      "        [1.0022],\n",
      "        [1.0131],\n",
      "        [0.9925],\n",
      "        [1.0314],\n",
      "        [0.9734],\n",
      "        [0.9976],\n",
      "        [1.0198],\n",
      "        [1.0139],\n",
      "        [1.0151],\n",
      "        [1.0251],\n",
      "        [1.0078],\n",
      "        [1.0213],\n",
      "        [0.9999],\n",
      "        [1.0004],\n",
      "        [1.0271],\n",
      "        [1.0067],\n",
      "        [0.9333],\n",
      "        [0.9904],\n",
      "        [1.0240],\n",
      "        [0.9919],\n",
      "        [1.0211],\n",
      "        [1.0060],\n",
      "        [1.0156],\n",
      "        [0.9748],\n",
      "        [1.0062],\n",
      "        [1.0226],\n",
      "        [1.0129],\n",
      "        [0.9968],\n",
      "        [0.9599],\n",
      "        [1.0053],\n",
      "        [0.9703],\n",
      "        [1.0069],\n",
      "        [0.9945],\n",
      "        [0.9846],\n",
      "        [1.0051],\n",
      "        [1.0292],\n",
      "        [0.9822],\n",
      "        [0.9818],\n",
      "        [1.0227],\n",
      "        [1.0006],\n",
      "        [0.9816],\n",
      "        [0.9965],\n",
      "        [1.0190],\n",
      "        [1.0120],\n",
      "        [1.0079],\n",
      "        [0.9939],\n",
      "        [1.0302],\n",
      "        [1.0195],\n",
      "        [1.0092],\n",
      "        [1.0305],\n",
      "        [0.9995],\n",
      "        [1.0301],\n",
      "        [0.9916],\n",
      "        [0.9753],\n",
      "        [0.9958],\n",
      "        [0.9335],\n",
      "        [1.0029],\n",
      "        [1.0320],\n",
      "        [0.9967],\n",
      "        [0.9946],\n",
      "        [1.0262],\n",
      "        [1.0024],\n",
      "        [0.9890],\n",
      "        [0.9821],\n",
      "        [1.0220],\n",
      "        [0.9953],\n",
      "        [0.9933],\n",
      "        [1.0143],\n",
      "        [1.0094],\n",
      "        [1.0161],\n",
      "        [1.0306],\n",
      "        [1.0175],\n",
      "        [0.9993],\n",
      "        [0.9975],\n",
      "        [0.9890],\n",
      "        [1.0284],\n",
      "        [1.0162],\n",
      "        [0.9922],\n",
      "        [0.9984],\n",
      "        [1.0070],\n",
      "        [1.0032],\n",
      "        [0.9868],\n",
      "        [1.0044],\n",
      "        [1.0089],\n",
      "        [1.0186],\n",
      "        [1.0031],\n",
      "        [1.0194],\n",
      "        [0.9971],\n",
      "        [1.0336],\n",
      "        [0.9392],\n",
      "        [1.0127],\n",
      "        [1.0053],\n",
      "        [1.0118],\n",
      "        [0.9881],\n",
      "        [0.9859],\n",
      "        [1.0190],\n",
      "        [1.0271],\n",
      "        [1.0197],\n",
      "        [1.0062]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0098],\n",
      "        [0.9932],\n",
      "        [1.0282],\n",
      "        [1.0255],\n",
      "        [1.0277],\n",
      "        [0.9799],\n",
      "        [1.0040],\n",
      "        [1.0277],\n",
      "        [0.9932],\n",
      "        [0.9894],\n",
      "        [0.9633],\n",
      "        [0.9854],\n",
      "        [1.0067],\n",
      "        [1.0253],\n",
      "        [1.0236],\n",
      "        [1.0134],\n",
      "        [0.9951],\n",
      "        [1.0009],\n",
      "        [1.0289],\n",
      "        [1.0160],\n",
      "        [0.9975],\n",
      "        [1.0183],\n",
      "        [1.0126],\n",
      "        [1.0122],\n",
      "        [1.0230],\n",
      "        [1.0014],\n",
      "        [1.0019],\n",
      "        [0.9616],\n",
      "        [1.0008],\n",
      "        [0.9511],\n",
      "        [1.0211],\n",
      "        [1.0227],\n",
      "        [0.9996],\n",
      "        [0.9882],\n",
      "        [1.0056],\n",
      "        [1.0256],\n",
      "        [1.0210],\n",
      "        [1.0182],\n",
      "        [1.0249],\n",
      "        [1.0159],\n",
      "        [0.9811],\n",
      "        [0.9822],\n",
      "        [1.0296],\n",
      "        [0.9613],\n",
      "        [1.0106],\n",
      "        [0.9928],\n",
      "        [0.9936],\n",
      "        [0.9757],\n",
      "        [1.0280],\n",
      "        [1.0029],\n",
      "        [0.9867],\n",
      "        [0.9793],\n",
      "        [1.0220],\n",
      "        [0.9708],\n",
      "        [1.0293],\n",
      "        [1.0165],\n",
      "        [0.9840],\n",
      "        [0.9803],\n",
      "        [1.0268],\n",
      "        [0.9863],\n",
      "        [1.0264],\n",
      "        [0.9978],\n",
      "        [1.0032],\n",
      "        [0.9955],\n",
      "        [0.9939],\n",
      "        [0.9801],\n",
      "        [1.0157],\n",
      "        [1.0280],\n",
      "        [0.9700],\n",
      "        [1.0011],\n",
      "        [1.0269],\n",
      "        [0.9825],\n",
      "        [1.0308],\n",
      "        [0.9568],\n",
      "        [1.0187],\n",
      "        [0.9867],\n",
      "        [1.0242],\n",
      "        [0.9845],\n",
      "        [1.0263],\n",
      "        [1.0099],\n",
      "        [1.0219],\n",
      "        [0.9900],\n",
      "        [1.0120],\n",
      "        [1.0058],\n",
      "        [1.0163],\n",
      "        [0.9964],\n",
      "        [0.9874],\n",
      "        [1.0080],\n",
      "        [1.0193],\n",
      "        [1.0276],\n",
      "        [1.0019],\n",
      "        [0.9763],\n",
      "        [1.0283],\n",
      "        [1.0077],\n",
      "        [0.9945],\n",
      "        [1.0170],\n",
      "        [0.9709],\n",
      "        [1.0063],\n",
      "        [1.0265],\n",
      "        [0.9842],\n",
      "        [0.9931],\n",
      "        [1.0179],\n",
      "        [0.9645],\n",
      "        [0.9797],\n",
      "        [0.9713],\n",
      "        [1.0202],\n",
      "        [1.0012],\n",
      "        [0.9761],\n",
      "        [0.9694],\n",
      "        [0.9885],\n",
      "        [1.0171],\n",
      "        [0.9970],\n",
      "        [1.0161],\n",
      "        [0.9902],\n",
      "        [0.9971],\n",
      "        [1.0045],\n",
      "        [1.0277],\n",
      "        [0.9772],\n",
      "        [1.0204],\n",
      "        [1.0058],\n",
      "        [0.9545],\n",
      "        [1.0091],\n",
      "        [0.9937],\n",
      "        [0.9673],\n",
      "        [1.0121],\n",
      "        [1.0042],\n",
      "        [1.0074],\n",
      "        [0.9687]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0102],\n",
      "        [1.0186],\n",
      "        [0.9960],\n",
      "        [0.9545],\n",
      "        [1.0118],\n",
      "        [1.0229],\n",
      "        [1.0209],\n",
      "        [1.0037],\n",
      "        [1.0041],\n",
      "        [1.0154],\n",
      "        [1.0199],\n",
      "        [0.0779],\n",
      "        [1.0282],\n",
      "        [1.0248],\n",
      "        [0.9945],\n",
      "        [0.9994],\n",
      "        [1.0242],\n",
      "        [1.0076],\n",
      "        [1.0293],\n",
      "        [0.9688],\n",
      "        [1.0076],\n",
      "        [0.9798],\n",
      "        [1.0253],\n",
      "        [0.9949],\n",
      "        [1.0059],\n",
      "        [1.0218],\n",
      "        [1.0190],\n",
      "        [0.9845],\n",
      "        [0.9776],\n",
      "        [1.0035],\n",
      "        [1.0050],\n",
      "        [0.9600],\n",
      "        [1.0072],\n",
      "        [1.0262],\n",
      "        [0.9935],\n",
      "        [1.0224],\n",
      "        [0.9725],\n",
      "        [0.9411],\n",
      "        [1.0185],\n",
      "        [0.9810],\n",
      "        [0.9914],\n",
      "        [0.9756],\n",
      "        [1.0194],\n",
      "        [1.0143],\n",
      "        [1.0023],\n",
      "        [0.9738],\n",
      "        [0.9607],\n",
      "        [1.0220],\n",
      "        [1.0299],\n",
      "        [1.0025],\n",
      "        [1.0016],\n",
      "        [1.0064],\n",
      "        [0.9930],\n",
      "        [0.9883],\n",
      "        [1.0053],\n",
      "        [1.0183],\n",
      "        [1.0277],\n",
      "        [1.0016],\n",
      "        [1.0164],\n",
      "        [1.0278],\n",
      "        [1.0267],\n",
      "        [1.0100],\n",
      "        [1.0251],\n",
      "        [0.9801],\n",
      "        [1.0107],\n",
      "        [1.0209],\n",
      "        [0.9910],\n",
      "        [0.9895],\n",
      "        [0.9850],\n",
      "        [1.0177],\n",
      "        [1.0276],\n",
      "        [0.9949],\n",
      "        [1.0121],\n",
      "        [0.9863],\n",
      "        [1.0279],\n",
      "        [0.9999],\n",
      "        [0.9804],\n",
      "        [1.0160],\n",
      "        [0.9855],\n",
      "        [1.0204],\n",
      "        [0.9752],\n",
      "        [1.0121],\n",
      "        [1.0290],\n",
      "        [1.0003],\n",
      "        [1.0288],\n",
      "        [0.9840],\n",
      "        [1.0145],\n",
      "        [1.0168],\n",
      "        [1.0135],\n",
      "        [0.9720],\n",
      "        [1.0001],\n",
      "        [0.9809],\n",
      "        [1.0271],\n",
      "        [0.9930],\n",
      "        [1.0180],\n",
      "        [0.9789],\n",
      "        [0.9711],\n",
      "        [1.0070],\n",
      "        [1.0168],\n",
      "        [0.9787],\n",
      "        [1.0066],\n",
      "        [1.0195],\n",
      "        [1.0266],\n",
      "        [1.0187],\n",
      "        [1.0194],\n",
      "        [0.9471],\n",
      "        [1.0256],\n",
      "        [1.0159],\n",
      "        [1.0150],\n",
      "        [1.0007],\n",
      "        [1.0139],\n",
      "        [1.0190],\n",
      "        [0.9911],\n",
      "        [1.0174],\n",
      "        [1.0076],\n",
      "        [0.9567],\n",
      "        [0.9831],\n",
      "        [1.0128],\n",
      "        [1.0102],\n",
      "        [1.0234],\n",
      "        [1.0197],\n",
      "        [1.0185],\n",
      "        [0.9933],\n",
      "        [0.9981],\n",
      "        [0.9973],\n",
      "        [1.0210],\n",
      "        [0.9816],\n",
      "        [1.0107]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0023],\n",
      "        [1.0189],\n",
      "        [0.9805],\n",
      "        [1.0227]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   3 | lr 0.00100 train_loss 2.12918 | val_loss 2.32186 | val_rmse 1.52377\n",
      "tensor([[1.0153],\n",
      "        [1.0147],\n",
      "        [0.9992],\n",
      "        [0.9964],\n",
      "        [1.0194],\n",
      "        [1.0365],\n",
      "        [1.0291],\n",
      "        [1.0017],\n",
      "        [0.9841],\n",
      "        [1.0038],\n",
      "        [0.9657],\n",
      "        [1.0379],\n",
      "        [0.9853],\n",
      "        [1.0166],\n",
      "        [1.0046],\n",
      "        [0.9813],\n",
      "        [0.9917],\n",
      "        [0.9876],\n",
      "        [1.0210],\n",
      "        [0.9765],\n",
      "        [1.0115],\n",
      "        [0.9833],\n",
      "        [1.0291],\n",
      "        [0.9738],\n",
      "        [1.0020],\n",
      "        [1.0083],\n",
      "        [1.0361],\n",
      "        [1.0081],\n",
      "        [0.9708],\n",
      "        [1.0140],\n",
      "        [1.0244],\n",
      "        [0.9789],\n",
      "        [1.0284],\n",
      "        [1.0363],\n",
      "        [0.9845],\n",
      "        [0.9061],\n",
      "        [0.9885],\n",
      "        [1.0130],\n",
      "        [1.0286],\n",
      "        [1.0345],\n",
      "        [0.9868],\n",
      "        [0.9864],\n",
      "        [0.9705],\n",
      "        [1.0266],\n",
      "        [1.0325],\n",
      "        [1.0137],\n",
      "        [1.0288],\n",
      "        [1.0324],\n",
      "        [1.0279],\n",
      "        [0.9912],\n",
      "        [0.9922],\n",
      "        [1.0219],\n",
      "        [1.0101],\n",
      "        [1.0044],\n",
      "        [1.0363],\n",
      "        [0.9880],\n",
      "        [1.0208],\n",
      "        [1.0221],\n",
      "        [0.9921],\n",
      "        [1.0026],\n",
      "        [1.0148],\n",
      "        [0.9974],\n",
      "        [1.0352],\n",
      "        [1.0064],\n",
      "        [0.9700],\n",
      "        [1.0314],\n",
      "        [1.0238],\n",
      "        [1.0156],\n",
      "        [1.0355],\n",
      "        [0.9998],\n",
      "        [1.0276],\n",
      "        [1.0000],\n",
      "        [0.9995],\n",
      "        [1.0068],\n",
      "        [1.0286],\n",
      "        [0.9920],\n",
      "        [1.0083],\n",
      "        [1.0199],\n",
      "        [1.0254],\n",
      "        [1.0227],\n",
      "        [0.9525],\n",
      "        [1.0158],\n",
      "        [0.9920],\n",
      "        [0.9958],\n",
      "        [1.0350],\n",
      "        [0.9985],\n",
      "        [0.9996],\n",
      "        [1.0357],\n",
      "        [1.0152],\n",
      "        [1.0144],\n",
      "        [1.0237],\n",
      "        [1.0313],\n",
      "        [1.0269],\n",
      "        [1.0174],\n",
      "        [1.0078],\n",
      "        [0.9948],\n",
      "        [1.0109],\n",
      "        [1.0183],\n",
      "        [1.0171],\n",
      "        [1.0318],\n",
      "        [1.0322],\n",
      "        [1.0019],\n",
      "        [1.0377],\n",
      "        [1.0132],\n",
      "        [1.0322],\n",
      "        [1.0213],\n",
      "        [1.0081],\n",
      "        [0.9652],\n",
      "        [0.9932],\n",
      "        [1.0337],\n",
      "        [1.0133],\n",
      "        [1.0187],\n",
      "        [1.0021],\n",
      "        [1.0172],\n",
      "        [0.9990],\n",
      "        [1.0221],\n",
      "        [0.9868],\n",
      "        [1.0030],\n",
      "        [1.0109],\n",
      "        [1.0143],\n",
      "        [1.0329],\n",
      "        [1.0127],\n",
      "        [1.0120],\n",
      "        [1.0343],\n",
      "        [1.0134],\n",
      "        [1.0161],\n",
      "        [1.0037],\n",
      "        [1.0034]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.9646],\n",
      "        [1.0128],\n",
      "        [0.9746],\n",
      "        [1.0342],\n",
      "        [1.0092],\n",
      "        [0.9822],\n",
      "        [0.9899],\n",
      "        [1.0303],\n",
      "        [1.0117],\n",
      "        [1.0402],\n",
      "        [1.0415],\n",
      "        [1.0078],\n",
      "        [1.0269],\n",
      "        [1.0432],\n",
      "        [1.0124],\n",
      "        [1.0291],\n",
      "        [0.9817],\n",
      "        [1.0319],\n",
      "        [1.0426],\n",
      "        [1.0272],\n",
      "        [1.0278],\n",
      "        [1.0160],\n",
      "        [0.9832],\n",
      "        [1.0236],\n",
      "        [1.0147],\n",
      "        [0.9747],\n",
      "        [1.0438],\n",
      "        [1.0200],\n",
      "        [1.0412],\n",
      "        [1.0356],\n",
      "        [1.0267],\n",
      "        [1.0303],\n",
      "        [1.0155],\n",
      "        [1.0431],\n",
      "        [1.0387],\n",
      "        [1.0258],\n",
      "        [0.9990],\n",
      "        [1.0123],\n",
      "        [1.0128],\n",
      "        [1.0155],\n",
      "        [0.9689],\n",
      "        [1.0431],\n",
      "        [1.0200],\n",
      "        [1.0104],\n",
      "        [1.0363],\n",
      "        [1.0133],\n",
      "        [1.0190],\n",
      "        [0.9854],\n",
      "        [1.0101],\n",
      "        [0.9633],\n",
      "        [0.9646],\n",
      "        [0.9964],\n",
      "        [1.0190],\n",
      "        [0.9930],\n",
      "        [1.0295],\n",
      "        [0.9943],\n",
      "        [1.0311],\n",
      "        [1.0085],\n",
      "        [0.9955],\n",
      "        [1.0220],\n",
      "        [1.0349],\n",
      "        [1.0062],\n",
      "        [1.0278],\n",
      "        [0.9963],\n",
      "        [1.0281],\n",
      "        [0.9871],\n",
      "        [1.0357],\n",
      "        [1.0179],\n",
      "        [0.9882],\n",
      "        [1.0301],\n",
      "        [1.0198],\n",
      "        [1.0152],\n",
      "        [1.0430],\n",
      "        [1.0270],\n",
      "        [0.9522],\n",
      "        [0.9959],\n",
      "        [1.0392],\n",
      "        [0.9984],\n",
      "        [1.0416],\n",
      "        [1.0121],\n",
      "        [0.9871],\n",
      "        [1.0395],\n",
      "        [1.0323],\n",
      "        [1.0113],\n",
      "        [1.0090],\n",
      "        [1.0316],\n",
      "        [0.9951],\n",
      "        [1.0002],\n",
      "        [1.0102],\n",
      "        [1.0192],\n",
      "        [1.0143],\n",
      "        [0.9998],\n",
      "        [1.0043],\n",
      "        [0.9995],\n",
      "        [1.0279],\n",
      "        [0.9937],\n",
      "        [1.0296],\n",
      "        [0.9768],\n",
      "        [1.0033],\n",
      "        [0.9718],\n",
      "        [1.0238],\n",
      "        [1.0355],\n",
      "        [1.0213],\n",
      "        [0.9663],\n",
      "        [1.0124],\n",
      "        [1.0379],\n",
      "        [1.0062],\n",
      "        [0.9976],\n",
      "        [0.9984],\n",
      "        [0.9812],\n",
      "        [1.0207],\n",
      "        [1.0012],\n",
      "        [1.0116],\n",
      "        [1.0238],\n",
      "        [1.0104],\n",
      "        [1.0209],\n",
      "        [1.0416],\n",
      "        [1.0195],\n",
      "        [1.0113],\n",
      "        [1.0043],\n",
      "        [0.9979],\n",
      "        [1.0153],\n",
      "        [1.0318],\n",
      "        [1.0234],\n",
      "        [1.0043],\n",
      "        [1.0055],\n",
      "        [1.0043],\n",
      "        [1.0340]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0112],\n",
      "        [1.0226],\n",
      "        [1.0311],\n",
      "        [1.0348],\n",
      "        [1.0123],\n",
      "        [1.0030],\n",
      "        [1.0172],\n",
      "        [1.0231],\n",
      "        [1.0315],\n",
      "        [1.0500],\n",
      "        [0.9704],\n",
      "        [1.0359],\n",
      "        [1.0201],\n",
      "        [0.9895],\n",
      "        [1.0456],\n",
      "        [1.0233],\n",
      "        [1.0272],\n",
      "        [1.0192],\n",
      "        [1.0344],\n",
      "        [1.0108],\n",
      "        [1.0225],\n",
      "        [1.0239],\n",
      "        [1.0223],\n",
      "        [0.9985],\n",
      "        [1.0345],\n",
      "        [1.0211],\n",
      "        [1.0335],\n",
      "        [1.0065],\n",
      "        [1.0171],\n",
      "        [1.0343],\n",
      "        [1.0432],\n",
      "        [1.0410],\n",
      "        [1.0307],\n",
      "        [1.0409],\n",
      "        [1.0460],\n",
      "        [1.0391],\n",
      "        [1.0465],\n",
      "        [0.9961],\n",
      "        [1.0370],\n",
      "        [1.0260],\n",
      "        [1.0384],\n",
      "        [1.0096],\n",
      "        [1.0115],\n",
      "        [1.0180],\n",
      "        [1.0232],\n",
      "        [0.9943],\n",
      "        [1.0234],\n",
      "        [1.0094],\n",
      "        [1.0256],\n",
      "        [1.0292],\n",
      "        [1.0475],\n",
      "        [1.0484],\n",
      "        [0.9743],\n",
      "        [1.0246],\n",
      "        [1.0304],\n",
      "        [1.0083],\n",
      "        [0.9956],\n",
      "        [1.0236],\n",
      "        [1.0334],\n",
      "        [1.0461],\n",
      "        [1.0469],\n",
      "        [1.0456],\n",
      "        [1.0474],\n",
      "        [1.0511],\n",
      "        [0.9750],\n",
      "        [0.9850],\n",
      "        [1.0357],\n",
      "        [1.0293],\n",
      "        [1.0479],\n",
      "        [0.6746],\n",
      "        [1.0319],\n",
      "        [1.0278],\n",
      "        [1.0058],\n",
      "        [1.0466],\n",
      "        [1.0160],\n",
      "        [1.0105],\n",
      "        [1.0227],\n",
      "        [1.0049],\n",
      "        [1.0461],\n",
      "        [0.9948],\n",
      "        [0.9947],\n",
      "        [1.0293],\n",
      "        [1.0264],\n",
      "        [1.0071],\n",
      "        [1.0261],\n",
      "        [1.0388],\n",
      "        [1.0308],\n",
      "        [1.0144],\n",
      "        [1.0448],\n",
      "        [1.0278],\n",
      "        [1.0136],\n",
      "        [1.0410],\n",
      "        [1.0097],\n",
      "        [0.9461],\n",
      "        [1.0110],\n",
      "        [1.0384],\n",
      "        [0.9850],\n",
      "        [1.0440],\n",
      "        [0.9870],\n",
      "        [1.0313],\n",
      "        [1.0198],\n",
      "        [1.0326],\n",
      "        [1.0368],\n",
      "        [1.0420],\n",
      "        [0.9917],\n",
      "        [1.0213],\n",
      "        [1.0258],\n",
      "        [1.0400],\n",
      "        [1.0292],\n",
      "        [1.0431],\n",
      "        [1.0331],\n",
      "        [1.0098],\n",
      "        [1.0018],\n",
      "        [1.0263],\n",
      "        [1.0257],\n",
      "        [1.0212],\n",
      "        [1.0348],\n",
      "        [1.0229],\n",
      "        [0.9763],\n",
      "        [1.0150],\n",
      "        [1.0105],\n",
      "        [0.9899],\n",
      "        [0.9573],\n",
      "        [1.0263],\n",
      "        [0.9924],\n",
      "        [1.0252],\n",
      "        [1.0470],\n",
      "        [0.9951]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0087],\n",
      "        [1.0277],\n",
      "        [0.9913],\n",
      "        [1.0518],\n",
      "        [1.0507],\n",
      "        [0.9886],\n",
      "        [1.0415],\n",
      "        [1.0262],\n",
      "        [1.0512],\n",
      "        [1.0168],\n",
      "        [1.0195],\n",
      "        [1.0579],\n",
      "        [1.0177],\n",
      "        [1.0278],\n",
      "        [1.0038],\n",
      "        [1.0256],\n",
      "        [1.0545],\n",
      "        [1.0273],\n",
      "        [1.0495],\n",
      "        [0.9982],\n",
      "        [1.0558],\n",
      "        [1.0417],\n",
      "        [1.0557],\n",
      "        [1.0576],\n",
      "        [1.0480],\n",
      "        [1.0097],\n",
      "        [1.0414],\n",
      "        [1.0120],\n",
      "        [1.0503],\n",
      "        [1.0483],\n",
      "        [1.0299],\n",
      "        [1.0144],\n",
      "        [1.0440],\n",
      "        [1.0244],\n",
      "        [1.0006],\n",
      "        [1.0315],\n",
      "        [1.0432],\n",
      "        [1.0212],\n",
      "        [1.0571],\n",
      "        [1.0348],\n",
      "        [1.0486],\n",
      "        [1.0156],\n",
      "        [1.0118],\n",
      "        [1.0467],\n",
      "        [1.0404],\n",
      "        [1.0123],\n",
      "        [0.9490],\n",
      "        [1.0181],\n",
      "        [1.0127],\n",
      "        [1.0150],\n",
      "        [1.0198],\n",
      "        [1.0522],\n",
      "        [1.0027],\n",
      "        [1.0112],\n",
      "        [0.9985],\n",
      "        [0.9918],\n",
      "        [1.0141],\n",
      "        [1.0345],\n",
      "        [1.0486],\n",
      "        [1.0569],\n",
      "        [1.0340],\n",
      "        [1.0175],\n",
      "        [1.0335],\n",
      "        [1.0500],\n",
      "        [1.0497],\n",
      "        [1.0520],\n",
      "        [0.0508],\n",
      "        [1.0121],\n",
      "        [1.0520],\n",
      "        [1.0231],\n",
      "        [1.0422],\n",
      "        [1.0251],\n",
      "        [1.0567],\n",
      "        [1.0480],\n",
      "        [1.0318],\n",
      "        [0.9891],\n",
      "        [1.0555],\n",
      "        [1.0542],\n",
      "        [1.0361],\n",
      "        [1.0342],\n",
      "        [1.0204],\n",
      "        [1.0117],\n",
      "        [0.9950],\n",
      "        [1.0094],\n",
      "        [1.0551],\n",
      "        [1.0415],\n",
      "        [1.0531],\n",
      "        [1.0202],\n",
      "        [1.0346],\n",
      "        [1.0209],\n",
      "        [1.0256],\n",
      "        [1.0436],\n",
      "        [1.0469],\n",
      "        [1.0465],\n",
      "        [1.0218],\n",
      "        [1.0569],\n",
      "        [1.0244],\n",
      "        [1.0488],\n",
      "        [1.0411],\n",
      "        [0.9881],\n",
      "        [1.0293],\n",
      "        [1.0348],\n",
      "        [1.0385],\n",
      "        [1.0232],\n",
      "        [1.0105],\n",
      "        [0.9831],\n",
      "        [1.0169],\n",
      "        [1.0569],\n",
      "        [1.0256],\n",
      "        [1.0320],\n",
      "        [1.0507],\n",
      "        [1.0367],\n",
      "        [1.0347],\n",
      "        [1.0453],\n",
      "        [1.0105],\n",
      "        [1.0307],\n",
      "        [1.0429],\n",
      "        [1.0377],\n",
      "        [1.0174],\n",
      "        [1.0397],\n",
      "        [1.0225],\n",
      "        [1.0259],\n",
      "        [1.0368],\n",
      "        [1.0124],\n",
      "        [1.0386],\n",
      "        [1.0369],\n",
      "        [1.0439],\n",
      "        [0.9952]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0123],\n",
      "        [1.0545],\n",
      "        [1.0388],\n",
      "        [1.0539],\n",
      "        [1.0270],\n",
      "        [0.9718],\n",
      "        [1.0485],\n",
      "        [1.0509],\n",
      "        [1.0438],\n",
      "        [1.0489],\n",
      "        [1.0146],\n",
      "        [1.0186],\n",
      "        [1.0615],\n",
      "        [1.0497],\n",
      "        [1.0057],\n",
      "        [1.0335],\n",
      "        [1.0383],\n",
      "        [1.0532],\n",
      "        [1.0376],\n",
      "        [1.0328],\n",
      "        [1.0337],\n",
      "        [1.0229],\n",
      "        [0.9863],\n",
      "        [1.0328],\n",
      "        [1.0056],\n",
      "        [1.0182],\n",
      "        [1.0505],\n",
      "        [1.0487],\n",
      "        [1.0617],\n",
      "        [1.0590],\n",
      "        [1.0642],\n",
      "        [1.0634],\n",
      "        [1.0389],\n",
      "        [1.0490],\n",
      "        [1.0290],\n",
      "        [1.0101],\n",
      "        [1.0458],\n",
      "        [1.0296],\n",
      "        [1.0373],\n",
      "        [1.0130],\n",
      "        [1.0300],\n",
      "        [1.0517],\n",
      "        [1.0591],\n",
      "        [1.0455],\n",
      "        [1.0350],\n",
      "        [1.0594],\n",
      "        [1.0458],\n",
      "        [1.0323],\n",
      "        [1.0480],\n",
      "        [1.0474],\n",
      "        [1.0183],\n",
      "        [1.0520],\n",
      "        [1.0396],\n",
      "        [1.0384],\n",
      "        [1.0402],\n",
      "        [1.0550],\n",
      "        [1.0377],\n",
      "        [1.0441],\n",
      "        [1.0413],\n",
      "        [0.9916],\n",
      "        [1.0629],\n",
      "        [1.0483],\n",
      "        [1.0614],\n",
      "        [1.0437],\n",
      "        [1.0136],\n",
      "        [1.0151],\n",
      "        [1.0260],\n",
      "        [1.0458],\n",
      "        [0.9939],\n",
      "        [1.0518],\n",
      "        [1.0457],\n",
      "        [1.0512],\n",
      "        [1.0335],\n",
      "        [1.0114],\n",
      "        [1.0300],\n",
      "        [1.0627],\n",
      "        [0.9998],\n",
      "        [1.0574],\n",
      "        [1.0383],\n",
      "        [1.0503],\n",
      "        [1.0409],\n",
      "        [1.0558],\n",
      "        [0.9986],\n",
      "        [1.0165],\n",
      "        [1.0136],\n",
      "        [0.9893],\n",
      "        [1.0547],\n",
      "        [1.0176],\n",
      "        [1.0291],\n",
      "        [1.0560],\n",
      "        [1.0280],\n",
      "        [1.0588],\n",
      "        [1.0029],\n",
      "        [1.0473],\n",
      "        [1.0412],\n",
      "        [1.0287],\n",
      "        [1.0293],\n",
      "        [1.0236],\n",
      "        [1.0190],\n",
      "        [0.9875],\n",
      "        [1.0264],\n",
      "        [1.0014],\n",
      "        [0.9923],\n",
      "        [1.0627],\n",
      "        [1.0059],\n",
      "        [1.0367],\n",
      "        [1.0124],\n",
      "        [1.0151],\n",
      "        [1.0635],\n",
      "        [0.9824],\n",
      "        [1.0355],\n",
      "        [1.0486],\n",
      "        [1.0476],\n",
      "        [1.0629],\n",
      "        [1.0483],\n",
      "        [1.0430],\n",
      "        [1.0176],\n",
      "        [1.0614],\n",
      "        [1.0220],\n",
      "        [1.0129],\n",
      "        [1.0427],\n",
      "        [1.0293],\n",
      "        [1.0396],\n",
      "        [1.0605],\n",
      "        [0.9645],\n",
      "        [1.0185],\n",
      "        [1.0307],\n",
      "        [1.0250]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0600],\n",
      "        [1.0056],\n",
      "        [1.0195],\n",
      "        [1.0326],\n",
      "        [1.0107],\n",
      "        [1.0625],\n",
      "        [1.0412],\n",
      "        [1.0534],\n",
      "        [0.9933],\n",
      "        [1.0438],\n",
      "        [1.0534],\n",
      "        [1.0405],\n",
      "        [1.0383],\n",
      "        [1.0230],\n",
      "        [1.0661],\n",
      "        [1.0512],\n",
      "        [1.0355],\n",
      "        [1.0674],\n",
      "        [1.0237],\n",
      "        [1.0470],\n",
      "        [1.0497],\n",
      "        [1.0616],\n",
      "        [1.0633],\n",
      "        [1.0210],\n",
      "        [1.0394],\n",
      "        [1.0439],\n",
      "        [1.0203],\n",
      "        [1.0417],\n",
      "        [1.0593],\n",
      "        [1.0539],\n",
      "        [1.0692],\n",
      "        [1.0520],\n",
      "        [1.0056],\n",
      "        [1.0595],\n",
      "        [1.0565],\n",
      "        [1.0181],\n",
      "        [1.0530],\n",
      "        [1.0429],\n",
      "        [1.0651],\n",
      "        [1.0503],\n",
      "        [1.0602],\n",
      "        [1.0499],\n",
      "        [1.0379],\n",
      "        [1.0617],\n",
      "        [1.0069],\n",
      "        [1.0069],\n",
      "        [1.0345],\n",
      "        [1.0542],\n",
      "        [1.0179],\n",
      "        [1.0672],\n",
      "        [1.0340],\n",
      "        [1.0260],\n",
      "        [1.0380],\n",
      "        [1.0201],\n",
      "        [1.0341],\n",
      "        [1.0256],\n",
      "        [1.0657],\n",
      "        [1.0087],\n",
      "        [1.0575],\n",
      "        [1.0075],\n",
      "        [1.0438],\n",
      "        [1.0587],\n",
      "        [1.0649],\n",
      "        [1.0576],\n",
      "        [1.0418],\n",
      "        [1.0661],\n",
      "        [1.0433],\n",
      "        [1.0190],\n",
      "        [1.0589],\n",
      "        [1.0334],\n",
      "        [1.0317],\n",
      "        [1.0667],\n",
      "        [1.0234],\n",
      "        [1.0409],\n",
      "        [1.0642],\n",
      "        [1.0488],\n",
      "        [1.0247],\n",
      "        [1.0526],\n",
      "        [1.0549],\n",
      "        [1.0231],\n",
      "        [1.0213],\n",
      "        [1.0637],\n",
      "        [1.0395],\n",
      "        [1.0183],\n",
      "        [1.0031],\n",
      "        [1.0248],\n",
      "        [1.0550],\n",
      "        [1.0642],\n",
      "        [1.0019],\n",
      "        [1.0486],\n",
      "        [0.9938],\n",
      "        [1.0649],\n",
      "        [1.0510],\n",
      "        [1.0244],\n",
      "        [0.9884],\n",
      "        [1.0302],\n",
      "        [1.0333],\n",
      "        [1.0678],\n",
      "        [1.0569],\n",
      "        [1.0610],\n",
      "        [1.0207],\n",
      "        [1.0285],\n",
      "        [0.9875],\n",
      "        [0.9891],\n",
      "        [1.0551],\n",
      "        [0.9942],\n",
      "        [1.0568],\n",
      "        [1.0378],\n",
      "        [1.0332],\n",
      "        [1.0583],\n",
      "        [1.0295],\n",
      "        [1.0594],\n",
      "        [1.0574],\n",
      "        [1.0129],\n",
      "        [1.0359],\n",
      "        [1.0676],\n",
      "        [1.0189],\n",
      "        [1.0652],\n",
      "        [1.0449],\n",
      "        [1.0567],\n",
      "        [1.0677],\n",
      "        [1.0645],\n",
      "        [1.0474],\n",
      "        [1.0058],\n",
      "        [1.0328],\n",
      "        [1.0148],\n",
      "        [1.0433],\n",
      "        [1.0430]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0624],\n",
      "        [1.0231],\n",
      "        [1.0609],\n",
      "        [1.0185],\n",
      "        [1.0224],\n",
      "        [1.0032],\n",
      "        [1.0708],\n",
      "        [1.0585],\n",
      "        [1.0116],\n",
      "        [1.0363],\n",
      "        [1.0417],\n",
      "        [1.0715],\n",
      "        [1.0347],\n",
      "        [1.0491],\n",
      "        [1.0633],\n",
      "        [1.0701],\n",
      "        [1.0389],\n",
      "        [1.0235],\n",
      "        [1.0591],\n",
      "        [1.0451],\n",
      "        [1.0361],\n",
      "        [1.0420],\n",
      "        [1.0396],\n",
      "        [1.0499],\n",
      "        [1.0541],\n",
      "        [1.0063],\n",
      "        [1.0460],\n",
      "        [1.0276],\n",
      "        [1.0537],\n",
      "        [1.0454],\n",
      "        [1.0338],\n",
      "        [1.0733],\n",
      "        [1.0743],\n",
      "        [1.0541],\n",
      "        [1.0562],\n",
      "        [1.0484],\n",
      "        [1.0463],\n",
      "        [1.0353],\n",
      "        [1.0151],\n",
      "        [1.0403],\n",
      "        [1.0476],\n",
      "        [1.0105],\n",
      "        [1.0407],\n",
      "        [0.9964],\n",
      "        [1.0479],\n",
      "        [1.0145],\n",
      "        [0.9828],\n",
      "        [1.0436],\n",
      "        [1.0108],\n",
      "        [1.0601],\n",
      "        [1.0044],\n",
      "        [1.0360],\n",
      "        [1.0321],\n",
      "        [1.0538],\n",
      "        [1.0336],\n",
      "        [1.0339],\n",
      "        [1.0169],\n",
      "        [1.0580],\n",
      "        [1.0505],\n",
      "        [1.0541],\n",
      "        [1.0252],\n",
      "        [1.0615],\n",
      "        [1.0240],\n",
      "        [1.0265],\n",
      "        [1.0301],\n",
      "        [0.9417],\n",
      "        [0.9917],\n",
      "        [1.0492],\n",
      "        [1.0190],\n",
      "        [1.0362],\n",
      "        [1.0335],\n",
      "        [0.9967],\n",
      "        [1.0477],\n",
      "        [1.0549],\n",
      "        [1.0369],\n",
      "        [1.0705],\n",
      "        [1.0402],\n",
      "        [1.0555],\n",
      "        [1.0616],\n",
      "        [1.0317],\n",
      "        [1.0587],\n",
      "        [1.0123],\n",
      "        [1.0136],\n",
      "        [1.0599],\n",
      "        [1.0223],\n",
      "        [1.0680],\n",
      "        [1.0508],\n",
      "        [1.0675],\n",
      "        [1.0483],\n",
      "        [1.0670],\n",
      "        [1.0535],\n",
      "        [1.0501],\n",
      "        [1.0489],\n",
      "        [0.9942],\n",
      "        [1.0569],\n",
      "        [1.0402],\n",
      "        [0.1473],\n",
      "        [1.0563],\n",
      "        [1.0658],\n",
      "        [1.0222],\n",
      "        [1.0689],\n",
      "        [1.0592],\n",
      "        [1.0709],\n",
      "        [1.0456],\n",
      "        [1.0508],\n",
      "        [1.0558],\n",
      "        [1.0484],\n",
      "        [1.0319],\n",
      "        [1.0317],\n",
      "        [1.0680],\n",
      "        [1.0410],\n",
      "        [1.0355],\n",
      "        [1.0195],\n",
      "        [1.0249],\n",
      "        [1.0211],\n",
      "        [1.0482],\n",
      "        [1.0173],\n",
      "        [1.0134],\n",
      "        [0.9821],\n",
      "        [1.0175],\n",
      "        [1.0620],\n",
      "        [1.0698],\n",
      "        [1.0066],\n",
      "        [1.0675],\n",
      "        [1.0434],\n",
      "        [1.0699],\n",
      "        [1.0266],\n",
      "        [1.0550]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0232],\n",
      "        [1.0345],\n",
      "        [1.0622],\n",
      "        [1.0747]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   4 | lr 0.00100 train_loss 2.13092 | val_loss 2.30236 | val_rmse 1.51735\n",
      "tensor([[1.0471],\n",
      "        [1.0635],\n",
      "        [1.0739],\n",
      "        [1.0491],\n",
      "        [1.0406],\n",
      "        [1.0660],\n",
      "        [1.0133],\n",
      "        [1.0787],\n",
      "        [1.0869],\n",
      "        [1.0776],\n",
      "        [1.0853],\n",
      "        [1.0676],\n",
      "        [1.0803],\n",
      "        [1.0855],\n",
      "        [1.0652],\n",
      "        [1.0867],\n",
      "        [1.0613],\n",
      "        [1.0548],\n",
      "        [1.0553],\n",
      "        [1.0534],\n",
      "        [1.0375],\n",
      "        [1.0772],\n",
      "        [1.0048],\n",
      "        [1.0473],\n",
      "        [0.9879],\n",
      "        [1.0496],\n",
      "        [1.0643],\n",
      "        [1.0262],\n",
      "        [1.0735],\n",
      "        [1.0446],\n",
      "        [1.0883],\n",
      "        [1.0769],\n",
      "        [1.0681],\n",
      "        [1.0386],\n",
      "        [1.0573],\n",
      "        [1.0500],\n",
      "        [1.0564],\n",
      "        [1.0381],\n",
      "        [1.0259],\n",
      "        [1.0710],\n",
      "        [1.0205],\n",
      "        [1.0299],\n",
      "        [1.0583],\n",
      "        [1.0338],\n",
      "        [1.0214],\n",
      "        [1.0643],\n",
      "        [1.0300],\n",
      "        [1.0535],\n",
      "        [1.0554],\n",
      "        [0.9770],\n",
      "        [1.0498],\n",
      "        [1.0820],\n",
      "        [1.0615],\n",
      "        [1.0432],\n",
      "        [1.0717],\n",
      "        [1.0645],\n",
      "        [1.0275],\n",
      "        [1.0511],\n",
      "        [1.0841],\n",
      "        [1.0669],\n",
      "        [1.0474],\n",
      "        [1.0407],\n",
      "        [1.0490],\n",
      "        [1.0757],\n",
      "        [1.0207],\n",
      "        [1.0618],\n",
      "        [1.0740],\n",
      "        [1.0851],\n",
      "        [1.0588],\n",
      "        [1.0690],\n",
      "        [1.0760],\n",
      "        [1.0515],\n",
      "        [1.0267],\n",
      "        [1.0582],\n",
      "        [1.0581],\n",
      "        [1.0109],\n",
      "        [1.0790],\n",
      "        [1.0747],\n",
      "        [1.0428],\n",
      "        [1.0645],\n",
      "        [1.0842],\n",
      "        [1.0534],\n",
      "        [1.0618],\n",
      "        [1.0714],\n",
      "        [1.0240],\n",
      "        [1.0585],\n",
      "        [1.0763],\n",
      "        [1.0413],\n",
      "        [1.0571],\n",
      "        [1.0094],\n",
      "        [1.0708],\n",
      "        [1.0550],\n",
      "        [1.0615],\n",
      "        [1.0659],\n",
      "        [1.0190],\n",
      "        [1.0642],\n",
      "        [1.0349],\n",
      "        [1.0376],\n",
      "        [1.0565],\n",
      "        [1.0758],\n",
      "        [1.0610],\n",
      "        [1.0863],\n",
      "        [1.0732],\n",
      "        [1.0127],\n",
      "        [1.0777],\n",
      "        [1.0322],\n",
      "        [1.0634],\n",
      "        [1.0720],\n",
      "        [1.0562],\n",
      "        [1.0817],\n",
      "        [1.0714],\n",
      "        [1.0450],\n",
      "        [1.0484],\n",
      "        [1.0716],\n",
      "        [1.0713],\n",
      "        [1.0612],\n",
      "        [1.0723],\n",
      "        [1.0329],\n",
      "        [1.0494],\n",
      "        [1.0863],\n",
      "        [1.0308],\n",
      "        [1.0578],\n",
      "        [1.0451],\n",
      "        [1.0363],\n",
      "        [1.0382],\n",
      "        [1.0789],\n",
      "        [1.0750],\n",
      "        [1.0591]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0788],\n",
      "        [1.0605],\n",
      "        [1.0443],\n",
      "        [1.0791],\n",
      "        [1.0696],\n",
      "        [1.0646],\n",
      "        [1.0292],\n",
      "        [1.0550],\n",
      "        [1.0540],\n",
      "        [1.0293],\n",
      "        [1.0850],\n",
      "        [1.0697],\n",
      "        [1.0587],\n",
      "        [1.0936],\n",
      "        [1.0800],\n",
      "        [1.0867],\n",
      "        [1.0535],\n",
      "        [1.0608],\n",
      "        [1.0798],\n",
      "        [1.0553],\n",
      "        [1.0825],\n",
      "        [1.0891],\n",
      "        [1.0585],\n",
      "        [1.0581],\n",
      "        [1.0634],\n",
      "        [1.0413],\n",
      "        [1.0651],\n",
      "        [1.0545],\n",
      "        [1.0032],\n",
      "        [1.0467],\n",
      "        [1.0811],\n",
      "        [1.0681],\n",
      "        [1.0406],\n",
      "        [1.0647],\n",
      "        [1.0712],\n",
      "        [1.0901],\n",
      "        [1.0466],\n",
      "        [1.0913],\n",
      "        [1.0907],\n",
      "        [1.0435],\n",
      "        [1.0799],\n",
      "        [1.0346],\n",
      "        [1.0683],\n",
      "        [1.0777],\n",
      "        [1.0700],\n",
      "        [1.0555],\n",
      "        [1.0957],\n",
      "        [1.0630],\n",
      "        [1.0953],\n",
      "        [1.0637],\n",
      "        [1.0602],\n",
      "        [1.0672],\n",
      "        [1.0513],\n",
      "        [1.0833],\n",
      "        [1.0688],\n",
      "        [1.0710],\n",
      "        [1.0814],\n",
      "        [1.0530],\n",
      "        [1.0886],\n",
      "        [1.0870],\n",
      "        [1.0838],\n",
      "        [1.0895],\n",
      "        [1.0119],\n",
      "        [1.0565],\n",
      "        [1.0841],\n",
      "        [1.0577],\n",
      "        [1.0949],\n",
      "        [1.0557],\n",
      "        [1.0883],\n",
      "        [1.0392],\n",
      "        [1.0370],\n",
      "        [1.0683],\n",
      "        [1.0846],\n",
      "        [1.0812],\n",
      "        [1.0912],\n",
      "        [1.0891],\n",
      "        [1.0452],\n",
      "        [1.0936],\n",
      "        [1.0805],\n",
      "        [1.0950],\n",
      "        [1.0818],\n",
      "        [1.0917],\n",
      "        [1.0829],\n",
      "        [1.0929],\n",
      "        [1.0949],\n",
      "        [1.0511],\n",
      "        [1.0614],\n",
      "        [1.0898],\n",
      "        [1.0769],\n",
      "        [1.0626],\n",
      "        [1.0677],\n",
      "        [1.0543],\n",
      "        [1.0799],\n",
      "        [1.0930],\n",
      "        [1.0835],\n",
      "        [1.0885],\n",
      "        [1.0502],\n",
      "        [1.0902],\n",
      "        [1.0363],\n",
      "        [1.0960],\n",
      "        [1.0926],\n",
      "        [1.0902],\n",
      "        [1.0910],\n",
      "        [1.0931],\n",
      "        [1.0921],\n",
      "        [1.0949],\n",
      "        [1.0465],\n",
      "        [1.0719],\n",
      "        [1.0701],\n",
      "        [1.0564],\n",
      "        [1.0564],\n",
      "        [1.0626],\n",
      "        [1.0927],\n",
      "        [1.0744],\n",
      "        [1.0908],\n",
      "        [1.0688],\n",
      "        [1.0421],\n",
      "        [1.0585],\n",
      "        [1.0538],\n",
      "        [1.0606],\n",
      "        [1.0432],\n",
      "        [1.0530],\n",
      "        [1.0681],\n",
      "        [1.0493],\n",
      "        [1.0019],\n",
      "        [1.0863],\n",
      "        [1.0721],\n",
      "        [1.0495]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0900],\n",
      "        [1.0860],\n",
      "        [1.0636],\n",
      "        [1.0999],\n",
      "        [1.0798],\n",
      "        [1.0986],\n",
      "        [1.0822],\n",
      "        [1.0286],\n",
      "        [1.1025],\n",
      "        [1.0714],\n",
      "        [1.1027],\n",
      "        [1.0697],\n",
      "        [1.0885],\n",
      "        [1.0590],\n",
      "        [1.0605],\n",
      "        [1.0949],\n",
      "        [1.0687],\n",
      "        [1.0993],\n",
      "        [1.0812],\n",
      "        [1.0760],\n",
      "        [1.0564],\n",
      "        [1.0499],\n",
      "        [1.0683],\n",
      "        [1.0212],\n",
      "        [1.0876],\n",
      "        [1.0394],\n",
      "        [1.0283],\n",
      "        [1.0790],\n",
      "        [1.0997],\n",
      "        [1.0686],\n",
      "        [1.0508],\n",
      "        [1.0723],\n",
      "        [1.0695],\n",
      "        [1.0969],\n",
      "        [1.0653],\n",
      "        [1.0355],\n",
      "        [1.0392],\n",
      "        [1.0644],\n",
      "        [1.0661],\n",
      "        [1.0649],\n",
      "        [1.0832],\n",
      "        [1.1002],\n",
      "        [1.0430],\n",
      "        [1.0567],\n",
      "        [1.0956],\n",
      "        [1.0701],\n",
      "        [1.0440],\n",
      "        [1.0402],\n",
      "        [1.0725],\n",
      "        [1.0419],\n",
      "        [1.0671],\n",
      "        [1.0692],\n",
      "        [1.0673],\n",
      "        [1.0773],\n",
      "        [1.0470],\n",
      "        [1.0985],\n",
      "        [1.0411],\n",
      "        [0.9722],\n",
      "        [1.0841],\n",
      "        [1.0843],\n",
      "        [1.0787],\n",
      "        [1.0744],\n",
      "        [1.0827],\n",
      "        [1.0419],\n",
      "        [1.0751],\n",
      "        [1.0814],\n",
      "        [1.0834],\n",
      "        [1.0899],\n",
      "        [1.0690],\n",
      "        [1.0860],\n",
      "        [1.0654],\n",
      "        [1.0316],\n",
      "        [1.0937],\n",
      "        [1.0620],\n",
      "        [1.0460],\n",
      "        [1.0785],\n",
      "        [1.0554],\n",
      "        [1.0831],\n",
      "        [1.0989],\n",
      "        [1.0679],\n",
      "        [1.0958],\n",
      "        [1.1007],\n",
      "        [1.0600],\n",
      "        [1.0940],\n",
      "        [1.0813],\n",
      "        [1.0906],\n",
      "        [1.0133],\n",
      "        [1.0762],\n",
      "        [1.0690],\n",
      "        [1.0866],\n",
      "        [1.1003],\n",
      "        [1.0879],\n",
      "        [1.0488],\n",
      "        [1.0942],\n",
      "        [1.0876],\n",
      "        [1.0812],\n",
      "        [1.0606],\n",
      "        [1.0946],\n",
      "        [1.0528],\n",
      "        [1.0788],\n",
      "        [1.0904],\n",
      "        [1.0614],\n",
      "        [1.0858],\n",
      "        [1.0823],\n",
      "        [1.0913],\n",
      "        [1.0368],\n",
      "        [1.0421],\n",
      "        [1.0777],\n",
      "        [1.0791],\n",
      "        [1.0774],\n",
      "        [1.0626],\n",
      "        [1.0466],\n",
      "        [1.1007],\n",
      "        [1.0551],\n",
      "        [1.0592],\n",
      "        [1.0607],\n",
      "        [1.1027],\n",
      "        [1.0928],\n",
      "        [1.0965],\n",
      "        [1.0376],\n",
      "        [1.0910],\n",
      "        [1.0975],\n",
      "        [1.0904],\n",
      "        [1.0831],\n",
      "        [1.0973],\n",
      "        [1.0523],\n",
      "        [1.0912],\n",
      "        [1.0964]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1009],\n",
      "        [1.0984],\n",
      "        [1.0604],\n",
      "        [1.0778],\n",
      "        [1.0755],\n",
      "        [1.1097],\n",
      "        [1.0386],\n",
      "        [1.0561],\n",
      "        [1.0775],\n",
      "        [1.0677],\n",
      "        [1.0709],\n",
      "        [1.1011],\n",
      "        [1.0874],\n",
      "        [1.0768],\n",
      "        [1.1072],\n",
      "        [1.0601],\n",
      "        [1.0641],\n",
      "        [1.0730],\n",
      "        [1.0733],\n",
      "        [1.0903],\n",
      "        [1.0876],\n",
      "        [1.0694],\n",
      "        [1.1090],\n",
      "        [1.0948],\n",
      "        [1.0791],\n",
      "        [1.1032],\n",
      "        [1.0905],\n",
      "        [1.0699],\n",
      "        [1.0667],\n",
      "        [1.1083],\n",
      "        [1.0766],\n",
      "        [1.0861],\n",
      "        [1.0825],\n",
      "        [1.1047],\n",
      "        [1.0684],\n",
      "        [1.1076],\n",
      "        [1.0864],\n",
      "        [1.0958],\n",
      "        [1.0912],\n",
      "        [1.0751],\n",
      "        [1.0928],\n",
      "        [1.0662],\n",
      "        [1.0715],\n",
      "        [1.0832],\n",
      "        [1.1045],\n",
      "        [1.0842],\n",
      "        [1.1063],\n",
      "        [1.0990],\n",
      "        [1.0959],\n",
      "        [1.0580],\n",
      "        [1.1011],\n",
      "        [1.0946],\n",
      "        [1.0820],\n",
      "        [1.0946],\n",
      "        [1.0886],\n",
      "        [1.0852],\n",
      "        [1.0944],\n",
      "        [1.0911],\n",
      "        [1.0277],\n",
      "        [1.0785],\n",
      "        [1.1054],\n",
      "        [1.1016],\n",
      "        [1.0933],\n",
      "        [1.0962],\n",
      "        [1.0515],\n",
      "        [1.1084],\n",
      "        [1.0763],\n",
      "        [1.0645],\n",
      "        [1.1019],\n",
      "        [1.0752],\n",
      "        [1.0799],\n",
      "        [1.0904],\n",
      "        [1.0653],\n",
      "        [1.0987],\n",
      "        [1.0430],\n",
      "        [1.0898],\n",
      "        [1.0557],\n",
      "        [1.0627],\n",
      "        [1.0963],\n",
      "        [1.0920],\n",
      "        [1.0841],\n",
      "        [1.0536],\n",
      "        [1.0661],\n",
      "        [1.0969],\n",
      "        [1.0805],\n",
      "        [1.0894],\n",
      "        [1.0830],\n",
      "        [1.1071],\n",
      "        [1.0873],\n",
      "        [1.0381],\n",
      "        [1.0225],\n",
      "        [1.1034],\n",
      "        [1.0724],\n",
      "        [1.0694],\n",
      "        [1.0992],\n",
      "        [1.0907],\n",
      "        [1.0625],\n",
      "        [1.0780],\n",
      "        [1.0922],\n",
      "        [1.0848],\n",
      "        [1.0778],\n",
      "        [1.0667],\n",
      "        [1.0699],\n",
      "        [1.0796],\n",
      "        [1.0860],\n",
      "        [1.0741],\n",
      "        [1.0524],\n",
      "        [1.1085],\n",
      "        [1.0670],\n",
      "        [1.0881],\n",
      "        [1.0759],\n",
      "        [1.0876],\n",
      "        [1.0951],\n",
      "        [1.0655],\n",
      "        [1.0833],\n",
      "        [0.0174],\n",
      "        [1.0638],\n",
      "        [1.0637],\n",
      "        [1.0803],\n",
      "        [1.0386],\n",
      "        [1.0345],\n",
      "        [1.0514],\n",
      "        [1.0974],\n",
      "        [1.0706],\n",
      "        [1.0909],\n",
      "        [1.0902],\n",
      "        [1.0661],\n",
      "        [1.0838]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1115],\n",
      "        [1.1007],\n",
      "        [1.0975],\n",
      "        [1.0765],\n",
      "        [1.0489],\n",
      "        [1.1058],\n",
      "        [1.1004],\n",
      "        [1.1158],\n",
      "        [1.0910],\n",
      "        [1.1062],\n",
      "        [1.0767],\n",
      "        [1.0607],\n",
      "        [1.1147],\n",
      "        [1.0613],\n",
      "        [1.1039],\n",
      "        [1.0986],\n",
      "        [1.1087],\n",
      "        [1.1005],\n",
      "        [1.1061],\n",
      "        [1.1159],\n",
      "        [1.1162],\n",
      "        [1.1060],\n",
      "        [1.0649],\n",
      "        [1.0999],\n",
      "        [0.1766],\n",
      "        [1.0916],\n",
      "        [1.1044],\n",
      "        [1.0250],\n",
      "        [1.0979],\n",
      "        [1.1148],\n",
      "        [1.0949],\n",
      "        [1.1012],\n",
      "        [1.0665],\n",
      "        [1.0903],\n",
      "        [1.0375],\n",
      "        [1.0013],\n",
      "        [1.0732],\n",
      "        [1.0927],\n",
      "        [1.0693],\n",
      "        [1.1003],\n",
      "        [1.1082],\n",
      "        [1.0855],\n",
      "        [1.1132],\n",
      "        [1.0954],\n",
      "        [1.1161],\n",
      "        [1.1055],\n",
      "        [1.0990],\n",
      "        [1.0674],\n",
      "        [1.1078],\n",
      "        [1.0526],\n",
      "        [1.0709],\n",
      "        [1.1009],\n",
      "        [1.0131],\n",
      "        [1.0970],\n",
      "        [1.0461],\n",
      "        [1.1013],\n",
      "        [1.0643],\n",
      "        [1.0913],\n",
      "        [1.0892],\n",
      "        [1.1015],\n",
      "        [1.0985],\n",
      "        [1.1108],\n",
      "        [1.1104],\n",
      "        [1.0661],\n",
      "        [1.1126],\n",
      "        [1.0663],\n",
      "        [1.0481],\n",
      "        [1.1020],\n",
      "        [1.1162],\n",
      "        [1.0935],\n",
      "        [1.1069],\n",
      "        [1.0801],\n",
      "        [1.0773],\n",
      "        [1.0730],\n",
      "        [1.0827],\n",
      "        [1.0747],\n",
      "        [1.0856],\n",
      "        [1.0680],\n",
      "        [1.0360],\n",
      "        [1.0746],\n",
      "        [1.1185],\n",
      "        [1.1077],\n",
      "        [1.1012],\n",
      "        [1.0824],\n",
      "        [1.0419],\n",
      "        [1.1092],\n",
      "        [1.0878],\n",
      "        [1.1050],\n",
      "        [1.0803],\n",
      "        [1.0956],\n",
      "        [1.1017],\n",
      "        [1.0941],\n",
      "        [1.0894],\n",
      "        [1.0918],\n",
      "        [1.1121],\n",
      "        [1.1135],\n",
      "        [1.0900],\n",
      "        [1.1115],\n",
      "        [1.0592],\n",
      "        [1.0472],\n",
      "        [1.0948],\n",
      "        [1.1091],\n",
      "        [1.1157],\n",
      "        [1.0746],\n",
      "        [1.1079],\n",
      "        [1.0428],\n",
      "        [1.0561],\n",
      "        [1.0835],\n",
      "        [1.1094],\n",
      "        [1.0478],\n",
      "        [1.0987],\n",
      "        [1.0919],\n",
      "        [1.0584],\n",
      "        [1.0876],\n",
      "        [1.1041],\n",
      "        [1.0707],\n",
      "        [1.1164],\n",
      "        [1.0517],\n",
      "        [1.1010],\n",
      "        [1.0977],\n",
      "        [1.1068],\n",
      "        [1.0541],\n",
      "        [1.0721],\n",
      "        [1.0748],\n",
      "        [1.0958],\n",
      "        [1.0940],\n",
      "        [1.0836],\n",
      "        [1.0626]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0968],\n",
      "        [1.1043],\n",
      "        [1.1200],\n",
      "        [1.0955],\n",
      "        [1.0373],\n",
      "        [1.0450],\n",
      "        [1.0937],\n",
      "        [1.1008],\n",
      "        [1.1000],\n",
      "        [1.0835],\n",
      "        [1.1193],\n",
      "        [1.1218],\n",
      "        [1.1147],\n",
      "        [1.0889],\n",
      "        [1.0938],\n",
      "        [1.0749],\n",
      "        [1.0488],\n",
      "        [1.1208],\n",
      "        [1.0831],\n",
      "        [1.1021],\n",
      "        [1.0156],\n",
      "        [1.1066],\n",
      "        [1.0994],\n",
      "        [1.1020],\n",
      "        [1.0937],\n",
      "        [1.0813],\n",
      "        [1.1105],\n",
      "        [1.0847],\n",
      "        [1.0846],\n",
      "        [1.0582],\n",
      "        [1.0925],\n",
      "        [1.0903],\n",
      "        [1.1206],\n",
      "        [1.1198],\n",
      "        [1.0917],\n",
      "        [1.0911],\n",
      "        [1.1099],\n",
      "        [1.0940],\n",
      "        [1.0755],\n",
      "        [1.0802],\n",
      "        [1.0910],\n",
      "        [1.1196],\n",
      "        [1.0926],\n",
      "        [1.0805],\n",
      "        [1.0945],\n",
      "        [1.0997],\n",
      "        [1.0670],\n",
      "        [1.0871],\n",
      "        [1.1210],\n",
      "        [1.0784],\n",
      "        [1.0916],\n",
      "        [1.0895],\n",
      "        [1.0936],\n",
      "        [1.1192],\n",
      "        [1.0989],\n",
      "        [1.0972],\n",
      "        [1.0789],\n",
      "        [1.1069],\n",
      "        [1.0748],\n",
      "        [1.1125],\n",
      "        [1.0964],\n",
      "        [1.0620],\n",
      "        [1.0835],\n",
      "        [1.0767],\n",
      "        [1.1030],\n",
      "        [1.1056],\n",
      "        [1.0726],\n",
      "        [1.0705],\n",
      "        [1.1206],\n",
      "        [1.0776],\n",
      "        [1.1008],\n",
      "        [1.0490],\n",
      "        [1.1013],\n",
      "        [1.1127],\n",
      "        [0.7867],\n",
      "        [1.0750],\n",
      "        [1.0924],\n",
      "        [1.0648],\n",
      "        [1.1024],\n",
      "        [1.0938],\n",
      "        [1.0478],\n",
      "        [1.1093],\n",
      "        [1.0925],\n",
      "        [1.1157],\n",
      "        [1.0555],\n",
      "        [1.1192],\n",
      "        [1.0664],\n",
      "        [1.0446],\n",
      "        [1.0731],\n",
      "        [1.1094],\n",
      "        [1.1089],\n",
      "        [1.0665],\n",
      "        [1.1208],\n",
      "        [1.1024],\n",
      "        [1.0994],\n",
      "        [1.0832],\n",
      "        [1.1213],\n",
      "        [1.1147],\n",
      "        [1.1148],\n",
      "        [1.0989],\n",
      "        [1.1178],\n",
      "        [1.0988],\n",
      "        [1.0838],\n",
      "        [1.1202],\n",
      "        [1.1172],\n",
      "        [1.1074],\n",
      "        [1.0927],\n",
      "        [1.0909],\n",
      "        [1.1113],\n",
      "        [1.0832],\n",
      "        [1.1207],\n",
      "        [1.1031],\n",
      "        [1.0803],\n",
      "        [1.0647],\n",
      "        [1.0514],\n",
      "        [1.0890],\n",
      "        [1.1070],\n",
      "        [1.0764],\n",
      "        [1.1046],\n",
      "        [1.0643],\n",
      "        [1.0843],\n",
      "        [1.0784],\n",
      "        [1.1118],\n",
      "        [1.0875],\n",
      "        [1.1052],\n",
      "        [1.1035],\n",
      "        [1.0776],\n",
      "        [1.0899]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0746],\n",
      "        [1.0943],\n",
      "        [1.1024],\n",
      "        [1.0970],\n",
      "        [1.1151],\n",
      "        [1.0975],\n",
      "        [1.0801],\n",
      "        [1.0807],\n",
      "        [1.0951],\n",
      "        [1.0747],\n",
      "        [1.1145],\n",
      "        [1.1042],\n",
      "        [1.1131],\n",
      "        [1.1000],\n",
      "        [1.1122],\n",
      "        [1.1017],\n",
      "        [1.1172],\n",
      "        [1.0794],\n",
      "        [1.1023],\n",
      "        [1.0910],\n",
      "        [1.1073],\n",
      "        [1.1023],\n",
      "        [1.1000],\n",
      "        [1.0838],\n",
      "        [1.0489],\n",
      "        [1.0763],\n",
      "        [1.0732],\n",
      "        [1.0527],\n",
      "        [1.1154],\n",
      "        [1.1075],\n",
      "        [1.0982],\n",
      "        [1.1027],\n",
      "        [1.0629],\n",
      "        [1.0797],\n",
      "        [1.0880],\n",
      "        [1.1173],\n",
      "        [1.1161],\n",
      "        [1.1132],\n",
      "        [1.0999],\n",
      "        [1.1215],\n",
      "        [1.1257],\n",
      "        [1.0985],\n",
      "        [1.1261],\n",
      "        [1.0547],\n",
      "        [1.1102],\n",
      "        [1.1231],\n",
      "        [1.1257],\n",
      "        [1.1091],\n",
      "        [1.1253],\n",
      "        [1.0929],\n",
      "        [1.0834],\n",
      "        [1.0863],\n",
      "        [1.0513],\n",
      "        [1.1146],\n",
      "        [1.0325],\n",
      "        [1.0764],\n",
      "        [1.0994],\n",
      "        [1.1009],\n",
      "        [1.1061],\n",
      "        [1.1226],\n",
      "        [1.0790],\n",
      "        [1.1026],\n",
      "        [1.1068],\n",
      "        [1.0659],\n",
      "        [1.0756],\n",
      "        [1.1020],\n",
      "        [1.1165],\n",
      "        [1.0719],\n",
      "        [1.1111],\n",
      "        [1.1040],\n",
      "        [1.0970],\n",
      "        [1.1072],\n",
      "        [1.1072],\n",
      "        [1.0871],\n",
      "        [1.1025],\n",
      "        [1.1260],\n",
      "        [1.1169],\n",
      "        [1.0605],\n",
      "        [1.1157],\n",
      "        [1.0758],\n",
      "        [1.0873],\n",
      "        [1.0616],\n",
      "        [1.1096],\n",
      "        [1.1065],\n",
      "        [1.1120],\n",
      "        [1.1022],\n",
      "        [1.0800],\n",
      "        [1.1251],\n",
      "        [1.0863],\n",
      "        [1.1212],\n",
      "        [1.0155],\n",
      "        [1.0797],\n",
      "        [1.0393],\n",
      "        [1.0965],\n",
      "        [1.0442],\n",
      "        [1.0852],\n",
      "        [1.0767],\n",
      "        [1.0625],\n",
      "        [1.1130],\n",
      "        [1.0810],\n",
      "        [1.0855],\n",
      "        [1.0939],\n",
      "        [1.0938],\n",
      "        [1.1111],\n",
      "        [1.1081],\n",
      "        [1.1142],\n",
      "        [1.0983],\n",
      "        [1.1044],\n",
      "        [1.1099],\n",
      "        [1.0783],\n",
      "        [1.1071],\n",
      "        [1.1152],\n",
      "        [1.0969],\n",
      "        [1.0999],\n",
      "        [1.0995],\n",
      "        [1.0431],\n",
      "        [1.0803],\n",
      "        [1.1012],\n",
      "        [1.0921],\n",
      "        [1.1073],\n",
      "        [1.1063],\n",
      "        [1.0957],\n",
      "        [1.1193],\n",
      "        [1.1125],\n",
      "        [1.1030],\n",
      "        [1.1027],\n",
      "        [1.1131],\n",
      "        [1.1130]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0906],\n",
      "        [1.1116],\n",
      "        [1.1142],\n",
      "        [1.1007]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   5 | lr 0.00100 train_loss 2.12350 | val_loss 2.28797 | val_rmse 1.51260\n",
      "tensor([[1.1045],\n",
      "        [1.0801],\n",
      "        [1.1368],\n",
      "        [1.1100],\n",
      "        [1.0972],\n",
      "        [1.0512],\n",
      "        [1.1292],\n",
      "        [1.0927],\n",
      "        [1.0971],\n",
      "        [0.6492],\n",
      "        [1.1138],\n",
      "        [1.0691],\n",
      "        [1.1173],\n",
      "        [1.1280],\n",
      "        [1.1182],\n",
      "        [1.1101],\n",
      "        [1.0638],\n",
      "        [1.1115],\n",
      "        [1.1251],\n",
      "        [1.0956],\n",
      "        [1.1171],\n",
      "        [1.1191],\n",
      "        [1.1183],\n",
      "        [1.1115],\n",
      "        [1.0581],\n",
      "        [1.1251],\n",
      "        [1.0892],\n",
      "        [1.1176],\n",
      "        [1.1092],\n",
      "        [1.1164],\n",
      "        [1.1089],\n",
      "        [1.1143],\n",
      "        [1.1131],\n",
      "        [1.0840],\n",
      "        [1.0486],\n",
      "        [1.1008],\n",
      "        [1.1137],\n",
      "        [1.0256],\n",
      "        [1.1184],\n",
      "        [1.1166],\n",
      "        [1.0803],\n",
      "        [1.1026],\n",
      "        [1.1219],\n",
      "        [1.1060],\n",
      "        [1.1059],\n",
      "        [1.0790],\n",
      "        [1.1074],\n",
      "        [1.0350],\n",
      "        [1.1274],\n",
      "        [1.0777],\n",
      "        [1.0822],\n",
      "        [1.1326],\n",
      "        [1.1204],\n",
      "        [1.0603],\n",
      "        [1.0939],\n",
      "        [1.1048],\n",
      "        [1.1207],\n",
      "        [1.1264],\n",
      "        [1.6570],\n",
      "        [1.0931],\n",
      "        [1.1259],\n",
      "        [1.0989],\n",
      "        [1.0410],\n",
      "        [1.0763],\n",
      "        [1.1091],\n",
      "        [1.1020],\n",
      "        [1.1230],\n",
      "        [1.0976],\n",
      "        [1.0996],\n",
      "        [1.0894],\n",
      "        [1.0953],\n",
      "        [1.1280],\n",
      "        [1.1334],\n",
      "        [1.1171],\n",
      "        [0.3853],\n",
      "        [1.1002],\n",
      "        [1.1199],\n",
      "        [1.1007],\n",
      "        [1.1328],\n",
      "        [1.0651],\n",
      "        [1.1246],\n",
      "        [1.1327],\n",
      "        [1.0824],\n",
      "        [1.1239],\n",
      "        [1.1188],\n",
      "        [1.0965],\n",
      "        [1.1065],\n",
      "        [1.1284],\n",
      "        [1.1352],\n",
      "        [1.0997],\n",
      "        [1.0703],\n",
      "        [1.0856],\n",
      "        [1.1299],\n",
      "        [1.1105],\n",
      "        [1.1129],\n",
      "        [1.0831],\n",
      "        [1.1358],\n",
      "        [1.1310],\n",
      "        [1.1051],\n",
      "        [1.1237],\n",
      "        [1.1350],\n",
      "        [1.0917],\n",
      "        [1.0998],\n",
      "        [1.0794],\n",
      "        [1.0842],\n",
      "        [1.1341],\n",
      "        [1.1280],\n",
      "        [1.1190],\n",
      "        [1.1369],\n",
      "        [1.0664],\n",
      "        [1.1300],\n",
      "        [1.1066],\n",
      "        [1.1253],\n",
      "        [1.1345],\n",
      "        [1.1119],\n",
      "        [1.0703],\n",
      "        [1.1062],\n",
      "        [1.0975],\n",
      "        [1.0924],\n",
      "        [1.0955],\n",
      "        [1.0577],\n",
      "        [1.1234],\n",
      "        [1.1145],\n",
      "        [1.1213],\n",
      "        [1.1013],\n",
      "        [1.0950],\n",
      "        [1.1259],\n",
      "        [1.1138]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1372],\n",
      "        [1.1032],\n",
      "        [1.1384],\n",
      "        [1.0818],\n",
      "        [1.1267],\n",
      "        [1.1133],\n",
      "        [1.1014],\n",
      "        [1.1171],\n",
      "        [1.1257],\n",
      "        [1.1204],\n",
      "        [1.1399],\n",
      "        [1.1215],\n",
      "        [1.1277],\n",
      "        [1.1278],\n",
      "        [1.0974],\n",
      "        [1.1364],\n",
      "        [1.1278],\n",
      "        [1.1139],\n",
      "        [1.1228],\n",
      "        [1.1345],\n",
      "        [1.1101],\n",
      "        [1.1123],\n",
      "        [1.1107],\n",
      "        [1.1177],\n",
      "        [1.1418],\n",
      "        [1.1333],\n",
      "        [1.1171],\n",
      "        [1.1130],\n",
      "        [1.0981],\n",
      "        [1.1415],\n",
      "        [1.1145],\n",
      "        [1.1281],\n",
      "        [1.1425],\n",
      "        [1.1148],\n",
      "        [1.1137],\n",
      "        [1.1268],\n",
      "        [1.1011],\n",
      "        [1.1419],\n",
      "        [1.1410],\n",
      "        [1.1172],\n",
      "        [1.1179],\n",
      "        [1.1048],\n",
      "        [1.1167],\n",
      "        [1.1013],\n",
      "        [1.1394],\n",
      "        [1.0781],\n",
      "        [1.1429],\n",
      "        [1.1415],\n",
      "        [1.0911],\n",
      "        [1.0937],\n",
      "        [1.0528],\n",
      "        [1.1348],\n",
      "        [1.1295],\n",
      "        [1.1263],\n",
      "        [1.1102],\n",
      "        [1.1329],\n",
      "        [1.0900],\n",
      "        [1.1234],\n",
      "        [1.1367],\n",
      "        [1.1169],\n",
      "        [1.0769],\n",
      "        [1.1286],\n",
      "        [1.1436],\n",
      "        [1.1425],\n",
      "        [1.0742],\n",
      "        [1.0942],\n",
      "        [1.0879],\n",
      "        [1.1349],\n",
      "        [1.1443],\n",
      "        [1.0994],\n",
      "        [1.0613],\n",
      "        [1.1140],\n",
      "        [1.0861],\n",
      "        [1.1392],\n",
      "        [1.0429],\n",
      "        [1.1002],\n",
      "        [1.1264],\n",
      "        [1.1206],\n",
      "        [1.1225],\n",
      "        [1.1444],\n",
      "        [1.1283],\n",
      "        [1.1361],\n",
      "        [1.1203],\n",
      "        [1.0630],\n",
      "        [1.1163],\n",
      "        [1.1099],\n",
      "        [1.0919],\n",
      "        [1.1156],\n",
      "        [1.1413],\n",
      "        [1.1443],\n",
      "        [1.1185],\n",
      "        [1.1420],\n",
      "        [1.1067],\n",
      "        [1.1142],\n",
      "        [1.1277],\n",
      "        [1.0902],\n",
      "        [1.1409],\n",
      "        [1.1260],\n",
      "        [1.1330],\n",
      "        [1.1231],\n",
      "        [1.1064],\n",
      "        [1.1303],\n",
      "        [1.1238],\n",
      "        [1.1358],\n",
      "        [1.1416],\n",
      "        [1.1162],\n",
      "        [1.1241],\n",
      "        [1.1402],\n",
      "        [1.0450],\n",
      "        [1.1424],\n",
      "        [1.1322],\n",
      "        [1.1424],\n",
      "        [1.1355],\n",
      "        [1.1173],\n",
      "        [1.1047],\n",
      "        [1.1393],\n",
      "        [1.0974],\n",
      "        [1.1135],\n",
      "        [1.0715],\n",
      "        [1.1403],\n",
      "        [1.1178],\n",
      "        [1.1102],\n",
      "        [1.1037],\n",
      "        [1.1111],\n",
      "        [1.1173],\n",
      "        [1.0789],\n",
      "        [1.1374],\n",
      "        [1.1122]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1055],\n",
      "        [1.1199],\n",
      "        [1.0921],\n",
      "        [1.1339],\n",
      "        [1.1011],\n",
      "        [1.1478],\n",
      "        [1.1209],\n",
      "        [1.0830],\n",
      "        [1.1333],\n",
      "        [1.1250],\n",
      "        [1.1137],\n",
      "        [1.0819],\n",
      "        [1.0877],\n",
      "        [1.1481],\n",
      "        [1.1485],\n",
      "        [1.1196],\n",
      "        [1.0929],\n",
      "        [1.1444],\n",
      "        [1.1291],\n",
      "        [1.1262],\n",
      "        [1.1347],\n",
      "        [1.1099],\n",
      "        [1.1285],\n",
      "        [1.0918],\n",
      "        [1.0912],\n",
      "        [1.0999],\n",
      "        [1.1387],\n",
      "        [1.1156],\n",
      "        [1.0778],\n",
      "        [1.1298],\n",
      "        [1.1291],\n",
      "        [1.1491],\n",
      "        [1.0908],\n",
      "        [1.1335],\n",
      "        [1.1461],\n",
      "        [1.1190],\n",
      "        [1.0712],\n",
      "        [1.1026],\n",
      "        [1.1274],\n",
      "        [1.1280],\n",
      "        [1.1001],\n",
      "        [1.1131],\n",
      "        [1.1450],\n",
      "        [1.1414],\n",
      "        [1.1183],\n",
      "        [1.1060],\n",
      "        [1.1340],\n",
      "        [1.1171],\n",
      "        [1.0650],\n",
      "        [1.1149],\n",
      "        [1.1354],\n",
      "        [1.1438],\n",
      "        [1.0768],\n",
      "        [1.1214],\n",
      "        [1.1066],\n",
      "        [1.1402],\n",
      "        [1.1342],\n",
      "        [1.1278],\n",
      "        [1.1230],\n",
      "        [1.1434],\n",
      "        [1.1190],\n",
      "        [1.1463],\n",
      "        [1.1230],\n",
      "        [1.1483],\n",
      "        [1.1267],\n",
      "        [1.1481],\n",
      "        [1.0953],\n",
      "        [1.1183],\n",
      "        [1.1013],\n",
      "        [1.1042],\n",
      "        [1.1134],\n",
      "        [1.1100],\n",
      "        [1.1100],\n",
      "        [1.1153],\n",
      "        [1.1304],\n",
      "        [1.1057],\n",
      "        [1.1112],\n",
      "        [1.0809],\n",
      "        [1.1335],\n",
      "        [1.1247],\n",
      "        [1.0959],\n",
      "        [1.1174],\n",
      "        [1.1196],\n",
      "        [1.1154],\n",
      "        [1.0861],\n",
      "        [1.1048],\n",
      "        [1.1250],\n",
      "        [1.1091],\n",
      "        [1.1281],\n",
      "        [1.1385],\n",
      "        [1.1383],\n",
      "        [1.1008],\n",
      "        [1.1287],\n",
      "        [1.1103],\n",
      "        [1.1229],\n",
      "        [1.1307],\n",
      "        [1.1042],\n",
      "        [1.1330],\n",
      "        [1.1472],\n",
      "        [1.1487],\n",
      "        [1.1486],\n",
      "        [1.0743],\n",
      "        [1.1186],\n",
      "        [1.1183],\n",
      "        [1.1146],\n",
      "        [1.1275],\n",
      "        [1.1284],\n",
      "        [1.1443],\n",
      "        [1.0891],\n",
      "        [1.1031],\n",
      "        [1.1420],\n",
      "        [1.1360],\n",
      "        [1.1138],\n",
      "        [1.1204],\n",
      "        [1.1437],\n",
      "        [1.0768],\n",
      "        [1.1377],\n",
      "        [1.0957],\n",
      "        [1.1346],\n",
      "        [1.1414],\n",
      "        [1.1379],\n",
      "        [1.1337],\n",
      "        [1.1451],\n",
      "        [1.1351],\n",
      "        [1.0874],\n",
      "        [1.1190],\n",
      "        [1.1242],\n",
      "        [1.1148]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1466],\n",
      "        [1.1119],\n",
      "        [1.1117],\n",
      "        [1.1355],\n",
      "        [1.1182],\n",
      "        [1.1417],\n",
      "        [1.1358],\n",
      "        [1.1395],\n",
      "        [1.1375],\n",
      "        [1.0800],\n",
      "        [1.1099],\n",
      "        [1.1434],\n",
      "        [1.1336],\n",
      "        [1.1437],\n",
      "        [1.1470],\n",
      "        [1.1418],\n",
      "        [1.1372],\n",
      "        [1.1439],\n",
      "        [1.1198],\n",
      "        [1.0802],\n",
      "        [1.1468],\n",
      "        [1.1360],\n",
      "        [1.1153],\n",
      "        [1.1501],\n",
      "        [1.1305],\n",
      "        [1.1337],\n",
      "        [1.0805],\n",
      "        [1.1138],\n",
      "        [1.0793],\n",
      "        [1.0945],\n",
      "        [1.1474],\n",
      "        [1.1359],\n",
      "        [1.1493],\n",
      "        [1.1067],\n",
      "        [1.1300],\n",
      "        [1.1452],\n",
      "        [1.1286],\n",
      "        [1.1254],\n",
      "        [1.1403],\n",
      "        [1.1059],\n",
      "        [1.2193],\n",
      "        [1.1546],\n",
      "        [1.1275],\n",
      "        [1.1263],\n",
      "        [1.1060],\n",
      "        [1.1175],\n",
      "        [1.1063],\n",
      "        [1.1442],\n",
      "        [1.1424],\n",
      "        [1.0979],\n",
      "        [1.0999],\n",
      "        [1.1227],\n",
      "        [1.1214],\n",
      "        [1.1244],\n",
      "        [1.1483],\n",
      "        [1.1392],\n",
      "        [1.1083],\n",
      "        [1.1398],\n",
      "        [1.0873],\n",
      "        [1.0954],\n",
      "        [0.3698],\n",
      "        [1.1210],\n",
      "        [1.1046],\n",
      "        [1.1287],\n",
      "        [1.0842],\n",
      "        [1.1247],\n",
      "        [1.1415],\n",
      "        [1.1406],\n",
      "        [1.1124],\n",
      "        [1.1104],\n",
      "        [1.1029],\n",
      "        [1.1388],\n",
      "        [1.1110],\n",
      "        [1.0922],\n",
      "        [1.1098],\n",
      "        [1.1295],\n",
      "        [1.1495],\n",
      "        [1.0792],\n",
      "        [1.1387],\n",
      "        [1.1080],\n",
      "        [1.1223],\n",
      "        [1.1194],\n",
      "        [1.1536],\n",
      "        [1.1137],\n",
      "        [1.1511],\n",
      "        [1.0824],\n",
      "        [1.0939],\n",
      "        [1.1482],\n",
      "        [1.1427],\n",
      "        [1.1074],\n",
      "        [1.1340],\n",
      "        [1.1031],\n",
      "        [1.1432],\n",
      "        [1.0977],\n",
      "        [1.1080],\n",
      "        [1.0977],\n",
      "        [1.1483],\n",
      "        [1.1183],\n",
      "        [1.1322],\n",
      "        [1.1246],\n",
      "        [1.1105],\n",
      "        [1.1092],\n",
      "        [1.0984],\n",
      "        [1.1188],\n",
      "        [1.0860],\n",
      "        [1.0949],\n",
      "        [1.0979],\n",
      "        [1.0884],\n",
      "        [1.1250],\n",
      "        [1.1284],\n",
      "        [1.0954],\n",
      "        [1.1327],\n",
      "        [1.1437],\n",
      "        [1.1114],\n",
      "        [1.1050],\n",
      "        [1.1448],\n",
      "        [1.1494],\n",
      "        [1.1192],\n",
      "        [1.1237],\n",
      "        [1.1230],\n",
      "        [1.1540],\n",
      "        [1.1094],\n",
      "        [1.1224],\n",
      "        [1.1301],\n",
      "        [1.1399],\n",
      "        [1.1355],\n",
      "        [1.1538],\n",
      "        [1.0910]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1319],\n",
      "        [1.1532],\n",
      "        [1.0917],\n",
      "        [1.1109],\n",
      "        [1.1327],\n",
      "        [1.1098],\n",
      "        [1.1398],\n",
      "        [1.0995],\n",
      "        [1.1260],\n",
      "        [1.1454],\n",
      "        [1.1080],\n",
      "        [1.1352],\n",
      "        [1.1282],\n",
      "        [1.1368],\n",
      "        [1.0631],\n",
      "        [1.1032],\n",
      "        [1.1253],\n",
      "        [1.1136],\n",
      "        [1.1250],\n",
      "        [1.1417],\n",
      "        [1.1434],\n",
      "        [1.1324],\n",
      "        [1.0823],\n",
      "        [1.1079],\n",
      "        [1.1486],\n",
      "        [1.1198],\n",
      "        [1.1422],\n",
      "        [1.1198],\n",
      "        [1.1561],\n",
      "        [1.1424],\n",
      "        [1.1513],\n",
      "        [1.1554],\n",
      "        [1.1320],\n",
      "        [1.1329],\n",
      "        [1.1001],\n",
      "        [1.1309],\n",
      "        [1.1262],\n",
      "        [1.1381],\n",
      "        [1.1165],\n",
      "        [1.1513],\n",
      "        [1.1339],\n",
      "        [1.1170],\n",
      "        [1.1324],\n",
      "        [1.1361],\n",
      "        [1.1170],\n",
      "        [1.1212],\n",
      "        [1.1456],\n",
      "        [1.1048],\n",
      "        [1.1268],\n",
      "        [1.1277],\n",
      "        [1.1417],\n",
      "        [1.1291],\n",
      "        [1.1067],\n",
      "        [1.0794],\n",
      "        [1.1483],\n",
      "        [1.1267],\n",
      "        [1.1490],\n",
      "        [1.1523],\n",
      "        [1.1313],\n",
      "        [1.1387],\n",
      "        [1.1402],\n",
      "        [1.1200],\n",
      "        [1.1333],\n",
      "        [1.1193],\n",
      "        [1.1084],\n",
      "        [1.1262],\n",
      "        [1.1217],\n",
      "        [1.1381],\n",
      "        [1.0851],\n",
      "        [1.0764],\n",
      "        [1.1225],\n",
      "        [1.1134],\n",
      "        [1.1485],\n",
      "        [1.1455],\n",
      "        [1.0706],\n",
      "        [1.1363],\n",
      "        [1.1173],\n",
      "        [1.1158],\n",
      "        [1.1333],\n",
      "        [1.1430],\n",
      "        [1.1522],\n",
      "        [1.1482],\n",
      "        [1.1223],\n",
      "        [1.1169],\n",
      "        [1.1256],\n",
      "        [1.1521],\n",
      "        [1.1271],\n",
      "        [1.1241],\n",
      "        [1.1301],\n",
      "        [1.0731],\n",
      "        [1.1363],\n",
      "        [1.1505],\n",
      "        [1.1468],\n",
      "        [1.1417],\n",
      "        [1.1574],\n",
      "        [1.1569],\n",
      "        [1.1395],\n",
      "        [1.1314],\n",
      "        [1.1408],\n",
      "        [1.0914],\n",
      "        [1.1443],\n",
      "        [1.1059],\n",
      "        [1.1271],\n",
      "        [1.1320],\n",
      "        [1.1071],\n",
      "        [1.1280],\n",
      "        [1.0942],\n",
      "        [1.1567],\n",
      "        [1.1195],\n",
      "        [1.1173],\n",
      "        [1.1513],\n",
      "        [1.0131],\n",
      "        [1.0969],\n",
      "        [1.1217],\n",
      "        [1.1532],\n",
      "        [1.1072],\n",
      "        [1.1129],\n",
      "        [1.0980],\n",
      "        [1.1051],\n",
      "        [1.1023],\n",
      "        [1.1290],\n",
      "        [1.0801],\n",
      "        [1.1218],\n",
      "        [1.1283],\n",
      "        [1.0747],\n",
      "        [1.1390],\n",
      "        [1.1513],\n",
      "        [1.1207]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.1299],\n",
      "        [ 1.1356],\n",
      "        [ 1.1400],\n",
      "        [ 1.1141],\n",
      "        [ 1.0755],\n",
      "        [ 1.1132],\n",
      "        [ 1.0831],\n",
      "        [ 1.1007],\n",
      "        [ 1.1132],\n",
      "        [ 1.1011],\n",
      "        [ 1.1462],\n",
      "        [ 1.1339],\n",
      "        [ 1.1039],\n",
      "        [ 1.1403],\n",
      "        [ 1.1163],\n",
      "        [ 1.1337],\n",
      "        [ 1.1475],\n",
      "        [ 1.1155],\n",
      "        [ 1.1383],\n",
      "        [ 1.1346],\n",
      "        [ 1.1585],\n",
      "        [ 1.0915],\n",
      "        [ 1.1130],\n",
      "        [ 1.1067],\n",
      "        [ 1.1112],\n",
      "        [ 1.1356],\n",
      "        [ 1.1161],\n",
      "        [ 1.1492],\n",
      "        [ 1.1462],\n",
      "        [ 1.1438],\n",
      "        [ 1.1430],\n",
      "        [ 1.1363],\n",
      "        [ 1.1294],\n",
      "        [ 1.1167],\n",
      "        [ 1.1205],\n",
      "        [ 1.1402],\n",
      "        [ 1.1576],\n",
      "        [ 1.1448],\n",
      "        [ 1.1337],\n",
      "        [ 1.1557],\n",
      "        [ 1.1531],\n",
      "        [ 1.1209],\n",
      "        [ 1.1556],\n",
      "        [ 1.1311],\n",
      "        [ 1.1587],\n",
      "        [ 1.1090],\n",
      "        [ 1.0952],\n",
      "        [ 1.1420],\n",
      "        [ 1.1129],\n",
      "        [ 1.1545],\n",
      "        [ 1.1437],\n",
      "        [ 1.1283],\n",
      "        [ 1.1509],\n",
      "        [ 1.1438],\n",
      "        [ 1.1355],\n",
      "        [ 1.0861],\n",
      "        [ 1.1562],\n",
      "        [ 1.1365],\n",
      "        [ 1.1084],\n",
      "        [ 1.1545],\n",
      "        [ 1.1307],\n",
      "        [ 1.0875],\n",
      "        [ 1.1091],\n",
      "        [ 1.1483],\n",
      "        [ 1.1420],\n",
      "        [ 1.1173],\n",
      "        [ 1.1576],\n",
      "        [ 1.0784],\n",
      "        [ 1.1083],\n",
      "        [ 1.1428],\n",
      "        [ 1.1035],\n",
      "        [ 1.1446],\n",
      "        [ 1.1438],\n",
      "        [ 1.1512],\n",
      "        [ 1.1299],\n",
      "        [ 1.1570],\n",
      "        [ 1.0986],\n",
      "        [ 1.1312],\n",
      "        [ 1.0908],\n",
      "        [ 1.1489],\n",
      "        [ 1.1110],\n",
      "        [ 1.0902],\n",
      "        [ 1.1211],\n",
      "        [ 1.1548],\n",
      "        [ 1.1225],\n",
      "        [ 1.1353],\n",
      "        [ 1.1539],\n",
      "        [ 1.0867],\n",
      "        [ 1.1466],\n",
      "        [ 1.1429],\n",
      "        [ 1.0698],\n",
      "        [ 1.1117],\n",
      "        [ 1.1507],\n",
      "        [ 1.1504],\n",
      "        [ 1.1294],\n",
      "        [ 1.1321],\n",
      "        [ 1.1136],\n",
      "        [ 1.1354],\n",
      "        [ 1.1291],\n",
      "        [ 1.1347],\n",
      "        [ 1.1515],\n",
      "        [ 1.1516],\n",
      "        [ 1.0838],\n",
      "        [14.3409],\n",
      "        [ 1.1577],\n",
      "        [ 1.1103],\n",
      "        [ 1.1006],\n",
      "        [ 1.1456],\n",
      "        [ 1.0924],\n",
      "        [ 1.1475],\n",
      "        [ 1.1264],\n",
      "        [ 1.0910],\n",
      "        [ 1.1351],\n",
      "        [ 1.1571],\n",
      "        [ 1.1500],\n",
      "        [ 1.1393],\n",
      "        [ 1.1542],\n",
      "        [ 1.1426],\n",
      "        [ 1.1079],\n",
      "        [ 1.1285],\n",
      "        [ 1.0955],\n",
      "        [ 1.1190],\n",
      "        [ 1.1190],\n",
      "        [ 1.1566],\n",
      "        [ 1.1533],\n",
      "        [ 1.1241],\n",
      "        [ 1.1213],\n",
      "        [ 1.1136]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1479],\n",
      "        [1.0860],\n",
      "        [1.1216],\n",
      "        [1.0864],\n",
      "        [1.1322],\n",
      "        [1.1423],\n",
      "        [1.1417],\n",
      "        [1.1511],\n",
      "        [1.1390],\n",
      "        [1.1540],\n",
      "        [1.1542],\n",
      "        [1.0811],\n",
      "        [1.0723],\n",
      "        [1.1052],\n",
      "        [1.0867],\n",
      "        [1.1124],\n",
      "        [1.1460],\n",
      "        [1.1477],\n",
      "        [1.1025],\n",
      "        [1.1327],\n",
      "        [1.1143],\n",
      "        [1.1374],\n",
      "        [1.1292],\n",
      "        [1.1469],\n",
      "        [1.1211],\n",
      "        [1.1414],\n",
      "        [1.1052],\n",
      "        [1.1336],\n",
      "        [1.1571],\n",
      "        [1.0961],\n",
      "        [1.1220],\n",
      "        [1.1275],\n",
      "        [1.1583],\n",
      "        [1.1336],\n",
      "        [1.1007],\n",
      "        [1.1382],\n",
      "        [1.1043],\n",
      "        [1.1464],\n",
      "        [1.1121],\n",
      "        [1.0833],\n",
      "        [1.1430],\n",
      "        [1.1451],\n",
      "        [1.1304],\n",
      "        [1.1470],\n",
      "        [1.1266],\n",
      "        [1.1425],\n",
      "        [1.1449],\n",
      "        [1.0913],\n",
      "        [1.1569],\n",
      "        [1.1240],\n",
      "        [1.1056],\n",
      "        [1.1308],\n",
      "        [1.1249],\n",
      "        [1.1384],\n",
      "        [1.1335],\n",
      "        [1.1267],\n",
      "        [1.1021],\n",
      "        [1.1334],\n",
      "        [1.1436],\n",
      "        [1.0886],\n",
      "        [1.1522],\n",
      "        [1.1117],\n",
      "        [1.1265],\n",
      "        [1.1315],\n",
      "        [1.1286],\n",
      "        [1.1316],\n",
      "        [1.0937],\n",
      "        [1.1357],\n",
      "        [1.1440],\n",
      "        [1.1199],\n",
      "        [1.1572],\n",
      "        [1.1482],\n",
      "        [1.0860],\n",
      "        [1.1537],\n",
      "        [1.1117],\n",
      "        [1.1425],\n",
      "        [1.1224],\n",
      "        [1.1470],\n",
      "        [1.1336],\n",
      "        [1.1316],\n",
      "        [1.1438],\n",
      "        [1.1147],\n",
      "        [1.1227],\n",
      "        [1.1126],\n",
      "        [1.0528],\n",
      "        [1.1038],\n",
      "        [1.1288],\n",
      "        [1.1559],\n",
      "        [1.1476],\n",
      "        [1.1310],\n",
      "        [1.1326],\n",
      "        [0.1499],\n",
      "        [1.1437],\n",
      "        [1.1417],\n",
      "        [1.1408],\n",
      "        [1.1388],\n",
      "        [1.1571],\n",
      "        [1.1530],\n",
      "        [1.1022],\n",
      "        [1.1222],\n",
      "        [1.1518],\n",
      "        [1.1093],\n",
      "        [1.1369],\n",
      "        [1.1263],\n",
      "        [1.1524],\n",
      "        [1.1218],\n",
      "        [1.0937],\n",
      "        [1.1528],\n",
      "        [1.1537],\n",
      "        [1.1403],\n",
      "        [1.1011],\n",
      "        [1.1277],\n",
      "        [1.1392],\n",
      "        [1.1456],\n",
      "        [1.1345],\n",
      "        [1.0611],\n",
      "        [1.1273],\n",
      "        [1.1055],\n",
      "        [1.1578],\n",
      "        [1.1325],\n",
      "        [1.1377],\n",
      "        [1.0988],\n",
      "        [1.1271],\n",
      "        [1.1399],\n",
      "        [1.0960],\n",
      "        [1.1328],\n",
      "        [1.1558],\n",
      "        [1.1319]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1120],\n",
      "        [1.1314],\n",
      "        [1.1197],\n",
      "        [1.1092]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   6 | lr 0.00100 train_loss 2.24159 | val_loss 2.28363 | val_rmse 1.51117\n",
      "tensor([[1.1233],\n",
      "        [1.1344],\n",
      "        [1.1519],\n",
      "        [1.1573],\n",
      "        [1.1492],\n",
      "        [1.0983],\n",
      "        [1.1223],\n",
      "        [1.1411],\n",
      "        [1.1211],\n",
      "        [1.1535],\n",
      "        [1.1099],\n",
      "        [1.1568],\n",
      "        [1.0982],\n",
      "        [1.1559],\n",
      "        [1.0960],\n",
      "        [1.1241],\n",
      "        [1.1407],\n",
      "        [1.1450],\n",
      "        [1.1099],\n",
      "        [1.1208],\n",
      "        [1.1064],\n",
      "        [1.1520],\n",
      "        [1.0954],\n",
      "        [1.1140],\n",
      "        [1.1476],\n",
      "        [1.1532],\n",
      "        [1.1451],\n",
      "        [1.1387],\n",
      "        [1.1377],\n",
      "        [1.1256],\n",
      "        [1.1521],\n",
      "        [1.1209],\n",
      "        [1.0791],\n",
      "        [1.1401],\n",
      "        [1.1391],\n",
      "        [1.1381],\n",
      "        [1.1470],\n",
      "        [0.6546],\n",
      "        [1.1202],\n",
      "        [1.1383],\n",
      "        [1.1495],\n",
      "        [1.1328],\n",
      "        [1.0668],\n",
      "        [1.0532],\n",
      "        [1.1324],\n",
      "        [1.1444],\n",
      "        [1.1167],\n",
      "        [1.1273],\n",
      "        [1.1151],\n",
      "        [1.0470],\n",
      "        [1.1052],\n",
      "        [1.1535],\n",
      "        [1.1355],\n",
      "        [1.1287],\n",
      "        [1.1315],\n",
      "        [1.1226],\n",
      "        [1.1476],\n",
      "        [1.1066],\n",
      "        [1.1291],\n",
      "        [1.1438],\n",
      "        [1.1334],\n",
      "        [1.1307],\n",
      "        [1.1279],\n",
      "        [1.0735],\n",
      "        [1.1177],\n",
      "        [1.1019],\n",
      "        [1.1304],\n",
      "        [1.1423],\n",
      "        [1.1236],\n",
      "        [1.1378],\n",
      "        [1.1460],\n",
      "        [1.1138],\n",
      "        [1.1400],\n",
      "        [1.1006],\n",
      "        [1.1525],\n",
      "        [1.0872],\n",
      "        [1.1432],\n",
      "        [1.1073],\n",
      "        [1.1502],\n",
      "        [1.1428],\n",
      "        [1.1260],\n",
      "        [1.1241],\n",
      "        [1.1560],\n",
      "        [1.1172],\n",
      "        [1.1460],\n",
      "        [1.1143],\n",
      "        [1.1056],\n",
      "        [1.1249],\n",
      "        [1.0815],\n",
      "        [1.1413],\n",
      "        [1.1363],\n",
      "        [1.1518],\n",
      "        [1.1548],\n",
      "        [1.1335],\n",
      "        [1.1127],\n",
      "        [1.1274],\n",
      "        [1.1377],\n",
      "        [1.1155],\n",
      "        [1.1383],\n",
      "        [1.1449],\n",
      "        [1.1490],\n",
      "        [1.1214],\n",
      "        [1.1398],\n",
      "        [1.1292],\n",
      "        [1.1426],\n",
      "        [1.1295],\n",
      "        [1.1255],\n",
      "        [1.1495],\n",
      "        [1.0907],\n",
      "        [1.1541],\n",
      "        [1.1364],\n",
      "        [1.1382],\n",
      "        [1.1257],\n",
      "        [1.1106],\n",
      "        [1.1038],\n",
      "        [1.1419],\n",
      "        [1.1051],\n",
      "        [1.1509],\n",
      "        [1.1505],\n",
      "        [1.1063],\n",
      "        [1.1227],\n",
      "        [1.1370],\n",
      "        [1.1011],\n",
      "        [1.1361],\n",
      "        [1.1424],\n",
      "        [1.1060],\n",
      "        [1.0893],\n",
      "        [1.0825]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1400],\n",
      "        [1.0801],\n",
      "        [1.1268],\n",
      "        [1.1385],\n",
      "        [1.1284],\n",
      "        [1.1501],\n",
      "        [1.1400],\n",
      "        [1.1275],\n",
      "        [1.1312],\n",
      "        [1.1192],\n",
      "        [1.1349],\n",
      "        [1.1308],\n",
      "        [1.1304],\n",
      "        [1.1443],\n",
      "        [1.1506],\n",
      "        [1.1451],\n",
      "        [1.0931],\n",
      "        [1.1541],\n",
      "        [1.1179],\n",
      "        [1.1257],\n",
      "        [1.1112],\n",
      "        [1.0916],\n",
      "        [1.1000],\n",
      "        [1.1137],\n",
      "        [1.1498],\n",
      "        [1.1513],\n",
      "        [1.1417],\n",
      "        [1.1368],\n",
      "        [1.0960],\n",
      "        [1.1506],\n",
      "        [1.1532],\n",
      "        [1.1162],\n",
      "        [1.0991],\n",
      "        [1.1530],\n",
      "        [1.1499],\n",
      "        [1.0908],\n",
      "        [1.0611],\n",
      "        [1.1212],\n",
      "        [1.1368],\n",
      "        [1.1375],\n",
      "        [1.1307],\n",
      "        [1.1352],\n",
      "        [1.0905],\n",
      "        [1.1437],\n",
      "        [1.1313],\n",
      "        [1.1176],\n",
      "        [1.1452],\n",
      "        [1.1127],\n",
      "        [1.1301],\n",
      "        [1.1434],\n",
      "        [1.1173],\n",
      "        [1.1197],\n",
      "        [1.1397],\n",
      "        [1.1216],\n",
      "        [1.1396],\n",
      "        [1.0903],\n",
      "        [1.1087],\n",
      "        [1.1371],\n",
      "        [1.1382],\n",
      "        [1.0867],\n",
      "        [1.1367],\n",
      "        [1.1055],\n",
      "        [1.1412],\n",
      "        [1.1183],\n",
      "        [1.1189],\n",
      "        [1.1228],\n",
      "        [1.1188],\n",
      "        [1.1224],\n",
      "        [1.1174],\n",
      "        [1.0763],\n",
      "        [1.1226],\n",
      "        [1.1245],\n",
      "        [1.1154],\n",
      "        [1.1087],\n",
      "        [1.1357],\n",
      "        [1.0910],\n",
      "        [1.1244],\n",
      "        [1.1505],\n",
      "        [1.0414],\n",
      "        [1.1402],\n",
      "        [1.0986],\n",
      "        [1.1409],\n",
      "        [1.1383],\n",
      "        [1.0948],\n",
      "        [1.1190],\n",
      "        [1.0844],\n",
      "        [1.1378],\n",
      "        [1.1087],\n",
      "        [1.1255],\n",
      "        [1.1443],\n",
      "        [1.1210],\n",
      "        [1.1416],\n",
      "        [1.1264],\n",
      "        [1.1360],\n",
      "        [1.1465],\n",
      "        [1.1186],\n",
      "        [1.1117],\n",
      "        [1.1427],\n",
      "        [1.1427],\n",
      "        [1.1355],\n",
      "        [1.1076],\n",
      "        [1.1321],\n",
      "        [1.1277],\n",
      "        [1.1394],\n",
      "        [1.1216],\n",
      "        [1.1098],\n",
      "        [1.1284],\n",
      "        [1.1541],\n",
      "        [1.1413],\n",
      "        [1.1324],\n",
      "        [1.1224],\n",
      "        [1.1371],\n",
      "        [1.1315],\n",
      "        [1.1548],\n",
      "        [1.0363],\n",
      "        [1.1265],\n",
      "        [1.0802],\n",
      "        [1.1286],\n",
      "        [1.1503],\n",
      "        [1.1227],\n",
      "        [1.1420],\n",
      "        [1.1394],\n",
      "        [1.1530],\n",
      "        [1.0645],\n",
      "        [1.1177],\n",
      "        [1.1348],\n",
      "        [1.1221],\n",
      "        [1.1436]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1341],\n",
      "        [1.1386],\n",
      "        [1.1437],\n",
      "        [1.1326],\n",
      "        [1.1333],\n",
      "        [1.1180],\n",
      "        [1.1425],\n",
      "        [1.1370],\n",
      "        [1.1396],\n",
      "        [1.0797],\n",
      "        [1.1014],\n",
      "        [1.1267],\n",
      "        [1.0982],\n",
      "        [1.1475],\n",
      "        [1.1224],\n",
      "        [1.1150],\n",
      "        [1.1485],\n",
      "        [1.1221],\n",
      "        [1.1526],\n",
      "        [1.1302],\n",
      "        [1.0909],\n",
      "        [1.1395],\n",
      "        [1.1365],\n",
      "        [1.0951],\n",
      "        [1.1257],\n",
      "        [1.1136],\n",
      "        [1.1397],\n",
      "        [1.1476],\n",
      "        [1.1229],\n",
      "        [1.1336],\n",
      "        [1.1425],\n",
      "        [1.1335],\n",
      "        [1.0846],\n",
      "        [1.1521],\n",
      "        [1.1254],\n",
      "        [1.1320],\n",
      "        [1.1063],\n",
      "        [1.0800],\n",
      "        [1.1272],\n",
      "        [1.1509],\n",
      "        [1.0991],\n",
      "        [1.1066],\n",
      "        [1.0825],\n",
      "        [1.1537],\n",
      "        [1.1474],\n",
      "        [1.1400],\n",
      "        [1.1388],\n",
      "        [1.1240],\n",
      "        [1.1442],\n",
      "        [1.1343],\n",
      "        [1.1447],\n",
      "        [1.1525],\n",
      "        [1.1252],\n",
      "        [1.1399],\n",
      "        [1.1109],\n",
      "        [1.0854],\n",
      "        [1.1422],\n",
      "        [1.1287],\n",
      "        [1.0800],\n",
      "        [1.1163],\n",
      "        [1.1065],\n",
      "        [1.1415],\n",
      "        [1.1206],\n",
      "        [1.1245],\n",
      "        [1.1490],\n",
      "        [1.1026],\n",
      "        [1.1402],\n",
      "        [1.1353],\n",
      "        [1.0785],\n",
      "        [1.1537],\n",
      "        [1.1500],\n",
      "        [1.1296],\n",
      "        [1.0750],\n",
      "        [1.1437],\n",
      "        [1.1269],\n",
      "        [1.1308],\n",
      "        [1.1027],\n",
      "        [1.1478],\n",
      "        [1.1183],\n",
      "        [1.1099],\n",
      "        [1.0926],\n",
      "        [1.1426],\n",
      "        [1.1523],\n",
      "        [1.1233],\n",
      "        [1.1375],\n",
      "        [1.1504],\n",
      "        [1.1161],\n",
      "        [1.0843],\n",
      "        [1.1216],\n",
      "        [1.1395],\n",
      "        [1.1282],\n",
      "        [1.1414],\n",
      "        [1.1250],\n",
      "        [1.1048],\n",
      "        [1.0912],\n",
      "        [1.1414],\n",
      "        [1.1346],\n",
      "        [1.1200],\n",
      "        [1.1111],\n",
      "        [1.1232],\n",
      "        [1.1421],\n",
      "        [1.1282],\n",
      "        [1.1150],\n",
      "        [1.1278],\n",
      "        [1.1374],\n",
      "        [1.0965],\n",
      "        [1.1254],\n",
      "        [1.1141],\n",
      "        [1.1186],\n",
      "        [1.1472],\n",
      "        [1.1081],\n",
      "        [1.1243],\n",
      "        [1.1532],\n",
      "        [1.1268],\n",
      "        [1.1482],\n",
      "        [1.1233],\n",
      "        [1.0952],\n",
      "        [1.1306],\n",
      "        [1.1232],\n",
      "        [1.0690],\n",
      "        [1.1068],\n",
      "        [1.0887],\n",
      "        [1.1398],\n",
      "        [1.1111],\n",
      "        [1.0925],\n",
      "        [1.1526],\n",
      "        [1.1329],\n",
      "        [1.1368]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1529],\n",
      "        [1.1352],\n",
      "        [1.1038],\n",
      "        [1.1269],\n",
      "        [1.1467],\n",
      "        [1.1503],\n",
      "        [1.1194],\n",
      "        [1.1087],\n",
      "        [1.1362],\n",
      "        [1.1252],\n",
      "        [1.1273],\n",
      "        [1.0988],\n",
      "        [1.1478],\n",
      "        [1.1284],\n",
      "        [1.1240],\n",
      "        [1.1215],\n",
      "        [1.1526],\n",
      "        [1.0835],\n",
      "        [1.1155],\n",
      "        [1.1483],\n",
      "        [1.0750],\n",
      "        [1.1407],\n",
      "        [1.1314],\n",
      "        [1.0802],\n",
      "        [1.1154],\n",
      "        [1.1470],\n",
      "        [1.1170],\n",
      "        [1.1507],\n",
      "        [1.1475],\n",
      "        [1.1119],\n",
      "        [1.0679],\n",
      "        [1.1456],\n",
      "        [1.1476],\n",
      "        [1.1265],\n",
      "        [1.1151],\n",
      "        [1.1336],\n",
      "        [1.1397],\n",
      "        [1.1477],\n",
      "        [1.1292],\n",
      "        [1.0991],\n",
      "        [1.1286],\n",
      "        [1.1165],\n",
      "        [1.1365],\n",
      "        [1.1427],\n",
      "        [1.1205],\n",
      "        [1.1508],\n",
      "        [1.0830],\n",
      "        [1.1281],\n",
      "        [1.1282],\n",
      "        [1.0827],\n",
      "        [1.1052],\n",
      "        [1.1286],\n",
      "        [1.0871],\n",
      "        [1.1414],\n",
      "        [1.1360],\n",
      "        [1.0993],\n",
      "        [1.1269],\n",
      "        [1.1400],\n",
      "        [1.1219],\n",
      "        [1.1353],\n",
      "        [1.1209],\n",
      "        [1.0933],\n",
      "        [1.1156],\n",
      "        [1.1338],\n",
      "        [1.1448],\n",
      "        [1.1529],\n",
      "        [1.1536],\n",
      "        [1.1508],\n",
      "        [1.0904],\n",
      "        [1.1277],\n",
      "        [1.1265],\n",
      "        [1.1363],\n",
      "        [1.1035],\n",
      "        [1.1303],\n",
      "        [1.1143],\n",
      "        [1.1540],\n",
      "        [1.1474],\n",
      "        [1.1116],\n",
      "        [1.1089],\n",
      "        [1.1126],\n",
      "        [1.1108],\n",
      "        [1.1320],\n",
      "        [1.1452],\n",
      "        [1.1282],\n",
      "        [1.1150],\n",
      "        [1.1196],\n",
      "        [1.0984],\n",
      "        [1.0874],\n",
      "        [1.1282],\n",
      "        [1.1423],\n",
      "        [1.0718],\n",
      "        [1.1101],\n",
      "        [1.0917],\n",
      "        [1.1448],\n",
      "        [1.1295],\n",
      "        [1.1441],\n",
      "        [1.1472],\n",
      "        [1.0784],\n",
      "        [1.1348],\n",
      "        [1.1420],\n",
      "        [1.0987],\n",
      "        [1.1131],\n",
      "        [1.1473],\n",
      "        [1.1250],\n",
      "        [1.1381],\n",
      "        [1.1387],\n",
      "        [1.1008],\n",
      "        [1.1228],\n",
      "        [1.0864],\n",
      "        [1.1396],\n",
      "        [1.1065],\n",
      "        [1.0666],\n",
      "        [1.0841],\n",
      "        [1.0648],\n",
      "        [1.1455],\n",
      "        [1.1149],\n",
      "        [1.1018],\n",
      "        [1.1387],\n",
      "        [1.1163],\n",
      "        [1.1477],\n",
      "        [1.1407],\n",
      "        [1.1105],\n",
      "        [1.1110],\n",
      "        [1.1484],\n",
      "        [1.1334],\n",
      "        [1.1099],\n",
      "        [1.1440],\n",
      "        [1.1476]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1311],\n",
      "        [1.1223],\n",
      "        [0.1483],\n",
      "        [1.1367],\n",
      "        [1.1329],\n",
      "        [1.1496],\n",
      "        [1.0914],\n",
      "        [1.1330],\n",
      "        [1.0839],\n",
      "        [1.1090],\n",
      "        [1.1444],\n",
      "        [1.1212],\n",
      "        [1.1267],\n",
      "        [1.1259],\n",
      "        [1.1426],\n",
      "        [0.6912],\n",
      "        [1.1009],\n",
      "        [1.0550],\n",
      "        [1.0998],\n",
      "        [1.1122],\n",
      "        [1.0864],\n",
      "        [1.1428],\n",
      "        [1.1295],\n",
      "        [1.0847],\n",
      "        [1.1146],\n",
      "        [1.1248],\n",
      "        [1.1484],\n",
      "        [1.1254],\n",
      "        [1.1212],\n",
      "        [1.1127],\n",
      "        [1.1296],\n",
      "        [1.1328],\n",
      "        [1.0927],\n",
      "        [1.0933],\n",
      "        [1.0875],\n",
      "        [1.1498],\n",
      "        [1.1072],\n",
      "        [1.1230],\n",
      "        [1.1037],\n",
      "        [1.1214],\n",
      "        [1.1385],\n",
      "        [1.1448],\n",
      "        [1.1488],\n",
      "        [1.1290],\n",
      "        [1.1375],\n",
      "        [1.1343],\n",
      "        [1.1369],\n",
      "        [1.1162],\n",
      "        [1.1237],\n",
      "        [1.1447],\n",
      "        [1.0975],\n",
      "        [1.1245],\n",
      "        [1.1211],\n",
      "        [1.1366],\n",
      "        [1.1179],\n",
      "        [1.1197],\n",
      "        [1.1174],\n",
      "        [1.1428],\n",
      "        [1.1235],\n",
      "        [1.1290],\n",
      "        [1.1204],\n",
      "        [1.1350],\n",
      "        [1.0626],\n",
      "        [1.1331],\n",
      "        [1.1331],\n",
      "        [1.0805],\n",
      "        [1.1242],\n",
      "        [1.0715],\n",
      "        [1.0944],\n",
      "        [1.1223],\n",
      "        [1.0967],\n",
      "        [1.1126],\n",
      "        [1.1095],\n",
      "        [1.1190],\n",
      "        [1.1498],\n",
      "        [1.1415],\n",
      "        [1.1258],\n",
      "        [1.1262],\n",
      "        [1.1352],\n",
      "        [1.1467],\n",
      "        [1.0752],\n",
      "        [1.1497],\n",
      "        [1.1128],\n",
      "        [1.1497],\n",
      "        [1.1333],\n",
      "        [1.1028],\n",
      "        [1.1337],\n",
      "        [1.1142],\n",
      "        [1.1467],\n",
      "        [1.1398],\n",
      "        [1.1188],\n",
      "        [1.0932],\n",
      "        [1.1333],\n",
      "        [1.1422],\n",
      "        [1.0976],\n",
      "        [1.1142],\n",
      "        [1.1334],\n",
      "        [1.0902],\n",
      "        [1.0584],\n",
      "        [1.1230],\n",
      "        [1.0979],\n",
      "        [1.1331],\n",
      "        [1.1297],\n",
      "        [1.1420],\n",
      "        [1.1111],\n",
      "        [1.1465],\n",
      "        [1.0966],\n",
      "        [1.1355],\n",
      "        [1.0919],\n",
      "        [1.1338],\n",
      "        [1.1251],\n",
      "        [1.1027],\n",
      "        [1.1316],\n",
      "        [1.1237],\n",
      "        [1.1438],\n",
      "        [1.1273],\n",
      "        [1.1369],\n",
      "        [1.0953],\n",
      "        [1.1415],\n",
      "        [1.0953],\n",
      "        [1.0588],\n",
      "        [1.1020],\n",
      "        [1.0984],\n",
      "        [1.1252],\n",
      "        [1.1487],\n",
      "        [1.1386],\n",
      "        [1.1276],\n",
      "        [1.1040]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0993],\n",
      "        [1.1280],\n",
      "        [1.1004],\n",
      "        [1.1363],\n",
      "        [1.1439],\n",
      "        [1.1153],\n",
      "        [1.0613],\n",
      "        [1.1020],\n",
      "        [1.0834],\n",
      "        [1.1305],\n",
      "        [1.0756],\n",
      "        [1.0846],\n",
      "        [1.1171],\n",
      "        [1.0916],\n",
      "        [1.1318],\n",
      "        [1.1414],\n",
      "        [1.1303],\n",
      "        [1.1133],\n",
      "        [1.1151],\n",
      "        [1.1412],\n",
      "        [1.0920],\n",
      "        [1.1019],\n",
      "        [1.0172],\n",
      "        [1.1203],\n",
      "        [1.0881],\n",
      "        [1.0580],\n",
      "        [1.0979],\n",
      "        [1.1108],\n",
      "        [1.1102],\n",
      "        [1.1117],\n",
      "        [1.1477],\n",
      "        [1.1023],\n",
      "        [1.1363],\n",
      "        [1.1420],\n",
      "        [1.0960],\n",
      "        [1.1447],\n",
      "        [1.1284],\n",
      "        [1.1411],\n",
      "        [1.1156],\n",
      "        [1.1466],\n",
      "        [1.1009],\n",
      "        [1.1466],\n",
      "        [1.1188],\n",
      "        [1.1361],\n",
      "        [1.1294],\n",
      "        [1.1235],\n",
      "        [1.1067],\n",
      "        [1.1348],\n",
      "        [1.1029],\n",
      "        [1.1144],\n",
      "        [1.1437],\n",
      "        [1.1330],\n",
      "        [1.1451],\n",
      "        [1.1113],\n",
      "        [1.1238],\n",
      "        [1.1153],\n",
      "        [1.1079],\n",
      "        [1.1384],\n",
      "        [1.1485],\n",
      "        [1.0961],\n",
      "        [1.1042],\n",
      "        [1.1137],\n",
      "        [1.0725],\n",
      "        [1.1334],\n",
      "        [1.0819],\n",
      "        [1.1345],\n",
      "        [1.1331],\n",
      "        [1.1392],\n",
      "        [1.1173],\n",
      "        [1.1197],\n",
      "        [1.1333],\n",
      "        [1.0861],\n",
      "        [1.1299],\n",
      "        [1.1155],\n",
      "        [1.1442],\n",
      "        [1.1409],\n",
      "        [1.0967],\n",
      "        [1.1225],\n",
      "        [1.1274],\n",
      "        [1.1360],\n",
      "        [1.1439],\n",
      "        [1.1137],\n",
      "        [1.0629],\n",
      "        [1.1064],\n",
      "        [1.1249],\n",
      "        [1.1234],\n",
      "        [1.1194],\n",
      "        [1.1001],\n",
      "        [1.1441],\n",
      "        [1.1432],\n",
      "        [1.1412],\n",
      "        [1.1426],\n",
      "        [1.1276],\n",
      "        [1.1085],\n",
      "        [1.0731],\n",
      "        [1.1205],\n",
      "        [1.1147],\n",
      "        [1.0949],\n",
      "        [1.0934],\n",
      "        [1.1309],\n",
      "        [1.1462],\n",
      "        [1.1195],\n",
      "        [1.1412],\n",
      "        [1.1355],\n",
      "        [1.1134],\n",
      "        [1.1275],\n",
      "        [1.1102],\n",
      "        [1.1406],\n",
      "        [1.0783],\n",
      "        [1.1335],\n",
      "        [1.0637],\n",
      "        [1.1198],\n",
      "        [1.1178],\n",
      "        [1.1284],\n",
      "        [1.1330],\n",
      "        [1.1145],\n",
      "        [1.1105],\n",
      "        [1.1364],\n",
      "        [1.1088],\n",
      "        [1.1126],\n",
      "        [1.1441],\n",
      "        [1.1023],\n",
      "        [1.1257],\n",
      "        [1.1344],\n",
      "        [1.1366],\n",
      "        [1.1352],\n",
      "        [1.0654],\n",
      "        [1.0989]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0899],\n",
      "        [1.1088],\n",
      "        [1.0953],\n",
      "        [1.1346],\n",
      "        [1.1414],\n",
      "        [1.1254],\n",
      "        [1.0766],\n",
      "        [1.1292],\n",
      "        [1.1045],\n",
      "        [1.1387],\n",
      "        [1.1232],\n",
      "        [1.0673],\n",
      "        [1.0987],\n",
      "        [1.1076],\n",
      "        [1.1190],\n",
      "        [1.1429],\n",
      "        [1.0973],\n",
      "        [1.1228],\n",
      "        [1.1282],\n",
      "        [1.1402],\n",
      "        [1.1341],\n",
      "        [1.1209],\n",
      "        [1.1119],\n",
      "        [1.1159],\n",
      "        [1.1205],\n",
      "        [1.1336],\n",
      "        [1.1283],\n",
      "        [1.1205],\n",
      "        [1.1247],\n",
      "        [1.1158],\n",
      "        [1.1056],\n",
      "        [1.1280],\n",
      "        [1.0983],\n",
      "        [1.1147],\n",
      "        [1.1311],\n",
      "        [1.0888],\n",
      "        [1.1178],\n",
      "        [1.1333],\n",
      "        [1.1297],\n",
      "        [1.0816],\n",
      "        [1.1105],\n",
      "        [1.0697],\n",
      "        [1.1213],\n",
      "        [1.0387],\n",
      "        [1.1166],\n",
      "        [1.1050],\n",
      "        [1.1254],\n",
      "        [1.1279],\n",
      "        [1.1378],\n",
      "        [1.1237],\n",
      "        [1.1009],\n",
      "        [1.1065],\n",
      "        [1.1384],\n",
      "        [1.1463],\n",
      "        [1.1457],\n",
      "        [1.0275],\n",
      "        [1.1464],\n",
      "        [1.1236],\n",
      "        [1.1200],\n",
      "        [1.0924],\n",
      "        [1.1116],\n",
      "        [1.1297],\n",
      "        [1.1313],\n",
      "        [1.1074],\n",
      "        [1.0886],\n",
      "        [1.0670],\n",
      "        [1.1185],\n",
      "        [1.0452],\n",
      "        [1.0803],\n",
      "        [1.1309],\n",
      "        [1.1053],\n",
      "        [1.0963],\n",
      "        [1.0827],\n",
      "        [1.1267],\n",
      "        [1.1229],\n",
      "        [1.0870],\n",
      "        [1.1157],\n",
      "        [1.1190],\n",
      "        [1.1320],\n",
      "        [1.1023],\n",
      "        [1.1086],\n",
      "        [1.0810],\n",
      "        [1.0846],\n",
      "        [1.1037],\n",
      "        [1.1123],\n",
      "        [1.0742],\n",
      "        [1.1207],\n",
      "        [1.0914],\n",
      "        [1.1181],\n",
      "        [1.1294],\n",
      "        [1.1387],\n",
      "        [1.0887],\n",
      "        [1.1138],\n",
      "        [1.1409],\n",
      "        [1.1323],\n",
      "        [1.1193],\n",
      "        [1.1086],\n",
      "        [1.1059],\n",
      "        [1.1319],\n",
      "        [1.1315],\n",
      "        [1.1153],\n",
      "        [1.1107],\n",
      "        [1.1025],\n",
      "        [1.1466],\n",
      "        [1.1031],\n",
      "        [1.1021],\n",
      "        [1.1377],\n",
      "        [0.2496],\n",
      "        [1.1125],\n",
      "        [1.1365],\n",
      "        [1.0763],\n",
      "        [1.1231],\n",
      "        [1.1267],\n",
      "        [1.1318],\n",
      "        [1.0989],\n",
      "        [1.1355],\n",
      "        [1.1236],\n",
      "        [1.1461],\n",
      "        [1.1087],\n",
      "        [1.1423],\n",
      "        [1.0667],\n",
      "        [1.1431],\n",
      "        [1.1382],\n",
      "        [1.1021],\n",
      "        [1.1226],\n",
      "        [1.1220],\n",
      "        [1.0885],\n",
      "        [1.1078]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0944],\n",
      "        [1.0869],\n",
      "        [1.1395],\n",
      "        [1.0506]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   7 | lr 0.00100 train_loss 2.12578 | val_loss 2.28491 | val_rmse 1.51159\n",
      "tensor([[1.0849],\n",
      "        [1.1240],\n",
      "        [1.1269],\n",
      "        [1.1240],\n",
      "        [1.1227],\n",
      "        [1.1194],\n",
      "        [1.0816],\n",
      "        [1.0922],\n",
      "        [1.0967],\n",
      "        [1.0823],\n",
      "        [1.1479],\n",
      "        [1.1078],\n",
      "        [1.1263],\n",
      "        [1.1494],\n",
      "        [1.1491],\n",
      "        [1.0996],\n",
      "        [1.1471],\n",
      "        [1.1030],\n",
      "        [1.1338],\n",
      "        [1.1492],\n",
      "        [1.1018],\n",
      "        [1.1422],\n",
      "        [1.1132],\n",
      "        [1.1339],\n",
      "        [1.0744],\n",
      "        [1.1073],\n",
      "        [1.1207],\n",
      "        [1.1173],\n",
      "        [0.0387],\n",
      "        [1.0733],\n",
      "        [1.1240],\n",
      "        [1.1459],\n",
      "        [1.1410],\n",
      "        [1.1349],\n",
      "        [1.0856],\n",
      "        [1.1375],\n",
      "        [1.1412],\n",
      "        [1.0914],\n",
      "        [1.1360],\n",
      "        [1.1433],\n",
      "        [1.1162],\n",
      "        [1.1105],\n",
      "        [1.1401],\n",
      "        [1.1377],\n",
      "        [1.1459],\n",
      "        [1.1447],\n",
      "        [1.1441],\n",
      "        [1.1304],\n",
      "        [1.1258],\n",
      "        [1.1286],\n",
      "        [1.1333],\n",
      "        [1.1443],\n",
      "        [1.1509],\n",
      "        [1.1361],\n",
      "        [1.0994],\n",
      "        [1.1150],\n",
      "        [1.1395],\n",
      "        [1.1347],\n",
      "        [1.1418],\n",
      "        [1.1239],\n",
      "        [1.1221],\n",
      "        [1.1460],\n",
      "        [1.1360],\n",
      "        [1.1492],\n",
      "        [1.0779],\n",
      "        [1.1127],\n",
      "        [1.1353],\n",
      "        [1.1444],\n",
      "        [1.1253],\n",
      "        [1.1404],\n",
      "        [1.1464],\n",
      "        [1.1332],\n",
      "        [1.1245],\n",
      "        [1.0569],\n",
      "        [1.0738],\n",
      "        [1.1106],\n",
      "        [1.1162],\n",
      "        [1.1504],\n",
      "        [1.1081],\n",
      "        [1.1220],\n",
      "        [1.1422],\n",
      "        [1.1381],\n",
      "        [1.1492],\n",
      "        [1.1209],\n",
      "        [1.0893],\n",
      "        [1.0914],\n",
      "        [1.0744],\n",
      "        [1.1496],\n",
      "        [1.1098],\n",
      "        [1.0905],\n",
      "        [1.0981],\n",
      "        [1.1222],\n",
      "        [1.1352],\n",
      "        [1.1415],\n",
      "        [1.1346],\n",
      "        [1.1129],\n",
      "        [1.1309],\n",
      "        [1.1234],\n",
      "        [1.1263],\n",
      "        [1.0897],\n",
      "        [1.1353],\n",
      "        [1.1340],\n",
      "        [1.1165],\n",
      "        [1.1387],\n",
      "        [1.1151],\n",
      "        [1.1174],\n",
      "        [1.1306],\n",
      "        [1.1308],\n",
      "        [1.1080],\n",
      "        [1.1151],\n",
      "        [1.1402],\n",
      "        [1.1495],\n",
      "        [1.1397],\n",
      "        [1.1047],\n",
      "        [1.1399],\n",
      "        [1.1355],\n",
      "        [1.0615],\n",
      "        [1.1031],\n",
      "        [1.1149],\n",
      "        [1.1324],\n",
      "        [1.1258],\n",
      "        [1.0878],\n",
      "        [1.1020],\n",
      "        [1.1136],\n",
      "        [1.1454],\n",
      "        [1.1162],\n",
      "        [1.1386],\n",
      "        [1.1445]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1284],\n",
      "        [1.1033],\n",
      "        [1.1125],\n",
      "        [1.1484],\n",
      "        [1.1522],\n",
      "        [0.7965],\n",
      "        [1.1288],\n",
      "        [1.1406],\n",
      "        [1.1285],\n",
      "        [1.1405],\n",
      "        [1.1425],\n",
      "        [1.1313],\n",
      "        [1.0384],\n",
      "        [1.1150],\n",
      "        [1.1509],\n",
      "        [1.1276],\n",
      "        [1.0979],\n",
      "        [1.1031],\n",
      "        [1.1386],\n",
      "        [1.1304],\n",
      "        [1.1367],\n",
      "        [1.1035],\n",
      "        [1.1505],\n",
      "        [1.1214],\n",
      "        [1.1311],\n",
      "        [1.1254],\n",
      "        [1.1520],\n",
      "        [1.1435],\n",
      "        [1.1236],\n",
      "        [1.1446],\n",
      "        [1.1407],\n",
      "        [1.1000],\n",
      "        [1.0667],\n",
      "        [1.1357],\n",
      "        [1.0743],\n",
      "        [1.1452],\n",
      "        [1.0995],\n",
      "        [1.1082],\n",
      "        [1.1213],\n",
      "        [1.1156],\n",
      "        [1.1344],\n",
      "        [1.1278],\n",
      "        [1.1279],\n",
      "        [1.1387],\n",
      "        [1.1516],\n",
      "        [1.1404],\n",
      "        [1.0786],\n",
      "        [1.1223],\n",
      "        [1.0829],\n",
      "        [1.1460],\n",
      "        [1.1390],\n",
      "        [1.1270],\n",
      "        [1.1039],\n",
      "        [1.1278],\n",
      "        [1.1473],\n",
      "        [1.1495],\n",
      "        [1.1042],\n",
      "        [1.1266],\n",
      "        [1.0873],\n",
      "        [1.1334],\n",
      "        [1.1479],\n",
      "        [1.1177],\n",
      "        [1.1003],\n",
      "        [1.1480],\n",
      "        [1.1535],\n",
      "        [1.1047],\n",
      "        [1.1492],\n",
      "        [1.1190],\n",
      "        [1.1449],\n",
      "        [1.1304],\n",
      "        [1.1324],\n",
      "        [1.1044],\n",
      "        [1.1128],\n",
      "        [1.0743],\n",
      "        [1.1029],\n",
      "        [1.1200],\n",
      "        [1.1118],\n",
      "        [1.1365],\n",
      "        [1.1459],\n",
      "        [1.1332],\n",
      "        [1.1350],\n",
      "        [1.0837],\n",
      "        [1.1183],\n",
      "        [1.1250],\n",
      "        [1.0970],\n",
      "        [1.1292],\n",
      "        [1.1129],\n",
      "        [1.1136],\n",
      "        [1.1143],\n",
      "        [1.1111],\n",
      "        [1.1410],\n",
      "        [1.0591],\n",
      "        [1.0884],\n",
      "        [1.1380],\n",
      "        [1.1513],\n",
      "        [1.1159],\n",
      "        [1.1225],\n",
      "        [1.1480],\n",
      "        [1.1103],\n",
      "        [0.0189],\n",
      "        [1.1042],\n",
      "        [1.1502],\n",
      "        [1.1438],\n",
      "        [1.0557],\n",
      "        [1.0966],\n",
      "        [1.1245],\n",
      "        [1.1005],\n",
      "        [1.1189],\n",
      "        [1.1070],\n",
      "        [1.1077],\n",
      "        [1.1464],\n",
      "        [1.1447],\n",
      "        [1.0763],\n",
      "        [1.1103],\n",
      "        [1.1262],\n",
      "        [1.1539],\n",
      "        [1.1451],\n",
      "        [1.1350],\n",
      "        [1.1203],\n",
      "        [1.1092],\n",
      "        [1.1474],\n",
      "        [1.1137],\n",
      "        [1.1278],\n",
      "        [1.1293],\n",
      "        [1.1192],\n",
      "        [1.1518],\n",
      "        [1.1195],\n",
      "        [1.1159]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1297],\n",
      "        [1.1432],\n",
      "        [1.1522],\n",
      "        [1.1457],\n",
      "        [1.1144],\n",
      "        [1.0748],\n",
      "        [1.1380],\n",
      "        [1.0886],\n",
      "        [1.1036],\n",
      "        [1.1347],\n",
      "        [1.1554],\n",
      "        [1.1066],\n",
      "        [1.1143],\n",
      "        [1.0619],\n",
      "        [1.1370],\n",
      "        [1.1302],\n",
      "        [1.1356],\n",
      "        [1.0871],\n",
      "        [1.1171],\n",
      "        [1.1381],\n",
      "        [1.1370],\n",
      "        [1.1553],\n",
      "        [1.1188],\n",
      "        [1.1050],\n",
      "        [1.1449],\n",
      "        [1.0866],\n",
      "        [1.1291],\n",
      "        [1.1350],\n",
      "        [1.1287],\n",
      "        [1.0983],\n",
      "        [1.1016],\n",
      "        [1.1336],\n",
      "        [1.1311],\n",
      "        [1.1562],\n",
      "        [1.1437],\n",
      "        [1.1450],\n",
      "        [1.1231],\n",
      "        [1.0957],\n",
      "        [1.1344],\n",
      "        [1.1113],\n",
      "        [1.1355],\n",
      "        [1.1511],\n",
      "        [1.1203],\n",
      "        [1.1102],\n",
      "        [1.1323],\n",
      "        [1.1048],\n",
      "        [1.1562],\n",
      "        [1.1554],\n",
      "        [1.1031],\n",
      "        [1.1292],\n",
      "        [1.1033],\n",
      "        [1.0739],\n",
      "        [1.1042],\n",
      "        [1.0896],\n",
      "        [1.1553],\n",
      "        [1.1007],\n",
      "        [1.1231],\n",
      "        [1.1164],\n",
      "        [1.0733],\n",
      "        [1.1426],\n",
      "        [1.1068],\n",
      "        [1.1173],\n",
      "        [1.1290],\n",
      "        [1.1253],\n",
      "        [1.1040],\n",
      "        [1.1198],\n",
      "        [1.1153],\n",
      "        [1.1335],\n",
      "        [1.1216],\n",
      "        [1.0697],\n",
      "        [1.1520],\n",
      "        [1.1249],\n",
      "        [1.1477],\n",
      "        [1.1340],\n",
      "        [1.0842],\n",
      "        [1.1562],\n",
      "        [1.1044],\n",
      "        [1.1545],\n",
      "        [1.1358],\n",
      "        [1.1423],\n",
      "        [1.1102],\n",
      "        [1.1363],\n",
      "        [1.1016],\n",
      "        [1.1433],\n",
      "        [1.0766],\n",
      "        [1.1524],\n",
      "        [1.0981],\n",
      "        [1.0839],\n",
      "        [1.1278],\n",
      "        [1.0952],\n",
      "        [1.1405],\n",
      "        [1.1259],\n",
      "        [1.1296],\n",
      "        [1.0770],\n",
      "        [1.1204],\n",
      "        [1.1469],\n",
      "        [1.1194],\n",
      "        [1.0611],\n",
      "        [1.1508],\n",
      "        [1.1549],\n",
      "        [1.0921],\n",
      "        [1.1412],\n",
      "        [1.1450],\n",
      "        [1.1520],\n",
      "        [1.1305],\n",
      "        [1.0824],\n",
      "        [1.1157],\n",
      "        [1.1274],\n",
      "        [1.1309],\n",
      "        [1.1471],\n",
      "        [1.1575],\n",
      "        [1.1288],\n",
      "        [1.1451],\n",
      "        [1.1520],\n",
      "        [1.1170],\n",
      "        [1.1469],\n",
      "        [1.1534],\n",
      "        [1.0879],\n",
      "        [1.1180],\n",
      "        [1.1432],\n",
      "        [1.0640],\n",
      "        [1.1482],\n",
      "        [1.1333],\n",
      "        [1.1544],\n",
      "        [1.1442],\n",
      "        [1.1447],\n",
      "        [1.1552],\n",
      "        [1.1227]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1167],\n",
      "        [1.1594],\n",
      "        [1.1055],\n",
      "        [1.1117],\n",
      "        [1.1572],\n",
      "        [1.0947],\n",
      "        [1.1425],\n",
      "        [1.0479],\n",
      "        [1.1219],\n",
      "        [1.1170],\n",
      "        [1.1479],\n",
      "        [1.0982],\n",
      "        [1.1588],\n",
      "        [1.1198],\n",
      "        [1.1563],\n",
      "        [1.1431],\n",
      "        [1.1415],\n",
      "        [1.1547],\n",
      "        [1.0774],\n",
      "        [1.0335],\n",
      "        [1.1587],\n",
      "        [1.1359],\n",
      "        [1.0950],\n",
      "        [1.1382],\n",
      "        [1.1527],\n",
      "        [1.1382],\n",
      "        [1.0888],\n",
      "        [1.0842],\n",
      "        [1.1321],\n",
      "        [1.1158],\n",
      "        [1.1160],\n",
      "        [1.1581],\n",
      "        [1.1209],\n",
      "        [1.1502],\n",
      "        [1.1386],\n",
      "        [0.3855],\n",
      "        [1.1484],\n",
      "        [1.1370],\n",
      "        [1.1495],\n",
      "        [1.1042],\n",
      "        [1.1150],\n",
      "        [1.1557],\n",
      "        [1.1151],\n",
      "        [1.1329],\n",
      "        [1.1573],\n",
      "        [1.1356],\n",
      "        [1.1364],\n",
      "        [1.1468],\n",
      "        [1.1351],\n",
      "        [1.1373],\n",
      "        [1.1438],\n",
      "        [1.1493],\n",
      "        [1.1101],\n",
      "        [1.1469],\n",
      "        [1.1284],\n",
      "        [1.0775],\n",
      "        [1.1199],\n",
      "        [1.1489],\n",
      "        [1.1616],\n",
      "        [1.1291],\n",
      "        [1.0853],\n",
      "        [1.0993],\n",
      "        [1.1330],\n",
      "        [1.1296],\n",
      "        [1.1548],\n",
      "        [1.1324],\n",
      "        [1.0938],\n",
      "        [1.1493],\n",
      "        [1.1482],\n",
      "        [1.1397],\n",
      "        [1.1545],\n",
      "        [1.1256],\n",
      "        [1.1327],\n",
      "        [1.1187],\n",
      "        [1.1466],\n",
      "        [1.1305],\n",
      "        [1.1492],\n",
      "        [1.1472],\n",
      "        [1.0944],\n",
      "        [1.1262],\n",
      "        [1.1230],\n",
      "        [1.1378],\n",
      "        [1.1392],\n",
      "        [1.1564],\n",
      "        [1.0870],\n",
      "        [1.1247],\n",
      "        [1.0908],\n",
      "        [1.1497],\n",
      "        [1.1401],\n",
      "        [1.1325],\n",
      "        [1.1565],\n",
      "        [1.0706],\n",
      "        [1.1563],\n",
      "        [1.1222],\n",
      "        [1.1559],\n",
      "        [1.0914],\n",
      "        [1.1511],\n",
      "        [1.1416],\n",
      "        [1.1370],\n",
      "        [1.1476],\n",
      "        [1.1602],\n",
      "        [1.0917],\n",
      "        [1.1533],\n",
      "        [1.1222],\n",
      "        [1.1579],\n",
      "        [1.1238],\n",
      "        [1.1136],\n",
      "        [1.1441],\n",
      "        [1.1479],\n",
      "        [1.1417],\n",
      "        [1.1023],\n",
      "        [1.1110],\n",
      "        [1.1476],\n",
      "        [1.1603],\n",
      "        [1.1549],\n",
      "        [1.1584],\n",
      "        [1.1617],\n",
      "        [1.1320],\n",
      "        [1.1073],\n",
      "        [1.1236],\n",
      "        [1.0990],\n",
      "        [1.1474],\n",
      "        [1.1186],\n",
      "        [1.1272],\n",
      "        [1.0711],\n",
      "        [1.1617],\n",
      "        [1.1219],\n",
      "        [1.1044]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1492],\n",
      "        [1.0567],\n",
      "        [1.1600],\n",
      "        [1.1272],\n",
      "        [1.1541],\n",
      "        [1.1587],\n",
      "        [1.1518],\n",
      "        [1.0799],\n",
      "        [1.1414],\n",
      "        [1.1180],\n",
      "        [1.1501],\n",
      "        [1.0871],\n",
      "        [1.1615],\n",
      "        [1.1436],\n",
      "        [1.1625],\n",
      "        [1.1570],\n",
      "        [1.0850],\n",
      "        [1.1228],\n",
      "        [1.1464],\n",
      "        [1.1247],\n",
      "        [1.1101],\n",
      "        [1.1311],\n",
      "        [1.1218],\n",
      "        [1.1061],\n",
      "        [1.1475],\n",
      "        [1.1117],\n",
      "        [1.1565],\n",
      "        [1.0964],\n",
      "        [1.1261],\n",
      "        [1.1549],\n",
      "        [1.1592],\n",
      "        [1.1237],\n",
      "        [1.1578],\n",
      "        [1.1568],\n",
      "        [1.1405],\n",
      "        [1.1564],\n",
      "        [1.1259],\n",
      "        [1.1488],\n",
      "        [1.0937],\n",
      "        [1.0683],\n",
      "        [1.1295],\n",
      "        [1.1440],\n",
      "        [1.1480],\n",
      "        [1.1653],\n",
      "        [1.1421],\n",
      "        [1.1392],\n",
      "        [1.0839],\n",
      "        [1.1653],\n",
      "        [1.1027],\n",
      "        [1.1205],\n",
      "        [1.1176],\n",
      "        [1.1324],\n",
      "        [1.1569],\n",
      "        [1.0941],\n",
      "        [1.1511],\n",
      "        [1.1631],\n",
      "        [1.1496],\n",
      "        [1.1457],\n",
      "        [1.1211],\n",
      "        [1.1642],\n",
      "        [1.1398],\n",
      "        [1.1351],\n",
      "        [1.1325],\n",
      "        [1.1366],\n",
      "        [1.1175],\n",
      "        [1.0921],\n",
      "        [1.1567],\n",
      "        [1.1471],\n",
      "        [1.1370],\n",
      "        [1.1439],\n",
      "        [1.1489],\n",
      "        [1.1530],\n",
      "        [1.1648],\n",
      "        [1.1457],\n",
      "        [1.0998],\n",
      "        [1.1298],\n",
      "        [1.1229],\n",
      "        [1.1311],\n",
      "        [1.1536],\n",
      "        [1.1222],\n",
      "        [1.1133],\n",
      "        [1.1094],\n",
      "        [1.1557],\n",
      "        [1.1447],\n",
      "        [1.1239],\n",
      "        [1.1631],\n",
      "        [1.0721],\n",
      "        [1.1561],\n",
      "        [1.1525],\n",
      "        [1.0924],\n",
      "        [1.1422],\n",
      "        [1.1220],\n",
      "        [1.1497],\n",
      "        [1.1292],\n",
      "        [1.1178],\n",
      "        [1.1587],\n",
      "        [1.1464],\n",
      "        [1.1623],\n",
      "        [1.1570],\n",
      "        [1.1619],\n",
      "        [1.1486],\n",
      "        [1.1606],\n",
      "        [1.1171],\n",
      "        [1.1518],\n",
      "        [1.1269],\n",
      "        [1.1615],\n",
      "        [1.1371],\n",
      "        [1.1510],\n",
      "        [1.1473],\n",
      "        [1.1119],\n",
      "        [1.1479],\n",
      "        [1.1618],\n",
      "        [1.1408],\n",
      "        [1.1383],\n",
      "        [1.1092],\n",
      "        [1.1569],\n",
      "        [1.1291],\n",
      "        [1.1533],\n",
      "        [1.1175],\n",
      "        [1.1329],\n",
      "        [1.0805],\n",
      "        [1.1456],\n",
      "        [1.1047],\n",
      "        [1.1386],\n",
      "        [1.1299],\n",
      "        [1.1242],\n",
      "        [1.1584],\n",
      "        [1.1640]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1357],\n",
      "        [1.1047],\n",
      "        [1.1573],\n",
      "        [1.1489],\n",
      "        [1.1153],\n",
      "        [1.1290],\n",
      "        [1.1283],\n",
      "        [1.1427],\n",
      "        [1.1278],\n",
      "        [1.1387],\n",
      "        [1.1579],\n",
      "        [1.1219],\n",
      "        [1.1619],\n",
      "        [1.1398],\n",
      "        [1.1439],\n",
      "        [1.1081],\n",
      "        [1.1412],\n",
      "        [1.1464],\n",
      "        [1.1138],\n",
      "        [1.1341],\n",
      "        [1.1453],\n",
      "        [1.1303],\n",
      "        [1.1318],\n",
      "        [1.1645],\n",
      "        [1.1379],\n",
      "        [1.1589],\n",
      "        [1.1570],\n",
      "        [1.1490],\n",
      "        [1.1395],\n",
      "        [1.1160],\n",
      "        [1.1393],\n",
      "        [1.1674],\n",
      "        [1.1421],\n",
      "        [1.1291],\n",
      "        [1.1146],\n",
      "        [1.1589],\n",
      "        [1.1552],\n",
      "        [1.1390],\n",
      "        [1.1209],\n",
      "        [1.1617],\n",
      "        [1.1431],\n",
      "        [1.0688],\n",
      "        [1.1629],\n",
      "        [1.1380],\n",
      "        [1.1635],\n",
      "        [1.0928],\n",
      "        [1.1518],\n",
      "        [1.1384],\n",
      "        [1.1641],\n",
      "        [1.1437],\n",
      "        [1.1634],\n",
      "        [1.1628],\n",
      "        [1.1351],\n",
      "        [1.1585],\n",
      "        [1.1144],\n",
      "        [1.0939],\n",
      "        [1.1382],\n",
      "        [1.1627],\n",
      "        [1.1316],\n",
      "        [1.1165],\n",
      "        [1.1437],\n",
      "        [1.1415],\n",
      "        [1.1647],\n",
      "        [1.1513],\n",
      "        [1.1315],\n",
      "        [1.1492],\n",
      "        [1.1229],\n",
      "        [1.1282],\n",
      "        [1.1202],\n",
      "        [1.1399],\n",
      "        [1.1473],\n",
      "        [1.1236],\n",
      "        [1.1426],\n",
      "        [1.1702],\n",
      "        [1.1516],\n",
      "        [1.1349],\n",
      "        [1.1182],\n",
      "        [1.1036],\n",
      "        [1.1271],\n",
      "        [1.1221],\n",
      "        [1.1593],\n",
      "        [1.1493],\n",
      "        [1.1341],\n",
      "        [1.1276],\n",
      "        [1.1369],\n",
      "        [1.1679],\n",
      "        [1.1516],\n",
      "        [1.1335],\n",
      "        [1.1446],\n",
      "        [1.1643],\n",
      "        [1.1316],\n",
      "        [1.1520],\n",
      "        [1.1263],\n",
      "        [1.0980],\n",
      "        [1.1263],\n",
      "        [1.1651],\n",
      "        [1.1553],\n",
      "        [1.1212],\n",
      "        [1.0906],\n",
      "        [1.1679],\n",
      "        [1.1578],\n",
      "        [1.0946],\n",
      "        [1.1133],\n",
      "        [1.1438],\n",
      "        [1.1483],\n",
      "        [1.1445],\n",
      "        [1.1649],\n",
      "        [1.1260],\n",
      "        [1.1595],\n",
      "        [1.1249],\n",
      "        [1.1635],\n",
      "        [1.1547],\n",
      "        [1.1401],\n",
      "        [1.1679],\n",
      "        [1.1322],\n",
      "        [1.1374],\n",
      "        [1.1392],\n",
      "        [1.1661],\n",
      "        [1.1071],\n",
      "        [1.1575],\n",
      "        [1.1363],\n",
      "        [1.1255],\n",
      "        [1.1182],\n",
      "        [1.1195],\n",
      "        [1.1520],\n",
      "        [1.1243],\n",
      "        [1.1563],\n",
      "        [1.1656]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1585],\n",
      "        [1.1431],\n",
      "        [1.1618],\n",
      "        [1.1586],\n",
      "        [1.1338],\n",
      "        [1.1004],\n",
      "        [1.1685],\n",
      "        [1.1461],\n",
      "        [1.1570],\n",
      "        [1.1212],\n",
      "        [1.1396],\n",
      "        [1.0715],\n",
      "        [1.1543],\n",
      "        [1.1561],\n",
      "        [1.1399],\n",
      "        [1.1470],\n",
      "        [1.0834],\n",
      "        [1.1316],\n",
      "        [1.1363],\n",
      "        [1.1208],\n",
      "        [1.1230],\n",
      "        [1.1578],\n",
      "        [1.1036],\n",
      "        [1.1515],\n",
      "        [1.1301],\n",
      "        [1.1392],\n",
      "        [1.0852],\n",
      "        [1.1449],\n",
      "        [1.0957],\n",
      "        [1.1077],\n",
      "        [1.1215],\n",
      "        [1.1470],\n",
      "        [1.1172],\n",
      "        [1.1180],\n",
      "        [1.1190],\n",
      "        [1.1408],\n",
      "        [1.1248],\n",
      "        [1.1574],\n",
      "        [1.1611],\n",
      "        [1.0881],\n",
      "        [1.1533],\n",
      "        [1.1389],\n",
      "        [1.1240],\n",
      "        [1.1207],\n",
      "        [1.1220],\n",
      "        [1.1176],\n",
      "        [1.1586],\n",
      "        [1.1457],\n",
      "        [1.1389],\n",
      "        [1.1579],\n",
      "        [1.1342],\n",
      "        [1.1469],\n",
      "        [1.1139],\n",
      "        [1.1509],\n",
      "        [1.1217],\n",
      "        [1.0983],\n",
      "        [1.1249],\n",
      "        [1.1164],\n",
      "        [1.1614],\n",
      "        [1.1424],\n",
      "        [1.1593],\n",
      "        [1.1638],\n",
      "        [1.0981],\n",
      "        [1.1487],\n",
      "        [1.1680],\n",
      "        [1.1393],\n",
      "        [1.1017],\n",
      "        [1.1540],\n",
      "        [1.1323],\n",
      "        [1.1546],\n",
      "        [1.1181],\n",
      "        [1.1546],\n",
      "        [1.1368],\n",
      "        [1.1234],\n",
      "        [1.1549],\n",
      "        [1.0921],\n",
      "        [1.1632],\n",
      "        [1.1340],\n",
      "        [1.1533],\n",
      "        [1.1603],\n",
      "        [1.1549],\n",
      "        [1.1411],\n",
      "        [1.1393],\n",
      "        [1.1078],\n",
      "        [1.1350],\n",
      "        [1.1411],\n",
      "        [1.1386],\n",
      "        [1.1550],\n",
      "        [1.1555],\n",
      "        [1.1275],\n",
      "        [1.1502],\n",
      "        [0.2977],\n",
      "        [1.1105],\n",
      "        [1.1531],\n",
      "        [1.1257],\n",
      "        [1.1683],\n",
      "        [1.1318],\n",
      "        [1.1501],\n",
      "        [1.1302],\n",
      "        [1.1039],\n",
      "        [1.1297],\n",
      "        [1.1236],\n",
      "        [1.1420],\n",
      "        [1.1473],\n",
      "        [1.1451],\n",
      "        [1.1478],\n",
      "        [1.1668],\n",
      "        [1.1419],\n",
      "        [1.1343],\n",
      "        [1.1384],\n",
      "        [1.1438],\n",
      "        [1.1210],\n",
      "        [1.1299],\n",
      "        [1.1354],\n",
      "        [1.1587],\n",
      "        [1.1592],\n",
      "        [1.1025],\n",
      "        [1.1664],\n",
      "        [1.1682],\n",
      "        [1.1298],\n",
      "        [1.1491],\n",
      "        [1.0987],\n",
      "        [1.1583],\n",
      "        [1.1430],\n",
      "        [1.1204],\n",
      "        [1.1681],\n",
      "        [1.1159],\n",
      "        [1.1167]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1143],\n",
      "        [1.0761],\n",
      "        [1.1619],\n",
      "        [1.1506]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   8 | lr 0.00100 train_loss 2.11923 | val_loss 2.28116 | val_rmse 1.51035\n",
      "tensor([[1.1510],\n",
      "        [1.1231],\n",
      "        [1.0952],\n",
      "        [1.1567],\n",
      "        [1.1182],\n",
      "        [1.1391],\n",
      "        [1.1520],\n",
      "        [1.1284],\n",
      "        [1.0966],\n",
      "        [1.1535],\n",
      "        [1.1276],\n",
      "        [1.1078],\n",
      "        [1.0901],\n",
      "        [1.1620],\n",
      "        [1.1400],\n",
      "        [1.1535],\n",
      "        [1.1487],\n",
      "        [1.1456],\n",
      "        [1.1518],\n",
      "        [1.1506],\n",
      "        [1.1599],\n",
      "        [1.1424],\n",
      "        [1.1275],\n",
      "        [1.1222],\n",
      "        [1.1371],\n",
      "        [1.1643],\n",
      "        [1.1580],\n",
      "        [1.1124],\n",
      "        [1.1272],\n",
      "        [1.1567],\n",
      "        [1.1373],\n",
      "        [1.1100],\n",
      "        [1.1265],\n",
      "        [1.1185],\n",
      "        [1.1655],\n",
      "        [1.1283],\n",
      "        [1.1080],\n",
      "        [1.1447],\n",
      "        [1.1300],\n",
      "        [1.1702],\n",
      "        [1.1287],\n",
      "        [1.1580],\n",
      "        [1.1401],\n",
      "        [1.1083],\n",
      "        [1.1161],\n",
      "        [1.1119],\n",
      "        [1.1390],\n",
      "        [1.1216],\n",
      "        [1.1131],\n",
      "        [1.1378],\n",
      "        [1.1319],\n",
      "        [1.1294],\n",
      "        [1.1353],\n",
      "        [1.1486],\n",
      "        [1.1171],\n",
      "        [1.1605],\n",
      "        [1.1228],\n",
      "        [1.1437],\n",
      "        [1.1400],\n",
      "        [1.1427],\n",
      "        [1.1172],\n",
      "        [1.1352],\n",
      "        [1.1302],\n",
      "        [1.1368],\n",
      "        [1.1279],\n",
      "        [1.1509],\n",
      "        [1.1681],\n",
      "        [1.0467],\n",
      "        [1.1644],\n",
      "        [1.1326],\n",
      "        [1.1627],\n",
      "        [1.1182],\n",
      "        [1.1686],\n",
      "        [1.0825],\n",
      "        [1.1295],\n",
      "        [1.1633],\n",
      "        [1.1533],\n",
      "        [1.1395],\n",
      "        [1.1572],\n",
      "        [1.1430],\n",
      "        [1.1647],\n",
      "        [1.1681],\n",
      "        [1.0956],\n",
      "        [1.1273],\n",
      "        [1.1163],\n",
      "        [1.1542],\n",
      "        [1.0762],\n",
      "        [1.1460],\n",
      "        [1.1080],\n",
      "        [1.1654],\n",
      "        [1.1589],\n",
      "        [1.1546],\n",
      "        [1.1251],\n",
      "        [1.1415],\n",
      "        [1.1133],\n",
      "        [1.1436],\n",
      "        [1.1090],\n",
      "        [1.1306],\n",
      "        [1.1308],\n",
      "        [1.1498],\n",
      "        [1.1472],\n",
      "        [1.1421],\n",
      "        [1.1485],\n",
      "        [1.1448],\n",
      "        [1.1240],\n",
      "        [1.1457],\n",
      "        [1.1536],\n",
      "        [1.1298],\n",
      "        [1.1512],\n",
      "        [1.1624],\n",
      "        [1.1482],\n",
      "        [1.1530],\n",
      "        [1.1459],\n",
      "        [1.1348],\n",
      "        [1.1126],\n",
      "        [1.1526],\n",
      "        [1.1429],\n",
      "        [1.1270],\n",
      "        [1.1422],\n",
      "        [1.1231],\n",
      "        [1.1187],\n",
      "        [1.1531],\n",
      "        [1.1624],\n",
      "        [1.1544],\n",
      "        [1.1307],\n",
      "        [1.1517],\n",
      "        [1.1648],\n",
      "        [1.1197]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1070],\n",
      "        [1.1564],\n",
      "        [1.1266],\n",
      "        [1.1572],\n",
      "        [1.1207],\n",
      "        [1.1311],\n",
      "        [1.1618],\n",
      "        [1.1244],\n",
      "        [1.1208],\n",
      "        [1.1344],\n",
      "        [1.1460],\n",
      "        [1.1537],\n",
      "        [1.1183],\n",
      "        [1.0745],\n",
      "        [1.1458],\n",
      "        [1.1289],\n",
      "        [1.1537],\n",
      "        [1.1540],\n",
      "        [1.1250],\n",
      "        [1.1570],\n",
      "        [1.1670],\n",
      "        [1.1615],\n",
      "        [1.1466],\n",
      "        [1.1449],\n",
      "        [1.1397],\n",
      "        [1.1195],\n",
      "        [1.1642],\n",
      "        [1.1664],\n",
      "        [1.1480],\n",
      "        [1.1304],\n",
      "        [1.1502],\n",
      "        [1.1338],\n",
      "        [1.1383],\n",
      "        [1.1611],\n",
      "        [1.1159],\n",
      "        [1.1086],\n",
      "        [1.1303],\n",
      "        [1.1495],\n",
      "        [1.1631],\n",
      "        [1.1345],\n",
      "        [1.1248],\n",
      "        [1.1382],\n",
      "        [1.1129],\n",
      "        [1.1268],\n",
      "        [1.1432],\n",
      "        [1.1566],\n",
      "        [1.1442],\n",
      "        [1.1572],\n",
      "        [1.1674],\n",
      "        [1.1169],\n",
      "        [1.1273],\n",
      "        [1.1064],\n",
      "        [1.1279],\n",
      "        [1.1487],\n",
      "        [1.0802],\n",
      "        [1.1314],\n",
      "        [1.1521],\n",
      "        [1.1673],\n",
      "        [1.0911],\n",
      "        [1.1238],\n",
      "        [1.1018],\n",
      "        [1.1153],\n",
      "        [1.1150],\n",
      "        [1.1354],\n",
      "        [1.1591],\n",
      "        [1.1098],\n",
      "        [1.1398],\n",
      "        [1.1385],\n",
      "        [1.1074],\n",
      "        [1.1611],\n",
      "        [1.1476],\n",
      "        [1.1435],\n",
      "        [1.1483],\n",
      "        [1.1563],\n",
      "        [1.1470],\n",
      "        [1.1661],\n",
      "        [1.1413],\n",
      "        [1.1557],\n",
      "        [1.1629],\n",
      "        [1.1124],\n",
      "        [1.1233],\n",
      "        [1.1056],\n",
      "        [1.1366],\n",
      "        [1.1242],\n",
      "        [1.1654],\n",
      "        [1.1639],\n",
      "        [1.1276],\n",
      "        [1.1670],\n",
      "        [1.1264],\n",
      "        [1.1671],\n",
      "        [1.1303],\n",
      "        [1.1199],\n",
      "        [1.1445],\n",
      "        [1.1559],\n",
      "        [1.1489],\n",
      "        [1.1560],\n",
      "        [1.1152],\n",
      "        [1.1406],\n",
      "        [1.1512],\n",
      "        [1.1679],\n",
      "        [1.1643],\n",
      "        [1.1451],\n",
      "        [1.1342],\n",
      "        [1.1349],\n",
      "        [1.1126],\n",
      "        [1.1109],\n",
      "        [1.1546],\n",
      "        [1.1068],\n",
      "        [1.1246],\n",
      "        [1.1560],\n",
      "        [1.1040],\n",
      "        [1.1489],\n",
      "        [1.1274],\n",
      "        [1.1561],\n",
      "        [1.1053],\n",
      "        [1.1045],\n",
      "        [1.1470],\n",
      "        [1.1379],\n",
      "        [1.1586],\n",
      "        [1.1419],\n",
      "        [1.1097],\n",
      "        [1.1341],\n",
      "        [1.1318],\n",
      "        [1.1374],\n",
      "        [1.1502],\n",
      "        [1.1562],\n",
      "        [1.1310],\n",
      "        [1.1297]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0941],\n",
      "        [1.1171],\n",
      "        [1.1404],\n",
      "        [1.1268],\n",
      "        [1.1124],\n",
      "        [1.1375],\n",
      "        [1.1475],\n",
      "        [1.1623],\n",
      "        [1.1270],\n",
      "        [1.1380],\n",
      "        [1.1396],\n",
      "        [1.1373],\n",
      "        [1.1412],\n",
      "        [1.1273],\n",
      "        [1.1245],\n",
      "        [1.1418],\n",
      "        [0.6831],\n",
      "        [1.0821],\n",
      "        [1.1213],\n",
      "        [1.1181],\n",
      "        [1.1266],\n",
      "        [1.1566],\n",
      "        [1.1587],\n",
      "        [1.1053],\n",
      "        [1.1646],\n",
      "        [1.1046],\n",
      "        [1.1574],\n",
      "        [1.1131],\n",
      "        [1.1191],\n",
      "        [1.1328],\n",
      "        [1.1503],\n",
      "        [1.1551],\n",
      "        [1.0853],\n",
      "        [1.1444],\n",
      "        [1.1506],\n",
      "        [1.1553],\n",
      "        [1.1431],\n",
      "        [1.1459],\n",
      "        [1.1599],\n",
      "        [1.1552],\n",
      "        [1.1226],\n",
      "        [1.1579],\n",
      "        [1.1437],\n",
      "        [1.1639],\n",
      "        [1.1220],\n",
      "        [1.0930],\n",
      "        [1.1123],\n",
      "        [1.1529],\n",
      "        [1.1192],\n",
      "        [1.1559],\n",
      "        [1.1393],\n",
      "        [1.1589],\n",
      "        [1.1340],\n",
      "        [1.1552],\n",
      "        [1.0974],\n",
      "        [1.1561],\n",
      "        [1.1449],\n",
      "        [1.0898],\n",
      "        [1.1512],\n",
      "        [1.1681],\n",
      "        [1.1557],\n",
      "        [1.1277],\n",
      "        [1.1640],\n",
      "        [1.1400],\n",
      "        [1.1258],\n",
      "        [1.1148],\n",
      "        [1.1086],\n",
      "        [1.1435],\n",
      "        [1.1384],\n",
      "        [1.1490],\n",
      "        [1.1469],\n",
      "        [1.1324],\n",
      "        [1.0735],\n",
      "        [1.1228],\n",
      "        [1.1638],\n",
      "        [1.1489],\n",
      "        [1.1405],\n",
      "        [1.1437],\n",
      "        [1.1649],\n",
      "        [1.1196],\n",
      "        [1.1573],\n",
      "        [1.1079],\n",
      "        [1.1600],\n",
      "        [1.1131],\n",
      "        [1.1109],\n",
      "        [1.1118],\n",
      "        [1.1597],\n",
      "        [1.1656],\n",
      "        [1.1137],\n",
      "        [1.1454],\n",
      "        [1.1202],\n",
      "        [1.0928],\n",
      "        [1.1419],\n",
      "        [1.1623],\n",
      "        [1.1472],\n",
      "        [1.0883],\n",
      "        [1.1002],\n",
      "        [1.1654],\n",
      "        [1.1230],\n",
      "        [1.0742],\n",
      "        [1.1044],\n",
      "        [1.1604],\n",
      "        [1.1669],\n",
      "        [1.0547],\n",
      "        [1.1487],\n",
      "        [1.1457],\n",
      "        [1.1623],\n",
      "        [1.1660],\n",
      "        [1.1344],\n",
      "        [1.1633],\n",
      "        [1.1688],\n",
      "        [1.1331],\n",
      "        [1.1279],\n",
      "        [1.1667],\n",
      "        [1.1490],\n",
      "        [1.1062],\n",
      "        [1.1280],\n",
      "        [1.1428],\n",
      "        [1.1496],\n",
      "        [1.1255],\n",
      "        [1.1264],\n",
      "        [1.1381],\n",
      "        [1.1254],\n",
      "        [1.1506],\n",
      "        [1.1070],\n",
      "        [1.1495],\n",
      "        [1.1650],\n",
      "        [1.1386]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1465],\n",
      "        [1.1356],\n",
      "        [1.1548],\n",
      "        [1.1409],\n",
      "        [1.1389],\n",
      "        [1.1032],\n",
      "        [1.1627],\n",
      "        [1.0979],\n",
      "        [1.1330],\n",
      "        [1.1507],\n",
      "        [1.1308],\n",
      "        [1.1632],\n",
      "        [1.1393],\n",
      "        [1.1439],\n",
      "        [1.1674],\n",
      "        [1.1223],\n",
      "        [1.1338],\n",
      "        [1.1276],\n",
      "        [1.1637],\n",
      "        [1.1585],\n",
      "        [1.1583],\n",
      "        [1.1133],\n",
      "        [1.1355],\n",
      "        [1.1221],\n",
      "        [1.1475],\n",
      "        [1.1394],\n",
      "        [1.1609],\n",
      "        [1.1197],\n",
      "        [1.1197],\n",
      "        [1.1287],\n",
      "        [1.1368],\n",
      "        [1.1104],\n",
      "        [1.1296],\n",
      "        [1.1574],\n",
      "        [1.1397],\n",
      "        [1.1252],\n",
      "        [1.1373],\n",
      "        [1.1490],\n",
      "        [1.1350],\n",
      "        [1.1356],\n",
      "        [1.1153],\n",
      "        [1.1587],\n",
      "        [1.1297],\n",
      "        [1.1422],\n",
      "        [1.1394],\n",
      "        [1.1394],\n",
      "        [1.1538],\n",
      "        [1.1147],\n",
      "        [1.1402],\n",
      "        [1.1554],\n",
      "        [1.1019],\n",
      "        [1.1403],\n",
      "        [1.1049],\n",
      "        [1.1287],\n",
      "        [1.1061],\n",
      "        [1.0559],\n",
      "        [1.0981],\n",
      "        [1.1309],\n",
      "        [1.1484],\n",
      "        [1.1540],\n",
      "        [1.1677],\n",
      "        [1.1166],\n",
      "        [1.1588],\n",
      "        [1.1401],\n",
      "        [1.1677],\n",
      "        [1.1110],\n",
      "        [1.1659],\n",
      "        [1.1616],\n",
      "        [1.1100],\n",
      "        [1.1607],\n",
      "        [1.1338],\n",
      "        [1.1665],\n",
      "        [1.1301],\n",
      "        [1.1610],\n",
      "        [1.1478],\n",
      "        [1.1657],\n",
      "        [1.1311],\n",
      "        [1.0941],\n",
      "        [1.1095],\n",
      "        [1.1502],\n",
      "        [1.1381],\n",
      "        [1.1264],\n",
      "        [1.1636],\n",
      "        [1.1624],\n",
      "        [1.0806],\n",
      "        [1.1665],\n",
      "        [1.0866],\n",
      "        [1.1610],\n",
      "        [1.0894],\n",
      "        [1.1294],\n",
      "        [1.1631],\n",
      "        [1.1233],\n",
      "        [1.1405],\n",
      "        [1.1274],\n",
      "        [1.1530],\n",
      "        [1.1574],\n",
      "        [1.1547],\n",
      "        [1.1392],\n",
      "        [1.0915],\n",
      "        [1.1308],\n",
      "        [1.1504],\n",
      "        [1.1183],\n",
      "        [1.1019],\n",
      "        [1.1549],\n",
      "        [1.1443],\n",
      "        [1.1205],\n",
      "        [1.1488],\n",
      "        [1.1273],\n",
      "        [1.1640],\n",
      "        [1.1233],\n",
      "        [1.0982],\n",
      "        [1.1452],\n",
      "        [1.1349],\n",
      "        [1.1441],\n",
      "        [1.1512],\n",
      "        [1.1141],\n",
      "        [1.1413],\n",
      "        [1.1375],\n",
      "        [1.1427],\n",
      "        [1.1299],\n",
      "        [1.1233],\n",
      "        [1.1583],\n",
      "        [1.0939],\n",
      "        [1.1665],\n",
      "        [1.1537],\n",
      "        [1.1409],\n",
      "        [1.1349],\n",
      "        [1.1324]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1048],\n",
      "        [1.1669],\n",
      "        [1.1566],\n",
      "        [1.1597],\n",
      "        [1.1340],\n",
      "        [1.0903],\n",
      "        [1.1324],\n",
      "        [1.1442],\n",
      "        [1.0925],\n",
      "        [1.1365],\n",
      "        [1.1375],\n",
      "        [1.1132],\n",
      "        [1.1341],\n",
      "        [1.1677],\n",
      "        [1.1166],\n",
      "        [1.1683],\n",
      "        [1.1268],\n",
      "        [1.1547],\n",
      "        [1.1391],\n",
      "        [1.1482],\n",
      "        [1.1607],\n",
      "        [1.1431],\n",
      "        [1.1212],\n",
      "        [1.1278],\n",
      "        [1.1206],\n",
      "        [1.1523],\n",
      "        [1.1407],\n",
      "        [1.1493],\n",
      "        [1.1672],\n",
      "        [1.1551],\n",
      "        [1.1667],\n",
      "        [1.1448],\n",
      "        [1.1404],\n",
      "        [1.1252],\n",
      "        [1.1548],\n",
      "        [1.1421],\n",
      "        [1.1638],\n",
      "        [1.1383],\n",
      "        [1.1560],\n",
      "        [1.1258],\n",
      "        [1.1321],\n",
      "        [1.1282],\n",
      "        [1.1543],\n",
      "        [1.1001],\n",
      "        [1.1641],\n",
      "        [1.1476],\n",
      "        [1.0980],\n",
      "        [1.1487],\n",
      "        [1.1363],\n",
      "        [1.1351],\n",
      "        [1.1379],\n",
      "        [1.1416],\n",
      "        [1.1524],\n",
      "        [1.1378],\n",
      "        [1.1044],\n",
      "        [1.1531],\n",
      "        [1.1527],\n",
      "        [1.1212],\n",
      "        [1.1377],\n",
      "        [1.1452],\n",
      "        [1.1201],\n",
      "        [1.1097],\n",
      "        [1.1533],\n",
      "        [1.1525],\n",
      "        [1.1020],\n",
      "        [1.1218],\n",
      "        [1.1584],\n",
      "        [1.1488],\n",
      "        [1.1596],\n",
      "        [1.1154],\n",
      "        [1.1426],\n",
      "        [1.1467],\n",
      "        [1.1288],\n",
      "        [1.0999],\n",
      "        [1.1509],\n",
      "        [1.1466],\n",
      "        [1.1419],\n",
      "        [1.1460],\n",
      "        [1.1673],\n",
      "        [1.1296],\n",
      "        [1.1496],\n",
      "        [1.1557],\n",
      "        [1.1652],\n",
      "        [1.1276],\n",
      "        [1.1117],\n",
      "        [1.1505],\n",
      "        [1.1675],\n",
      "        [1.1465],\n",
      "        [1.1073],\n",
      "        [1.1362],\n",
      "        [1.1597],\n",
      "        [1.1112],\n",
      "        [1.1306],\n",
      "        [1.1118],\n",
      "        [1.1550],\n",
      "        [1.1435],\n",
      "        [1.1250],\n",
      "        [1.1017],\n",
      "        [1.1131],\n",
      "        [1.1061],\n",
      "        [1.1628],\n",
      "        [1.0950],\n",
      "        [1.1420],\n",
      "        [1.1332],\n",
      "        [1.1325],\n",
      "        [1.1323],\n",
      "        [1.1653],\n",
      "        [1.1625],\n",
      "        [1.1059],\n",
      "        [1.1431],\n",
      "        [1.1005],\n",
      "        [1.1408],\n",
      "        [1.1616],\n",
      "        [1.1031],\n",
      "        [1.1512],\n",
      "        [1.1287],\n",
      "        [1.1350],\n",
      "        [1.1059],\n",
      "        [1.1321],\n",
      "        [1.1487],\n",
      "        [1.1050],\n",
      "        [1.1511],\n",
      "        [1.1368],\n",
      "        [1.1418],\n",
      "        [1.1377],\n",
      "        [1.1213],\n",
      "        [1.1435],\n",
      "        [1.1450]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1126],\n",
      "        [1.1342],\n",
      "        [1.1140],\n",
      "        [1.1454],\n",
      "        [1.1387],\n",
      "        [1.0954],\n",
      "        [1.1243],\n",
      "        [1.1425],\n",
      "        [1.1351],\n",
      "        [1.1450],\n",
      "        [1.1545],\n",
      "        [1.1177],\n",
      "        [1.1166],\n",
      "        [1.1115],\n",
      "        [1.1269],\n",
      "        [1.1702],\n",
      "        [1.1427],\n",
      "        [1.1581],\n",
      "        [1.1536],\n",
      "        [1.1598],\n",
      "        [1.1300],\n",
      "        [1.0641],\n",
      "        [1.0929],\n",
      "        [1.1589],\n",
      "        [1.1670],\n",
      "        [1.1615],\n",
      "        [1.1321],\n",
      "        [1.1007],\n",
      "        [1.1077],\n",
      "        [1.0997],\n",
      "        [1.1487],\n",
      "        [1.1354],\n",
      "        [1.1239],\n",
      "        [1.1424],\n",
      "        [1.1451],\n",
      "        [1.1664],\n",
      "        [1.1543],\n",
      "        [1.1415],\n",
      "        [1.1652],\n",
      "        [1.1514],\n",
      "        [1.1483],\n",
      "        [1.1575],\n",
      "        [1.1308],\n",
      "        [1.1169],\n",
      "        [1.1676],\n",
      "        [1.1274],\n",
      "        [1.1485],\n",
      "        [1.1410],\n",
      "        [1.1275],\n",
      "        [1.1515],\n",
      "        [1.1217],\n",
      "        [1.1235],\n",
      "        [1.1239],\n",
      "        [1.1232],\n",
      "        [1.1002],\n",
      "        [1.1287],\n",
      "        [1.1341],\n",
      "        [1.1432],\n",
      "        [1.1173],\n",
      "        [1.1296],\n",
      "        [1.1358],\n",
      "        [1.1312],\n",
      "        [1.0922],\n",
      "        [1.0721],\n",
      "        [1.0994],\n",
      "        [1.1117],\n",
      "        [1.1474],\n",
      "        [1.1371],\n",
      "        [1.1536],\n",
      "        [1.1556],\n",
      "        [1.1628],\n",
      "        [1.0726],\n",
      "        [1.1527],\n",
      "        [1.1651],\n",
      "        [1.0794],\n",
      "        [1.1282],\n",
      "        [1.1666],\n",
      "        [1.1430],\n",
      "        [1.1576],\n",
      "        [1.1686],\n",
      "        [1.1528],\n",
      "        [1.1386],\n",
      "        [1.1655],\n",
      "        [1.1543],\n",
      "        [1.1491],\n",
      "        [1.0996],\n",
      "        [1.1542],\n",
      "        [1.1460],\n",
      "        [1.1503],\n",
      "        [1.1088],\n",
      "        [1.1579],\n",
      "        [1.1640],\n",
      "        [1.1703],\n",
      "        [1.1066],\n",
      "        [1.1598],\n",
      "        [1.1593],\n",
      "        [1.0962],\n",
      "        [1.1451],\n",
      "        [1.1624],\n",
      "        [1.1514],\n",
      "        [1.1678],\n",
      "        [1.1251],\n",
      "        [1.1138],\n",
      "        [1.1136],\n",
      "        [1.1506],\n",
      "        [1.1416],\n",
      "        [1.1116],\n",
      "        [1.1296],\n",
      "        [1.1566],\n",
      "        [1.0643],\n",
      "        [1.1546],\n",
      "        [1.1371],\n",
      "        [1.1671],\n",
      "        [1.1295],\n",
      "        [1.1653],\n",
      "        [1.1302],\n",
      "        [1.1453],\n",
      "        [1.1557],\n",
      "        [1.1433],\n",
      "        [1.1327],\n",
      "        [1.1576],\n",
      "        [1.1302],\n",
      "        [1.1509],\n",
      "        [1.1044],\n",
      "        [1.1371],\n",
      "        [1.1496],\n",
      "        [1.1455],\n",
      "        [1.1523]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0996],\n",
      "        [1.1201],\n",
      "        [1.1287],\n",
      "        [1.1479],\n",
      "        [1.1095],\n",
      "        [1.1483],\n",
      "        [1.1636],\n",
      "        [1.1129],\n",
      "        [1.1305],\n",
      "        [1.1323],\n",
      "        [1.1287],\n",
      "        [1.1331],\n",
      "        [1.0678],\n",
      "        [1.1406],\n",
      "        [1.1551],\n",
      "        [1.1481],\n",
      "        [1.1130],\n",
      "        [1.0834],\n",
      "        [1.1269],\n",
      "        [1.1582],\n",
      "        [1.1125],\n",
      "        [1.0948],\n",
      "        [1.1441],\n",
      "        [1.1303],\n",
      "        [1.1434],\n",
      "        [1.1501],\n",
      "        [1.1410],\n",
      "        [1.1409],\n",
      "        [1.1344],\n",
      "        [1.1128],\n",
      "        [1.1067],\n",
      "        [1.1390],\n",
      "        [1.1242],\n",
      "        [1.1278],\n",
      "        [1.1547],\n",
      "        [1.1461],\n",
      "        [1.1455],\n",
      "        [1.1503],\n",
      "        [1.1640],\n",
      "        [1.1132],\n",
      "        [1.0873],\n",
      "        [1.1434],\n",
      "        [1.0838],\n",
      "        [1.0964],\n",
      "        [1.1414],\n",
      "        [1.1605],\n",
      "        [1.1468],\n",
      "        [1.1307],\n",
      "        [1.1129],\n",
      "        [1.1182],\n",
      "        [1.1614],\n",
      "        [1.1524],\n",
      "        [1.1540],\n",
      "        [1.1640],\n",
      "        [1.1310],\n",
      "        [1.1327],\n",
      "        [1.1675],\n",
      "        [1.1573],\n",
      "        [1.1256],\n",
      "        [1.1166],\n",
      "        [1.0921],\n",
      "        [1.1467],\n",
      "        [1.1233],\n",
      "        [1.0890],\n",
      "        [1.1473],\n",
      "        [1.1485],\n",
      "        [1.1567],\n",
      "        [1.1396],\n",
      "        [1.1297],\n",
      "        [1.1335],\n",
      "        [1.1449],\n",
      "        [1.1395],\n",
      "        [1.1556],\n",
      "        [1.1508],\n",
      "        [1.0815],\n",
      "        [1.1530],\n",
      "        [1.1402],\n",
      "        [1.1124],\n",
      "        [1.1351],\n",
      "        [1.1379],\n",
      "        [1.1069],\n",
      "        [1.1452],\n",
      "        [1.1182],\n",
      "        [1.1560],\n",
      "        [1.1211],\n",
      "        [1.1017],\n",
      "        [1.1567],\n",
      "        [1.0943],\n",
      "        [1.1393],\n",
      "        [1.1027],\n",
      "        [1.1547],\n",
      "        [1.1368],\n",
      "        [1.1551],\n",
      "        [1.1535],\n",
      "        [1.1455],\n",
      "        [1.1631],\n",
      "        [1.1060],\n",
      "        [1.1296],\n",
      "        [1.1498],\n",
      "        [1.1625],\n",
      "        [1.1190],\n",
      "        [1.1645],\n",
      "        [1.1209],\n",
      "        [1.1461],\n",
      "        [1.1453],\n",
      "        [1.1521],\n",
      "        [1.1144],\n",
      "        [1.1661],\n",
      "        [1.1291],\n",
      "        [1.1580],\n",
      "        [1.1121],\n",
      "        [1.1461],\n",
      "        [1.0583],\n",
      "        [1.1508],\n",
      "        [1.1213],\n",
      "        [1.1101],\n",
      "        [1.1325],\n",
      "        [1.1229],\n",
      "        [1.1477],\n",
      "        [1.1550],\n",
      "        [1.1476],\n",
      "        [1.1551],\n",
      "        [1.0964],\n",
      "        [1.1319],\n",
      "        [1.1582],\n",
      "        [1.1534],\n",
      "        [1.1585],\n",
      "        [1.1150]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1389],\n",
      "        [1.1480],\n",
      "        [1.1380],\n",
      "        [1.1510]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch   9 | lr 0.00100 train_loss 2.12008 | val_loss 2.28173 | val_rmse 1.51054\n",
      "tensor([[1.1071],\n",
      "        [1.1334],\n",
      "        [1.1487],\n",
      "        [1.1281],\n",
      "        [1.1502],\n",
      "        [1.1355],\n",
      "        [1.1342],\n",
      "        [1.1608],\n",
      "        [1.1243],\n",
      "        [1.1121],\n",
      "        [1.1501],\n",
      "        [1.1599],\n",
      "        [1.1497],\n",
      "        [1.1266],\n",
      "        [1.1323],\n",
      "        [1.1263],\n",
      "        [1.1269],\n",
      "        [1.1306],\n",
      "        [1.1485],\n",
      "        [1.1464],\n",
      "        [1.1388],\n",
      "        [1.1255],\n",
      "        [1.1450],\n",
      "        [1.1473],\n",
      "        [1.1569],\n",
      "        [1.1539],\n",
      "        [1.1550],\n",
      "        [1.1353],\n",
      "        [1.1218],\n",
      "        [1.1582],\n",
      "        [1.0845],\n",
      "        [1.1203],\n",
      "        [1.1265],\n",
      "        [1.1438],\n",
      "        [1.1560],\n",
      "        [1.1645],\n",
      "        [1.1157],\n",
      "        [1.1411],\n",
      "        [1.1396],\n",
      "        [1.1235],\n",
      "        [1.0921],\n",
      "        [1.1292],\n",
      "        [1.1543],\n",
      "        [1.1451],\n",
      "        [1.1352],\n",
      "        [1.1551],\n",
      "        [1.1662],\n",
      "        [1.1331],\n",
      "        [1.1436],\n",
      "        [1.1316],\n",
      "        [1.1450],\n",
      "        [1.1230],\n",
      "        [1.1163],\n",
      "        [1.1517],\n",
      "        [1.1426],\n",
      "        [1.1601],\n",
      "        [1.1075],\n",
      "        [1.1650],\n",
      "        [1.1204],\n",
      "        [1.1364],\n",
      "        [1.1015],\n",
      "        [1.1289],\n",
      "        [1.1160],\n",
      "        [1.1307],\n",
      "        [1.1586],\n",
      "        [1.1561],\n",
      "        [1.1468],\n",
      "        [1.1056],\n",
      "        [1.1417],\n",
      "        [1.1650],\n",
      "        [1.0947],\n",
      "        [1.1348],\n",
      "        [1.0940],\n",
      "        [1.1502],\n",
      "        [1.1450],\n",
      "        [1.1610],\n",
      "        [1.1364],\n",
      "        [1.1077],\n",
      "        [1.1043],\n",
      "        [1.1556],\n",
      "        [1.1503],\n",
      "        [1.1433],\n",
      "        [1.1554],\n",
      "        [1.1524],\n",
      "        [1.1393],\n",
      "        [1.1603],\n",
      "        [1.1158],\n",
      "        [1.1507],\n",
      "        [1.1410],\n",
      "        [1.1544],\n",
      "        [1.1447],\n",
      "        [1.1165],\n",
      "        [1.1186],\n",
      "        [1.1315],\n",
      "        [1.1428],\n",
      "        [1.1405],\n",
      "        [1.1261],\n",
      "        [1.1317],\n",
      "        [1.1500],\n",
      "        [1.0842],\n",
      "        [1.0956],\n",
      "        [1.1352],\n",
      "        [1.1329],\n",
      "        [1.0929],\n",
      "        [1.0848],\n",
      "        [1.1410],\n",
      "        [1.1548],\n",
      "        [1.1363],\n",
      "        [1.1469],\n",
      "        [1.0811],\n",
      "        [1.1602],\n",
      "        [1.0793],\n",
      "        [1.1288],\n",
      "        [1.1361],\n",
      "        [1.1050],\n",
      "        [1.1265],\n",
      "        [1.0885],\n",
      "        [1.1012],\n",
      "        [1.1484],\n",
      "        [1.1147],\n",
      "        [1.1528],\n",
      "        [1.1214],\n",
      "        [1.1084],\n",
      "        [1.1477],\n",
      "        [1.1344],\n",
      "        [1.1363],\n",
      "        [1.1252],\n",
      "        [1.1205]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1522],\n",
      "        [1.1421],\n",
      "        [1.1587],\n",
      "        [1.1219],\n",
      "        [1.1501],\n",
      "        [1.1006],\n",
      "        [1.1556],\n",
      "        [1.1302],\n",
      "        [1.1408],\n",
      "        [1.1491],\n",
      "        [1.1437],\n",
      "        [1.1262],\n",
      "        [1.1033],\n",
      "        [1.1347],\n",
      "        [1.1035],\n",
      "        [1.1514],\n",
      "        [1.1484],\n",
      "        [1.1438],\n",
      "        [1.1328],\n",
      "        [1.1574],\n",
      "        [1.0931],\n",
      "        [1.1217],\n",
      "        [1.1071],\n",
      "        [1.1109],\n",
      "        [1.1502],\n",
      "        [1.1346],\n",
      "        [1.1005],\n",
      "        [1.1206],\n",
      "        [1.1448],\n",
      "        [1.1458],\n",
      "        [1.1583],\n",
      "        [1.0985],\n",
      "        [1.1495],\n",
      "        [1.1400],\n",
      "        [1.1513],\n",
      "        [1.1029],\n",
      "        [1.1604],\n",
      "        [1.1249],\n",
      "        [1.1320],\n",
      "        [1.1528],\n",
      "        [1.1451],\n",
      "        [1.1614],\n",
      "        [1.1196],\n",
      "        [1.1583],\n",
      "        [1.1358],\n",
      "        [1.1148],\n",
      "        [1.1597],\n",
      "        [1.1380],\n",
      "        [1.1259],\n",
      "        [1.1333],\n",
      "        [1.1491],\n",
      "        [1.1503],\n",
      "        [1.1547],\n",
      "        [1.1366],\n",
      "        [1.1544],\n",
      "        [1.1134],\n",
      "        [1.1511],\n",
      "        [1.1446],\n",
      "        [1.1419],\n",
      "        [1.1629],\n",
      "        [1.1494],\n",
      "        [1.1416],\n",
      "        [1.1151],\n",
      "        [1.1510],\n",
      "        [1.1373],\n",
      "        [1.1522],\n",
      "        [0.5920],\n",
      "        [1.1249],\n",
      "        [1.1330],\n",
      "        [1.1274],\n",
      "        [1.1625],\n",
      "        [1.1139],\n",
      "        [1.1280],\n",
      "        [1.1181],\n",
      "        [1.1483],\n",
      "        [1.1254],\n",
      "        [1.0875],\n",
      "        [1.1315],\n",
      "        [1.1207],\n",
      "        [1.1615],\n",
      "        [1.1401],\n",
      "        [1.1175],\n",
      "        [1.0922],\n",
      "        [1.1509],\n",
      "        [1.1541],\n",
      "        [1.1158],\n",
      "        [1.1549],\n",
      "        [1.0990],\n",
      "        [1.0830],\n",
      "        [1.1391],\n",
      "        [1.1354],\n",
      "        [1.1069],\n",
      "        [1.1602],\n",
      "        [1.1383],\n",
      "        [1.1266],\n",
      "        [1.1222],\n",
      "        [1.1581],\n",
      "        [1.1375],\n",
      "        [1.0496],\n",
      "        [1.1396],\n",
      "        [1.1172],\n",
      "        [1.0838],\n",
      "        [1.1481],\n",
      "        [1.1249],\n",
      "        [1.1483],\n",
      "        [1.0958],\n",
      "        [1.1129],\n",
      "        [1.1124],\n",
      "        [1.1323],\n",
      "        [1.1189],\n",
      "        [1.1301],\n",
      "        [1.1345],\n",
      "        [1.1605],\n",
      "        [1.0836],\n",
      "        [1.1417],\n",
      "        [0.1187],\n",
      "        [1.1490],\n",
      "        [1.1489],\n",
      "        [1.1493],\n",
      "        [1.1538],\n",
      "        [1.1373],\n",
      "        [1.1086],\n",
      "        [1.1563],\n",
      "        [1.1472],\n",
      "        [1.1150],\n",
      "        [1.0827],\n",
      "        [1.1468],\n",
      "        [1.1334]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0997],\n",
      "        [1.1361],\n",
      "        [1.1456],\n",
      "        [1.1446],\n",
      "        [1.1237],\n",
      "        [1.1237],\n",
      "        [1.1458],\n",
      "        [1.1590],\n",
      "        [1.0921],\n",
      "        [1.1227],\n",
      "        [1.1596],\n",
      "        [1.1435],\n",
      "        [1.1368],\n",
      "        [1.0381],\n",
      "        [1.1598],\n",
      "        [1.1088],\n",
      "        [1.1421],\n",
      "        [1.1168],\n",
      "        [1.1227],\n",
      "        [1.1619],\n",
      "        [1.1591],\n",
      "        [1.1503],\n",
      "        [1.1021],\n",
      "        [1.1228],\n",
      "        [1.1564],\n",
      "        [1.1378],\n",
      "        [1.1542],\n",
      "        [1.1586],\n",
      "        [1.1348],\n",
      "        [1.1457],\n",
      "        [1.1160],\n",
      "        [1.1554],\n",
      "        [1.0915],\n",
      "        [1.1348],\n",
      "        [1.0783],\n",
      "        [1.0967],\n",
      "        [1.0735],\n",
      "        [1.1481],\n",
      "        [1.1250],\n",
      "        [1.1136],\n",
      "        [1.1215],\n",
      "        [1.1322],\n",
      "        [1.0916],\n",
      "        [1.1277],\n",
      "        [1.1267],\n",
      "        [1.0959],\n",
      "        [1.1312],\n",
      "        [1.1306],\n",
      "        [1.1413],\n",
      "        [1.1496],\n",
      "        [1.1177],\n",
      "        [1.1135],\n",
      "        [1.1473],\n",
      "        [1.1476],\n",
      "        [1.1523],\n",
      "        [1.1511],\n",
      "        [1.1195],\n",
      "        [1.1479],\n",
      "        [1.1280],\n",
      "        [1.1353],\n",
      "        [1.1190],\n",
      "        [1.1476],\n",
      "        [1.1534],\n",
      "        [1.1059],\n",
      "        [1.1225],\n",
      "        [1.1659],\n",
      "        [1.1389],\n",
      "        [1.1478],\n",
      "        [1.1365],\n",
      "        [1.1160],\n",
      "        [1.1076],\n",
      "        [1.1365],\n",
      "        [1.1420],\n",
      "        [1.1146],\n",
      "        [1.1384],\n",
      "        [1.1408],\n",
      "        [1.1399],\n",
      "        [1.1290],\n",
      "        [1.1198],\n",
      "        [1.1374],\n",
      "        [1.1199],\n",
      "        [1.1556],\n",
      "        [1.1488],\n",
      "        [1.1133],\n",
      "        [1.1534],\n",
      "        [0.2566],\n",
      "        [1.1331],\n",
      "        [1.0937],\n",
      "        [1.1064],\n",
      "        [1.1595],\n",
      "        [1.1229],\n",
      "        [1.1144],\n",
      "        [1.1137],\n",
      "        [1.1496],\n",
      "        [1.1404],\n",
      "        [1.1463],\n",
      "        [1.1561],\n",
      "        [1.1582],\n",
      "        [1.1338],\n",
      "        [1.1420],\n",
      "        [1.1314],\n",
      "        [1.1257],\n",
      "        [1.1606],\n",
      "        [1.1276],\n",
      "        [1.1344],\n",
      "        [1.1026],\n",
      "        [1.1505],\n",
      "        [1.1301],\n",
      "        [1.1359],\n",
      "        [1.1529],\n",
      "        [1.1525],\n",
      "        [1.1336],\n",
      "        [1.1581],\n",
      "        [1.1483],\n",
      "        [1.1600],\n",
      "        [1.1236],\n",
      "        [1.1143],\n",
      "        [1.1227],\n",
      "        [1.1468],\n",
      "        [1.1211],\n",
      "        [1.1540],\n",
      "        [1.1237],\n",
      "        [1.1096],\n",
      "        [1.1413],\n",
      "        [1.1427],\n",
      "        [1.1641],\n",
      "        [1.1439],\n",
      "        [1.1290]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1151],\n",
      "        [0.5463],\n",
      "        [1.1430],\n",
      "        [1.1579],\n",
      "        [1.1358],\n",
      "        [1.1289],\n",
      "        [1.1049],\n",
      "        [1.1443],\n",
      "        [1.1237],\n",
      "        [1.1179],\n",
      "        [1.1502],\n",
      "        [1.1594],\n",
      "        [1.1578],\n",
      "        [1.1136],\n",
      "        [1.1265],\n",
      "        [1.1083],\n",
      "        [1.1400],\n",
      "        [1.1241],\n",
      "        [1.1532],\n",
      "        [1.1465],\n",
      "        [1.1194],\n",
      "        [1.1391],\n",
      "        [1.1118],\n",
      "        [1.1434],\n",
      "        [1.1444],\n",
      "        [1.1579],\n",
      "        [1.1346],\n",
      "        [1.1446],\n",
      "        [1.1094],\n",
      "        [1.1608],\n",
      "        [1.1099],\n",
      "        [1.1460],\n",
      "        [1.1536],\n",
      "        [1.1258],\n",
      "        [1.1105],\n",
      "        [1.1005],\n",
      "        [1.1209],\n",
      "        [1.1042],\n",
      "        [1.0568],\n",
      "        [1.1597],\n",
      "        [1.1307],\n",
      "        [1.1355],\n",
      "        [1.1591],\n",
      "        [1.1314],\n",
      "        [1.1070],\n",
      "        [1.1037],\n",
      "        [1.1260],\n",
      "        [1.1467],\n",
      "        [1.1225],\n",
      "        [1.0967],\n",
      "        [1.1353],\n",
      "        [1.1230],\n",
      "        [1.1460],\n",
      "        [1.1560],\n",
      "        [1.1469],\n",
      "        [1.1369],\n",
      "        [1.1564],\n",
      "        [1.1213],\n",
      "        [1.0582],\n",
      "        [1.1314],\n",
      "        [1.1346],\n",
      "        [1.1489],\n",
      "        [1.1502],\n",
      "        [1.1406],\n",
      "        [1.0912],\n",
      "        [1.1135],\n",
      "        [1.0986],\n",
      "        [1.1449],\n",
      "        [1.1470],\n",
      "        [1.0790],\n",
      "        [1.1426],\n",
      "        [1.1234],\n",
      "        [1.0912],\n",
      "        [1.1170],\n",
      "        [1.1452],\n",
      "        [1.1500],\n",
      "        [1.1417],\n",
      "        [1.1451],\n",
      "        [1.1391],\n",
      "        [1.0979],\n",
      "        [1.1150],\n",
      "        [1.1248],\n",
      "        [1.1007],\n",
      "        [1.1537],\n",
      "        [1.1371],\n",
      "        [1.1380],\n",
      "        [1.1375],\n",
      "        [1.1528],\n",
      "        [1.1373],\n",
      "        [1.1585],\n",
      "        [1.1183],\n",
      "        [1.1352],\n",
      "        [1.1299],\n",
      "        [1.1211],\n",
      "        [1.1434],\n",
      "        [1.1312],\n",
      "        [1.1474],\n",
      "        [1.1464],\n",
      "        [1.1505],\n",
      "        [1.1341],\n",
      "        [1.1393],\n",
      "        [1.1198],\n",
      "        [1.1260],\n",
      "        [1.1456],\n",
      "        [1.1341],\n",
      "        [1.1456],\n",
      "        [1.1330],\n",
      "        [1.1298],\n",
      "        [1.1241],\n",
      "        [1.0918],\n",
      "        [1.1168],\n",
      "        [1.1288],\n",
      "        [1.1441],\n",
      "        [1.1456],\n",
      "        [1.0961],\n",
      "        [1.0804],\n",
      "        [1.0555],\n",
      "        [1.1005],\n",
      "        [1.1593],\n",
      "        [1.1319],\n",
      "        [1.1463],\n",
      "        [1.1087],\n",
      "        [1.1490],\n",
      "        [1.1278],\n",
      "        [1.1473],\n",
      "        [1.1499],\n",
      "        [1.1518],\n",
      "        [1.1045]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1456],\n",
      "        [1.1151],\n",
      "        [1.1574],\n",
      "        [1.0986],\n",
      "        [1.0704],\n",
      "        [1.0624],\n",
      "        [1.1036],\n",
      "        [1.1404],\n",
      "        [1.1283],\n",
      "        [1.1395],\n",
      "        [1.1358],\n",
      "        [1.1011],\n",
      "        [1.1276],\n",
      "        [1.1101],\n",
      "        [1.1000],\n",
      "        [1.1264],\n",
      "        [1.1222],\n",
      "        [1.1401],\n",
      "        [1.1111],\n",
      "        [1.1440],\n",
      "        [1.1195],\n",
      "        [1.1264],\n",
      "        [1.1108],\n",
      "        [1.0978],\n",
      "        [1.1243],\n",
      "        [1.1582],\n",
      "        [1.1296],\n",
      "        [1.0782],\n",
      "        [1.1283],\n",
      "        [1.1163],\n",
      "        [1.1193],\n",
      "        [1.1518],\n",
      "        [1.1498],\n",
      "        [1.1245],\n",
      "        [1.1137],\n",
      "        [1.0758],\n",
      "        [1.1562],\n",
      "        [1.1453],\n",
      "        [1.1272],\n",
      "        [1.1422],\n",
      "        [1.1398],\n",
      "        [1.1336],\n",
      "        [1.1024],\n",
      "        [1.0604],\n",
      "        [1.1208],\n",
      "        [1.1392],\n",
      "        [1.1026],\n",
      "        [1.1410],\n",
      "        [1.0807],\n",
      "        [1.1289],\n",
      "        [1.0950],\n",
      "        [1.1085],\n",
      "        [1.0623],\n",
      "        [1.1430],\n",
      "        [1.1400],\n",
      "        [1.0995],\n",
      "        [1.0900],\n",
      "        [1.1397],\n",
      "        [1.1237],\n",
      "        [1.1168],\n",
      "        [1.1316],\n",
      "        [1.1378],\n",
      "        [1.0987],\n",
      "        [1.1462],\n",
      "        [1.1226],\n",
      "        [1.1325],\n",
      "        [1.1448],\n",
      "        [1.0997],\n",
      "        [1.1357],\n",
      "        [1.1016],\n",
      "        [1.1427],\n",
      "        [1.1334],\n",
      "        [1.1329],\n",
      "        [1.1318],\n",
      "        [1.1556],\n",
      "        [1.1387],\n",
      "        [1.1371],\n",
      "        [1.1375],\n",
      "        [1.0943],\n",
      "        [1.1275],\n",
      "        [1.1503],\n",
      "        [1.1195],\n",
      "        [1.1073],\n",
      "        [1.1011],\n",
      "        [1.1211],\n",
      "        [1.1209],\n",
      "        [1.1308],\n",
      "        [1.1453],\n",
      "        [1.0721],\n",
      "        [1.1108],\n",
      "        [1.1457],\n",
      "        [1.1367],\n",
      "        [1.0496],\n",
      "        [1.1241],\n",
      "        [1.1371],\n",
      "        [1.1569],\n",
      "        [1.1532],\n",
      "        [1.0983],\n",
      "        [1.1175],\n",
      "        [1.1056],\n",
      "        [1.0901],\n",
      "        [1.1372],\n",
      "        [1.1465],\n",
      "        [1.1225],\n",
      "        [1.0999],\n",
      "        [1.1279],\n",
      "        [1.1250],\n",
      "        [1.1441],\n",
      "        [1.0540],\n",
      "        [1.1258],\n",
      "        [1.1258],\n",
      "        [1.1423],\n",
      "        [1.1418],\n",
      "        [1.1573],\n",
      "        [1.1259],\n",
      "        [1.1188],\n",
      "        [1.1279],\n",
      "        [1.1012],\n",
      "        [1.1054],\n",
      "        [1.1419],\n",
      "        [0.1737],\n",
      "        [1.1235],\n",
      "        [1.0900],\n",
      "        [1.1055],\n",
      "        [1.1205],\n",
      "        [1.0893],\n",
      "        [1.1328],\n",
      "        [1.1374]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1475],\n",
      "        [1.1287],\n",
      "        [1.1015],\n",
      "        [1.0922],\n",
      "        [1.1207],\n",
      "        [1.1382],\n",
      "        [1.1394],\n",
      "        [1.0708],\n",
      "        [1.0987],\n",
      "        [1.0900],\n",
      "        [1.1336],\n",
      "        [1.1253],\n",
      "        [1.1254],\n",
      "        [1.1478],\n",
      "        [1.1131],\n",
      "        [1.1130],\n",
      "        [1.0919],\n",
      "        [1.1439],\n",
      "        [1.1335],\n",
      "        [1.1272],\n",
      "        [1.0377],\n",
      "        [1.1037],\n",
      "        [1.1393],\n",
      "        [1.0876],\n",
      "        [1.1097],\n",
      "        [1.1283],\n",
      "        [1.1260],\n",
      "        [1.1540],\n",
      "        [1.1481],\n",
      "        [1.1558],\n",
      "        [1.0914],\n",
      "        [1.1304],\n",
      "        [1.0931],\n",
      "        [1.1411],\n",
      "        [1.0778],\n",
      "        [1.1234],\n",
      "        [1.1111],\n",
      "        [1.0858],\n",
      "        [1.1377],\n",
      "        [1.1265],\n",
      "        [1.1247],\n",
      "        [1.1210],\n",
      "        [1.1342],\n",
      "        [1.1504],\n",
      "        [1.1212],\n",
      "        [1.1337],\n",
      "        [1.1161],\n",
      "        [1.1328],\n",
      "        [1.1227],\n",
      "        [1.1130],\n",
      "        [1.1196],\n",
      "        [1.1522],\n",
      "        [1.1281],\n",
      "        [1.1458],\n",
      "        [1.1528],\n",
      "        [1.1146],\n",
      "        [1.1507],\n",
      "        [1.1537],\n",
      "        [1.1494],\n",
      "        [1.1182],\n",
      "        [1.0999],\n",
      "        [1.1137],\n",
      "        [1.1365],\n",
      "        [1.1299],\n",
      "        [1.1571],\n",
      "        [1.1168],\n",
      "        [1.1282],\n",
      "        [1.1538],\n",
      "        [1.1538],\n",
      "        [1.1290],\n",
      "        [1.1478],\n",
      "        [1.1483],\n",
      "        [1.1229],\n",
      "        [1.1230],\n",
      "        [1.1387],\n",
      "        [1.0658],\n",
      "        [1.1426],\n",
      "        [1.1363],\n",
      "        [1.1060],\n",
      "        [1.1459],\n",
      "        [1.0927],\n",
      "        [1.1289],\n",
      "        [1.0940],\n",
      "        [1.1365],\n",
      "        [1.1561],\n",
      "        [1.1403],\n",
      "        [1.1528],\n",
      "        [1.1475],\n",
      "        [1.1193],\n",
      "        [1.0880],\n",
      "        [1.0951],\n",
      "        [1.1096],\n",
      "        [1.1091],\n",
      "        [1.1321],\n",
      "        [1.1399],\n",
      "        [1.1455],\n",
      "        [1.0937],\n",
      "        [1.1251],\n",
      "        [1.1526],\n",
      "        [1.0976],\n",
      "        [1.1244],\n",
      "        [1.1327],\n",
      "        [1.1403],\n",
      "        [1.1355],\n",
      "        [1.1120],\n",
      "        [1.1182],\n",
      "        [1.1041],\n",
      "        [1.1057],\n",
      "        [1.0733],\n",
      "        [1.0915],\n",
      "        [1.1298],\n",
      "        [1.1404],\n",
      "        [1.1182],\n",
      "        [1.1227],\n",
      "        [1.1535],\n",
      "        [1.1012],\n",
      "        [1.1530],\n",
      "        [1.1079],\n",
      "        [1.0767],\n",
      "        [1.1337],\n",
      "        [1.1049],\n",
      "        [1.1221],\n",
      "        [1.1098],\n",
      "        [1.1543],\n",
      "        [1.1231],\n",
      "        [1.1254],\n",
      "        [1.1167],\n",
      "        [1.0898]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1061],\n",
      "        [1.0599],\n",
      "        [1.1082],\n",
      "        [1.0948],\n",
      "        [1.1522],\n",
      "        [1.1191],\n",
      "        [1.1313],\n",
      "        [1.0877],\n",
      "        [1.1347],\n",
      "        [1.1149],\n",
      "        [1.1375],\n",
      "        [1.1142],\n",
      "        [1.1539],\n",
      "        [1.1035],\n",
      "        [1.0952],\n",
      "        [1.1162],\n",
      "        [1.1404],\n",
      "        [1.0834],\n",
      "        [1.1099],\n",
      "        [1.1496],\n",
      "        [1.1066],\n",
      "        [1.0434],\n",
      "        [1.0798],\n",
      "        [1.1076],\n",
      "        [1.1355],\n",
      "        [1.1160],\n",
      "        [1.1309],\n",
      "        [1.1428],\n",
      "        [1.1221],\n",
      "        [1.1158],\n",
      "        [1.1064],\n",
      "        [1.0964],\n",
      "        [1.1288],\n",
      "        [1.0950],\n",
      "        [1.1174],\n",
      "        [1.0965],\n",
      "        [1.0854],\n",
      "        [1.1125],\n",
      "        [1.1261],\n",
      "        [1.1401],\n",
      "        [1.0930],\n",
      "        [1.1273],\n",
      "        [1.1178],\n",
      "        [1.1535],\n",
      "        [1.1353],\n",
      "        [1.1536],\n",
      "        [1.1054],\n",
      "        [1.1126],\n",
      "        [1.1095],\n",
      "        [1.1356],\n",
      "        [1.1490],\n",
      "        [1.0698],\n",
      "        [1.1168],\n",
      "        [1.1000],\n",
      "        [1.1481],\n",
      "        [1.1197],\n",
      "        [1.0998],\n",
      "        [1.1480],\n",
      "        [1.1342],\n",
      "        [1.1509],\n",
      "        [1.1012],\n",
      "        [1.1234],\n",
      "        [1.0747],\n",
      "        [1.1542],\n",
      "        [1.1269],\n",
      "        [1.1285],\n",
      "        [1.1335],\n",
      "        [1.0832],\n",
      "        [1.1135],\n",
      "        [1.1462],\n",
      "        [1.1223],\n",
      "        [1.1294],\n",
      "        [1.1385],\n",
      "        [1.1386],\n",
      "        [1.1012],\n",
      "        [1.1261],\n",
      "        [1.1245],\n",
      "        [1.1447],\n",
      "        [1.1362],\n",
      "        [1.1276],\n",
      "        [1.1402],\n",
      "        [1.1285],\n",
      "        [1.1326],\n",
      "        [1.0884],\n",
      "        [1.0811],\n",
      "        [1.0666],\n",
      "        [1.1379],\n",
      "        [1.1001],\n",
      "        [1.1350],\n",
      "        [1.1336],\n",
      "        [1.1372],\n",
      "        [1.1253],\n",
      "        [0.0244],\n",
      "        [1.1005],\n",
      "        [1.1204],\n",
      "        [1.1377],\n",
      "        [1.1480],\n",
      "        [1.1255],\n",
      "        [1.1296],\n",
      "        [1.1386],\n",
      "        [1.1317],\n",
      "        [1.1243],\n",
      "        [1.1517],\n",
      "        [1.1248],\n",
      "        [1.1254],\n",
      "        [1.1187],\n",
      "        [1.1018],\n",
      "        [1.1159],\n",
      "        [1.1259],\n",
      "        [1.0702],\n",
      "        [1.1113],\n",
      "        [1.1029],\n",
      "        [1.0978],\n",
      "        [1.1292],\n",
      "        [1.1350],\n",
      "        [1.1437],\n",
      "        [1.0964],\n",
      "        [1.1508],\n",
      "        [1.1489],\n",
      "        [1.1398],\n",
      "        [1.1379],\n",
      "        [1.1475],\n",
      "        [1.1028],\n",
      "        [1.1294],\n",
      "        [1.1302],\n",
      "        [1.1394],\n",
      "        [1.1080],\n",
      "        [1.1467]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1154],\n",
      "        [1.1325],\n",
      "        [1.1203],\n",
      "        [1.1179]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  10 | lr 0.00100 train_loss 2.13306 | val_loss 2.28456 | val_rmse 1.51148\n",
      "tensor([[1.1181],\n",
      "        [1.1510],\n",
      "        [1.1261],\n",
      "        [1.1394],\n",
      "        [1.1413],\n",
      "        [1.0951],\n",
      "        [1.1042],\n",
      "        [1.1314],\n",
      "        [1.1341],\n",
      "        [1.1296],\n",
      "        [1.1305],\n",
      "        [1.1180],\n",
      "        [1.1481],\n",
      "        [1.0964],\n",
      "        [1.1322],\n",
      "        [1.1508],\n",
      "        [1.1429],\n",
      "        [1.1419],\n",
      "        [1.0851],\n",
      "        [1.1320],\n",
      "        [1.1387],\n",
      "        [1.1078],\n",
      "        [1.0988],\n",
      "        [1.1297],\n",
      "        [1.0857],\n",
      "        [1.1058],\n",
      "        [1.1442],\n",
      "        [1.1165],\n",
      "        [1.1287],\n",
      "        [1.1368],\n",
      "        [1.1122],\n",
      "        [1.1317],\n",
      "        [1.1381],\n",
      "        [1.1207],\n",
      "        [1.1361],\n",
      "        [1.0767],\n",
      "        [1.1037],\n",
      "        [1.0913],\n",
      "        [1.1450],\n",
      "        [1.1109],\n",
      "        [1.1342],\n",
      "        [1.1411],\n",
      "        [1.1005],\n",
      "        [1.1105],\n",
      "        [1.0968],\n",
      "        [1.1232],\n",
      "        [1.1274],\n",
      "        [1.1479],\n",
      "        [1.1236],\n",
      "        [1.1212],\n",
      "        [1.1438],\n",
      "        [1.1274],\n",
      "        [1.1038],\n",
      "        [1.1238],\n",
      "        [1.1200],\n",
      "        [1.1246],\n",
      "        [1.1200],\n",
      "        [1.1181],\n",
      "        [1.1231],\n",
      "        [1.0967],\n",
      "        [1.1042],\n",
      "        [1.1502],\n",
      "        [1.1381],\n",
      "        [1.1091],\n",
      "        [1.1109],\n",
      "        [1.1441],\n",
      "        [1.0609],\n",
      "        [1.1188],\n",
      "        [1.1420],\n",
      "        [1.1268],\n",
      "        [1.1468],\n",
      "        [1.1119],\n",
      "        [1.1221],\n",
      "        [1.0983],\n",
      "        [1.1510],\n",
      "        [1.1078],\n",
      "        [1.1432],\n",
      "        [1.1429],\n",
      "        [1.1293],\n",
      "        [1.1478],\n",
      "        [1.0924],\n",
      "        [1.1472],\n",
      "        [1.1226],\n",
      "        [1.1117],\n",
      "        [1.1394],\n",
      "        [1.1413],\n",
      "        [1.1180],\n",
      "        [1.0985],\n",
      "        [1.1072],\n",
      "        [1.1262],\n",
      "        [1.1103],\n",
      "        [1.1451],\n",
      "        [1.1368],\n",
      "        [1.1069],\n",
      "        [1.1431],\n",
      "        [1.1215],\n",
      "        [1.1496],\n",
      "        [1.1490],\n",
      "        [1.1231],\n",
      "        [1.1283],\n",
      "        [1.0659],\n",
      "        [1.1315],\n",
      "        [1.1503],\n",
      "        [1.1171],\n",
      "        [1.1276],\n",
      "        [1.0672],\n",
      "        [1.1448],\n",
      "        [1.1353],\n",
      "        [1.1244],\n",
      "        [1.1310],\n",
      "        [1.1434],\n",
      "        [1.1429],\n",
      "        [1.0919],\n",
      "        [1.1273],\n",
      "        [1.0874],\n",
      "        [1.1318],\n",
      "        [1.0641],\n",
      "        [1.1092],\n",
      "        [1.1171],\n",
      "        [1.1502],\n",
      "        [1.1189],\n",
      "        [1.1292],\n",
      "        [1.1250],\n",
      "        [1.1393],\n",
      "        [1.1274],\n",
      "        [1.1161],\n",
      "        [1.1322],\n",
      "        [1.1258]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1433],\n",
      "        [1.1358],\n",
      "        [1.0725],\n",
      "        [1.1347],\n",
      "        [1.1402],\n",
      "        [1.1261],\n",
      "        [1.0679],\n",
      "        [1.1453],\n",
      "        [1.1002],\n",
      "        [1.1127],\n",
      "        [1.1227],\n",
      "        [1.1120],\n",
      "        [1.1337],\n",
      "        [1.1413],\n",
      "        [1.0915],\n",
      "        [1.1289],\n",
      "        [1.1342],\n",
      "        [1.1039],\n",
      "        [1.1234],\n",
      "        [1.1464],\n",
      "        [1.1304],\n",
      "        [1.1120],\n",
      "        [1.1283],\n",
      "        [1.0857],\n",
      "        [1.1329],\n",
      "        [1.1007],\n",
      "        [1.1258],\n",
      "        [1.1440],\n",
      "        [1.1072],\n",
      "        [1.1022],\n",
      "        [1.1435],\n",
      "        [1.1234],\n",
      "        [1.1235],\n",
      "        [1.1110],\n",
      "        [1.1431],\n",
      "        [1.1487],\n",
      "        [1.1288],\n",
      "        [1.1216],\n",
      "        [1.0710],\n",
      "        [1.1395],\n",
      "        [1.1485],\n",
      "        [1.1135],\n",
      "        [1.1408],\n",
      "        [1.1105],\n",
      "        [1.1210],\n",
      "        [1.1097],\n",
      "        [1.1050],\n",
      "        [1.1338],\n",
      "        [1.1303],\n",
      "        [1.1088],\n",
      "        [1.1429],\n",
      "        [1.1425],\n",
      "        [1.1314],\n",
      "        [1.1364],\n",
      "        [1.0902],\n",
      "        [1.1133],\n",
      "        [1.0941],\n",
      "        [1.1205],\n",
      "        [1.1383],\n",
      "        [1.1137],\n",
      "        [1.1205],\n",
      "        [1.0996],\n",
      "        [1.0884],\n",
      "        [1.1299],\n",
      "        [1.1130],\n",
      "        [1.1402],\n",
      "        [1.1467],\n",
      "        [1.1135],\n",
      "        [1.1328],\n",
      "        [1.0707],\n",
      "        [1.1309],\n",
      "        [1.0751],\n",
      "        [1.1042],\n",
      "        [1.1363],\n",
      "        [1.1472],\n",
      "        [1.1111],\n",
      "        [1.0911],\n",
      "        [1.1316],\n",
      "        [1.0903],\n",
      "        [1.1071],\n",
      "        [1.0721],\n",
      "        [1.0971],\n",
      "        [1.1027],\n",
      "        [1.1241],\n",
      "        [1.1198],\n",
      "        [1.0796],\n",
      "        [1.0619],\n",
      "        [1.1010],\n",
      "        [1.0982],\n",
      "        [1.1187],\n",
      "        [1.1020],\n",
      "        [1.1079],\n",
      "        [1.1396],\n",
      "        [1.1218],\n",
      "        [1.1181],\n",
      "        [1.1148],\n",
      "        [1.0719],\n",
      "        [1.0996],\n",
      "        [1.1424],\n",
      "        [1.1259],\n",
      "        [1.1180],\n",
      "        [1.1002],\n",
      "        [1.1082],\n",
      "        [1.1057],\n",
      "        [1.1335],\n",
      "        [1.1379],\n",
      "        [1.0957],\n",
      "        [1.0727],\n",
      "        [1.1314],\n",
      "        [1.1283],\n",
      "        [1.0970],\n",
      "        [1.1419],\n",
      "        [1.1345],\n",
      "        [1.1345],\n",
      "        [1.0635],\n",
      "        [1.0991],\n",
      "        [1.0947],\n",
      "        [1.1238],\n",
      "        [1.1249],\n",
      "        [1.1320],\n",
      "        [1.1109],\n",
      "        [1.1409],\n",
      "        [1.1069],\n",
      "        [1.1331],\n",
      "        [1.1328],\n",
      "        [1.1462],\n",
      "        [1.1126],\n",
      "        [1.1219]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1314],\n",
      "        [1.1283],\n",
      "        [1.1248],\n",
      "        [1.1356],\n",
      "        [1.1104],\n",
      "        [1.1020],\n",
      "        [1.1138],\n",
      "        [1.1171],\n",
      "        [1.1279],\n",
      "        [1.1337],\n",
      "        [1.1218],\n",
      "        [1.1079],\n",
      "        [1.1063],\n",
      "        [1.0916],\n",
      "        [1.0998],\n",
      "        [1.0919],\n",
      "        [1.0967],\n",
      "        [1.1146],\n",
      "        [1.1023],\n",
      "        [1.1416],\n",
      "        [1.1042],\n",
      "        [1.1164],\n",
      "        [1.0718],\n",
      "        [1.1143],\n",
      "        [1.1447],\n",
      "        [1.1423],\n",
      "        [1.1128],\n",
      "        [1.0826],\n",
      "        [1.0584],\n",
      "        [1.0575],\n",
      "        [1.1334],\n",
      "        [1.1206],\n",
      "        [1.1144],\n",
      "        [1.1219],\n",
      "        [1.1205],\n",
      "        [1.1000],\n",
      "        [1.0935],\n",
      "        [1.1199],\n",
      "        [1.1413],\n",
      "        [1.1305],\n",
      "        [1.0873],\n",
      "        [1.1355],\n",
      "        [1.1343],\n",
      "        [1.1197],\n",
      "        [1.0814],\n",
      "        [1.0898],\n",
      "        [1.1418],\n",
      "        [1.0866],\n",
      "        [1.1072],\n",
      "        [1.1280],\n",
      "        [1.0883],\n",
      "        [1.1175],\n",
      "        [1.0706],\n",
      "        [1.1361],\n",
      "        [1.1260],\n",
      "        [1.1157],\n",
      "        [1.1153],\n",
      "        [1.1449],\n",
      "        [1.1387],\n",
      "        [1.1205],\n",
      "        [1.1039],\n",
      "        [1.1021],\n",
      "        [1.1378],\n",
      "        [1.1205],\n",
      "        [1.1308],\n",
      "        [1.1409],\n",
      "        [1.1223],\n",
      "        [1.1184],\n",
      "        [1.1263],\n",
      "        [1.1413],\n",
      "        [1.1148],\n",
      "        [1.0957],\n",
      "        [1.1115],\n",
      "        [1.0967],\n",
      "        [1.1052],\n",
      "        [1.0927],\n",
      "        [1.0582],\n",
      "        [1.1184],\n",
      "        [1.0995],\n",
      "        [1.1276],\n",
      "        [1.0917],\n",
      "        [1.0911],\n",
      "        [1.0920],\n",
      "        [1.1191],\n",
      "        [1.1048],\n",
      "        [1.1177],\n",
      "        [1.1370],\n",
      "        [1.1306],\n",
      "        [1.1319],\n",
      "        [1.1252],\n",
      "        [1.1406],\n",
      "        [1.1306],\n",
      "        [1.1217],\n",
      "        [1.1110],\n",
      "        [1.1010],\n",
      "        [1.1289],\n",
      "        [1.1234],\n",
      "        [1.0964],\n",
      "        [1.1421],\n",
      "        [1.1446],\n",
      "        [1.1360],\n",
      "        [1.1207],\n",
      "        [1.0916],\n",
      "        [1.1279],\n",
      "        [1.1132],\n",
      "        [1.0982],\n",
      "        [1.1422],\n",
      "        [1.0488],\n",
      "        [1.1323],\n",
      "        [1.1320],\n",
      "        [1.1108],\n",
      "        [1.1208],\n",
      "        [1.1405],\n",
      "        [1.1330],\n",
      "        [1.1301],\n",
      "        [1.1099],\n",
      "        [1.1344],\n",
      "        [1.1018],\n",
      "        [1.1171],\n",
      "        [1.1408],\n",
      "        [1.1095],\n",
      "        [1.0908],\n",
      "        [1.0907],\n",
      "        [1.1228],\n",
      "        [1.1314],\n",
      "        [1.0859],\n",
      "        [1.1315],\n",
      "        [1.1376]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1171],\n",
      "        [1.0989],\n",
      "        [1.1356],\n",
      "        [1.1249],\n",
      "        [1.0950],\n",
      "        [1.1211],\n",
      "        [1.0911],\n",
      "        [1.1252],\n",
      "        [1.1225],\n",
      "        [1.1181],\n",
      "        [1.1121],\n",
      "        [1.1412],\n",
      "        [1.0967],\n",
      "        [1.1244],\n",
      "        [1.1074],\n",
      "        [1.0578],\n",
      "        [1.0989],\n",
      "        [1.1245],\n",
      "        [1.0959],\n",
      "        [1.1236],\n",
      "        [1.1297],\n",
      "        [1.1284],\n",
      "        [1.0927],\n",
      "        [1.1229],\n",
      "        [1.1101],\n",
      "        [1.1125],\n",
      "        [1.1214],\n",
      "        [1.0497],\n",
      "        [1.1278],\n",
      "        [1.1010],\n",
      "        [1.1122],\n",
      "        [1.1098],\n",
      "        [1.1035],\n",
      "        [1.0838],\n",
      "        [1.1396],\n",
      "        [1.1365],\n",
      "        [1.1050],\n",
      "        [1.1169],\n",
      "        [1.1086],\n",
      "        [1.1326],\n",
      "        [1.1067],\n",
      "        [1.1270],\n",
      "        [1.1165],\n",
      "        [1.1161],\n",
      "        [1.1361],\n",
      "        [1.0780],\n",
      "        [1.1113],\n",
      "        [1.0977],\n",
      "        [1.0773],\n",
      "        [1.1341],\n",
      "        [1.1260],\n",
      "        [1.0887],\n",
      "        [1.1193],\n",
      "        [1.1053],\n",
      "        [1.1136],\n",
      "        [1.1149],\n",
      "        [1.1243],\n",
      "        [1.0519],\n",
      "        [1.0922],\n",
      "        [1.1109],\n",
      "        [1.0956],\n",
      "        [1.0927],\n",
      "        [1.0880],\n",
      "        [1.1006],\n",
      "        [1.1326],\n",
      "        [1.1047],\n",
      "        [1.1129],\n",
      "        [1.0917],\n",
      "        [1.0950],\n",
      "        [1.1008],\n",
      "        [1.1144],\n",
      "        [1.0957],\n",
      "        [1.1264],\n",
      "        [1.0891],\n",
      "        [1.0895],\n",
      "        [1.1351],\n",
      "        [1.1200],\n",
      "        [1.1369],\n",
      "        [1.0799],\n",
      "        [1.1071],\n",
      "        [1.1153],\n",
      "        [1.1189],\n",
      "        [1.1303],\n",
      "        [1.0894],\n",
      "        [1.1019],\n",
      "        [1.1227],\n",
      "        [0.0473],\n",
      "        [1.0889],\n",
      "        [1.1394],\n",
      "        [1.0964],\n",
      "        [1.1223],\n",
      "        [1.1355],\n",
      "        [1.1160],\n",
      "        [1.1172],\n",
      "        [1.1315],\n",
      "        [1.1143],\n",
      "        [1.1018],\n",
      "        [1.0752],\n",
      "        [1.1277],\n",
      "        [1.0967],\n",
      "        [1.1212],\n",
      "        [1.1284],\n",
      "        [1.1314],\n",
      "        [1.1115],\n",
      "        [1.1198],\n",
      "        [1.1231],\n",
      "        [1.0645],\n",
      "        [1.0413],\n",
      "        [1.0734],\n",
      "        [1.1171],\n",
      "        [1.1033],\n",
      "        [1.1269],\n",
      "        [1.1282],\n",
      "        [1.1120],\n",
      "        [1.1030],\n",
      "        [1.1211],\n",
      "        [1.0875],\n",
      "        [1.0967],\n",
      "        [1.1435],\n",
      "        [1.0683],\n",
      "        [1.1175],\n",
      "        [1.0944],\n",
      "        [1.1278],\n",
      "        [1.0731],\n",
      "        [1.1273],\n",
      "        [1.1334],\n",
      "        [1.1107],\n",
      "        [1.1290]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0679],\n",
      "        [1.0460],\n",
      "        [1.1274],\n",
      "        [1.0572],\n",
      "        [1.0896],\n",
      "        [1.1289],\n",
      "        [1.1229],\n",
      "        [0.6288],\n",
      "        [1.1186],\n",
      "        [1.1217],\n",
      "        [1.1130],\n",
      "        [1.0676],\n",
      "        [1.1008],\n",
      "        [1.1370],\n",
      "        [1.1233],\n",
      "        [1.1086],\n",
      "        [1.1166],\n",
      "        [1.1039],\n",
      "        [1.1115],\n",
      "        [1.0727],\n",
      "        [1.1238],\n",
      "        [1.0793],\n",
      "        [1.1194],\n",
      "        [1.1056],\n",
      "        [1.1182],\n",
      "        [1.1179],\n",
      "        [1.1078],\n",
      "        [1.0838],\n",
      "        [1.1106],\n",
      "        [1.0842],\n",
      "        [1.1130],\n",
      "        [1.1237],\n",
      "        [1.1351],\n",
      "        [1.0815],\n",
      "        [1.1004],\n",
      "        [1.0896],\n",
      "        [1.1247],\n",
      "        [1.1244],\n",
      "        [1.1259],\n",
      "        [1.0900],\n",
      "        [1.0758],\n",
      "        [1.0989],\n",
      "        [1.0977],\n",
      "        [1.1099],\n",
      "        [1.1368],\n",
      "        [1.1156],\n",
      "        [1.1367],\n",
      "        [1.1103],\n",
      "        [1.1246],\n",
      "        [1.0712],\n",
      "        [1.1273],\n",
      "        [1.1096],\n",
      "        [1.1145],\n",
      "        [1.0782],\n",
      "        [1.1262],\n",
      "        [1.0887],\n",
      "        [1.0945],\n",
      "        [1.1285],\n",
      "        [1.1163],\n",
      "        [1.1208],\n",
      "        [1.1292],\n",
      "        [1.0858],\n",
      "        [1.0978],\n",
      "        [1.1332],\n",
      "        [1.1181],\n",
      "        [1.0678],\n",
      "        [1.1328],\n",
      "        [1.0841],\n",
      "        [1.1095],\n",
      "        [1.0582],\n",
      "        [1.0998],\n",
      "        [1.1344],\n",
      "        [1.1159],\n",
      "        [1.1156],\n",
      "        [1.1256],\n",
      "        [1.1274],\n",
      "        [1.0569],\n",
      "        [1.1198],\n",
      "        [1.1205],\n",
      "        [1.1208],\n",
      "        [1.1351],\n",
      "        [1.0948],\n",
      "        [1.1337],\n",
      "        [1.1234],\n",
      "        [1.0397],\n",
      "        [1.1251],\n",
      "        [1.0748],\n",
      "        [1.0782],\n",
      "        [1.0705],\n",
      "        [1.1306],\n",
      "        [1.1107],\n",
      "        [1.1058],\n",
      "        [1.0859],\n",
      "        [1.0775],\n",
      "        [1.1165],\n",
      "        [1.0909],\n",
      "        [1.1292],\n",
      "        [1.0977],\n",
      "        [1.0849],\n",
      "        [1.1249],\n",
      "        [1.1166],\n",
      "        [1.0919],\n",
      "        [1.1049],\n",
      "        [1.1259],\n",
      "        [1.1187],\n",
      "        [1.0990],\n",
      "        [1.0930],\n",
      "        [1.1200],\n",
      "        [1.1131],\n",
      "        [1.1137],\n",
      "        [1.1113],\n",
      "        [1.0916],\n",
      "        [1.1143],\n",
      "        [1.1011],\n",
      "        [1.0969],\n",
      "        [1.1059],\n",
      "        [1.0926],\n",
      "        [1.1111],\n",
      "        [1.0792],\n",
      "        [1.1073],\n",
      "        [1.0710],\n",
      "        [1.1371],\n",
      "        [1.1332],\n",
      "        [1.1105],\n",
      "        [1.1046],\n",
      "        [1.1096],\n",
      "        [1.1110],\n",
      "        [1.1224]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1076],\n",
      "        [1.1230],\n",
      "        [1.0499],\n",
      "        [1.1210],\n",
      "        [1.1092],\n",
      "        [1.1319],\n",
      "        [1.0587],\n",
      "        [1.1041],\n",
      "        [1.0780],\n",
      "        [1.1005],\n",
      "        [1.0823],\n",
      "        [1.0866],\n",
      "        [1.0900],\n",
      "        [1.1082],\n",
      "        [1.1281],\n",
      "        [1.1004],\n",
      "        [1.0790],\n",
      "        [1.0592],\n",
      "        [1.1009],\n",
      "        [1.1188],\n",
      "        [1.0976],\n",
      "        [1.1119],\n",
      "        [1.1019],\n",
      "        [1.1256],\n",
      "        [1.0864],\n",
      "        [1.1272],\n",
      "        [1.1136],\n",
      "        [1.0726],\n",
      "        [1.0818],\n",
      "        [1.0513],\n",
      "        [1.1249],\n",
      "        [1.1337],\n",
      "        [1.0918],\n",
      "        [1.1226],\n",
      "        [1.1164],\n",
      "        [1.1092],\n",
      "        [1.0839],\n",
      "        [1.0916],\n",
      "        [1.1001],\n",
      "        [1.0776],\n",
      "        [1.0975],\n",
      "        [1.0952],\n",
      "        [1.1302],\n",
      "        [1.1215],\n",
      "        [1.1106],\n",
      "        [1.1264],\n",
      "        [1.0933],\n",
      "        [1.0488],\n",
      "        [1.1302],\n",
      "        [1.0721],\n",
      "        [1.0853],\n",
      "        [1.0894],\n",
      "        [1.1065],\n",
      "        [1.1301],\n",
      "        [1.1281],\n",
      "        [1.1336],\n",
      "        [1.1280],\n",
      "        [1.1341],\n",
      "        [1.0846],\n",
      "        [1.1175],\n",
      "        [1.1317],\n",
      "        [1.1175],\n",
      "        [1.1205],\n",
      "        [1.1206],\n",
      "        [1.1168],\n",
      "        [1.1049],\n",
      "        [1.1197],\n",
      "        [1.1323],\n",
      "        [1.1040],\n",
      "        [2.0567],\n",
      "        [1.1036],\n",
      "        [1.1051],\n",
      "        [1.1223],\n",
      "        [1.1130],\n",
      "        [1.0987],\n",
      "        [1.1141],\n",
      "        [1.1072],\n",
      "        [1.1143],\n",
      "        [1.0898],\n",
      "        [1.0893],\n",
      "        [1.1106],\n",
      "        [1.1275],\n",
      "        [1.1078],\n",
      "        [1.1056],\n",
      "        [1.1123],\n",
      "        [1.1310],\n",
      "        [1.0887],\n",
      "        [1.0837],\n",
      "        [1.1050],\n",
      "        [1.0962],\n",
      "        [1.1180],\n",
      "        [1.1318],\n",
      "        [1.0948],\n",
      "        [1.1241],\n",
      "        [1.1038],\n",
      "        [1.0586],\n",
      "        [1.0996],\n",
      "        [1.0944],\n",
      "        [1.1152],\n",
      "        [1.1048],\n",
      "        [1.1042],\n",
      "        [1.1168],\n",
      "        [1.1239],\n",
      "        [1.1057],\n",
      "        [1.1074],\n",
      "        [1.1069],\n",
      "        [1.0346],\n",
      "        [1.1014],\n",
      "        [1.1242],\n",
      "        [1.1296],\n",
      "        [1.1235],\n",
      "        [1.0840],\n",
      "        [1.1185],\n",
      "        [1.1278],\n",
      "        [1.0988],\n",
      "        [1.1259],\n",
      "        [1.0806],\n",
      "        [1.1137],\n",
      "        [1.0757],\n",
      "        [1.1223],\n",
      "        [1.1288],\n",
      "        [1.1210],\n",
      "        [1.1148],\n",
      "        [1.1311],\n",
      "        [1.0934],\n",
      "        [1.1347],\n",
      "        [1.0934],\n",
      "        [0.4193]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0536],\n",
      "        [1.0984],\n",
      "        [1.1022],\n",
      "        [1.1306],\n",
      "        [1.1250],\n",
      "        [1.1266],\n",
      "        [1.0848],\n",
      "        [1.1017],\n",
      "        [1.1155],\n",
      "        [1.1024],\n",
      "        [1.0961],\n",
      "        [1.0956],\n",
      "        [1.0977],\n",
      "        [1.1358],\n",
      "        [1.1019],\n",
      "        [1.1096],\n",
      "        [1.1182],\n",
      "        [1.0963],\n",
      "        [1.0887],\n",
      "        [1.1218],\n",
      "        [1.0869],\n",
      "        [1.1154],\n",
      "        [1.1247],\n",
      "        [1.1001],\n",
      "        [1.1108],\n",
      "        [1.1287],\n",
      "        [1.1078],\n",
      "        [1.1117],\n",
      "        [1.1287],\n",
      "        [1.1067],\n",
      "        [1.0583],\n",
      "        [1.1322],\n",
      "        [1.0773],\n",
      "        [1.1243],\n",
      "        [1.0919],\n",
      "        [1.0783],\n",
      "        [1.1010],\n",
      "        [1.1253],\n",
      "        [1.1094],\n",
      "        [1.1070],\n",
      "        [1.0661],\n",
      "        [1.1131],\n",
      "        [1.1175],\n",
      "        [1.1045],\n",
      "        [1.0941],\n",
      "        [1.1129],\n",
      "        [1.1198],\n",
      "        [1.1043],\n",
      "        [1.1129],\n",
      "        [1.1213],\n",
      "        [1.1187],\n",
      "        [1.1100],\n",
      "        [1.1197],\n",
      "        [1.1014],\n",
      "        [1.1320],\n",
      "        [1.1233],\n",
      "        [1.0961],\n",
      "        [1.1270],\n",
      "        [1.0934],\n",
      "        [1.1210],\n",
      "        [1.0820],\n",
      "        [1.1246],\n",
      "        [1.1013],\n",
      "        [1.0941],\n",
      "        [1.1062],\n",
      "        [1.0932],\n",
      "        [1.0798],\n",
      "        [1.0892],\n",
      "        [1.1010],\n",
      "        [1.0759],\n",
      "        [1.0712],\n",
      "        [1.1213],\n",
      "        [1.1203],\n",
      "        [1.0991],\n",
      "        [1.1171],\n",
      "        [1.1181],\n",
      "        [1.1222],\n",
      "        [1.1134],\n",
      "        [1.1299],\n",
      "        [1.1116],\n",
      "        [1.1187],\n",
      "        [1.1242],\n",
      "        [1.0437],\n",
      "        [1.1036],\n",
      "        [1.0937],\n",
      "        [1.0706],\n",
      "        [1.0771],\n",
      "        [1.0936],\n",
      "        [1.1279],\n",
      "        [1.1173],\n",
      "        [1.1304],\n",
      "        [1.0970],\n",
      "        [1.1046],\n",
      "        [1.1211],\n",
      "        [1.1013],\n",
      "        [1.0910],\n",
      "        [1.1225],\n",
      "        [1.1086],\n",
      "        [1.1259],\n",
      "        [1.0402],\n",
      "        [1.0896],\n",
      "        [1.1187],\n",
      "        [1.0975],\n",
      "        [1.0891],\n",
      "        [1.0942],\n",
      "        [1.0662],\n",
      "        [1.1284],\n",
      "        [1.0984],\n",
      "        [1.0740],\n",
      "        [1.1062],\n",
      "        [1.0739],\n",
      "        [1.0891],\n",
      "        [1.1325],\n",
      "        [1.1023],\n",
      "        [1.0917],\n",
      "        [1.1166],\n",
      "        [1.1031],\n",
      "        [1.1143],\n",
      "        [1.1031],\n",
      "        [1.1057],\n",
      "        [1.0851],\n",
      "        [1.1216],\n",
      "        [1.0912],\n",
      "        [1.1296],\n",
      "        [1.0986],\n",
      "        [1.1080],\n",
      "        [1.1062],\n",
      "        [1.1046]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1236],\n",
      "        [1.1029],\n",
      "        [1.1158],\n",
      "        [1.0862]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  11 | lr 0.00100 train_loss 2.12373 | val_loss 2.29030 | val_rmse 1.51337\n",
      "tensor([[1.1107],\n",
      "        [1.0830],\n",
      "        [1.0996],\n",
      "        [1.0691],\n",
      "        [1.0607],\n",
      "        [1.1087],\n",
      "        [1.0798],\n",
      "        [1.1199],\n",
      "        [1.1028],\n",
      "        [1.1228],\n",
      "        [1.1143],\n",
      "        [1.1124],\n",
      "        [1.1112],\n",
      "        [1.1043],\n",
      "        [1.0959],\n",
      "        [1.1178],\n",
      "        [1.1168],\n",
      "        [1.0645],\n",
      "        [1.0994],\n",
      "        [1.0667],\n",
      "        [1.1156],\n",
      "        [1.0958],\n",
      "        [1.1100],\n",
      "        [1.0894],\n",
      "        [1.1122],\n",
      "        [1.0874],\n",
      "        [1.1106],\n",
      "        [1.0536],\n",
      "        [1.1055],\n",
      "        [1.1267],\n",
      "        [1.1078],\n",
      "        [0.2145],\n",
      "        [1.1255],\n",
      "        [1.1248],\n",
      "        [1.1073],\n",
      "        [1.0925],\n",
      "        [1.0535],\n",
      "        [1.1141],\n",
      "        [1.1153],\n",
      "        [1.0832],\n",
      "        [1.1192],\n",
      "        [1.1216],\n",
      "        [1.0784],\n",
      "        [1.0801],\n",
      "        [1.1014],\n",
      "        [1.0828],\n",
      "        [1.0781],\n",
      "        [1.0964],\n",
      "        [1.0910],\n",
      "        [1.1180],\n",
      "        [1.0934],\n",
      "        [1.1167],\n",
      "        [1.1267],\n",
      "        [1.0667],\n",
      "        [1.1097],\n",
      "        [1.1192],\n",
      "        [1.0748],\n",
      "        [1.1012],\n",
      "        [1.0542],\n",
      "        [1.1132],\n",
      "        [1.0770],\n",
      "        [1.0796],\n",
      "        [1.1057],\n",
      "        [1.0708],\n",
      "        [1.0984],\n",
      "        [1.1185],\n",
      "        [1.0494],\n",
      "        [1.0580],\n",
      "        [1.1175],\n",
      "        [1.1180],\n",
      "        [1.0718],\n",
      "        [1.1016],\n",
      "        [1.1174],\n",
      "        [1.0758],\n",
      "        [1.0888],\n",
      "        [1.1266],\n",
      "        [1.1090],\n",
      "        [1.1039],\n",
      "        [1.0944],\n",
      "        [1.1247],\n",
      "        [1.0890],\n",
      "        [1.1294],\n",
      "        [1.0739],\n",
      "        [1.1228],\n",
      "        [1.0878],\n",
      "        [1.1116],\n",
      "        [1.0817],\n",
      "        [1.1048],\n",
      "        [1.1192],\n",
      "        [1.0960],\n",
      "        [1.0864],\n",
      "        [1.1091],\n",
      "        [1.1148],\n",
      "        [1.0760],\n",
      "        [1.0847],\n",
      "        [1.1102],\n",
      "        [1.0919],\n",
      "        [1.0834],\n",
      "        [1.1049],\n",
      "        [1.0682],\n",
      "        [1.0893],\n",
      "        [1.1077],\n",
      "        [1.0823],\n",
      "        [1.1037],\n",
      "        [1.0767],\n",
      "        [1.0795],\n",
      "        [1.1259],\n",
      "        [1.1097],\n",
      "        [1.0869],\n",
      "        [1.1119],\n",
      "        [1.0782],\n",
      "        [1.0647],\n",
      "        [1.0668],\n",
      "        [1.1095],\n",
      "        [1.1047],\n",
      "        [1.0863],\n",
      "        [1.0309],\n",
      "        [1.1211],\n",
      "        [1.1260],\n",
      "        [1.0735],\n",
      "        [1.1088],\n",
      "        [1.0999],\n",
      "        [1.1095],\n",
      "        [1.1265],\n",
      "        [1.1074],\n",
      "        [1.1151],\n",
      "        [1.1240],\n",
      "        [1.1078]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1192],\n",
      "        [1.0730],\n",
      "        [1.0803],\n",
      "        [1.1087],\n",
      "        [1.0756],\n",
      "        [1.0506],\n",
      "        [1.1014],\n",
      "        [1.0804],\n",
      "        [1.0654],\n",
      "        [1.1144],\n",
      "        [1.0821],\n",
      "        [1.0725],\n",
      "        [1.0969],\n",
      "        [1.0740],\n",
      "        [1.0983],\n",
      "        [1.1221],\n",
      "        [1.0818],\n",
      "        [1.0945],\n",
      "        [1.0841],\n",
      "        [1.0823],\n",
      "        [1.1051],\n",
      "        [1.1075],\n",
      "        [1.1081],\n",
      "        [1.1025],\n",
      "        [1.1162],\n",
      "        [1.1229],\n",
      "        [1.1121],\n",
      "        [1.1056],\n",
      "        [1.1067],\n",
      "        [1.0975],\n",
      "        [1.1000],\n",
      "        [1.1131],\n",
      "        [1.1014],\n",
      "        [1.0633],\n",
      "        [1.0881],\n",
      "        [1.1000],\n",
      "        [1.1198],\n",
      "        [1.1195],\n",
      "        [1.1189],\n",
      "        [1.1074],\n",
      "        [1.0544],\n",
      "        [1.1205],\n",
      "        [1.0810],\n",
      "        [1.1077],\n",
      "        [1.1142],\n",
      "        [1.1169],\n",
      "        [1.1016],\n",
      "        [1.0646],\n",
      "        [1.0843],\n",
      "        [1.1146],\n",
      "        [1.1025],\n",
      "        [1.0852],\n",
      "        [1.0824],\n",
      "        [1.1009],\n",
      "        [1.0537],\n",
      "        [1.0573],\n",
      "        [1.0715],\n",
      "        [1.0989],\n",
      "        [1.1087],\n",
      "        [1.0632],\n",
      "        [1.1028],\n",
      "        [1.0819],\n",
      "        [1.0859],\n",
      "        [1.1179],\n",
      "        [1.0904],\n",
      "        [1.0698],\n",
      "        [1.0639],\n",
      "        [1.1085],\n",
      "        [1.0774],\n",
      "        [1.0895],\n",
      "        [1.1022],\n",
      "        [1.1172],\n",
      "        [1.0617],\n",
      "        [1.1074],\n",
      "        [1.1092],\n",
      "        [1.0719],\n",
      "        [1.1107],\n",
      "        [1.0655],\n",
      "        [1.1061],\n",
      "        [1.1120],\n",
      "        [1.1170],\n",
      "        [1.0816],\n",
      "        [1.1041],\n",
      "        [1.1128],\n",
      "        [1.1114],\n",
      "        [1.0790],\n",
      "        [1.0898],\n",
      "        [1.0685],\n",
      "        [1.1132],\n",
      "        [1.0540],\n",
      "        [1.0522],\n",
      "        [1.1197],\n",
      "        [1.0544],\n",
      "        [1.1217],\n",
      "        [1.0926],\n",
      "        [1.0984],\n",
      "        [1.0921],\n",
      "        [1.0978],\n",
      "        [1.1128],\n",
      "        [1.1201],\n",
      "        [1.0847],\n",
      "        [1.0819],\n",
      "        [1.1106],\n",
      "        [1.1175],\n",
      "        [1.0791],\n",
      "        [1.1075],\n",
      "        [1.0872],\n",
      "        [1.1072],\n",
      "        [1.1126],\n",
      "        [1.0767],\n",
      "        [1.1109],\n",
      "        [1.0950],\n",
      "        [1.0603],\n",
      "        [1.0895],\n",
      "        [1.0679],\n",
      "        [1.0704],\n",
      "        [1.1059],\n",
      "        [1.0766],\n",
      "        [1.0813],\n",
      "        [1.0572],\n",
      "        [1.0961],\n",
      "        [1.0920],\n",
      "        [1.0944],\n",
      "        [1.1204],\n",
      "        [1.1060],\n",
      "        [1.0762],\n",
      "        [1.0802],\n",
      "        [1.1226]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0780],\n",
      "        [1.0868],\n",
      "        [1.1110],\n",
      "        [1.0999],\n",
      "        [1.0851],\n",
      "        [1.0902],\n",
      "        [1.1067],\n",
      "        [1.1033],\n",
      "        [1.0154],\n",
      "        [1.1072],\n",
      "        [1.0713],\n",
      "        [1.0790],\n",
      "        [1.0842],\n",
      "        [1.0478],\n",
      "        [1.0703],\n",
      "        [1.1011],\n",
      "        [1.0996],\n",
      "        [1.1091],\n",
      "        [1.0870],\n",
      "        [1.1168],\n",
      "        [1.0904],\n",
      "        [1.0843],\n",
      "        [1.1165],\n",
      "        [1.0865],\n",
      "        [1.0793],\n",
      "        [1.0846],\n",
      "        [1.0871],\n",
      "        [1.0766],\n",
      "        [1.0649],\n",
      "        [1.0232],\n",
      "        [1.1155],\n",
      "        [1.0774],\n",
      "        [1.0631],\n",
      "        [1.0486],\n",
      "        [1.0712],\n",
      "        [1.0820],\n",
      "        [1.0541],\n",
      "        [1.0398],\n",
      "        [1.1177],\n",
      "        [1.1083],\n",
      "        [1.0866],\n",
      "        [1.0763],\n",
      "        [1.1069],\n",
      "        [1.1055],\n",
      "        [1.0869],\n",
      "        [1.0910],\n",
      "        [1.0637],\n",
      "        [1.1157],\n",
      "        [1.1074],\n",
      "        [1.0884],\n",
      "        [1.1008],\n",
      "        [1.1032],\n",
      "        [1.1167],\n",
      "        [1.1134],\n",
      "        [1.1067],\n",
      "        [1.0926],\n",
      "        [1.0826],\n",
      "        [1.0674],\n",
      "        [1.1154],\n",
      "        [1.1020],\n",
      "        [1.0532],\n",
      "        [1.0941],\n",
      "        [1.0827],\n",
      "        [1.0839],\n",
      "        [1.0303],\n",
      "        [1.0759],\n",
      "        [1.0614],\n",
      "        [1.0870],\n",
      "        [1.0731],\n",
      "        [1.1044],\n",
      "        [1.0560],\n",
      "        [1.0791],\n",
      "        [1.0922],\n",
      "        [1.1012],\n",
      "        [1.0731],\n",
      "        [1.0770],\n",
      "        [1.0948],\n",
      "        [1.0705],\n",
      "        [1.0951],\n",
      "        [1.0376],\n",
      "        [1.1149],\n",
      "        [1.0814],\n",
      "        [1.1120],\n",
      "        [1.1152],\n",
      "        [1.1045],\n",
      "        [1.1141],\n",
      "        [1.0872],\n",
      "        [1.0886],\n",
      "        [1.0946],\n",
      "        [1.1118],\n",
      "        [1.1079],\n",
      "        [1.0716],\n",
      "        [1.0563],\n",
      "        [1.1077],\n",
      "        [1.1022],\n",
      "        [1.0949],\n",
      "        [1.0484],\n",
      "        [1.0859],\n",
      "        [1.0629],\n",
      "        [1.0872],\n",
      "        [1.0819],\n",
      "        [1.0877],\n",
      "        [1.1116],\n",
      "        [1.0952],\n",
      "        [1.1127],\n",
      "        [1.1056],\n",
      "        [1.0980],\n",
      "        [1.0647],\n",
      "        [1.0807],\n",
      "        [1.0806],\n",
      "        [1.1036],\n",
      "        [1.0839],\n",
      "        [1.1115],\n",
      "        [1.0968],\n",
      "        [1.0835],\n",
      "        [1.0836],\n",
      "        [1.0927],\n",
      "        [1.0903],\n",
      "        [1.0811],\n",
      "        [1.0458],\n",
      "        [1.1016],\n",
      "        [1.0820],\n",
      "        [1.0734],\n",
      "        [1.0724],\n",
      "        [1.0876],\n",
      "        [1.0858],\n",
      "        [1.1116],\n",
      "        [1.1110]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0516],\n",
      "        [1.0735],\n",
      "        [1.0832],\n",
      "        [1.0849],\n",
      "        [1.0680],\n",
      "        [1.0949],\n",
      "        [1.0660],\n",
      "        [1.0392],\n",
      "        [1.0935],\n",
      "        [1.0384],\n",
      "        [1.1095],\n",
      "        [1.1039],\n",
      "        [1.0973],\n",
      "        [1.0682],\n",
      "        [1.0697],\n",
      "        [1.0992],\n",
      "        [1.0821],\n",
      "        [1.1082],\n",
      "        [1.1039],\n",
      "        [1.0808],\n",
      "        [1.1068],\n",
      "        [1.0864],\n",
      "        [1.0934],\n",
      "        [1.0946],\n",
      "        [1.1077],\n",
      "        [1.0069],\n",
      "        [1.0712],\n",
      "        [1.1024],\n",
      "        [1.0898],\n",
      "        [1.0992],\n",
      "        [1.1013],\n",
      "        [1.0903],\n",
      "        [1.0873],\n",
      "        [1.1033],\n",
      "        [1.0734],\n",
      "        [1.0947],\n",
      "        [1.0958],\n",
      "        [1.0687],\n",
      "        [1.0819],\n",
      "        [1.0618],\n",
      "        [1.0891],\n",
      "        [1.1072],\n",
      "        [1.0857],\n",
      "        [1.0896],\n",
      "        [1.0709],\n",
      "        [1.0862],\n",
      "        [1.1120],\n",
      "        [1.0976],\n",
      "        [1.0976],\n",
      "        [1.0798],\n",
      "        [1.1085],\n",
      "        [1.0474],\n",
      "        [1.0932],\n",
      "        [1.0827],\n",
      "        [1.0970],\n",
      "        [1.0986],\n",
      "        [1.0816],\n",
      "        [1.0711],\n",
      "        [0.8420],\n",
      "        [1.1115],\n",
      "        [1.1057],\n",
      "        [1.1034],\n",
      "        [1.0901],\n",
      "        [1.0875],\n",
      "        [1.0913],\n",
      "        [0.0617],\n",
      "        [1.1086],\n",
      "        [1.0455],\n",
      "        [1.0429],\n",
      "        [1.1012],\n",
      "        [1.0748],\n",
      "        [1.1048],\n",
      "        [1.1034],\n",
      "        [1.1076],\n",
      "        [1.0929],\n",
      "        [1.1144],\n",
      "        [1.0958],\n",
      "        [1.0928],\n",
      "        [1.1116],\n",
      "        [1.0921],\n",
      "        [1.0786],\n",
      "        [1.1085],\n",
      "        [1.1032],\n",
      "        [1.1043],\n",
      "        [1.1006],\n",
      "        [1.0989],\n",
      "        [1.0743],\n",
      "        [1.0627],\n",
      "        [1.0849],\n",
      "        [1.0657],\n",
      "        [1.1074],\n",
      "        [1.0613],\n",
      "        [1.1022],\n",
      "        [1.0724],\n",
      "        [1.0774],\n",
      "        [1.0689],\n",
      "        [1.0675],\n",
      "        [1.1035],\n",
      "        [1.0662],\n",
      "        [1.0900],\n",
      "        [1.1020],\n",
      "        [1.1020],\n",
      "        [1.0275],\n",
      "        [1.0377],\n",
      "        [1.1007],\n",
      "        [1.1060],\n",
      "        [1.0901],\n",
      "        [1.0880],\n",
      "        [1.0986],\n",
      "        [1.0560],\n",
      "        [1.0992],\n",
      "        [1.0930],\n",
      "        [1.0481],\n",
      "        [1.0781],\n",
      "        [1.1031],\n",
      "        [1.0892],\n",
      "        [1.0976],\n",
      "        [1.0890],\n",
      "        [1.0718],\n",
      "        [1.0630],\n",
      "        [1.0910],\n",
      "        [1.0895],\n",
      "        [1.0871],\n",
      "        [1.1075],\n",
      "        [1.1067],\n",
      "        [1.1043],\n",
      "        [1.1083],\n",
      "        [1.0775]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0663],\n",
      "        [1.0202],\n",
      "        [1.0282],\n",
      "        [1.0419],\n",
      "        [1.0862],\n",
      "        [1.1067],\n",
      "        [1.0738],\n",
      "        [1.0969],\n",
      "        [1.1072],\n",
      "        [1.0962],\n",
      "        [1.1069],\n",
      "        [1.0776],\n",
      "        [1.0675],\n",
      "        [1.0827],\n",
      "        [1.0978],\n",
      "        [1.0771],\n",
      "        [1.0876],\n",
      "        [1.0843],\n",
      "        [1.0799],\n",
      "        [1.1054],\n",
      "        [1.0902],\n",
      "        [1.0798],\n",
      "        [1.1135],\n",
      "        [1.0881],\n",
      "        [1.1136],\n",
      "        [1.0803],\n",
      "        [1.0958],\n",
      "        [1.0767],\n",
      "        [1.0626],\n",
      "        [1.1022],\n",
      "        [1.0976],\n",
      "        [1.1023],\n",
      "        [1.0841],\n",
      "        [1.0713],\n",
      "        [1.0836],\n",
      "        [1.0815],\n",
      "        [1.1074],\n",
      "        [1.0978],\n",
      "        [1.0935],\n",
      "        [1.1075],\n",
      "        [1.0696],\n",
      "        [1.0963],\n",
      "        [1.0385],\n",
      "        [1.0850],\n",
      "        [1.0757],\n",
      "        [1.0897],\n",
      "        [1.0830],\n",
      "        [1.0861],\n",
      "        [1.0341],\n",
      "        [1.0802],\n",
      "        [1.0959],\n",
      "        [1.1094],\n",
      "        [1.0912],\n",
      "        [1.0731],\n",
      "        [1.0511],\n",
      "        [1.0621],\n",
      "        [1.0948],\n",
      "        [1.0612],\n",
      "        [1.0984],\n",
      "        [1.0717],\n",
      "        [1.0985],\n",
      "        [1.0788],\n",
      "        [1.0949],\n",
      "        [1.0406],\n",
      "        [1.0740],\n",
      "        [1.0833],\n",
      "        [1.0996],\n",
      "        [1.0988],\n",
      "        [1.0904],\n",
      "        [1.0587],\n",
      "        [1.0742],\n",
      "        [1.0786],\n",
      "        [1.0523],\n",
      "        [1.0854],\n",
      "        [1.1094],\n",
      "        [1.0946],\n",
      "        [1.0717],\n",
      "        [1.0382],\n",
      "        [1.1013],\n",
      "        [1.1015],\n",
      "        [1.1004],\n",
      "        [1.0899],\n",
      "        [1.0641],\n",
      "        [1.1072],\n",
      "        [1.0802],\n",
      "        [1.0767],\n",
      "        [1.0851],\n",
      "        [1.0931],\n",
      "        [1.0698],\n",
      "        [1.0471],\n",
      "        [1.0403],\n",
      "        [1.0636],\n",
      "        [1.0983],\n",
      "        [1.0948],\n",
      "        [1.0888],\n",
      "        [1.0356],\n",
      "        [1.1060],\n",
      "        [1.0932],\n",
      "        [1.0803],\n",
      "        [1.0868],\n",
      "        [1.0736],\n",
      "        [1.0856],\n",
      "        [1.0779],\n",
      "        [1.0546],\n",
      "        [1.0875],\n",
      "        [1.0905],\n",
      "        [1.0824],\n",
      "        [1.0751],\n",
      "        [1.0512],\n",
      "        [1.0803],\n",
      "        [1.0921],\n",
      "        [1.1067],\n",
      "        [1.0961],\n",
      "        [1.0519],\n",
      "        [1.0250],\n",
      "        [1.0567],\n",
      "        [1.0883],\n",
      "        [1.0780],\n",
      "        [1.0898],\n",
      "        [1.0711],\n",
      "        [1.0995],\n",
      "        [1.0787],\n",
      "        [1.0759],\n",
      "        [1.0339],\n",
      "        [1.0653],\n",
      "        [1.1033],\n",
      "        [1.0896],\n",
      "        [1.0689]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0959],\n",
      "        [1.0844],\n",
      "        [1.0617],\n",
      "        [1.0751],\n",
      "        [1.0885],\n",
      "        [1.0709],\n",
      "        [1.1039],\n",
      "        [1.0603],\n",
      "        [1.0757],\n",
      "        [1.0708],\n",
      "        [1.0981],\n",
      "        [1.0937],\n",
      "        [1.0866],\n",
      "        [1.0816],\n",
      "        [1.0377],\n",
      "        [1.0527],\n",
      "        [1.0946],\n",
      "        [1.0548],\n",
      "        [1.0544],\n",
      "        [1.0749],\n",
      "        [1.0720],\n",
      "        [1.0596],\n",
      "        [1.0698],\n",
      "        [1.0896],\n",
      "        [1.0631],\n",
      "        [1.0883],\n",
      "        [1.0898],\n",
      "        [1.0948],\n",
      "        [1.0977],\n",
      "        [1.0832],\n",
      "        [1.0630],\n",
      "        [1.0754],\n",
      "        [1.0792],\n",
      "        [1.0998],\n",
      "        [1.0806],\n",
      "        [1.0695],\n",
      "        [1.0859],\n",
      "        [1.1021],\n",
      "        [1.0451],\n",
      "        [1.0843],\n",
      "        [1.0958],\n",
      "        [1.0939],\n",
      "        [1.0481],\n",
      "        [1.0288],\n",
      "        [1.0644],\n",
      "        [1.0688],\n",
      "        [1.0952],\n",
      "        [1.0901],\n",
      "        [1.0817],\n",
      "        [1.0983],\n",
      "        [1.0989],\n",
      "        [1.0882],\n",
      "        [1.1036],\n",
      "        [1.1016],\n",
      "        [1.0564],\n",
      "        [1.0567],\n",
      "        [1.0693],\n",
      "        [1.0719],\n",
      "        [1.1000],\n",
      "        [1.0939],\n",
      "        [1.0841],\n",
      "        [1.0507],\n",
      "        [1.0838],\n",
      "        [1.0648],\n",
      "        [1.1023],\n",
      "        [1.0943],\n",
      "        [1.0794],\n",
      "        [1.0616],\n",
      "        [1.0758],\n",
      "        [1.0842],\n",
      "        [1.1011],\n",
      "        [1.0936],\n",
      "        [1.0673],\n",
      "        [1.0211],\n",
      "        [1.0522],\n",
      "        [1.0728],\n",
      "        [1.0720],\n",
      "        [1.0949],\n",
      "        [1.0808],\n",
      "        [1.0637],\n",
      "        [1.1045],\n",
      "        [1.0632],\n",
      "        [1.0845],\n",
      "        [1.1045],\n",
      "        [1.0368],\n",
      "        [1.0955],\n",
      "        [1.0571],\n",
      "        [1.0653],\n",
      "        [1.0816],\n",
      "        [1.0637],\n",
      "        [1.0837],\n",
      "        [1.1024],\n",
      "        [1.1041],\n",
      "        [1.0888],\n",
      "        [1.1048],\n",
      "        [1.0660],\n",
      "        [1.0972],\n",
      "        [1.0751],\n",
      "        [1.0609],\n",
      "        [1.0850],\n",
      "        [1.1052],\n",
      "        [1.0317],\n",
      "        [1.0391],\n",
      "        [1.0709],\n",
      "        [1.0494],\n",
      "        [1.0570],\n",
      "        [1.0204],\n",
      "        [1.0931],\n",
      "        [1.0704],\n",
      "        [1.0678],\n",
      "        [1.0817],\n",
      "        [1.0681],\n",
      "        [1.0903],\n",
      "        [1.0836],\n",
      "        [1.0792],\n",
      "        [1.0460],\n",
      "        [1.0769],\n",
      "        [1.0846],\n",
      "        [1.0686],\n",
      "        [1.1025],\n",
      "        [1.0494],\n",
      "        [1.0658],\n",
      "        [1.0822],\n",
      "        [1.0896],\n",
      "        [1.0985],\n",
      "        [1.0463],\n",
      "        [1.0606],\n",
      "        [1.0467]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0779],\n",
      "        [1.0757],\n",
      "        [1.0842],\n",
      "        [1.0259],\n",
      "        [1.0426],\n",
      "        [1.0278],\n",
      "        [1.0197],\n",
      "        [1.0747],\n",
      "        [1.0699],\n",
      "        [1.0800],\n",
      "        [1.0608],\n",
      "        [1.0564],\n",
      "        [1.0817],\n",
      "        [1.0785],\n",
      "        [1.0919],\n",
      "        [1.0803],\n",
      "        [1.1001],\n",
      "        [1.0850],\n",
      "        [1.0427],\n",
      "        [1.1018],\n",
      "        [1.0836],\n",
      "        [1.0675],\n",
      "        [1.0786],\n",
      "        [1.0694],\n",
      "        [1.0966],\n",
      "        [1.0914],\n",
      "        [1.0881],\n",
      "        [1.0774],\n",
      "        [1.0563],\n",
      "        [1.0515],\n",
      "        [1.0818],\n",
      "        [1.0219],\n",
      "        [1.0708],\n",
      "        [1.0983],\n",
      "        [1.0958],\n",
      "        [1.0810],\n",
      "        [1.0876],\n",
      "        [1.0831],\n",
      "        [1.0974],\n",
      "        [1.0820],\n",
      "        [1.0348],\n",
      "        [1.0279],\n",
      "        [1.0853],\n",
      "        [1.0483],\n",
      "        [1.0307],\n",
      "        [1.0775],\n",
      "        [1.0567],\n",
      "        [1.0479],\n",
      "        [1.0853],\n",
      "        [1.0211],\n",
      "        [1.0636],\n",
      "        [1.0909],\n",
      "        [1.0983],\n",
      "        [1.0957],\n",
      "        [1.0553],\n",
      "        [1.0444],\n",
      "        [1.0661],\n",
      "        [1.0849],\n",
      "        [1.0808],\n",
      "        [1.0823],\n",
      "        [1.0726],\n",
      "        [1.0827],\n",
      "        [1.0890],\n",
      "        [1.0519],\n",
      "        [1.0531],\n",
      "        [1.0971],\n",
      "        [1.0736],\n",
      "        [1.0524],\n",
      "        [1.0463],\n",
      "        [1.0176],\n",
      "        [1.0805],\n",
      "        [1.0525],\n",
      "        [1.0758],\n",
      "        [1.0870],\n",
      "        [1.0047],\n",
      "        [1.0989],\n",
      "        [1.0824],\n",
      "        [1.0747],\n",
      "        [1.0779],\n",
      "        [1.0736],\n",
      "        [1.0852],\n",
      "        [1.0637],\n",
      "        [1.0374],\n",
      "        [1.0651],\n",
      "        [1.0936],\n",
      "        [1.0706],\n",
      "        [1.0359],\n",
      "        [1.0286],\n",
      "        [1.0778],\n",
      "        [1.0740],\n",
      "        [1.0064],\n",
      "        [1.0237],\n",
      "        [1.0921],\n",
      "        [1.0000],\n",
      "        [1.0766],\n",
      "        [1.0320],\n",
      "        [1.0653],\n",
      "        [1.0931],\n",
      "        [1.0897],\n",
      "        [1.0988],\n",
      "        [1.0699],\n",
      "        [1.0513],\n",
      "        [1.0853],\n",
      "        [1.0770],\n",
      "        [1.0566],\n",
      "        [1.0964],\n",
      "        [1.0763],\n",
      "        [1.0817],\n",
      "        [1.0795],\n",
      "        [1.0742],\n",
      "        [0.9894],\n",
      "        [1.0974],\n",
      "        [1.0556],\n",
      "        [1.0701],\n",
      "        [1.0801],\n",
      "        [1.0993],\n",
      "        [1.1020],\n",
      "        [1.0853],\n",
      "        [1.0331],\n",
      "        [1.0767],\n",
      "        [1.0841],\n",
      "        [1.0940],\n",
      "        [1.0680],\n",
      "        [1.0854],\n",
      "        [1.0772],\n",
      "        [1.1046],\n",
      "        [1.0907],\n",
      "        [1.0790]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0812],\n",
      "        [1.0524],\n",
      "        [1.0988],\n",
      "        [1.0773]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  12 | lr 0.00100 train_loss 2.12663 | val_loss 2.29682 | val_rmse 1.51553\n",
      "tensor([[1.0676],\n",
      "        [1.0336],\n",
      "        [1.0959],\n",
      "        [1.0887],\n",
      "        [1.0601],\n",
      "        [1.0803],\n",
      "        [1.0499],\n",
      "        [1.0442],\n",
      "        [1.0630],\n",
      "        [1.0926],\n",
      "        [1.0722],\n",
      "        [1.0652],\n",
      "        [1.0708],\n",
      "        [1.0903],\n",
      "        [1.0831],\n",
      "        [1.1034],\n",
      "        [1.0736],\n",
      "        [1.0504],\n",
      "        [1.0704],\n",
      "        [1.0389],\n",
      "        [1.0705],\n",
      "        [1.0651],\n",
      "        [1.0880],\n",
      "        [1.0858],\n",
      "        [1.0791],\n",
      "        [1.0722],\n",
      "        [1.0848],\n",
      "        [1.0739],\n",
      "        [1.0878],\n",
      "        [1.0940],\n",
      "        [1.0692],\n",
      "        [1.0682],\n",
      "        [1.0929],\n",
      "        [1.1033],\n",
      "        [1.1011],\n",
      "        [1.1027],\n",
      "        [1.0991],\n",
      "        [1.0632],\n",
      "        [1.0895],\n",
      "        [1.1002],\n",
      "        [1.0669],\n",
      "        [1.0798],\n",
      "        [1.0786],\n",
      "        [1.0673],\n",
      "        [1.0331],\n",
      "        [1.0582],\n",
      "        [1.0595],\n",
      "        [1.0731],\n",
      "        [1.0444],\n",
      "        [1.0606],\n",
      "        [1.0588],\n",
      "        [1.0661],\n",
      "        [1.0670],\n",
      "        [1.0962],\n",
      "        [1.0472],\n",
      "        [1.0757],\n",
      "        [1.0930],\n",
      "        [1.0988],\n",
      "        [1.0798],\n",
      "        [1.0803],\n",
      "        [1.0712],\n",
      "        [1.0857],\n",
      "        [1.1014],\n",
      "        [1.0739],\n",
      "        [1.0560],\n",
      "        [1.1037],\n",
      "        [1.0888],\n",
      "        [1.0989],\n",
      "        [1.0596],\n",
      "        [1.0882],\n",
      "        [1.0702],\n",
      "        [1.0571],\n",
      "        [1.0604],\n",
      "        [1.0413],\n",
      "        [1.0779],\n",
      "        [1.0659],\n",
      "        [1.1007],\n",
      "        [1.0544],\n",
      "        [1.0661],\n",
      "        [1.0704],\n",
      "        [1.0840],\n",
      "        [1.0331],\n",
      "        [1.0959],\n",
      "        [1.0817],\n",
      "        [1.0950],\n",
      "        [1.0576],\n",
      "        [1.0866],\n",
      "        [1.1013],\n",
      "        [1.0914],\n",
      "        [1.0816],\n",
      "        [1.1024],\n",
      "        [1.0418],\n",
      "        [1.0545],\n",
      "        [1.0688],\n",
      "        [1.0749],\n",
      "        [1.0569],\n",
      "        [1.0653],\n",
      "        [1.0865],\n",
      "        [1.0738],\n",
      "        [0.0993],\n",
      "        [1.0627],\n",
      "        [1.1006],\n",
      "        [1.0749],\n",
      "        [1.0140],\n",
      "        [1.0405],\n",
      "        [1.1034],\n",
      "        [1.0571],\n",
      "        [1.0795],\n",
      "        [1.0888],\n",
      "        [1.0672],\n",
      "        [1.0950],\n",
      "        [1.0995],\n",
      "        [1.0681],\n",
      "        [1.0703],\n",
      "        [1.0145],\n",
      "        [1.1013],\n",
      "        [1.0840],\n",
      "        [1.0252],\n",
      "        [1.0605],\n",
      "        [1.0456],\n",
      "        [1.0860],\n",
      "        [1.0711],\n",
      "        [1.0783],\n",
      "        [1.0799],\n",
      "        [1.0774],\n",
      "        [1.0908],\n",
      "        [1.0974],\n",
      "        [1.0613]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0930],\n",
      "        [1.0956],\n",
      "        [1.0623],\n",
      "        [1.0944],\n",
      "        [1.1061],\n",
      "        [1.0621],\n",
      "        [1.0661],\n",
      "        [1.1042],\n",
      "        [1.0918],\n",
      "        [1.0417],\n",
      "        [1.0672],\n",
      "        [1.0971],\n",
      "        [1.1037],\n",
      "        [1.0652],\n",
      "        [1.0478],\n",
      "        [1.0453],\n",
      "        [1.0327],\n",
      "        [1.0979],\n",
      "        [1.0918],\n",
      "        [1.1078],\n",
      "        [1.0897],\n",
      "        [1.0809],\n",
      "        [1.0898],\n",
      "        [1.0464],\n",
      "        [1.0576],\n",
      "        [1.0792],\n",
      "        [1.0634],\n",
      "        [1.0933],\n",
      "        [1.0882],\n",
      "        [1.0761],\n",
      "        [1.0836],\n",
      "        [1.0915],\n",
      "        [1.1072],\n",
      "        [1.1014],\n",
      "        [1.0645],\n",
      "        [1.0959],\n",
      "        [1.1039],\n",
      "        [1.0623],\n",
      "        [1.0991],\n",
      "        [1.0497],\n",
      "        [1.1070],\n",
      "        [1.0512],\n",
      "        [1.0499],\n",
      "        [1.0703],\n",
      "        [1.0509],\n",
      "        [1.1043],\n",
      "        [1.0806],\n",
      "        [1.1009],\n",
      "        [1.0675],\n",
      "        [1.0968],\n",
      "        [1.0781],\n",
      "        [1.0917],\n",
      "        [1.0668],\n",
      "        [1.0745],\n",
      "        [1.0851],\n",
      "        [1.0519],\n",
      "        [1.0740],\n",
      "        [1.0700],\n",
      "        [1.0845],\n",
      "        [1.0882],\n",
      "        [1.1019],\n",
      "        [1.0738],\n",
      "        [1.0867],\n",
      "        [1.1006],\n",
      "        [1.0566],\n",
      "        [1.1062],\n",
      "        [1.0773],\n",
      "        [1.0606],\n",
      "        [1.0615],\n",
      "        [1.0767],\n",
      "        [1.0371],\n",
      "        [1.1043],\n",
      "        [1.0456],\n",
      "        [1.1028],\n",
      "        [1.0813],\n",
      "        [1.1035],\n",
      "        [1.1080],\n",
      "        [1.0937],\n",
      "        [1.0961],\n",
      "        [1.0342],\n",
      "        [1.0706],\n",
      "        [1.1053],\n",
      "        [1.0878],\n",
      "        [1.0712],\n",
      "        [1.0815],\n",
      "        [1.0402],\n",
      "        [1.0743],\n",
      "        [1.0877],\n",
      "        [1.0660],\n",
      "        [1.1042],\n",
      "        [1.1073],\n",
      "        [1.0550],\n",
      "        [1.0758],\n",
      "        [1.0772],\n",
      "        [1.0905],\n",
      "        [1.0528],\n",
      "        [1.0955],\n",
      "        [1.0885],\n",
      "        [1.0865],\n",
      "        [1.0480],\n",
      "        [1.0333],\n",
      "        [1.0606],\n",
      "        [1.0769],\n",
      "        [1.0772],\n",
      "        [1.0951],\n",
      "        [1.0484],\n",
      "        [1.1029],\n",
      "        [1.0296],\n",
      "        [1.0835],\n",
      "        [1.0627],\n",
      "        [1.0892],\n",
      "        [1.0856],\n",
      "        [1.0872],\n",
      "        [1.0699],\n",
      "        [1.0733],\n",
      "        [1.0953],\n",
      "        [1.0820],\n",
      "        [1.0959],\n",
      "        [1.0746],\n",
      "        [1.0566],\n",
      "        [1.1008],\n",
      "        [1.1071],\n",
      "        [1.1016],\n",
      "        [1.0920],\n",
      "        [1.0663],\n",
      "        [1.0966],\n",
      "        [1.0903],\n",
      "        [1.0355]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0277],\n",
      "        [1.0927],\n",
      "        [1.1117],\n",
      "        [1.1013],\n",
      "        [1.0547],\n",
      "        [1.0293],\n",
      "        [1.0806],\n",
      "        [1.0572],\n",
      "        [1.0895],\n",
      "        [1.1117],\n",
      "        [1.0785],\n",
      "        [1.1067],\n",
      "        [1.0994],\n",
      "        [1.0581],\n",
      "        [1.0656],\n",
      "        [1.0639],\n",
      "        [1.0645],\n",
      "        [1.1085],\n",
      "        [1.0903],\n",
      "        [1.0844],\n",
      "        [1.0982],\n",
      "        [1.0896],\n",
      "        [1.0627],\n",
      "        [1.0728],\n",
      "        [1.0775],\n",
      "        [1.0672],\n",
      "        [1.0964],\n",
      "        [1.0454],\n",
      "        [1.0965],\n",
      "        [1.0726],\n",
      "        [1.0998],\n",
      "        [1.0906],\n",
      "        [1.0242],\n",
      "        [0.1742],\n",
      "        [1.1051],\n",
      "        [1.1060],\n",
      "        [1.0821],\n",
      "        [1.0645],\n",
      "        [1.0888],\n",
      "        [1.0711],\n",
      "        [1.0787],\n",
      "        [1.0881],\n",
      "        [1.0850],\n",
      "        [1.0860],\n",
      "        [1.0908],\n",
      "        [1.0632],\n",
      "        [1.0765],\n",
      "        [1.1006],\n",
      "        [1.0935],\n",
      "        [1.0981],\n",
      "        [1.1108],\n",
      "        [1.0268],\n",
      "        [1.1026],\n",
      "        [1.0476],\n",
      "        [1.0638],\n",
      "        [1.0372],\n",
      "        [1.1086],\n",
      "        [1.0876],\n",
      "        [1.1102],\n",
      "        [1.0653],\n",
      "        [1.0693],\n",
      "        [1.0720],\n",
      "        [1.0491],\n",
      "        [1.0947],\n",
      "        [1.0478],\n",
      "        [1.0678],\n",
      "        [1.1001],\n",
      "        [1.0949],\n",
      "        [1.0466],\n",
      "        [1.1028],\n",
      "        [1.1008],\n",
      "        [1.0635],\n",
      "        [0.0777],\n",
      "        [1.0641],\n",
      "        [1.0945],\n",
      "        [1.1021],\n",
      "        [1.0945],\n",
      "        [1.0736],\n",
      "        [1.1092],\n",
      "        [1.0513],\n",
      "        [1.0741],\n",
      "        [1.0524],\n",
      "        [1.0765],\n",
      "        [1.1038],\n",
      "        [1.0686],\n",
      "        [1.0509],\n",
      "        [1.0670],\n",
      "        [1.0536],\n",
      "        [1.0825],\n",
      "        [1.0772],\n",
      "        [1.1089],\n",
      "        [1.0953],\n",
      "        [1.0956],\n",
      "        [1.1050],\n",
      "        [1.0918],\n",
      "        [1.0923],\n",
      "        [1.0712],\n",
      "        [1.0723],\n",
      "        [1.0967],\n",
      "        [1.0356],\n",
      "        [1.0828],\n",
      "        [1.0776],\n",
      "        [1.0720],\n",
      "        [1.1043],\n",
      "        [1.0598],\n",
      "        [1.0621],\n",
      "        [1.0762],\n",
      "        [1.0918],\n",
      "        [1.1145],\n",
      "        [1.1031],\n",
      "        [1.0960],\n",
      "        [1.0962],\n",
      "        [1.1054],\n",
      "        [1.0840],\n",
      "        [1.0994],\n",
      "        [1.0747],\n",
      "        [1.0994],\n",
      "        [1.0897],\n",
      "        [1.0775],\n",
      "        [1.0776],\n",
      "        [1.0802],\n",
      "        [1.0981],\n",
      "        [1.0976],\n",
      "        [1.1080],\n",
      "        [1.0412],\n",
      "        [1.1015],\n",
      "        [1.1056],\n",
      "        [1.0759]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1059],\n",
      "        [1.0755],\n",
      "        [1.1077],\n",
      "        [1.0677],\n",
      "        [1.0829],\n",
      "        [1.0590],\n",
      "        [1.0987],\n",
      "        [1.1200],\n",
      "        [1.0871],\n",
      "        [1.1030],\n",
      "        [1.0762],\n",
      "        [1.0941],\n",
      "        [1.0947],\n",
      "        [1.0885],\n",
      "        [1.1025],\n",
      "        [1.0601],\n",
      "        [1.0871],\n",
      "        [1.1009],\n",
      "        [1.1018],\n",
      "        [1.0895],\n",
      "        [1.1016],\n",
      "        [1.0937],\n",
      "        [1.0772],\n",
      "        [1.0683],\n",
      "        [1.0338],\n",
      "        [1.0531],\n",
      "        [1.1034],\n",
      "        [1.1006],\n",
      "        [1.0979],\n",
      "        [1.0981],\n",
      "        [1.0620],\n",
      "        [1.0728],\n",
      "        [1.0846],\n",
      "        [1.1030],\n",
      "        [1.0652],\n",
      "        [1.0394],\n",
      "        [1.0455],\n",
      "        [1.1012],\n",
      "        [1.0784],\n",
      "        [1.0629],\n",
      "        [1.0717],\n",
      "        [1.1036],\n",
      "        [1.0998],\n",
      "        [1.0667],\n",
      "        [1.7527],\n",
      "        [1.0527],\n",
      "        [1.1062],\n",
      "        [1.1070],\n",
      "        [1.0460],\n",
      "        [1.0723],\n",
      "        [1.0204],\n",
      "        [1.0666],\n",
      "        [1.1053],\n",
      "        [1.0785],\n",
      "        [1.0999],\n",
      "        [1.0684],\n",
      "        [1.0825],\n",
      "        [1.1013],\n",
      "        [1.1144],\n",
      "        [1.1080],\n",
      "        [1.1110],\n",
      "        [1.0905],\n",
      "        [1.0735],\n",
      "        [1.0764],\n",
      "        [1.0776],\n",
      "        [1.1114],\n",
      "        [1.1107],\n",
      "        [1.1092],\n",
      "        [1.0708],\n",
      "        [1.0977],\n",
      "        [1.0739],\n",
      "        [1.1004],\n",
      "        [1.0514],\n",
      "        [1.0591],\n",
      "        [1.1012],\n",
      "        [1.1133],\n",
      "        [1.1019],\n",
      "        [1.0756],\n",
      "        [1.0975],\n",
      "        [1.0885],\n",
      "        [1.0505],\n",
      "        [1.1055],\n",
      "        [1.0918],\n",
      "        [1.0920],\n",
      "        [1.0131],\n",
      "        [1.1003],\n",
      "        [1.1100],\n",
      "        [1.0905],\n",
      "        [1.0778],\n",
      "        [1.1005],\n",
      "        [1.0359],\n",
      "        [1.0650],\n",
      "        [1.0988],\n",
      "        [1.1134],\n",
      "        [1.1092],\n",
      "        [1.0971],\n",
      "        [1.0646],\n",
      "        [1.1030],\n",
      "        [1.1106],\n",
      "        [1.0761],\n",
      "        [1.1115],\n",
      "        [1.0764],\n",
      "        [1.0938],\n",
      "        [1.1035],\n",
      "        [1.1144],\n",
      "        [1.1033],\n",
      "        [1.0139],\n",
      "        [1.0961],\n",
      "        [1.1105],\n",
      "        [1.0956],\n",
      "        [1.1072],\n",
      "        [1.0591],\n",
      "        [1.0710],\n",
      "        [1.1016],\n",
      "        [1.0659],\n",
      "        [1.0556],\n",
      "        [1.1125],\n",
      "        [1.0801],\n",
      "        [1.0294],\n",
      "        [1.0693],\n",
      "        [1.0443],\n",
      "        [1.1066],\n",
      "        [1.0788],\n",
      "        [1.0797],\n",
      "        [1.0852],\n",
      "        [1.1123],\n",
      "        [1.1041],\n",
      "        [1.0880]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1043],\n",
      "        [1.1028],\n",
      "        [1.0966],\n",
      "        [1.1038],\n",
      "        [1.0848],\n",
      "        [1.0914],\n",
      "        [1.1005],\n",
      "        [1.1069],\n",
      "        [1.1129],\n",
      "        [1.0990],\n",
      "        [1.0802],\n",
      "        [1.0454],\n",
      "        [1.1154],\n",
      "        [1.0751],\n",
      "        [1.0862],\n",
      "        [1.0894],\n",
      "        [1.1186],\n",
      "        [1.1010],\n",
      "        [1.1090],\n",
      "        [1.1189],\n",
      "        [1.1008],\n",
      "        [1.0998],\n",
      "        [1.1180],\n",
      "        [1.1162],\n",
      "        [1.0624],\n",
      "        [1.0921],\n",
      "        [1.1079],\n",
      "        [1.1189],\n",
      "        [1.1133],\n",
      "        [1.0666],\n",
      "        [1.0928],\n",
      "        [1.0718],\n",
      "        [1.1104],\n",
      "        [1.0848],\n",
      "        [1.0686],\n",
      "        [1.1045],\n",
      "        [1.0775],\n",
      "        [1.1055],\n",
      "        [1.0680],\n",
      "        [1.0354],\n",
      "        [1.0806],\n",
      "        [1.1017],\n",
      "        [1.1068],\n",
      "        [1.1130],\n",
      "        [1.0916],\n",
      "        [1.0800],\n",
      "        [1.1066],\n",
      "        [1.0834],\n",
      "        [1.1146],\n",
      "        [1.0649],\n",
      "        [1.0755],\n",
      "        [1.0681],\n",
      "        [1.1090],\n",
      "        [1.1134],\n",
      "        [1.1099],\n",
      "        [1.0644],\n",
      "        [1.1078],\n",
      "        [1.0835],\n",
      "        [1.0847],\n",
      "        [1.0952],\n",
      "        [1.1066],\n",
      "        [1.1079],\n",
      "        [1.0672],\n",
      "        [1.1022],\n",
      "        [1.0806],\n",
      "        [1.1151],\n",
      "        [1.0863],\n",
      "        [1.0401],\n",
      "        [1.0809],\n",
      "        [1.0973],\n",
      "        [1.1057],\n",
      "        [1.0447],\n",
      "        [1.1039],\n",
      "        [1.0628],\n",
      "        [1.0774],\n",
      "        [1.0933],\n",
      "        [1.0836],\n",
      "        [1.1051],\n",
      "        [1.1151],\n",
      "        [1.0704],\n",
      "        [1.0949],\n",
      "        [1.0921],\n",
      "        [1.0798],\n",
      "        [1.0949],\n",
      "        [1.0995],\n",
      "        [1.0477],\n",
      "        [1.0655],\n",
      "        [1.0467],\n",
      "        [1.1047],\n",
      "        [1.0985],\n",
      "        [1.1130],\n",
      "        [1.1075],\n",
      "        [1.0748],\n",
      "        [1.1095],\n",
      "        [1.1002],\n",
      "        [1.0959],\n",
      "        [1.0831],\n",
      "        [1.0698],\n",
      "        [1.0700],\n",
      "        [1.1058],\n",
      "        [1.0812],\n",
      "        [1.1056],\n",
      "        [1.1083],\n",
      "        [1.1002],\n",
      "        [1.1062],\n",
      "        [1.1014],\n",
      "        [1.1126],\n",
      "        [1.0886],\n",
      "        [1.0473],\n",
      "        [1.0945],\n",
      "        [1.0743],\n",
      "        [1.1147],\n",
      "        [1.1070],\n",
      "        [1.0858],\n",
      "        [1.0773],\n",
      "        [1.0739],\n",
      "        [1.1131],\n",
      "        [1.0861],\n",
      "        [1.0634],\n",
      "        [1.0984],\n",
      "        [1.0994],\n",
      "        [1.0725],\n",
      "        [1.1104],\n",
      "        [1.0947],\n",
      "        [1.0694],\n",
      "        [1.1191],\n",
      "        [1.1095],\n",
      "        [1.0967]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1008],\n",
      "        [1.0772],\n",
      "        [1.0730],\n",
      "        [1.0746],\n",
      "        [1.0534],\n",
      "        [1.0827],\n",
      "        [1.1025],\n",
      "        [1.0836],\n",
      "        [1.0953],\n",
      "        [1.1194],\n",
      "        [1.0757],\n",
      "        [1.0949],\n",
      "        [1.0676],\n",
      "        [1.0902],\n",
      "        [1.0955],\n",
      "        [1.1054],\n",
      "        [1.0747],\n",
      "        [1.0776],\n",
      "        [1.0930],\n",
      "        [1.1124],\n",
      "        [1.0774],\n",
      "        [1.1003],\n",
      "        [1.0993],\n",
      "        [1.0979],\n",
      "        [1.0681],\n",
      "        [1.1064],\n",
      "        [1.0816],\n",
      "        [1.1015],\n",
      "        [1.0690],\n",
      "        [1.0294],\n",
      "        [1.0753],\n",
      "        [1.0591],\n",
      "        [1.0862],\n",
      "        [1.0803],\n",
      "        [1.0833],\n",
      "        [1.0742],\n",
      "        [1.0729],\n",
      "        [1.1028],\n",
      "        [1.0849],\n",
      "        [1.1037],\n",
      "        [1.0820],\n",
      "        [1.0710],\n",
      "        [1.0655],\n",
      "        [1.1222],\n",
      "        [1.0495],\n",
      "        [1.0782],\n",
      "        [1.0610],\n",
      "        [1.0656],\n",
      "        [1.0596],\n",
      "        [1.1153],\n",
      "        [1.0976],\n",
      "        [1.1029],\n",
      "        [1.0708],\n",
      "        [1.1154],\n",
      "        [1.0406],\n",
      "        [1.1222],\n",
      "        [1.1101],\n",
      "        [1.1005],\n",
      "        [1.0872],\n",
      "        [1.0775],\n",
      "        [1.0930],\n",
      "        [1.1150],\n",
      "        [1.0792],\n",
      "        [1.0842],\n",
      "        [1.0820],\n",
      "        [1.1019],\n",
      "        [1.0923],\n",
      "        [1.0940],\n",
      "        [1.0689],\n",
      "        [1.1188],\n",
      "        [1.0975],\n",
      "        [1.0981],\n",
      "        [1.1037],\n",
      "        [1.0642],\n",
      "        [1.0915],\n",
      "        [1.0888],\n",
      "        [1.0816],\n",
      "        [1.0365],\n",
      "        [1.0656],\n",
      "        [1.0691],\n",
      "        [1.0627],\n",
      "        [1.0626],\n",
      "        [1.0863],\n",
      "        [1.1011],\n",
      "        [1.1038],\n",
      "        [1.1198],\n",
      "        [1.0507],\n",
      "        [1.1039],\n",
      "        [1.0928],\n",
      "        [1.0565],\n",
      "        [1.1131],\n",
      "        [1.1224],\n",
      "        [1.0703],\n",
      "        [1.0941],\n",
      "        [1.0994],\n",
      "        [1.0776],\n",
      "        [1.0332],\n",
      "        [1.0779],\n",
      "        [1.0423],\n",
      "        [1.1061],\n",
      "        [1.0907],\n",
      "        [1.1008],\n",
      "        [1.0901],\n",
      "        [1.0942],\n",
      "        [1.0788],\n",
      "        [1.0475],\n",
      "        [1.0966],\n",
      "        [1.1089],\n",
      "        [1.0816],\n",
      "        [1.1100],\n",
      "        [1.1161],\n",
      "        [1.0661],\n",
      "        [1.0597],\n",
      "        [1.0965],\n",
      "        [1.0157],\n",
      "        [1.1147],\n",
      "        [1.1185],\n",
      "        [1.0575],\n",
      "        [1.0935],\n",
      "        [1.1182],\n",
      "        [1.1104],\n",
      "        [1.0992],\n",
      "        [1.0961],\n",
      "        [1.1205],\n",
      "        [1.0667],\n",
      "        [1.0826],\n",
      "        [1.0847],\n",
      "        [1.1025]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1075],\n",
      "        [1.0572],\n",
      "        [1.0773],\n",
      "        [1.0657],\n",
      "        [1.0596],\n",
      "        [1.0798],\n",
      "        [1.1117],\n",
      "        [1.0966],\n",
      "        [1.0975],\n",
      "        [1.1167],\n",
      "        [1.1149],\n",
      "        [1.0554],\n",
      "        [1.0610],\n",
      "        [1.1165],\n",
      "        [1.0961],\n",
      "        [1.0817],\n",
      "        [1.1173],\n",
      "        [1.0761],\n",
      "        [1.0922],\n",
      "        [1.0873],\n",
      "        [1.1025],\n",
      "        [1.0872],\n",
      "        [1.0896],\n",
      "        [1.0903],\n",
      "        [1.1109],\n",
      "        [1.0625],\n",
      "        [1.1215],\n",
      "        [1.1166],\n",
      "        [1.0475],\n",
      "        [1.0986],\n",
      "        [1.0801],\n",
      "        [1.1156],\n",
      "        [1.1043],\n",
      "        [1.1269],\n",
      "        [1.1077],\n",
      "        [1.0949],\n",
      "        [1.1095],\n",
      "        [1.0680],\n",
      "        [1.0847],\n",
      "        [1.0762],\n",
      "        [1.1044],\n",
      "        [1.1072],\n",
      "        [1.0597],\n",
      "        [1.0816],\n",
      "        [1.0995],\n",
      "        [1.0998],\n",
      "        [1.0983],\n",
      "        [1.1062],\n",
      "        [1.0582],\n",
      "        [1.0605],\n",
      "        [1.0920],\n",
      "        [1.1201],\n",
      "        [1.0711],\n",
      "        [1.0896],\n",
      "        [1.0687],\n",
      "        [1.0221],\n",
      "        [1.1133],\n",
      "        [1.0889],\n",
      "        [1.1062],\n",
      "        [1.1222],\n",
      "        [1.1171],\n",
      "        [1.0865],\n",
      "        [1.0813],\n",
      "        [1.0655],\n",
      "        [1.0774],\n",
      "        [1.0752],\n",
      "        [1.1123],\n",
      "        [1.0938],\n",
      "        [1.1241],\n",
      "        [1.1106],\n",
      "        [1.1128],\n",
      "        [1.0740],\n",
      "        [1.0650],\n",
      "        [1.0773],\n",
      "        [1.0833],\n",
      "        [1.0630],\n",
      "        [1.0733],\n",
      "        [1.0941],\n",
      "        [1.0507],\n",
      "        [1.0790],\n",
      "        [1.1063],\n",
      "        [1.0984],\n",
      "        [1.0572],\n",
      "        [1.1139],\n",
      "        [1.0932],\n",
      "        [1.0995],\n",
      "        [1.0888],\n",
      "        [1.1047],\n",
      "        [1.1202],\n",
      "        [1.0687],\n",
      "        [1.0958],\n",
      "        [1.0937],\n",
      "        [1.1226],\n",
      "        [1.0912],\n",
      "        [1.0973],\n",
      "        [1.1085],\n",
      "        [1.0746],\n",
      "        [1.1193],\n",
      "        [1.0676],\n",
      "        [1.1117],\n",
      "        [1.1004],\n",
      "        [1.0749],\n",
      "        [1.1133],\n",
      "        [1.1107],\n",
      "        [1.1178],\n",
      "        [1.0576],\n",
      "        [1.1120],\n",
      "        [1.0926],\n",
      "        [1.0964],\n",
      "        [1.0709],\n",
      "        [1.0749],\n",
      "        [1.1124],\n",
      "        [1.0973],\n",
      "        [1.1047],\n",
      "        [1.0796],\n",
      "        [1.1149],\n",
      "        [1.0965],\n",
      "        [1.0599],\n",
      "        [1.0597],\n",
      "        [1.1231],\n",
      "        [1.1084],\n",
      "        [1.0986],\n",
      "        [1.1067],\n",
      "        [1.0900],\n",
      "        [1.1194],\n",
      "        [1.0911],\n",
      "        [1.0999],\n",
      "        [1.1209]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1010],\n",
      "        [1.1078],\n",
      "        [1.1089],\n",
      "        [1.0764]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  13 | lr 0.00100 train_loss 2.12309 | val_loss 2.29049 | val_rmse 1.51344\n",
      "tensor([[1.0652],\n",
      "        [1.1078],\n",
      "        [1.0669],\n",
      "        [1.0801],\n",
      "        [1.0328],\n",
      "        [1.1248],\n",
      "        [1.0702],\n",
      "        [1.1139],\n",
      "        [1.1249],\n",
      "        [1.0983],\n",
      "        [1.1210],\n",
      "        [1.0569],\n",
      "        [1.1077],\n",
      "        [1.1014],\n",
      "        [1.0885],\n",
      "        [1.1103],\n",
      "        [1.1221],\n",
      "        [1.0705],\n",
      "        [1.1014],\n",
      "        [1.1009],\n",
      "        [1.1062],\n",
      "        [1.0576],\n",
      "        [1.0635],\n",
      "        [1.1105],\n",
      "        [1.0833],\n",
      "        [1.1217],\n",
      "        [0.3268],\n",
      "        [1.0749],\n",
      "        [1.0805],\n",
      "        [1.1091],\n",
      "        [1.1013],\n",
      "        [1.0868],\n",
      "        [1.1209],\n",
      "        [1.0374],\n",
      "        [1.1130],\n",
      "        [1.0926],\n",
      "        [1.0962],\n",
      "        [1.0800],\n",
      "        [1.0695],\n",
      "        [1.1112],\n",
      "        [1.0988],\n",
      "        [1.1155],\n",
      "        [1.0264],\n",
      "        [1.1078],\n",
      "        [1.1082],\n",
      "        [1.1026],\n",
      "        [1.1025],\n",
      "        [1.1002],\n",
      "        [1.1038],\n",
      "        [1.0752],\n",
      "        [1.0842],\n",
      "        [1.0935],\n",
      "        [1.0790],\n",
      "        [1.0988],\n",
      "        [1.1195],\n",
      "        [1.0676],\n",
      "        [1.1047],\n",
      "        [1.0824],\n",
      "        [1.0901],\n",
      "        [1.1114],\n",
      "        [1.1110],\n",
      "        [1.1114],\n",
      "        [1.0994],\n",
      "        [1.1030],\n",
      "        [1.0770],\n",
      "        [1.0862],\n",
      "        [1.1052],\n",
      "        [1.1028],\n",
      "        [1.0883],\n",
      "        [1.1174],\n",
      "        [1.0848],\n",
      "        [1.1225],\n",
      "        [1.1186],\n",
      "        [1.1259],\n",
      "        [1.1012],\n",
      "        [1.1185],\n",
      "        [1.1029],\n",
      "        [1.1281],\n",
      "        [1.1229],\n",
      "        [1.0929],\n",
      "        [1.1198],\n",
      "        [1.1093],\n",
      "        [1.1031],\n",
      "        [1.1123],\n",
      "        [1.0713],\n",
      "        [1.0920],\n",
      "        [1.1160],\n",
      "        [1.0712],\n",
      "        [1.0999],\n",
      "        [1.0700],\n",
      "        [1.1086],\n",
      "        [1.0913],\n",
      "        [1.1037],\n",
      "        [1.1016],\n",
      "        [1.0784],\n",
      "        [1.1165],\n",
      "        [0.0934],\n",
      "        [1.1157],\n",
      "        [1.1103],\n",
      "        [1.1115],\n",
      "        [1.1066],\n",
      "        [1.1190],\n",
      "        [1.1149],\n",
      "        [1.1168],\n",
      "        [1.0682],\n",
      "        [1.0770],\n",
      "        [1.0647],\n",
      "        [1.0836],\n",
      "        [1.0925],\n",
      "        [1.1181],\n",
      "        [1.1015],\n",
      "        [1.0895],\n",
      "        [1.1189],\n",
      "        [1.0748],\n",
      "        [1.1043],\n",
      "        [1.1031],\n",
      "        [1.1121],\n",
      "        [1.0058],\n",
      "        [1.0718],\n",
      "        [1.1138],\n",
      "        [1.1109],\n",
      "        [1.0702],\n",
      "        [1.0831],\n",
      "        [1.1193],\n",
      "        [1.1242],\n",
      "        [1.1099],\n",
      "        [1.0992],\n",
      "        [1.1217]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1231],\n",
      "        [1.1228],\n",
      "        [1.1062],\n",
      "        [1.1217],\n",
      "        [1.1112],\n",
      "        [1.0738],\n",
      "        [1.1251],\n",
      "        [1.0628],\n",
      "        [1.0848],\n",
      "        [1.1160],\n",
      "        [1.1039],\n",
      "        [1.0888],\n",
      "        [1.0539],\n",
      "        [1.0976],\n",
      "        [1.1054],\n",
      "        [1.1072],\n",
      "        [1.0493],\n",
      "        [1.0845],\n",
      "        [1.1011],\n",
      "        [1.0973],\n",
      "        [1.1118],\n",
      "        [1.0925],\n",
      "        [1.0965],\n",
      "        [1.0367],\n",
      "        [1.1215],\n",
      "        [1.1115],\n",
      "        [1.0755],\n",
      "        [1.0996],\n",
      "        [1.0610],\n",
      "        [1.1074],\n",
      "        [1.1186],\n",
      "        [1.1201],\n",
      "        [1.1250],\n",
      "        [1.0986],\n",
      "        [1.0780],\n",
      "        [1.1139],\n",
      "        [1.0851],\n",
      "        [1.1053],\n",
      "        [1.1093],\n",
      "        [1.0870],\n",
      "        [1.0915],\n",
      "        [1.0699],\n",
      "        [1.1006],\n",
      "        [1.1051],\n",
      "        [1.1253],\n",
      "        [1.0850],\n",
      "        [1.1171],\n",
      "        [1.0508],\n",
      "        [1.0973],\n",
      "        [1.0820],\n",
      "        [1.1081],\n",
      "        [1.1112],\n",
      "        [1.1259],\n",
      "        [1.1216],\n",
      "        [1.1326],\n",
      "        [1.0826],\n",
      "        [1.1060],\n",
      "        [1.0567],\n",
      "        [1.1040],\n",
      "        [1.1067],\n",
      "        [1.0931],\n",
      "        [1.1230],\n",
      "        [1.1091],\n",
      "        [1.1102],\n",
      "        [1.1251],\n",
      "        [1.1015],\n",
      "        [1.1080],\n",
      "        [1.0722],\n",
      "        [1.0967],\n",
      "        [1.0973],\n",
      "        [1.0693],\n",
      "        [1.0723],\n",
      "        [1.1075],\n",
      "        [1.1259],\n",
      "        [1.1127],\n",
      "        [1.0846],\n",
      "        [1.1157],\n",
      "        [1.1218],\n",
      "        [1.0892],\n",
      "        [1.0918],\n",
      "        [1.0896],\n",
      "        [1.0645],\n",
      "        [1.0758],\n",
      "        [1.1042],\n",
      "        [1.1173],\n",
      "        [1.1228],\n",
      "        [1.0953],\n",
      "        [1.1111],\n",
      "        [1.0869],\n",
      "        [1.1217],\n",
      "        [1.1112],\n",
      "        [1.1087],\n",
      "        [1.0825],\n",
      "        [1.0999],\n",
      "        [1.0889],\n",
      "        [1.0884],\n",
      "        [1.1246],\n",
      "        [1.1077],\n",
      "        [1.1076],\n",
      "        [1.0846],\n",
      "        [1.0859],\n",
      "        [1.0752],\n",
      "        [1.1092],\n",
      "        [1.1005],\n",
      "        [1.0934],\n",
      "        [1.0915],\n",
      "        [1.0691],\n",
      "        [1.0855],\n",
      "        [1.1042],\n",
      "        [1.0788],\n",
      "        [1.1079],\n",
      "        [1.0851],\n",
      "        [1.0665],\n",
      "        [1.1033],\n",
      "        [1.0882],\n",
      "        [1.0930],\n",
      "        [1.0817],\n",
      "        [1.1183],\n",
      "        [1.0814],\n",
      "        [1.1115],\n",
      "        [1.1245],\n",
      "        [1.0874],\n",
      "        [1.1211],\n",
      "        [1.0698],\n",
      "        [1.0987],\n",
      "        [1.0793],\n",
      "        [1.1146],\n",
      "        [1.0513]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1006],\n",
      "        [1.0946],\n",
      "        [1.0607],\n",
      "        [1.0861],\n",
      "        [1.1146],\n",
      "        [1.0988],\n",
      "        [1.0663],\n",
      "        [1.1004],\n",
      "        [1.1092],\n",
      "        [1.0901],\n",
      "        [1.0852],\n",
      "        [1.0893],\n",
      "        [1.1167],\n",
      "        [1.0944],\n",
      "        [1.1279],\n",
      "        [1.0662],\n",
      "        [1.1135],\n",
      "        [1.0614],\n",
      "        [1.1108],\n",
      "        [1.0956],\n",
      "        [1.1216],\n",
      "        [1.0731],\n",
      "        [1.1044],\n",
      "        [1.1017],\n",
      "        [1.0922],\n",
      "        [1.1163],\n",
      "        [1.0902],\n",
      "        [1.0614],\n",
      "        [1.1107],\n",
      "        [1.0697],\n",
      "        [1.0822],\n",
      "        [1.0820],\n",
      "        [1.1064],\n",
      "        [1.0745],\n",
      "        [1.0782],\n",
      "        [1.1028],\n",
      "        [1.1180],\n",
      "        [1.1185],\n",
      "        [1.0659],\n",
      "        [1.1153],\n",
      "        [1.0791],\n",
      "        [1.0784],\n",
      "        [1.0552],\n",
      "        [1.1067],\n",
      "        [1.0816],\n",
      "        [1.0554],\n",
      "        [1.1045],\n",
      "        [1.1215],\n",
      "        [1.1234],\n",
      "        [1.0966],\n",
      "        [1.1248],\n",
      "        [1.1192],\n",
      "        [1.1012],\n",
      "        [1.0978],\n",
      "        [1.1129],\n",
      "        [1.1071],\n",
      "        [1.1102],\n",
      "        [1.0981],\n",
      "        [1.0932],\n",
      "        [1.0971],\n",
      "        [1.1064],\n",
      "        [1.1025],\n",
      "        [1.0991],\n",
      "        [1.1016],\n",
      "        [1.0719],\n",
      "        [1.0695],\n",
      "        [1.1008],\n",
      "        [1.0919],\n",
      "        [1.1006],\n",
      "        [1.0463],\n",
      "        [1.0852],\n",
      "        [1.1200],\n",
      "        [1.0807],\n",
      "        [1.0953],\n",
      "        [1.1141],\n",
      "        [1.0847],\n",
      "        [1.0997],\n",
      "        [1.1209],\n",
      "        [1.1054],\n",
      "        [1.1097],\n",
      "        [1.1161],\n",
      "        [1.0870],\n",
      "        [1.0804],\n",
      "        [1.0854],\n",
      "        [1.1069],\n",
      "        [1.0844],\n",
      "        [1.1094],\n",
      "        [1.0985],\n",
      "        [1.1210],\n",
      "        [1.1245],\n",
      "        [1.1039],\n",
      "        [1.1171],\n",
      "        [1.0929],\n",
      "        [1.1226],\n",
      "        [1.0799],\n",
      "        [1.0708],\n",
      "        [1.0875],\n",
      "        [1.0923],\n",
      "        [1.1138],\n",
      "        [1.1162],\n",
      "        [1.1081],\n",
      "        [1.0659],\n",
      "        [1.1109],\n",
      "        [1.0448],\n",
      "        [1.1058],\n",
      "        [1.0999],\n",
      "        [1.1214],\n",
      "        [1.0398],\n",
      "        [1.1116],\n",
      "        [1.1162],\n",
      "        [1.1129],\n",
      "        [1.0891],\n",
      "        [1.0699],\n",
      "        [1.0879],\n",
      "        [1.0930],\n",
      "        [1.0799],\n",
      "        [1.1150],\n",
      "        [1.1058],\n",
      "        [1.0800],\n",
      "        [1.1033],\n",
      "        [1.1255],\n",
      "        [1.0980],\n",
      "        [1.1203],\n",
      "        [1.0783],\n",
      "        [1.1216],\n",
      "        [1.1231],\n",
      "        [1.1047],\n",
      "        [1.1076]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0665],\n",
      "        [1.0904],\n",
      "        [1.0832],\n",
      "        [1.1119],\n",
      "        [1.1057],\n",
      "        [1.1040],\n",
      "        [1.0931],\n",
      "        [1.1248],\n",
      "        [1.0394],\n",
      "        [1.1047],\n",
      "        [1.1036],\n",
      "        [1.1122],\n",
      "        [1.1226],\n",
      "        [1.1221],\n",
      "        [1.0879],\n",
      "        [1.0685],\n",
      "        [1.0743],\n",
      "        [1.1259],\n",
      "        [1.1248],\n",
      "        [1.0952],\n",
      "        [1.1003],\n",
      "        [1.0908],\n",
      "        [1.0733],\n",
      "        [1.1092],\n",
      "        [1.0782],\n",
      "        [1.1018],\n",
      "        [1.0955],\n",
      "        [1.0749],\n",
      "        [1.0533],\n",
      "        [1.1032],\n",
      "        [1.0682],\n",
      "        [1.0845],\n",
      "        [1.1213],\n",
      "        [1.1199],\n",
      "        [1.0529],\n",
      "        [1.0912],\n",
      "        [1.0954],\n",
      "        [1.0835],\n",
      "        [1.1243],\n",
      "        [1.1133],\n",
      "        [1.0824],\n",
      "        [1.1217],\n",
      "        [1.0933],\n",
      "        [1.1228],\n",
      "        [1.0958],\n",
      "        [1.0924],\n",
      "        [1.0662],\n",
      "        [1.1217],\n",
      "        [1.1055],\n",
      "        [1.0900],\n",
      "        [1.0995],\n",
      "        [1.0707],\n",
      "        [1.0874],\n",
      "        [1.0295],\n",
      "        [1.1119],\n",
      "        [1.1109],\n",
      "        [1.0897],\n",
      "        [1.1185],\n",
      "        [1.1204],\n",
      "        [1.0995],\n",
      "        [1.1115],\n",
      "        [1.1109],\n",
      "        [1.1017],\n",
      "        [1.1020],\n",
      "        [1.0803],\n",
      "        [1.0666],\n",
      "        [1.1025],\n",
      "        [1.0825],\n",
      "        [1.0346],\n",
      "        [1.0212],\n",
      "        [1.0805],\n",
      "        [1.1070],\n",
      "        [1.0703],\n",
      "        [1.1038],\n",
      "        [1.0667],\n",
      "        [1.1186],\n",
      "        [1.0739],\n",
      "        [1.0989],\n",
      "        [1.0854],\n",
      "        [1.1160],\n",
      "        [1.0900],\n",
      "        [1.1059],\n",
      "        [1.1057],\n",
      "        [1.1147],\n",
      "        [1.1029],\n",
      "        [1.1111],\n",
      "        [1.0472],\n",
      "        [1.0903],\n",
      "        [1.0931],\n",
      "        [1.1067],\n",
      "        [1.1170],\n",
      "        [1.0932],\n",
      "        [1.1260],\n",
      "        [1.1113],\n",
      "        [1.0963],\n",
      "        [1.1147],\n",
      "        [1.1266],\n",
      "        [1.1050],\n",
      "        [1.1098],\n",
      "        [1.1088],\n",
      "        [1.0974],\n",
      "        [1.0843],\n",
      "        [1.0890],\n",
      "        [1.0834],\n",
      "        [1.0575],\n",
      "        [1.0960],\n",
      "        [1.1241],\n",
      "        [1.0969],\n",
      "        [1.1140],\n",
      "        [1.1065],\n",
      "        [1.0630],\n",
      "        [1.0941],\n",
      "        [1.1156],\n",
      "        [1.0579],\n",
      "        [1.0638],\n",
      "        [1.0844],\n",
      "        [1.0752],\n",
      "        [1.1039],\n",
      "        [1.1258],\n",
      "        [1.0792],\n",
      "        [1.1068],\n",
      "        [1.0376],\n",
      "        [1.1185],\n",
      "        [1.0938],\n",
      "        [1.0928],\n",
      "        [1.1188],\n",
      "        [1.1211],\n",
      "        [1.0957]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0738],\n",
      "        [1.1148],\n",
      "        [1.0988],\n",
      "        [1.0911],\n",
      "        [1.1080],\n",
      "        [1.0804],\n",
      "        [1.0965],\n",
      "        [1.0777],\n",
      "        [1.0957],\n",
      "        [1.1158],\n",
      "        [1.1101],\n",
      "        [1.0992],\n",
      "        [1.0877],\n",
      "        [2.9629],\n",
      "        [1.0781],\n",
      "        [1.1110],\n",
      "        [1.1167],\n",
      "        [1.1173],\n",
      "        [1.1073],\n",
      "        [1.0676],\n",
      "        [1.0579],\n",
      "        [1.1153],\n",
      "        [1.0873],\n",
      "        [1.1251],\n",
      "        [1.1076],\n",
      "        [1.0936],\n",
      "        [1.0483],\n",
      "        [1.1145],\n",
      "        [1.1032],\n",
      "        [1.0718],\n",
      "        [1.1051],\n",
      "        [1.0708],\n",
      "        [1.0874],\n",
      "        [1.0857],\n",
      "        [1.0772],\n",
      "        [1.1063],\n",
      "        [1.1020],\n",
      "        [1.1221],\n",
      "        [1.1257],\n",
      "        [1.1260],\n",
      "        [1.0793],\n",
      "        [1.0774],\n",
      "        [1.0889],\n",
      "        [1.0737],\n",
      "        [1.0959],\n",
      "        [1.1018],\n",
      "        [1.0842],\n",
      "        [1.1080],\n",
      "        [1.0946],\n",
      "        [1.1101],\n",
      "        [1.0954],\n",
      "        [1.1234],\n",
      "        [1.0787],\n",
      "        [1.1092],\n",
      "        [1.1009],\n",
      "        [1.1236],\n",
      "        [1.0824],\n",
      "        [1.0973],\n",
      "        [1.1153],\n",
      "        [1.0914],\n",
      "        [1.1225],\n",
      "        [1.0838],\n",
      "        [1.1131],\n",
      "        [1.1198],\n",
      "        [1.1218],\n",
      "        [1.0924],\n",
      "        [1.1145],\n",
      "        [1.0927],\n",
      "        [1.0397],\n",
      "        [1.1234],\n",
      "        [1.0865],\n",
      "        [0.0143],\n",
      "        [1.1073],\n",
      "        [1.0963],\n",
      "        [1.1058],\n",
      "        [1.1180],\n",
      "        [1.1124],\n",
      "        [1.1022],\n",
      "        [1.0446],\n",
      "        [1.0666],\n",
      "        [1.1187],\n",
      "        [1.0880],\n",
      "        [1.1115],\n",
      "        [1.1075],\n",
      "        [1.0994],\n",
      "        [1.1242],\n",
      "        [1.1005],\n",
      "        [1.0827],\n",
      "        [1.1175],\n",
      "        [1.1030],\n",
      "        [1.1108],\n",
      "        [1.1232],\n",
      "        [1.1085],\n",
      "        [1.0827],\n",
      "        [1.1055],\n",
      "        [1.1178],\n",
      "        [1.1107],\n",
      "        [1.1202],\n",
      "        [1.0851],\n",
      "        [1.1049],\n",
      "        [1.0909],\n",
      "        [1.0397],\n",
      "        [1.0847],\n",
      "        [1.0950],\n",
      "        [1.0389],\n",
      "        [1.1042],\n",
      "        [1.0882],\n",
      "        [1.0937],\n",
      "        [1.1226],\n",
      "        [1.1258],\n",
      "        [1.0809],\n",
      "        [1.1089],\n",
      "        [1.1243],\n",
      "        [1.1140],\n",
      "        [1.1000],\n",
      "        [1.0600],\n",
      "        [1.1168],\n",
      "        [1.1126],\n",
      "        [1.0842],\n",
      "        [1.1049],\n",
      "        [1.1197],\n",
      "        [1.0757],\n",
      "        [1.0980],\n",
      "        [1.1138],\n",
      "        [1.0899],\n",
      "        [1.1009],\n",
      "        [1.1278],\n",
      "        [1.0224]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0912],\n",
      "        [1.0842],\n",
      "        [1.1026],\n",
      "        [1.0668],\n",
      "        [1.0770],\n",
      "        [1.0984],\n",
      "        [1.0758],\n",
      "        [1.0917],\n",
      "        [1.1000],\n",
      "        [1.0864],\n",
      "        [1.0913],\n",
      "        [1.1083],\n",
      "        [1.0891],\n",
      "        [1.0748],\n",
      "        [1.0968],\n",
      "        [1.1142],\n",
      "        [1.0197],\n",
      "        [1.0986],\n",
      "        [1.0959],\n",
      "        [1.1226],\n",
      "        [1.0820],\n",
      "        [1.0577],\n",
      "        [1.1097],\n",
      "        [1.0752],\n",
      "        [1.0961],\n",
      "        [1.0969],\n",
      "        [1.0532],\n",
      "        [1.1040],\n",
      "        [1.1043],\n",
      "        [1.0722],\n",
      "        [1.1003],\n",
      "        [1.0556],\n",
      "        [1.0855],\n",
      "        [1.1248],\n",
      "        [1.1047],\n",
      "        [1.0877],\n",
      "        [1.1042],\n",
      "        [1.1078],\n",
      "        [1.1101],\n",
      "        [1.0975],\n",
      "        [1.0729],\n",
      "        [1.1114],\n",
      "        [1.0884],\n",
      "        [1.0946],\n",
      "        [1.0804],\n",
      "        [1.1019],\n",
      "        [1.1197],\n",
      "        [1.1092],\n",
      "        [1.1194],\n",
      "        [1.1128],\n",
      "        [1.1148],\n",
      "        [1.1007],\n",
      "        [1.0581],\n",
      "        [1.0944],\n",
      "        [1.0766],\n",
      "        [1.1070],\n",
      "        [1.0869],\n",
      "        [1.0705],\n",
      "        [1.0693],\n",
      "        [1.0717],\n",
      "        [1.0777],\n",
      "        [1.1032],\n",
      "        [1.1197],\n",
      "        [1.0962],\n",
      "        [1.0564],\n",
      "        [1.0860],\n",
      "        [1.0859],\n",
      "        [1.0857],\n",
      "        [1.0975],\n",
      "        [1.1078],\n",
      "        [1.1121],\n",
      "        [1.0918],\n",
      "        [1.1100],\n",
      "        [1.0888],\n",
      "        [1.1052],\n",
      "        [1.1217],\n",
      "        [1.1035],\n",
      "        [1.1088],\n",
      "        [1.1141],\n",
      "        [1.1223],\n",
      "        [1.0657],\n",
      "        [1.0843],\n",
      "        [1.0949],\n",
      "        [1.1223],\n",
      "        [1.1109],\n",
      "        [1.0914],\n",
      "        [1.0866],\n",
      "        [1.1099],\n",
      "        [1.0840],\n",
      "        [1.1053],\n",
      "        [1.0636],\n",
      "        [1.0634],\n",
      "        [1.0610],\n",
      "        [1.1143],\n",
      "        [1.1025],\n",
      "        [1.1108],\n",
      "        [1.0799],\n",
      "        [1.1065],\n",
      "        [1.1031],\n",
      "        [1.0882],\n",
      "        [1.0759],\n",
      "        [1.1006],\n",
      "        [1.0941],\n",
      "        [1.1025],\n",
      "        [1.1013],\n",
      "        [1.0990],\n",
      "        [1.0909],\n",
      "        [1.0825],\n",
      "        [1.1212],\n",
      "        [1.1114],\n",
      "        [1.0846],\n",
      "        [1.0793],\n",
      "        [1.0978],\n",
      "        [1.0947],\n",
      "        [1.1020],\n",
      "        [1.0939],\n",
      "        [1.0563],\n",
      "        [1.0962],\n",
      "        [1.0993],\n",
      "        [1.0651],\n",
      "        [1.0903],\n",
      "        [1.0969],\n",
      "        [1.0686],\n",
      "        [1.1106],\n",
      "        [1.1098],\n",
      "        [1.0920],\n",
      "        [1.1017],\n",
      "        [1.1244]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1199],\n",
      "        [1.0723],\n",
      "        [1.0765],\n",
      "        [1.1156],\n",
      "        [1.0709],\n",
      "        [1.0890],\n",
      "        [1.0851],\n",
      "        [0.3758],\n",
      "        [1.0576],\n",
      "        [1.0635],\n",
      "        [1.1055],\n",
      "        [1.1026],\n",
      "        [1.0253],\n",
      "        [1.0899],\n",
      "        [1.0961],\n",
      "        [1.0911],\n",
      "        [1.1047],\n",
      "        [1.1122],\n",
      "        [1.0845],\n",
      "        [1.0964],\n",
      "        [1.1113],\n",
      "        [1.0710],\n",
      "        [1.1195],\n",
      "        [1.1181],\n",
      "        [1.1039],\n",
      "        [1.1023],\n",
      "        [1.1058],\n",
      "        [1.0565],\n",
      "        [1.0955],\n",
      "        [1.1060],\n",
      "        [1.0885],\n",
      "        [1.0995],\n",
      "        [1.0870],\n",
      "        [1.1058],\n",
      "        [1.0806],\n",
      "        [1.0915],\n",
      "        [1.0795],\n",
      "        [1.1060],\n",
      "        [1.0725],\n",
      "        [1.1115],\n",
      "        [1.0537],\n",
      "        [1.1017],\n",
      "        [1.0668],\n",
      "        [1.0946],\n",
      "        [1.0520],\n",
      "        [1.1006],\n",
      "        [1.1112],\n",
      "        [1.1143],\n",
      "        [1.0631],\n",
      "        [1.1011],\n",
      "        [1.0888],\n",
      "        [1.1222],\n",
      "        [1.0873],\n",
      "        [1.0545],\n",
      "        [1.0726],\n",
      "        [1.0626],\n",
      "        [1.0836],\n",
      "        [1.1085],\n",
      "        [1.1191],\n",
      "        [1.1039],\n",
      "        [1.0990],\n",
      "        [1.1176],\n",
      "        [1.0789],\n",
      "        [1.0829],\n",
      "        [1.1189],\n",
      "        [1.0843],\n",
      "        [1.1023],\n",
      "        [1.1200],\n",
      "        [1.0486],\n",
      "        [1.0797],\n",
      "        [1.1067],\n",
      "        [1.1089],\n",
      "        [1.1050],\n",
      "        [1.1228],\n",
      "        [1.0958],\n",
      "        [1.1010],\n",
      "        [1.1022],\n",
      "        [1.0894],\n",
      "        [1.0769],\n",
      "        [1.0919],\n",
      "        [1.1126],\n",
      "        [1.1142],\n",
      "        [1.0585],\n",
      "        [1.0571],\n",
      "        [1.0464],\n",
      "        [1.0910],\n",
      "        [1.0722],\n",
      "        [1.1194],\n",
      "        [1.0606],\n",
      "        [1.0984],\n",
      "        [1.0961],\n",
      "        [1.1128],\n",
      "        [1.1152],\n",
      "        [1.0937],\n",
      "        [1.1077],\n",
      "        [1.1070],\n",
      "        [1.0740],\n",
      "        [1.1062],\n",
      "        [1.0944],\n",
      "        [1.0831],\n",
      "        [1.1126],\n",
      "        [1.0788],\n",
      "        [1.1020],\n",
      "        [1.1182],\n",
      "        [1.0787],\n",
      "        [1.1078],\n",
      "        [1.0871],\n",
      "        [1.0871],\n",
      "        [1.0769],\n",
      "        [1.1276],\n",
      "        [1.0807],\n",
      "        [1.0852],\n",
      "        [1.0756],\n",
      "        [1.0761],\n",
      "        [1.0881],\n",
      "        [1.1025],\n",
      "        [1.0652],\n",
      "        [1.0710],\n",
      "        [1.0717],\n",
      "        [1.0937],\n",
      "        [1.1224],\n",
      "        [1.1055],\n",
      "        [1.0884],\n",
      "        [1.1111],\n",
      "        [1.1255],\n",
      "        [1.1136],\n",
      "        [1.0677],\n",
      "        [1.0678]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0685],\n",
      "        [1.0740],\n",
      "        [1.0849],\n",
      "        [1.1096]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  14 | lr 0.00100 train_loss 2.13422 | val_loss 2.29133 | val_rmse 1.51371\n",
      "tensor([[1.0877],\n",
      "        [1.1181],\n",
      "        [1.1226],\n",
      "        [1.1026],\n",
      "        [1.1049],\n",
      "        [1.1011],\n",
      "        [1.1158],\n",
      "        [1.1116],\n",
      "        [1.0770],\n",
      "        [1.0717],\n",
      "        [1.1073],\n",
      "        [1.0522],\n",
      "        [1.0894],\n",
      "        [1.0809],\n",
      "        [1.0949],\n",
      "        [1.1147],\n",
      "        [1.0497],\n",
      "        [1.0903],\n",
      "        [1.1129],\n",
      "        [1.0906],\n",
      "        [1.0940],\n",
      "        [1.0866],\n",
      "        [1.0965],\n",
      "        [1.0799],\n",
      "        [1.0552],\n",
      "        [1.1057],\n",
      "        [1.0977],\n",
      "        [1.0960],\n",
      "        [1.1001],\n",
      "        [1.1013],\n",
      "        [1.0874],\n",
      "        [1.1017],\n",
      "        [1.0932],\n",
      "        [1.1023],\n",
      "        [1.1233],\n",
      "        [1.1130],\n",
      "        [1.1055],\n",
      "        [1.1166],\n",
      "        [1.0850],\n",
      "        [1.1198],\n",
      "        [1.1036],\n",
      "        [1.1009],\n",
      "        [1.0744],\n",
      "        [1.1125],\n",
      "        [1.0942],\n",
      "        [1.0469],\n",
      "        [1.1155],\n",
      "        [1.1001],\n",
      "        [1.1104],\n",
      "        [1.1209],\n",
      "        [1.0815],\n",
      "        [1.0820],\n",
      "        [1.0791],\n",
      "        [1.0819],\n",
      "        [1.1137],\n",
      "        [1.1010],\n",
      "        [1.0887],\n",
      "        [1.1148],\n",
      "        [1.0872],\n",
      "        [1.0895],\n",
      "        [1.1103],\n",
      "        [1.0807],\n",
      "        [1.0903],\n",
      "        [1.0505],\n",
      "        [1.1228],\n",
      "        [1.1097],\n",
      "        [1.0980],\n",
      "        [1.1042],\n",
      "        [1.0789],\n",
      "        [1.1116],\n",
      "        [1.0664],\n",
      "        [1.0556],\n",
      "        [1.0953],\n",
      "        [1.1096],\n",
      "        [1.1072],\n",
      "        [1.0923],\n",
      "        [1.1147],\n",
      "        [1.0989],\n",
      "        [1.0669],\n",
      "        [1.0996],\n",
      "        [1.0823],\n",
      "        [1.0746],\n",
      "        [1.0567],\n",
      "        [1.0936],\n",
      "        [1.1060],\n",
      "        [1.0909],\n",
      "        [1.0794],\n",
      "        [1.1205],\n",
      "        [1.1057],\n",
      "        [1.1164],\n",
      "        [1.1244],\n",
      "        [1.0977],\n",
      "        [1.1174],\n",
      "        [1.0841],\n",
      "        [1.0603],\n",
      "        [1.0650],\n",
      "        [1.1186],\n",
      "        [1.0621],\n",
      "        [1.0903],\n",
      "        [1.0921],\n",
      "        [1.1075],\n",
      "        [1.1197],\n",
      "        [1.0993],\n",
      "        [1.0746],\n",
      "        [1.0844],\n",
      "        [1.1223],\n",
      "        [1.1111],\n",
      "        [1.0901],\n",
      "        [1.1178],\n",
      "        [1.0826],\n",
      "        [1.1093],\n",
      "        [1.0697],\n",
      "        [1.0872],\n",
      "        [1.0944],\n",
      "        [1.0982],\n",
      "        [1.0974],\n",
      "        [1.1190],\n",
      "        [1.0532],\n",
      "        [1.1117],\n",
      "        [1.1124],\n",
      "        [1.1225],\n",
      "        [1.0892],\n",
      "        [1.1125],\n",
      "        [1.1056],\n",
      "        [1.0821],\n",
      "        [1.1152],\n",
      "        [1.1259],\n",
      "        [1.0913]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0573],\n",
      "        [1.1099],\n",
      "        [1.1051],\n",
      "        [1.1018],\n",
      "        [1.1005],\n",
      "        [1.0869],\n",
      "        [1.0663],\n",
      "        [1.1008],\n",
      "        [1.1207],\n",
      "        [1.1187],\n",
      "        [1.0545],\n",
      "        [1.0963],\n",
      "        [1.0360],\n",
      "        [1.0928],\n",
      "        [1.0625],\n",
      "        [1.1195],\n",
      "        [1.1165],\n",
      "        [1.0828],\n",
      "        [1.0948],\n",
      "        [1.1143],\n",
      "        [1.0395],\n",
      "        [1.1134],\n",
      "        [1.0756],\n",
      "        [1.0962],\n",
      "        [1.1202],\n",
      "        [1.1121],\n",
      "        [1.1017],\n",
      "        [1.0660],\n",
      "        [1.1173],\n",
      "        [1.0803],\n",
      "        [1.0805],\n",
      "        [1.0672],\n",
      "        [1.0903],\n",
      "        [1.1005],\n",
      "        [1.0737],\n",
      "        [1.0991],\n",
      "        [1.0633],\n",
      "        [1.0939],\n",
      "        [1.1040],\n",
      "        [1.0628],\n",
      "        [1.0970],\n",
      "        [1.1010],\n",
      "        [1.1200],\n",
      "        [1.0852],\n",
      "        [1.1086],\n",
      "        [1.1015],\n",
      "        [1.0792],\n",
      "        [1.0759],\n",
      "        [1.0832],\n",
      "        [1.1169],\n",
      "        [1.0686],\n",
      "        [1.0772],\n",
      "        [1.0537],\n",
      "        [1.0557],\n",
      "        [1.0761],\n",
      "        [1.0838],\n",
      "        [1.0984],\n",
      "        [1.1128],\n",
      "        [1.0967],\n",
      "        [1.1028],\n",
      "        [1.1004],\n",
      "        [1.1064],\n",
      "        [1.0247],\n",
      "        [1.1140],\n",
      "        [1.0661],\n",
      "        [1.0417],\n",
      "        [1.0478],\n",
      "        [1.0704],\n",
      "        [1.1097],\n",
      "        [1.0750],\n",
      "        [1.0887],\n",
      "        [1.0927],\n",
      "        [1.1057],\n",
      "        [1.0896],\n",
      "        [1.0664],\n",
      "        [1.0422],\n",
      "        [1.1018],\n",
      "        [1.0928],\n",
      "        [1.1025],\n",
      "        [1.0737],\n",
      "        [1.1003],\n",
      "        [1.0915],\n",
      "        [1.1089],\n",
      "        [1.0593],\n",
      "        [1.0478],\n",
      "        [1.0660],\n",
      "        [1.0568],\n",
      "        [1.0592],\n",
      "        [1.0782],\n",
      "        [1.0973],\n",
      "        [1.1000],\n",
      "        [1.1116],\n",
      "        [1.1114],\n",
      "        [1.0625],\n",
      "        [1.1138],\n",
      "        [1.1010],\n",
      "        [1.0704],\n",
      "        [1.1071],\n",
      "        [1.0593],\n",
      "        [1.0739],\n",
      "        [1.0877],\n",
      "        [1.0237],\n",
      "        [1.1174],\n",
      "        [1.1067],\n",
      "        [1.0894],\n",
      "        [1.1167],\n",
      "        [1.0841],\n",
      "        [1.0266],\n",
      "        [1.1192],\n",
      "        [1.1088],\n",
      "        [1.0933],\n",
      "        [1.0832],\n",
      "        [1.0878],\n",
      "        [1.1086],\n",
      "        [1.0998],\n",
      "        [1.0761],\n",
      "        [1.0924],\n",
      "        [1.0957],\n",
      "        [1.0868],\n",
      "        [1.1185],\n",
      "        [1.0765],\n",
      "        [2.3245],\n",
      "        [1.1138],\n",
      "        [1.0875],\n",
      "        [1.1131],\n",
      "        [1.1018],\n",
      "        [1.0953],\n",
      "        [1.0802]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0826],\n",
      "        [1.0948],\n",
      "        [1.0670],\n",
      "        [1.0679],\n",
      "        [1.0748],\n",
      "        [1.1109],\n",
      "        [1.1163],\n",
      "        [1.0598],\n",
      "        [1.1089],\n",
      "        [1.0925],\n",
      "        [1.0786],\n",
      "        [1.0845],\n",
      "        [1.1130],\n",
      "        [1.0985],\n",
      "        [1.0960],\n",
      "        [1.0938],\n",
      "        [1.0730],\n",
      "        [1.1221],\n",
      "        [1.0484],\n",
      "        [1.1177],\n",
      "        [1.1019],\n",
      "        [1.1207],\n",
      "        [1.1191],\n",
      "        [1.1084],\n",
      "        [1.1071],\n",
      "        [1.0976],\n",
      "        [1.0336],\n",
      "        [1.1058],\n",
      "        [1.0773],\n",
      "        [1.1167],\n",
      "        [1.1142],\n",
      "        [1.0948],\n",
      "        [1.0820],\n",
      "        [1.1154],\n",
      "        [1.1033],\n",
      "        [1.0887],\n",
      "        [1.1052],\n",
      "        [1.1176],\n",
      "        [1.1044],\n",
      "        [1.1167],\n",
      "        [1.0950],\n",
      "        [1.0720],\n",
      "        [1.1134],\n",
      "        [1.0504],\n",
      "        [1.1191],\n",
      "        [1.1025],\n",
      "        [1.0659],\n",
      "        [1.1008],\n",
      "        [1.0760],\n",
      "        [1.1153],\n",
      "        [1.1063],\n",
      "        [1.0807],\n",
      "        [1.1193],\n",
      "        [1.0819],\n",
      "        [1.1190],\n",
      "        [1.1029],\n",
      "        [1.1166],\n",
      "        [1.0677],\n",
      "        [1.0974],\n",
      "        [1.1004],\n",
      "        [1.0186],\n",
      "        [1.1200],\n",
      "        [1.0837],\n",
      "        [1.0955],\n",
      "        [1.0495],\n",
      "        [1.1051],\n",
      "        [1.0955],\n",
      "        [1.1021],\n",
      "        [1.0828],\n",
      "        [1.0787],\n",
      "        [1.1002],\n",
      "        [1.0805],\n",
      "        [1.0879],\n",
      "        [1.1069],\n",
      "        [1.0991],\n",
      "        [1.1149],\n",
      "        [1.1146],\n",
      "        [1.0977],\n",
      "        [1.1203],\n",
      "        [1.1146],\n",
      "        [1.0949],\n",
      "        [1.0787],\n",
      "        [1.0655],\n",
      "        [1.0987],\n",
      "        [1.0923],\n",
      "        [1.1002],\n",
      "        [1.0700],\n",
      "        [1.1128],\n",
      "        [1.0977],\n",
      "        [1.1128],\n",
      "        [1.0885],\n",
      "        [1.0965],\n",
      "        [1.0931],\n",
      "        [1.1030],\n",
      "        [1.1086],\n",
      "        [1.0725],\n",
      "        [1.1107],\n",
      "        [1.0562],\n",
      "        [1.1041],\n",
      "        [1.0976],\n",
      "        [1.0996],\n",
      "        [1.1185],\n",
      "        [1.0901],\n",
      "        [1.0759],\n",
      "        [1.0766],\n",
      "        [1.0908],\n",
      "        [1.1178],\n",
      "        [1.1021],\n",
      "        [1.0970],\n",
      "        [1.0742],\n",
      "        [1.1023],\n",
      "        [1.1110],\n",
      "        [1.1075],\n",
      "        [1.1068],\n",
      "        [1.0816],\n",
      "        [1.1086],\n",
      "        [1.1213],\n",
      "        [1.0817],\n",
      "        [1.1076],\n",
      "        [1.0865],\n",
      "        [1.1075],\n",
      "        [1.1208],\n",
      "        [1.0989],\n",
      "        [1.1045],\n",
      "        [1.0802],\n",
      "        [1.0829],\n",
      "        [1.0852],\n",
      "        [1.0840]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0432],\n",
      "        [1.1032],\n",
      "        [1.0764],\n",
      "        [1.1193],\n",
      "        [1.1031],\n",
      "        [1.1183],\n",
      "        [1.0543],\n",
      "        [1.0664],\n",
      "        [1.0826],\n",
      "        [1.0603],\n",
      "        [1.1105],\n",
      "        [1.1116],\n",
      "        [1.0657],\n",
      "        [1.0782],\n",
      "        [1.0744],\n",
      "        [1.1077],\n",
      "        [1.0959],\n",
      "        [1.0723],\n",
      "        [1.0978],\n",
      "        [1.0635],\n",
      "        [1.1221],\n",
      "        [1.0886],\n",
      "        [1.0921],\n",
      "        [1.1123],\n",
      "        [1.0751],\n",
      "        [1.0608],\n",
      "        [1.0977],\n",
      "        [1.0902],\n",
      "        [1.1062],\n",
      "        [1.0466],\n",
      "        [1.0862],\n",
      "        [1.1180],\n",
      "        [1.1000],\n",
      "        [1.0863],\n",
      "        [1.1223],\n",
      "        [1.0898],\n",
      "        [1.1111],\n",
      "        [1.1218],\n",
      "        [1.1193],\n",
      "        [1.1162],\n",
      "        [1.1114],\n",
      "        [1.1133],\n",
      "        [1.1116],\n",
      "        [1.0822],\n",
      "        [1.1221],\n",
      "        [1.0646],\n",
      "        [1.1115],\n",
      "        [1.0678],\n",
      "        [1.0906],\n",
      "        [1.0357],\n",
      "        [1.1103],\n",
      "        [1.0984],\n",
      "        [1.0832],\n",
      "        [1.0725],\n",
      "        [1.0781],\n",
      "        [1.0886],\n",
      "        [1.1032],\n",
      "        [1.0964],\n",
      "        [1.0614],\n",
      "        [1.0620],\n",
      "        [1.0968],\n",
      "        [1.1178],\n",
      "        [1.1044],\n",
      "        [1.0605],\n",
      "        [1.0957],\n",
      "        [1.1034],\n",
      "        [1.1213],\n",
      "        [1.0870],\n",
      "        [1.0929],\n",
      "        [1.1077],\n",
      "        [1.1044],\n",
      "        [1.0807],\n",
      "        [1.1064],\n",
      "        [1.0937],\n",
      "        [0.1588],\n",
      "        [1.0854],\n",
      "        [1.0854],\n",
      "        [1.0816],\n",
      "        [1.1094],\n",
      "        [1.1174],\n",
      "        [1.0902],\n",
      "        [1.0830],\n",
      "        [1.0824],\n",
      "        [1.0993],\n",
      "        [1.0305],\n",
      "        [1.0567],\n",
      "        [1.0689],\n",
      "        [1.0674],\n",
      "        [1.1198],\n",
      "        [1.1042],\n",
      "        [1.0954],\n",
      "        [1.1009],\n",
      "        [1.0434],\n",
      "        [1.1092],\n",
      "        [1.0879],\n",
      "        [1.1030],\n",
      "        [1.0785],\n",
      "        [1.1156],\n",
      "        [1.0724],\n",
      "        [1.0248],\n",
      "        [1.0901],\n",
      "        [1.1063],\n",
      "        [1.1183],\n",
      "        [1.0941],\n",
      "        [1.0846],\n",
      "        [1.0846],\n",
      "        [1.1157],\n",
      "        [1.0991],\n",
      "        [1.1201],\n",
      "        [1.0701],\n",
      "        [1.0655],\n",
      "        [1.1137],\n",
      "        [1.1153],\n",
      "        [1.0786],\n",
      "        [1.0945],\n",
      "        [1.1225],\n",
      "        [1.0526],\n",
      "        [1.0873],\n",
      "        [1.0159],\n",
      "        [1.0552],\n",
      "        [1.1088],\n",
      "        [1.0878],\n",
      "        [1.0900],\n",
      "        [1.1112],\n",
      "        [1.0847],\n",
      "        [1.0883],\n",
      "        [1.0739],\n",
      "        [1.1199]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1025],\n",
      "        [1.0705],\n",
      "        [1.1017],\n",
      "        [1.0728],\n",
      "        [1.0710],\n",
      "        [1.0753],\n",
      "        [1.0881],\n",
      "        [1.1009],\n",
      "        [1.0668],\n",
      "        [1.1064],\n",
      "        [1.1017],\n",
      "        [1.0954],\n",
      "        [1.1173],\n",
      "        [1.1180],\n",
      "        [1.0544],\n",
      "        [1.1079],\n",
      "        [1.1206],\n",
      "        [1.1134],\n",
      "        [1.0656],\n",
      "        [1.0948],\n",
      "        [1.0843],\n",
      "        [1.0965],\n",
      "        [1.1220],\n",
      "        [1.0730],\n",
      "        [1.1232],\n",
      "        [1.1080],\n",
      "        [1.1147],\n",
      "        [1.0913],\n",
      "        [1.1158],\n",
      "        [1.1194],\n",
      "        [1.0802],\n",
      "        [1.1154],\n",
      "        [1.0618],\n",
      "        [1.0866],\n",
      "        [1.0835],\n",
      "        [1.0827],\n",
      "        [1.0982],\n",
      "        [1.0889],\n",
      "        [1.0982],\n",
      "        [1.0963],\n",
      "        [1.1001],\n",
      "        [1.0887],\n",
      "        [1.1208],\n",
      "        [1.0480],\n",
      "        [1.1023],\n",
      "        [1.0940],\n",
      "        [1.0903],\n",
      "        [1.0882],\n",
      "        [1.1004],\n",
      "        [1.1009],\n",
      "        [1.0862],\n",
      "        [1.1039],\n",
      "        [1.0698],\n",
      "        [1.1102],\n",
      "        [1.1023],\n",
      "        [1.0517],\n",
      "        [1.0676],\n",
      "        [1.1077],\n",
      "        [1.0911],\n",
      "        [1.0898],\n",
      "        [1.1161],\n",
      "        [1.0887],\n",
      "        [1.0877],\n",
      "        [1.0906],\n",
      "        [1.0969],\n",
      "        [1.1042],\n",
      "        [1.1115],\n",
      "        [1.1054],\n",
      "        [1.1007],\n",
      "        [1.0567],\n",
      "        [1.1224],\n",
      "        [1.1166],\n",
      "        [1.0852],\n",
      "        [1.0983],\n",
      "        [1.0801],\n",
      "        [1.0879],\n",
      "        [1.0726],\n",
      "        [1.1023],\n",
      "        [1.1008],\n",
      "        [1.1148],\n",
      "        [1.0235],\n",
      "        [1.0982],\n",
      "        [1.0937],\n",
      "        [1.1223],\n",
      "        [1.0828],\n",
      "        [1.1093],\n",
      "        [1.0874],\n",
      "        [1.1001],\n",
      "        [1.0968],\n",
      "        [1.0840],\n",
      "        [1.1081],\n",
      "        [1.0988],\n",
      "        [1.1148],\n",
      "        [1.0900],\n",
      "        [1.0824],\n",
      "        [1.1185],\n",
      "        [1.0772],\n",
      "        [1.0860],\n",
      "        [1.1016],\n",
      "        [1.1127],\n",
      "        [1.1148],\n",
      "        [1.1004],\n",
      "        [1.0695],\n",
      "        [1.0828],\n",
      "        [1.0874],\n",
      "        [1.0941],\n",
      "        [1.0902],\n",
      "        [1.1105],\n",
      "        [1.1043],\n",
      "        [1.0817],\n",
      "        [1.0692],\n",
      "        [1.0711],\n",
      "        [1.1024],\n",
      "        [1.1081],\n",
      "        [1.0976],\n",
      "        [1.0912],\n",
      "        [1.1089],\n",
      "        [1.0874],\n",
      "        [1.0427],\n",
      "        [1.0320],\n",
      "        [1.0675],\n",
      "        [1.0552],\n",
      "        [1.0386],\n",
      "        [1.1072],\n",
      "        [1.1109],\n",
      "        [1.0754],\n",
      "        [1.0947],\n",
      "        [1.0358]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0989],\n",
      "        [1.0993],\n",
      "        [1.0992],\n",
      "        [1.0929],\n",
      "        [1.0843],\n",
      "        [1.0693],\n",
      "        [1.0893],\n",
      "        [1.1153],\n",
      "        [1.0856],\n",
      "        [1.1092],\n",
      "        [1.1228],\n",
      "        [1.0802],\n",
      "        [1.1225],\n",
      "        [1.0616],\n",
      "        [1.0942],\n",
      "        [1.1177],\n",
      "        [1.1087],\n",
      "        [0.1112],\n",
      "        [1.0946],\n",
      "        [1.0861],\n",
      "        [1.1037],\n",
      "        [1.1047],\n",
      "        [1.0866],\n",
      "        [1.1158],\n",
      "        [1.0966],\n",
      "        [1.0662],\n",
      "        [1.0888],\n",
      "        [1.0872],\n",
      "        [1.1004],\n",
      "        [1.0884],\n",
      "        [1.1218],\n",
      "        [1.1268],\n",
      "        [1.0501],\n",
      "        [1.1120],\n",
      "        [1.0978],\n",
      "        [1.0624],\n",
      "        [1.0522],\n",
      "        [1.1139],\n",
      "        [1.0416],\n",
      "        [1.1132],\n",
      "        [1.0674],\n",
      "        [1.0857],\n",
      "        [1.1011],\n",
      "        [1.1095],\n",
      "        [1.1139],\n",
      "        [1.0934],\n",
      "        [1.1239],\n",
      "        [1.0695],\n",
      "        [1.1168],\n",
      "        [1.1226],\n",
      "        [1.1228],\n",
      "        [1.1223],\n",
      "        [1.0756],\n",
      "        [1.1099],\n",
      "        [1.0764],\n",
      "        [1.1047],\n",
      "        [1.1142],\n",
      "        [1.1144],\n",
      "        [1.0967],\n",
      "        [1.1079],\n",
      "        [1.0855],\n",
      "        [1.1124],\n",
      "        [1.1018],\n",
      "        [1.0790],\n",
      "        [1.0678],\n",
      "        [1.0865],\n",
      "        [1.1214],\n",
      "        [1.1138],\n",
      "        [1.0815],\n",
      "        [1.0863],\n",
      "        [1.1210],\n",
      "        [1.1162],\n",
      "        [1.0911],\n",
      "        [1.0969],\n",
      "        [1.1183],\n",
      "        [1.0938],\n",
      "        [1.1073],\n",
      "        [1.1003],\n",
      "        [1.0788],\n",
      "        [1.0871],\n",
      "        [1.1091],\n",
      "        [1.0872],\n",
      "        [1.0957],\n",
      "        [1.1068],\n",
      "        [1.0975],\n",
      "        [1.1184],\n",
      "        [1.1014],\n",
      "        [1.1092],\n",
      "        [1.1129],\n",
      "        [1.1170],\n",
      "        [1.0793],\n",
      "        [1.0972],\n",
      "        [1.0981],\n",
      "        [1.1227],\n",
      "        [1.0900],\n",
      "        [1.1157],\n",
      "        [1.1007],\n",
      "        [1.0701],\n",
      "        [1.1205],\n",
      "        [1.1185],\n",
      "        [1.0673],\n",
      "        [1.1023],\n",
      "        [1.0988],\n",
      "        [1.1078],\n",
      "        [1.1154],\n",
      "        [1.1155],\n",
      "        [1.1041],\n",
      "        [1.1119],\n",
      "        [1.0972],\n",
      "        [1.1048],\n",
      "        [1.0733],\n",
      "        [1.0902],\n",
      "        [1.1060],\n",
      "        [1.1178],\n",
      "        [1.0830],\n",
      "        [1.1121],\n",
      "        [1.1084],\n",
      "        [1.0851],\n",
      "        [1.1065],\n",
      "        [1.0938],\n",
      "        [1.0961],\n",
      "        [1.0867],\n",
      "        [1.0778],\n",
      "        [1.0919],\n",
      "        [1.0849],\n",
      "        [1.0476],\n",
      "        [1.1176],\n",
      "        [1.0846]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0882],\n",
      "        [1.1156],\n",
      "        [1.1055],\n",
      "        [1.1218],\n",
      "        [1.0855],\n",
      "        [1.0877],\n",
      "        [1.0722],\n",
      "        [0.5436],\n",
      "        [1.0608],\n",
      "        [1.1211],\n",
      "        [1.0909],\n",
      "        [1.1024],\n",
      "        [1.1159],\n",
      "        [1.0656],\n",
      "        [1.0541],\n",
      "        [1.0630],\n",
      "        [1.1024],\n",
      "        [0.2845],\n",
      "        [1.0898],\n",
      "        [1.0870],\n",
      "        [1.0928],\n",
      "        [1.0853],\n",
      "        [1.0901],\n",
      "        [1.0728],\n",
      "        [1.0935],\n",
      "        [1.0779],\n",
      "        [1.1143],\n",
      "        [1.1190],\n",
      "        [1.0995],\n",
      "        [1.0921],\n",
      "        [1.1195],\n",
      "        [1.0930],\n",
      "        [1.0960],\n",
      "        [1.0948],\n",
      "        [1.1170],\n",
      "        [1.1122],\n",
      "        [1.1016],\n",
      "        [1.0674],\n",
      "        [1.0729],\n",
      "        [1.0985],\n",
      "        [1.0678],\n",
      "        [1.0922],\n",
      "        [1.0727],\n",
      "        [1.1161],\n",
      "        [1.0780],\n",
      "        [1.1030],\n",
      "        [1.1134],\n",
      "        [1.0558],\n",
      "        [1.1028],\n",
      "        [1.1057],\n",
      "        [1.1192],\n",
      "        [1.1180],\n",
      "        [1.1130],\n",
      "        [1.1193],\n",
      "        [1.1009],\n",
      "        [1.0492],\n",
      "        [1.0962],\n",
      "        [1.0723],\n",
      "        [1.0822],\n",
      "        [1.1038],\n",
      "        [1.1216],\n",
      "        [1.0853],\n",
      "        [1.1004],\n",
      "        [1.1053],\n",
      "        [1.1218],\n",
      "        [1.0783],\n",
      "        [1.1001],\n",
      "        [1.0702],\n",
      "        [1.0804],\n",
      "        [1.0641],\n",
      "        [0.2658],\n",
      "        [1.1195],\n",
      "        [1.0694],\n",
      "        [1.0708],\n",
      "        [1.0728],\n",
      "        [1.0924],\n",
      "        [1.0593],\n",
      "        [1.1135],\n",
      "        [1.1186],\n",
      "        [1.1020],\n",
      "        [1.0946],\n",
      "        [1.0969],\n",
      "        [1.0922],\n",
      "        [1.0811],\n",
      "        [1.1092],\n",
      "        [1.0859],\n",
      "        [1.0765],\n",
      "        [1.1077],\n",
      "        [1.0694],\n",
      "        [1.1110],\n",
      "        [1.0952],\n",
      "        [1.1003],\n",
      "        [1.1021],\n",
      "        [1.0926],\n",
      "        [1.0953],\n",
      "        [1.0841],\n",
      "        [1.0611],\n",
      "        [1.0889],\n",
      "        [1.1043],\n",
      "        [1.1135],\n",
      "        [1.0801],\n",
      "        [1.0772],\n",
      "        [1.1058],\n",
      "        [1.0906],\n",
      "        [1.1126],\n",
      "        [1.0614],\n",
      "        [1.0883],\n",
      "        [1.0479],\n",
      "        [1.0704],\n",
      "        [1.1236],\n",
      "        [1.0438],\n",
      "        [1.0989],\n",
      "        [1.0918],\n",
      "        [1.0851],\n",
      "        [1.0600],\n",
      "        [1.0965],\n",
      "        [1.0996],\n",
      "        [1.0790],\n",
      "        [1.0816],\n",
      "        [1.0913],\n",
      "        [1.0987],\n",
      "        [1.0904],\n",
      "        [1.0835],\n",
      "        [1.1103],\n",
      "        [1.1073],\n",
      "        [1.0650],\n",
      "        [1.1186],\n",
      "        [1.0917]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0975],\n",
      "        [1.0443],\n",
      "        [1.0859],\n",
      "        [1.0757]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  15 | lr 0.00100 train_loss 2.12442 | val_loss 2.29287 | val_rmse 1.51422\n",
      "tensor([[1.0619],\n",
      "        [1.0710],\n",
      "        [1.0815],\n",
      "        [1.1080],\n",
      "        [1.0539],\n",
      "        [1.0637],\n",
      "        [1.0797],\n",
      "        [1.0420],\n",
      "        [1.0895],\n",
      "        [1.0917],\n",
      "        [1.0913],\n",
      "        [1.1068],\n",
      "        [1.1101],\n",
      "        [1.0714],\n",
      "        [1.0922],\n",
      "        [1.1162],\n",
      "        [1.0886],\n",
      "        [1.0967],\n",
      "        [1.1134],\n",
      "        [1.1046],\n",
      "        [1.1070],\n",
      "        [1.0824],\n",
      "        [1.1027],\n",
      "        [1.0956],\n",
      "        [1.0938],\n",
      "        [1.0347],\n",
      "        [1.0939],\n",
      "        [1.0542],\n",
      "        [1.1161],\n",
      "        [1.0743],\n",
      "        [1.1035],\n",
      "        [1.1107],\n",
      "        [1.0763],\n",
      "        [1.1014],\n",
      "        [1.0389],\n",
      "        [1.1019],\n",
      "        [1.1162],\n",
      "        [1.0720],\n",
      "        [1.0928],\n",
      "        [1.0800],\n",
      "        [1.0949],\n",
      "        [1.1126],\n",
      "        [1.0808],\n",
      "        [1.0786],\n",
      "        [1.1072],\n",
      "        [1.0771],\n",
      "        [1.1067],\n",
      "        [1.0666],\n",
      "        [1.0693],\n",
      "        [1.0574],\n",
      "        [1.0935],\n",
      "        [1.0981],\n",
      "        [1.1043],\n",
      "        [1.1155],\n",
      "        [1.0968],\n",
      "        [1.0724],\n",
      "        [1.0804],\n",
      "        [1.0937],\n",
      "        [1.1134],\n",
      "        [1.1004],\n",
      "        [1.0492],\n",
      "        [1.0853],\n",
      "        [1.1038],\n",
      "        [1.0304],\n",
      "        [1.0789],\n",
      "        [1.0711],\n",
      "        [1.0913],\n",
      "        [1.0632],\n",
      "        [1.0993],\n",
      "        [1.0631],\n",
      "        [1.0643],\n",
      "        [1.0737],\n",
      "        [1.1079],\n",
      "        [1.1059],\n",
      "        [1.1063],\n",
      "        [1.0821],\n",
      "        [1.0997],\n",
      "        [1.0921],\n",
      "        [1.0771],\n",
      "        [1.0957],\n",
      "        [1.1028],\n",
      "        [1.0642],\n",
      "        [1.0720],\n",
      "        [1.1009],\n",
      "        [1.0795],\n",
      "        [1.1116],\n",
      "        [1.0794],\n",
      "        [1.0757],\n",
      "        [1.1026],\n",
      "        [1.0959],\n",
      "        [1.0739],\n",
      "        [1.0972],\n",
      "        [1.0649],\n",
      "        [1.0990],\n",
      "        [1.0874],\n",
      "        [1.0910],\n",
      "        [1.0398],\n",
      "        [1.1027],\n",
      "        [1.0898],\n",
      "        [1.0886],\n",
      "        [1.0849],\n",
      "        [1.0808],\n",
      "        [1.1116],\n",
      "        [1.0304],\n",
      "        [1.1002],\n",
      "        [1.0897],\n",
      "        [1.1075],\n",
      "        [1.1198],\n",
      "        [1.0464],\n",
      "        [1.1018],\n",
      "        [1.1074],\n",
      "        [1.0665],\n",
      "        [1.0663],\n",
      "        [1.0946],\n",
      "        [1.1181],\n",
      "        [1.0772],\n",
      "        [1.1182],\n",
      "        [1.0603],\n",
      "        [1.0911],\n",
      "        [1.0985],\n",
      "        [1.0969],\n",
      "        [1.0971],\n",
      "        [1.0904],\n",
      "        [1.0731],\n",
      "        [1.0809],\n",
      "        [1.0721],\n",
      "        [1.1117],\n",
      "        [1.0770]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0833],\n",
      "        [1.0920],\n",
      "        [1.0655],\n",
      "        [1.0971],\n",
      "        [1.0363],\n",
      "        [1.0992],\n",
      "        [1.0817],\n",
      "        [1.0583],\n",
      "        [1.0962],\n",
      "        [1.1070],\n",
      "        [1.1095],\n",
      "        [1.0948],\n",
      "        [1.0793],\n",
      "        [1.0883],\n",
      "        [1.1133],\n",
      "        [1.1143],\n",
      "        [1.0876],\n",
      "        [1.1134],\n",
      "        [1.0470],\n",
      "        [1.1138],\n",
      "        [1.0660],\n",
      "        [1.0734],\n",
      "        [1.1007],\n",
      "        [1.1040],\n",
      "        [1.1012],\n",
      "        [1.0384],\n",
      "        [1.1119],\n",
      "        [1.0684],\n",
      "        [1.0873],\n",
      "        [1.1093],\n",
      "        [1.0569],\n",
      "        [1.0863],\n",
      "        [1.1076],\n",
      "        [1.0918],\n",
      "        [1.0939],\n",
      "        [1.1060],\n",
      "        [1.0656],\n",
      "        [1.0688],\n",
      "        [1.0637],\n",
      "        [1.0694],\n",
      "        [1.0590],\n",
      "        [1.1032],\n",
      "        [1.1122],\n",
      "        [1.0742],\n",
      "        [1.1016],\n",
      "        [1.0609],\n",
      "        [1.0769],\n",
      "        [1.0680],\n",
      "        [1.1025],\n",
      "        [1.0776],\n",
      "        [1.1017],\n",
      "        [1.0979],\n",
      "        [1.0804],\n",
      "        [1.0778],\n",
      "        [1.1140],\n",
      "        [1.0905],\n",
      "        [1.0742],\n",
      "        [1.0990],\n",
      "        [1.0425],\n",
      "        [1.1106],\n",
      "        [1.1026],\n",
      "        [1.0402],\n",
      "        [1.0790],\n",
      "        [1.0969],\n",
      "        [1.0877],\n",
      "        [1.0788],\n",
      "        [1.0788],\n",
      "        [1.0692],\n",
      "        [1.0950],\n",
      "        [1.1042],\n",
      "        [1.0565],\n",
      "        [1.0963],\n",
      "        [1.0596],\n",
      "        [1.1016],\n",
      "        [1.0364],\n",
      "        [1.0649],\n",
      "        [1.1121],\n",
      "        [1.0770],\n",
      "        [1.0134],\n",
      "        [1.1113],\n",
      "        [1.0865],\n",
      "        [1.1011],\n",
      "        [1.1135],\n",
      "        [1.0575],\n",
      "        [0.6972],\n",
      "        [1.0720],\n",
      "        [1.0693],\n",
      "        [1.0537],\n",
      "        [1.0671],\n",
      "        [1.1022],\n",
      "        [1.0819],\n",
      "        [1.0880],\n",
      "        [1.0911],\n",
      "        [1.1091],\n",
      "        [1.0780],\n",
      "        [1.0929],\n",
      "        [1.0994],\n",
      "        [1.0717],\n",
      "        [1.0894],\n",
      "        [1.0545],\n",
      "        [1.1085],\n",
      "        [1.1054],\n",
      "        [1.0916],\n",
      "        [1.1101],\n",
      "        [1.0992],\n",
      "        [1.0653],\n",
      "        [1.1083],\n",
      "        [1.0718],\n",
      "        [1.1118],\n",
      "        [1.0977],\n",
      "        [1.0794],\n",
      "        [1.1107],\n",
      "        [1.0932],\n",
      "        [1.0348],\n",
      "        [1.1093],\n",
      "        [1.1001],\n",
      "        [1.1051],\n",
      "        [1.0769],\n",
      "        [1.1115],\n",
      "        [1.0883],\n",
      "        [1.0762],\n",
      "        [1.0705],\n",
      "        [1.0901],\n",
      "        [1.0981],\n",
      "        [1.0755],\n",
      "        [1.0743],\n",
      "        [1.0752],\n",
      "        [1.0802]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0744],\n",
      "        [1.0924],\n",
      "        [1.0483],\n",
      "        [1.0650],\n",
      "        [1.0811],\n",
      "        [1.1084],\n",
      "        [1.0987],\n",
      "        [1.0692],\n",
      "        [1.0543],\n",
      "        [1.0962],\n",
      "        [1.0882],\n",
      "        [1.1072],\n",
      "        [1.0720],\n",
      "        [1.1075],\n",
      "        [1.1064],\n",
      "        [1.0701],\n",
      "        [1.0566],\n",
      "        [1.0955],\n",
      "        [1.0756],\n",
      "        [1.0457],\n",
      "        [1.0719],\n",
      "        [1.0447],\n",
      "        [1.0643],\n",
      "        [1.0730],\n",
      "        [1.0483],\n",
      "        [1.1136],\n",
      "        [1.1095],\n",
      "        [1.0783],\n",
      "        [1.1093],\n",
      "        [1.0943],\n",
      "        [1.0858],\n",
      "        [1.0462],\n",
      "        [1.0894],\n",
      "        [1.1124],\n",
      "        [1.0859],\n",
      "        [1.1012],\n",
      "        [1.0609],\n",
      "        [1.0935],\n",
      "        [1.1071],\n",
      "        [1.0258],\n",
      "        [1.0691],\n",
      "        [1.0777],\n",
      "        [1.0946],\n",
      "        [1.0677],\n",
      "        [1.0288],\n",
      "        [1.0796],\n",
      "        [1.0950],\n",
      "        [1.1062],\n",
      "        [1.0837],\n",
      "        [1.0715],\n",
      "        [1.0743],\n",
      "        [1.0432],\n",
      "        [1.0606],\n",
      "        [1.1013],\n",
      "        [1.0472],\n",
      "        [1.0673],\n",
      "        [1.0946],\n",
      "        [1.0455],\n",
      "        [1.0623],\n",
      "        [1.1105],\n",
      "        [1.1113],\n",
      "        [1.0975],\n",
      "        [1.0885],\n",
      "        [1.0957],\n",
      "        [1.1105],\n",
      "        [1.0687],\n",
      "        [1.0977],\n",
      "        [1.0966],\n",
      "        [1.0943],\n",
      "        [1.0913],\n",
      "        [1.0737],\n",
      "        [1.0570],\n",
      "        [1.0386],\n",
      "        [1.0961],\n",
      "        [1.0709],\n",
      "        [1.0358],\n",
      "        [1.0767],\n",
      "        [1.0895],\n",
      "        [1.0872],\n",
      "        [1.0968],\n",
      "        [1.0651],\n",
      "        [1.0981],\n",
      "        [1.0970],\n",
      "        [1.0626],\n",
      "        [1.0848],\n",
      "        [1.0870],\n",
      "        [1.1039],\n",
      "        [1.1022],\n",
      "        [1.0828],\n",
      "        [1.1000],\n",
      "        [1.0880],\n",
      "        [1.0785],\n",
      "        [1.0956],\n",
      "        [1.0540],\n",
      "        [1.0636],\n",
      "        [1.0764],\n",
      "        [1.0976],\n",
      "        [1.0802],\n",
      "        [1.0631],\n",
      "        [1.0723],\n",
      "        [1.0922],\n",
      "        [1.0776],\n",
      "        [1.1016],\n",
      "        [1.1092],\n",
      "        [1.1078],\n",
      "        [1.0889],\n",
      "        [1.0873],\n",
      "        [1.0224],\n",
      "        [1.1045],\n",
      "        [1.0998],\n",
      "        [1.0579],\n",
      "        [1.0679],\n",
      "        [1.0744],\n",
      "        [1.0745],\n",
      "        [1.0715],\n",
      "        [1.0682],\n",
      "        [1.0390],\n",
      "        [1.0571],\n",
      "        [1.0718],\n",
      "        [1.0895],\n",
      "        [1.0565],\n",
      "        [1.0645],\n",
      "        [1.0820],\n",
      "        [1.1090],\n",
      "        [1.1089],\n",
      "        [1.0176],\n",
      "        [1.1041],\n",
      "        [1.1068]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0748],\n",
      "        [1.0655],\n",
      "        [1.0628],\n",
      "        [1.0826],\n",
      "        [1.0958],\n",
      "        [1.0498],\n",
      "        [1.0834],\n",
      "        [1.1029],\n",
      "        [1.0657],\n",
      "        [1.0945],\n",
      "        [1.1008],\n",
      "        [1.0957],\n",
      "        [1.0641],\n",
      "        [1.0814],\n",
      "        [1.0892],\n",
      "        [1.0322],\n",
      "        [1.1014],\n",
      "        [1.0430],\n",
      "        [1.0897],\n",
      "        [1.0530],\n",
      "        [1.0908],\n",
      "        [1.0957],\n",
      "        [1.0906],\n",
      "        [1.0751],\n",
      "        [1.0999],\n",
      "        [1.0746],\n",
      "        [1.0838],\n",
      "        [1.1035],\n",
      "        [1.0677],\n",
      "        [1.0970],\n",
      "        [1.0418],\n",
      "        [1.0628],\n",
      "        [1.0915],\n",
      "        [1.0853],\n",
      "        [1.0985],\n",
      "        [1.1038],\n",
      "        [1.0823],\n",
      "        [1.0607],\n",
      "        [1.0941],\n",
      "        [1.0870],\n",
      "        [1.0970],\n",
      "        [1.0773],\n",
      "        [1.0645],\n",
      "        [1.0606],\n",
      "        [1.1103],\n",
      "        [1.1095],\n",
      "        [1.0726],\n",
      "        [1.1052],\n",
      "        [1.0742],\n",
      "        [1.1086],\n",
      "        [1.0865],\n",
      "        [1.0641],\n",
      "        [1.0778],\n",
      "        [1.0752],\n",
      "        [1.0603],\n",
      "        [1.1029],\n",
      "        [1.0585],\n",
      "        [1.0812],\n",
      "        [1.0569],\n",
      "        [1.0446],\n",
      "        [1.1043],\n",
      "        [1.0768],\n",
      "        [1.0678],\n",
      "        [1.0699],\n",
      "        [1.0771],\n",
      "        [1.0636],\n",
      "        [1.0879],\n",
      "        [1.1067],\n",
      "        [1.0918],\n",
      "        [1.0492],\n",
      "        [1.1010],\n",
      "        [1.0950],\n",
      "        [1.1093],\n",
      "        [1.0562],\n",
      "        [1.0676],\n",
      "        [1.1060],\n",
      "        [1.0492],\n",
      "        [0.2598],\n",
      "        [1.0792],\n",
      "        [1.1004],\n",
      "        [1.0704],\n",
      "        [1.0721],\n",
      "        [1.1008],\n",
      "        [1.0920],\n",
      "        [1.0772],\n",
      "        [1.0847],\n",
      "        [1.1056],\n",
      "        [1.0967],\n",
      "        [1.0825],\n",
      "        [1.0770],\n",
      "        [1.0785],\n",
      "        [1.0451],\n",
      "        [1.0771],\n",
      "        [1.0917],\n",
      "        [1.0889],\n",
      "        [1.1079],\n",
      "        [1.0634],\n",
      "        [1.1016],\n",
      "        [1.0930],\n",
      "        [1.0641],\n",
      "        [1.0766],\n",
      "        [1.0911],\n",
      "        [1.0990],\n",
      "        [1.0774],\n",
      "        [1.1034],\n",
      "        [1.0915],\n",
      "        [1.0802],\n",
      "        [1.0683],\n",
      "        [1.0604],\n",
      "        [1.0692],\n",
      "        [1.0418],\n",
      "        [0.1794],\n",
      "        [1.0715],\n",
      "        [1.0939],\n",
      "        [1.0821],\n",
      "        [1.0785],\n",
      "        [1.0844],\n",
      "        [1.0924],\n",
      "        [1.0966],\n",
      "        [1.0884],\n",
      "        [1.1107],\n",
      "        [1.0969],\n",
      "        [1.1083],\n",
      "        [1.0685],\n",
      "        [0.9823],\n",
      "        [1.1104],\n",
      "        [1.0917],\n",
      "        [1.0866]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1048],\n",
      "        [1.0444],\n",
      "        [0.2994],\n",
      "        [1.0957],\n",
      "        [1.0670],\n",
      "        [1.0777],\n",
      "        [1.0874],\n",
      "        [1.0349],\n",
      "        [1.0755],\n",
      "        [1.0296],\n",
      "        [1.0749],\n",
      "        [1.0976],\n",
      "        [1.0430],\n",
      "        [1.0931],\n",
      "        [1.1033],\n",
      "        [1.0661],\n",
      "        [1.0885],\n",
      "        [1.0737],\n",
      "        [1.0901],\n",
      "        [1.0245],\n",
      "        [1.0888],\n",
      "        [1.0950],\n",
      "        [1.0870],\n",
      "        [0.9767],\n",
      "        [1.0924],\n",
      "        [1.0868],\n",
      "        [1.0452],\n",
      "        [1.0832],\n",
      "        [1.0763],\n",
      "        [1.0659],\n",
      "        [1.1028],\n",
      "        [1.0385],\n",
      "        [1.0752],\n",
      "        [1.0715],\n",
      "        [1.0516],\n",
      "        [1.0789],\n",
      "        [1.0881],\n",
      "        [1.0983],\n",
      "        [1.0764],\n",
      "        [1.0545],\n",
      "        [1.0875],\n",
      "        [1.0536],\n",
      "        [1.1064],\n",
      "        [1.0743],\n",
      "        [1.0797],\n",
      "        [1.0941],\n",
      "        [1.0899],\n",
      "        [1.0897],\n",
      "        [1.0921],\n",
      "        [1.0735],\n",
      "        [1.1069],\n",
      "        [1.0780],\n",
      "        [1.1078],\n",
      "        [1.0938],\n",
      "        [1.0622],\n",
      "        [1.0835],\n",
      "        [1.0916],\n",
      "        [1.0975],\n",
      "        [1.0754],\n",
      "        [1.0924],\n",
      "        [1.0793],\n",
      "        [1.0617],\n",
      "        [1.0690],\n",
      "        [1.1015],\n",
      "        [1.0734],\n",
      "        [1.0845],\n",
      "        [1.0615],\n",
      "        [1.0870],\n",
      "        [1.0687],\n",
      "        [1.0822],\n",
      "        [1.0986],\n",
      "        [1.1004],\n",
      "        [1.0739],\n",
      "        [1.0858],\n",
      "        [1.0604],\n",
      "        [1.0852],\n",
      "        [1.1047],\n",
      "        [1.0739],\n",
      "        [1.0837],\n",
      "        [1.0899],\n",
      "        [1.0512],\n",
      "        [1.0576],\n",
      "        [1.0809],\n",
      "        [1.0955],\n",
      "        [1.0856],\n",
      "        [1.0265],\n",
      "        [1.1008],\n",
      "        [1.1110],\n",
      "        [1.0562],\n",
      "        [1.0617],\n",
      "        [1.0502],\n",
      "        [1.0796],\n",
      "        [1.0794],\n",
      "        [1.1013],\n",
      "        [1.0770],\n",
      "        [1.0906],\n",
      "        [1.0808],\n",
      "        [1.0601],\n",
      "        [1.1053],\n",
      "        [1.1002],\n",
      "        [1.0817],\n",
      "        [1.0894],\n",
      "        [1.1084],\n",
      "        [1.0813],\n",
      "        [1.0814],\n",
      "        [1.1051],\n",
      "        [1.0800],\n",
      "        [1.0942],\n",
      "        [1.1004],\n",
      "        [1.0045],\n",
      "        [1.0609],\n",
      "        [1.0905],\n",
      "        [1.0835],\n",
      "        [1.1006],\n",
      "        [1.0945],\n",
      "        [1.0874],\n",
      "        [1.0952],\n",
      "        [1.0837],\n",
      "        [1.0724],\n",
      "        [1.0671],\n",
      "        [1.0849],\n",
      "        [1.0403],\n",
      "        [1.0430],\n",
      "        [1.0718],\n",
      "        [1.0734],\n",
      "        [1.1008],\n",
      "        [1.0882],\n",
      "        [1.0756]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0394],\n",
      "        [1.0751],\n",
      "        [1.0859],\n",
      "        [1.0892],\n",
      "        [1.0525],\n",
      "        [1.1029],\n",
      "        [1.0747],\n",
      "        [1.1054],\n",
      "        [1.1055],\n",
      "        [1.0754],\n",
      "        [1.1086],\n",
      "        [1.0959],\n",
      "        [1.0767],\n",
      "        [1.0991],\n",
      "        [1.0797],\n",
      "        [1.0534],\n",
      "        [1.0836],\n",
      "        [1.0910],\n",
      "        [1.0680],\n",
      "        [1.0875],\n",
      "        [1.0834],\n",
      "        [1.0900],\n",
      "        [1.0797],\n",
      "        [1.0631],\n",
      "        [1.0626],\n",
      "        [1.0853],\n",
      "        [1.0770],\n",
      "        [1.0532],\n",
      "        [1.0539],\n",
      "        [1.0858],\n",
      "        [1.0591],\n",
      "        [1.0412],\n",
      "        [1.0473],\n",
      "        [1.0816],\n",
      "        [1.0756],\n",
      "        [1.0737],\n",
      "        [1.0627],\n",
      "        [1.0884],\n",
      "        [1.0602],\n",
      "        [1.0976],\n",
      "        [1.0820],\n",
      "        [1.1053],\n",
      "        [1.0642],\n",
      "        [1.1047],\n",
      "        [1.0649],\n",
      "        [1.1071],\n",
      "        [1.0828],\n",
      "        [1.0825],\n",
      "        [1.0697],\n",
      "        [1.0806],\n",
      "        [1.0905],\n",
      "        [1.1041],\n",
      "        [1.0691],\n",
      "        [1.0350],\n",
      "        [1.0995],\n",
      "        [1.0705],\n",
      "        [1.0499],\n",
      "        [1.0864],\n",
      "        [1.1094],\n",
      "        [1.1071],\n",
      "        [1.0475],\n",
      "        [1.0565],\n",
      "        [1.1085],\n",
      "        [1.0532],\n",
      "        [1.0508],\n",
      "        [1.0872],\n",
      "        [1.0739],\n",
      "        [1.0924],\n",
      "        [1.1071],\n",
      "        [1.0914],\n",
      "        [1.0873],\n",
      "        [1.0887],\n",
      "        [1.0822],\n",
      "        [1.0934],\n",
      "        [1.1042],\n",
      "        [1.0692],\n",
      "        [1.0808],\n",
      "        [1.0918],\n",
      "        [1.0722],\n",
      "        [1.0644],\n",
      "        [1.0859],\n",
      "        [1.1047],\n",
      "        [1.0651],\n",
      "        [1.1016],\n",
      "        [1.0911],\n",
      "        [1.1031],\n",
      "        [1.1043],\n",
      "        [1.0488],\n",
      "        [1.0864],\n",
      "        [1.0767],\n",
      "        [1.0604],\n",
      "        [1.0993],\n",
      "        [1.0768],\n",
      "        [1.1065],\n",
      "        [1.0463],\n",
      "        [1.1013],\n",
      "        [1.0717],\n",
      "        [1.0717],\n",
      "        [1.0969],\n",
      "        [1.1033],\n",
      "        [1.0954],\n",
      "        [1.1009],\n",
      "        [1.0546],\n",
      "        [1.0771],\n",
      "        [1.0545],\n",
      "        [1.0486],\n",
      "        [1.0792],\n",
      "        [1.0703],\n",
      "        [1.0727],\n",
      "        [1.0827],\n",
      "        [1.1017],\n",
      "        [1.1054],\n",
      "        [1.0927],\n",
      "        [1.1000],\n",
      "        [1.0666],\n",
      "        [1.0831],\n",
      "        [1.1018],\n",
      "        [1.0366],\n",
      "        [1.1032],\n",
      "        [1.0700],\n",
      "        [1.0673],\n",
      "        [1.0500],\n",
      "        [1.0163],\n",
      "        [1.0772],\n",
      "        [1.0892],\n",
      "        [1.0790],\n",
      "        [1.0986],\n",
      "        [1.0949]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0732],\n",
      "        [1.0705],\n",
      "        [1.0639],\n",
      "        [1.1030],\n",
      "        [1.1032],\n",
      "        [1.0982],\n",
      "        [1.0616],\n",
      "        [1.0553],\n",
      "        [1.0651],\n",
      "        [1.0645],\n",
      "        [1.0562],\n",
      "        [1.0740],\n",
      "        [1.0726],\n",
      "        [1.0524],\n",
      "        [1.0671],\n",
      "        [1.0280],\n",
      "        [1.0931],\n",
      "        [1.0591],\n",
      "        [1.0828],\n",
      "        [1.0987],\n",
      "        [1.0078],\n",
      "        [1.0856],\n",
      "        [1.0692],\n",
      "        [1.0719],\n",
      "        [1.0980],\n",
      "        [1.0761],\n",
      "        [1.0890],\n",
      "        [1.0836],\n",
      "        [1.0886],\n",
      "        [1.0702],\n",
      "        [1.1030],\n",
      "        [1.0598],\n",
      "        [1.0877],\n",
      "        [1.0668],\n",
      "        [1.1046],\n",
      "        [1.0909],\n",
      "        [1.0548],\n",
      "        [1.0673],\n",
      "        [1.0907],\n",
      "        [1.0527],\n",
      "        [1.0890],\n",
      "        [1.0931],\n",
      "        [1.0510],\n",
      "        [1.0533],\n",
      "        [1.0537],\n",
      "        [1.0900],\n",
      "        [1.0550],\n",
      "        [1.0697],\n",
      "        [1.0560],\n",
      "        [1.1042],\n",
      "        [1.0905],\n",
      "        [1.0783],\n",
      "        [1.0852],\n",
      "        [1.1037],\n",
      "        [1.0515],\n",
      "        [1.0859],\n",
      "        [1.0765],\n",
      "        [1.0865],\n",
      "        [1.0991],\n",
      "        [1.0152],\n",
      "        [1.0629],\n",
      "        [1.0873],\n",
      "        [1.0728],\n",
      "        [1.0760],\n",
      "        [1.0544],\n",
      "        [1.0963],\n",
      "        [1.0710],\n",
      "        [1.1051],\n",
      "        [1.0885],\n",
      "        [1.0517],\n",
      "        [1.0783],\n",
      "        [1.0651],\n",
      "        [1.0753],\n",
      "        [1.1034],\n",
      "        [1.1005],\n",
      "        [1.1002],\n",
      "        [1.0624],\n",
      "        [1.0696],\n",
      "        [1.0985],\n",
      "        [1.0725],\n",
      "        [1.0968],\n",
      "        [1.0675],\n",
      "        [1.0825],\n",
      "        [1.0724],\n",
      "        [1.0567],\n",
      "        [1.1033],\n",
      "        [1.0729],\n",
      "        [1.0884],\n",
      "        [1.0416],\n",
      "        [1.0782],\n",
      "        [1.0520],\n",
      "        [1.0846],\n",
      "        [1.0877],\n",
      "        [1.0843],\n",
      "        [1.0842],\n",
      "        [1.0918],\n",
      "        [1.0542],\n",
      "        [1.0728],\n",
      "        [1.0522],\n",
      "        [1.0882],\n",
      "        [1.0604],\n",
      "        [1.0830],\n",
      "        [1.0820],\n",
      "        [1.1037],\n",
      "        [1.0698],\n",
      "        [1.0866],\n",
      "        [1.0831],\n",
      "        [1.0982],\n",
      "        [1.0666],\n",
      "        [1.0670],\n",
      "        [1.0884],\n",
      "        [1.0804],\n",
      "        [1.1010],\n",
      "        [1.0898],\n",
      "        [1.0305],\n",
      "        [1.0437],\n",
      "        [1.0866],\n",
      "        [1.0938],\n",
      "        [1.0937],\n",
      "        [1.0821],\n",
      "        [1.0964],\n",
      "        [1.0994],\n",
      "        [1.0504],\n",
      "        [1.0656],\n",
      "        [1.0336],\n",
      "        [1.0310],\n",
      "        [1.0930],\n",
      "        [1.0898]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0686],\n",
      "        [1.0726],\n",
      "        [1.0780],\n",
      "        [1.0781]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  16 | lr 0.00100 train_loss 2.12775 | val_loss 2.29580 | val_rmse 1.51519\n",
      "tensor([[1.0168],\n",
      "        [1.0726],\n",
      "        [1.0797],\n",
      "        [1.0815],\n",
      "        [1.0886],\n",
      "        [1.0743],\n",
      "        [1.0228],\n",
      "        [1.0950],\n",
      "        [1.1070],\n",
      "        [1.0788],\n",
      "        [1.1066],\n",
      "        [1.0599],\n",
      "        [1.0851],\n",
      "        [1.0777],\n",
      "        [1.0653],\n",
      "        [1.0933],\n",
      "        [1.0798],\n",
      "        [1.0931],\n",
      "        [1.0976],\n",
      "        [1.0973],\n",
      "        [1.0468],\n",
      "        [1.0933],\n",
      "        [1.0899],\n",
      "        [1.1030],\n",
      "        [1.0815],\n",
      "        [1.0931],\n",
      "        [1.0926],\n",
      "        [1.0665],\n",
      "        [1.0664],\n",
      "        [1.0650],\n",
      "        [1.1014],\n",
      "        [1.0522],\n",
      "        [1.1065],\n",
      "        [1.0830],\n",
      "        [1.0589],\n",
      "        [1.0954],\n",
      "        [1.0974],\n",
      "        [1.1057],\n",
      "        [1.1075],\n",
      "        [1.0875],\n",
      "        [1.0679],\n",
      "        [1.0531],\n",
      "        [1.0503],\n",
      "        [1.0824],\n",
      "        [1.1002],\n",
      "        [1.0654],\n",
      "        [1.0616],\n",
      "        [1.0616],\n",
      "        [1.1048],\n",
      "        [1.1016],\n",
      "        [1.0710],\n",
      "        [1.0968],\n",
      "        [1.0951],\n",
      "        [1.0437],\n",
      "        [1.0838],\n",
      "        [1.1043],\n",
      "        [1.1029],\n",
      "        [1.0924],\n",
      "        [1.0757],\n",
      "        [1.0296],\n",
      "        [1.0942],\n",
      "        [1.1049],\n",
      "        [1.0587],\n",
      "        [1.0911],\n",
      "        [1.0508],\n",
      "        [1.0826],\n",
      "        [1.0898],\n",
      "        [1.0923],\n",
      "        [1.0729],\n",
      "        [1.0939],\n",
      "        [1.0736],\n",
      "        [1.0607],\n",
      "        [1.0874],\n",
      "        [1.1035],\n",
      "        [1.0838],\n",
      "        [1.0857],\n",
      "        [1.0617],\n",
      "        [1.0642],\n",
      "        [1.0913],\n",
      "        [1.0639],\n",
      "        [1.0911],\n",
      "        [1.0675],\n",
      "        [1.0843],\n",
      "        [1.0997],\n",
      "        [1.1052],\n",
      "        [1.0832],\n",
      "        [1.0616],\n",
      "        [1.0723],\n",
      "        [1.0641],\n",
      "        [1.0676],\n",
      "        [1.1046],\n",
      "        [1.0765],\n",
      "        [1.0787],\n",
      "        [1.0392],\n",
      "        [1.0892],\n",
      "        [1.0674],\n",
      "        [1.0658],\n",
      "        [1.0899],\n",
      "        [1.0607],\n",
      "        [1.0806],\n",
      "        [1.0385],\n",
      "        [1.0568],\n",
      "        [1.0766],\n",
      "        [1.0706],\n",
      "        [1.0862],\n",
      "        [1.0847],\n",
      "        [1.0910],\n",
      "        [1.0653],\n",
      "        [1.0978],\n",
      "        [1.0693],\n",
      "        [1.0601],\n",
      "        [1.0687],\n",
      "        [1.0199],\n",
      "        [1.0532],\n",
      "        [1.0162],\n",
      "        [1.0897],\n",
      "        [1.0722],\n",
      "        [1.0570],\n",
      "        [1.0866],\n",
      "        [1.0821],\n",
      "        [1.0972],\n",
      "        [1.0806],\n",
      "        [1.0665],\n",
      "        [1.0713],\n",
      "        [1.0905],\n",
      "        [1.1052],\n",
      "        [1.0850],\n",
      "        [1.0916]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0775],\n",
      "        [1.0964],\n",
      "        [1.0435],\n",
      "        [1.0575],\n",
      "        [1.1055],\n",
      "        [1.0833],\n",
      "        [1.0255],\n",
      "        [1.0667],\n",
      "        [1.0972],\n",
      "        [1.0858],\n",
      "        [1.0432],\n",
      "        [1.0382],\n",
      "        [1.1029],\n",
      "        [1.0932],\n",
      "        [1.0649],\n",
      "        [1.0949],\n",
      "        [1.1077],\n",
      "        [1.1110],\n",
      "        [1.0689],\n",
      "        [1.0948],\n",
      "        [1.0954],\n",
      "        [1.1018],\n",
      "        [1.0824],\n",
      "        [1.0922],\n",
      "        [1.0940],\n",
      "        [1.0851],\n",
      "        [1.0907],\n",
      "        [1.0888],\n",
      "        [1.0939],\n",
      "        [1.0844],\n",
      "        [1.0665],\n",
      "        [1.1109],\n",
      "        [1.0838],\n",
      "        [1.1109],\n",
      "        [1.0565],\n",
      "        [1.0876],\n",
      "        [1.1008],\n",
      "        [1.0892],\n",
      "        [1.0954],\n",
      "        [1.1084],\n",
      "        [1.0885],\n",
      "        [1.0821],\n",
      "        [1.1030],\n",
      "        [1.1054],\n",
      "        [1.0135],\n",
      "        [1.0498],\n",
      "        [1.0633],\n",
      "        [1.0413],\n",
      "        [1.1090],\n",
      "        [1.0274],\n",
      "        [1.0892],\n",
      "        [1.0800],\n",
      "        [1.0915],\n",
      "        [1.0982],\n",
      "        [1.0642],\n",
      "        [1.0748],\n",
      "        [1.0525],\n",
      "        [1.0891],\n",
      "        [1.0840],\n",
      "        [1.1064],\n",
      "        [1.0820],\n",
      "        [1.1047],\n",
      "        [1.0774],\n",
      "        [1.0746],\n",
      "        [1.1033],\n",
      "        [1.0909],\n",
      "        [1.0777],\n",
      "        [1.0792],\n",
      "        [1.0526],\n",
      "        [1.0751],\n",
      "        [1.1032],\n",
      "        [1.1080],\n",
      "        [1.0958],\n",
      "        [1.0980],\n",
      "        [1.0820],\n",
      "        [1.1049],\n",
      "        [1.0897],\n",
      "        [1.1006],\n",
      "        [1.0640],\n",
      "        [1.0775],\n",
      "        [1.0966],\n",
      "        [1.0957],\n",
      "        [1.0550],\n",
      "        [1.0784],\n",
      "        [1.0481],\n",
      "        [1.0892],\n",
      "        [1.0704],\n",
      "        [1.0869],\n",
      "        [1.1039],\n",
      "        [1.0797],\n",
      "        [1.0917],\n",
      "        [1.0936],\n",
      "        [1.0332],\n",
      "        [1.1022],\n",
      "        [1.0750],\n",
      "        [1.1109],\n",
      "        [1.0753],\n",
      "        [1.0480],\n",
      "        [1.0902],\n",
      "        [1.0986],\n",
      "        [1.0820],\n",
      "        [1.0831],\n",
      "        [1.0964],\n",
      "        [1.0807],\n",
      "        [1.0834],\n",
      "        [1.0849],\n",
      "        [1.0859],\n",
      "        [1.1034],\n",
      "        [1.0746],\n",
      "        [1.0491],\n",
      "        [1.1065],\n",
      "        [1.0904],\n",
      "        [1.0533],\n",
      "        [1.0872],\n",
      "        [1.1007],\n",
      "        [1.0643],\n",
      "        [1.0961],\n",
      "        [1.0812],\n",
      "        [1.0758],\n",
      "        [1.0846],\n",
      "        [1.0856],\n",
      "        [1.0940],\n",
      "        [1.1078],\n",
      "        [1.0877],\n",
      "        [1.0920],\n",
      "        [1.0823],\n",
      "        [1.1009],\n",
      "        [1.0971]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1142],\n",
      "        [1.0942],\n",
      "        [1.1061],\n",
      "        [1.0857],\n",
      "        [1.1043],\n",
      "        [1.0774],\n",
      "        [1.0883],\n",
      "        [1.0743],\n",
      "        [1.0896],\n",
      "        [1.0572],\n",
      "        [1.1106],\n",
      "        [1.0749],\n",
      "        [1.0910],\n",
      "        [1.0673],\n",
      "        [1.0759],\n",
      "        [1.0668],\n",
      "        [1.0524],\n",
      "        [1.1101],\n",
      "        [1.0907],\n",
      "        [1.1058],\n",
      "        [1.0573],\n",
      "        [1.0843],\n",
      "        [1.1018],\n",
      "        [1.1030],\n",
      "        [1.0909],\n",
      "        [1.1147],\n",
      "        [1.0959],\n",
      "        [1.0957],\n",
      "        [1.0928],\n",
      "        [1.0912],\n",
      "        [1.0990],\n",
      "        [1.0867],\n",
      "        [1.0802],\n",
      "        [1.0803],\n",
      "        [1.0967],\n",
      "        [1.1078],\n",
      "        [1.0617],\n",
      "        [1.0886],\n",
      "        [1.1004],\n",
      "        [1.1055],\n",
      "        [1.1144],\n",
      "        [1.0708],\n",
      "        [1.1012],\n",
      "        [1.0303],\n",
      "        [1.0738],\n",
      "        [1.0887],\n",
      "        [1.0947],\n",
      "        [1.0765],\n",
      "        [1.1142],\n",
      "        [1.0284],\n",
      "        [1.1112],\n",
      "        [1.0986],\n",
      "        [1.0711],\n",
      "        [1.1072],\n",
      "        [1.0838],\n",
      "        [1.1052],\n",
      "        [1.0963],\n",
      "        [1.1029],\n",
      "        [1.0668],\n",
      "        [1.0673],\n",
      "        [1.0864],\n",
      "        [1.0903],\n",
      "        [1.1129],\n",
      "        [1.0805],\n",
      "        [1.0633],\n",
      "        [1.1018],\n",
      "        [1.0699],\n",
      "        [1.1125],\n",
      "        [1.0971],\n",
      "        [1.0481],\n",
      "        [1.0744],\n",
      "        [1.0891],\n",
      "        [1.1001],\n",
      "        [1.0732],\n",
      "        [1.0889],\n",
      "        [1.0652],\n",
      "        [1.1003],\n",
      "        [1.0910],\n",
      "        [1.1070],\n",
      "        [1.1094],\n",
      "        [1.0552],\n",
      "        [1.1106],\n",
      "        [1.0845],\n",
      "        [1.1022],\n",
      "        [1.0779],\n",
      "        [1.1142],\n",
      "        [1.0940],\n",
      "        [1.0843],\n",
      "        [1.0969],\n",
      "        [1.0869],\n",
      "        [1.0652],\n",
      "        [1.0950],\n",
      "        [1.0635],\n",
      "        [1.0911],\n",
      "        [1.0833],\n",
      "        [1.1152],\n",
      "        [1.0821],\n",
      "        [1.0939],\n",
      "        [1.0922],\n",
      "        [1.0649],\n",
      "        [1.1003],\n",
      "        [1.0806],\n",
      "        [1.0916],\n",
      "        [1.1037],\n",
      "        [1.1023],\n",
      "        [1.1023],\n",
      "        [1.0722],\n",
      "        [1.1070],\n",
      "        [1.0816],\n",
      "        [1.0893],\n",
      "        [1.0834],\n",
      "        [1.1122],\n",
      "        [1.0996],\n",
      "        [1.0814],\n",
      "        [1.0793],\n",
      "        [1.0893],\n",
      "        [1.0739],\n",
      "        [1.0782],\n",
      "        [1.1090],\n",
      "        [1.1055],\n",
      "        [1.0948],\n",
      "        [1.0799],\n",
      "        [1.1114],\n",
      "        [1.0783],\n",
      "        [1.1048],\n",
      "        [1.0724],\n",
      "        [1.0912],\n",
      "        [1.1056]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1026],\n",
      "        [1.1190],\n",
      "        [1.1026],\n",
      "        [1.0745],\n",
      "        [1.0773],\n",
      "        [1.0617],\n",
      "        [1.1179],\n",
      "        [1.0742],\n",
      "        [1.0942],\n",
      "        [1.1080],\n",
      "        [1.0796],\n",
      "        [1.1130],\n",
      "        [1.0773],\n",
      "        [1.0907],\n",
      "        [1.0521],\n",
      "        [1.1188],\n",
      "        [1.0841],\n",
      "        [1.0826],\n",
      "        [1.1179],\n",
      "        [1.0510],\n",
      "        [1.0857],\n",
      "        [1.0807],\n",
      "        [1.0718],\n",
      "        [1.0847],\n",
      "        [1.1136],\n",
      "        [1.1156],\n",
      "        [1.0511],\n",
      "        [1.0745],\n",
      "        [0.3915],\n",
      "        [1.1069],\n",
      "        [1.0272],\n",
      "        [1.0743],\n",
      "        [1.0681],\n",
      "        [1.0591],\n",
      "        [1.0419],\n",
      "        [1.0907],\n",
      "        [1.0924],\n",
      "        [1.0754],\n",
      "        [1.0990],\n",
      "        [1.0748],\n",
      "        [1.1044],\n",
      "        [1.1150],\n",
      "        [1.0544],\n",
      "        [1.1167],\n",
      "        [1.0900],\n",
      "        [1.0828],\n",
      "        [1.1151],\n",
      "        [1.1081],\n",
      "        [1.1151],\n",
      "        [1.0865],\n",
      "        [1.0908],\n",
      "        [1.1075],\n",
      "        [1.1090],\n",
      "        [1.0912],\n",
      "        [1.0703],\n",
      "        [1.0958],\n",
      "        [1.1122],\n",
      "        [1.1084],\n",
      "        [1.0798],\n",
      "        [1.0861],\n",
      "        [1.0957],\n",
      "        [1.0840],\n",
      "        [1.0359],\n",
      "        [1.0587],\n",
      "        [1.0875],\n",
      "        [1.0961],\n",
      "        [1.1108],\n",
      "        [1.1080],\n",
      "        [1.0760],\n",
      "        [1.1063],\n",
      "        [1.0977],\n",
      "        [1.0381],\n",
      "        [1.0797],\n",
      "        [1.0695],\n",
      "        [1.0599],\n",
      "        [1.0995],\n",
      "        [1.0781],\n",
      "        [1.0816],\n",
      "        [1.1088],\n",
      "        [1.0887],\n",
      "        [1.0380],\n",
      "        [1.0731],\n",
      "        [1.0767],\n",
      "        [1.0970],\n",
      "        [1.1165],\n",
      "        [1.0407],\n",
      "        [1.0815],\n",
      "        [1.0563],\n",
      "        [1.0855],\n",
      "        [1.1177],\n",
      "        [1.1015],\n",
      "        [1.1061],\n",
      "        [1.0977],\n",
      "        [1.0607],\n",
      "        [1.0685],\n",
      "        [1.0839],\n",
      "        [1.1173],\n",
      "        [1.0747],\n",
      "        [1.1016],\n",
      "        [1.1039],\n",
      "        [1.1175],\n",
      "        [1.0568],\n",
      "        [1.0994],\n",
      "        [1.0620],\n",
      "        [1.1168],\n",
      "        [1.0712],\n",
      "        [1.1153],\n",
      "        [1.0995],\n",
      "        [1.0221],\n",
      "        [1.1012],\n",
      "        [1.0864],\n",
      "        [1.0417],\n",
      "        [1.0916],\n",
      "        [1.0973],\n",
      "        [1.0686],\n",
      "        [1.0795],\n",
      "        [1.1127],\n",
      "        [1.0958],\n",
      "        [1.1204],\n",
      "        [1.1003],\n",
      "        [1.1115],\n",
      "        [1.0987],\n",
      "        [1.0843],\n",
      "        [1.0957],\n",
      "        [1.0894],\n",
      "        [1.1132],\n",
      "        [1.1189],\n",
      "        [1.0806]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0980],\n",
      "        [1.0866],\n",
      "        [1.0779],\n",
      "        [1.0646],\n",
      "        [1.1002],\n",
      "        [1.1103],\n",
      "        [1.0778],\n",
      "        [1.0658],\n",
      "        [1.1008],\n",
      "        [1.1094],\n",
      "        [1.1236],\n",
      "        [1.1019],\n",
      "        [1.0739],\n",
      "        [1.1120],\n",
      "        [1.1206],\n",
      "        [1.0806],\n",
      "        [1.0807],\n",
      "        [1.0894],\n",
      "        [1.0951],\n",
      "        [1.0986],\n",
      "        [1.0647],\n",
      "        [1.0786],\n",
      "        [1.0382],\n",
      "        [1.0980],\n",
      "        [1.1017],\n",
      "        [1.0700],\n",
      "        [1.1053],\n",
      "        [1.1000],\n",
      "        [1.0805],\n",
      "        [1.1208],\n",
      "        [1.1081],\n",
      "        [1.0863],\n",
      "        [1.1141],\n",
      "        [1.1178],\n",
      "        [1.1228],\n",
      "        [1.1009],\n",
      "        [1.1245],\n",
      "        [1.1020],\n",
      "        [1.1010],\n",
      "        [1.1197],\n",
      "        [1.1122],\n",
      "        [1.1201],\n",
      "        [1.0969],\n",
      "        [1.1056],\n",
      "        [1.0932],\n",
      "        [1.1223],\n",
      "        [1.1139],\n",
      "        [1.1225],\n",
      "        [1.0898],\n",
      "        [1.0851],\n",
      "        [1.1054],\n",
      "        [1.0887],\n",
      "        [1.1079],\n",
      "        [1.1194],\n",
      "        [1.1214],\n",
      "        [1.1228],\n",
      "        [1.0978],\n",
      "        [1.0705],\n",
      "        [1.1035],\n",
      "        [1.1178],\n",
      "        [1.1094],\n",
      "        [1.1144],\n",
      "        [1.0445],\n",
      "        [1.1189],\n",
      "        [1.1063],\n",
      "        [1.0910],\n",
      "        [1.1147],\n",
      "        [1.0945],\n",
      "        [1.0751],\n",
      "        [1.0735],\n",
      "        [1.0709],\n",
      "        [1.1164],\n",
      "        [1.0896],\n",
      "        [1.0813],\n",
      "        [1.1179],\n",
      "        [1.0892],\n",
      "        [1.1168],\n",
      "        [1.0508],\n",
      "        [1.1224],\n",
      "        [1.1059],\n",
      "        [1.1026],\n",
      "        [1.0871],\n",
      "        [1.1013],\n",
      "        [1.1218],\n",
      "        [1.0784],\n",
      "        [1.0862],\n",
      "        [1.0601],\n",
      "        [1.0862],\n",
      "        [1.0931],\n",
      "        [1.0870],\n",
      "        [1.1060],\n",
      "        [1.1105],\n",
      "        [1.1194],\n",
      "        [1.0870],\n",
      "        [1.0878],\n",
      "        [1.0959],\n",
      "        [1.1091],\n",
      "        [1.0898],\n",
      "        [1.0738],\n",
      "        [1.0679],\n",
      "        [1.1032],\n",
      "        [1.0767],\n",
      "        [1.0611],\n",
      "        [1.0866],\n",
      "        [1.0286],\n",
      "        [1.0837],\n",
      "        [1.0939],\n",
      "        [1.1197],\n",
      "        [1.0985],\n",
      "        [1.0998],\n",
      "        [1.1195],\n",
      "        [1.1223],\n",
      "        [1.1027],\n",
      "        [1.1007],\n",
      "        [1.0798],\n",
      "        [1.0875],\n",
      "        [1.1022],\n",
      "        [1.1004],\n",
      "        [1.0841],\n",
      "        [1.1205],\n",
      "        [1.1117],\n",
      "        [1.0733],\n",
      "        [1.0588],\n",
      "        [1.1123],\n",
      "        [1.1233],\n",
      "        [1.0863],\n",
      "        [1.0450],\n",
      "        [1.1155]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0874],\n",
      "        [1.0673],\n",
      "        [1.0495],\n",
      "        [1.1005],\n",
      "        [1.1140],\n",
      "        [1.0999],\n",
      "        [1.0802],\n",
      "        [1.1219],\n",
      "        [1.0886],\n",
      "        [1.0900],\n",
      "        [1.1150],\n",
      "        [1.1125],\n",
      "        [1.0827],\n",
      "        [1.0823],\n",
      "        [1.0835],\n",
      "        [1.1167],\n",
      "        [1.1147],\n",
      "        [1.0690],\n",
      "        [1.0544],\n",
      "        [1.0891],\n",
      "        [1.1078],\n",
      "        [1.1222],\n",
      "        [1.1048],\n",
      "        [1.0887],\n",
      "        [1.1023],\n",
      "        [1.0915],\n",
      "        [1.1145],\n",
      "        [1.0823],\n",
      "        [1.1275],\n",
      "        [1.0766],\n",
      "        [1.1021],\n",
      "        [1.0669],\n",
      "        [1.0974],\n",
      "        [1.0865],\n",
      "        [1.0613],\n",
      "        [1.0607],\n",
      "        [1.1258],\n",
      "        [1.0940],\n",
      "        [1.1240],\n",
      "        [1.1009],\n",
      "        [1.0969],\n",
      "        [1.1008],\n",
      "        [1.1000],\n",
      "        [1.1057],\n",
      "        [1.0952],\n",
      "        [1.0999],\n",
      "        [1.1230],\n",
      "        [1.0873],\n",
      "        [1.1220],\n",
      "        [1.0875],\n",
      "        [0.2348],\n",
      "        [1.1106],\n",
      "        [1.0921],\n",
      "        [1.0849],\n",
      "        [1.1010],\n",
      "        [1.0617],\n",
      "        [1.1194],\n",
      "        [1.0865],\n",
      "        [1.1215],\n",
      "        [1.1253],\n",
      "        [1.1129],\n",
      "        [1.0932],\n",
      "        [1.0528],\n",
      "        [1.1146],\n",
      "        [1.1119],\n",
      "        [1.1232],\n",
      "        [1.1052],\n",
      "        [1.1236],\n",
      "        [1.1038],\n",
      "        [1.0928],\n",
      "        [1.0498],\n",
      "        [1.1244],\n",
      "        [1.1041],\n",
      "        [1.1172],\n",
      "        [1.1275],\n",
      "        [1.0618],\n",
      "        [1.1192],\n",
      "        [1.1145],\n",
      "        [1.0814],\n",
      "        [1.0980],\n",
      "        [1.1138],\n",
      "        [1.0858],\n",
      "        [1.1125],\n",
      "        [1.1215],\n",
      "        [1.0412],\n",
      "        [1.1128],\n",
      "        [1.1220],\n",
      "        [1.0816],\n",
      "        [1.1210],\n",
      "        [1.1163],\n",
      "        [1.0938],\n",
      "        [1.0986],\n",
      "        [1.1191],\n",
      "        [1.0793],\n",
      "        [1.0957],\n",
      "        [1.1272],\n",
      "        [1.0843],\n",
      "        [1.1006],\n",
      "        [1.1006],\n",
      "        [1.0692],\n",
      "        [1.1278],\n",
      "        [1.1104],\n",
      "        [1.1239],\n",
      "        [1.0900],\n",
      "        [1.1032],\n",
      "        [1.1241],\n",
      "        [1.0837],\n",
      "        [1.0603],\n",
      "        [1.0983],\n",
      "        [1.0755],\n",
      "        [1.0919],\n",
      "        [1.1241],\n",
      "        [1.0674],\n",
      "        [1.0974],\n",
      "        [1.1218],\n",
      "        [1.1047],\n",
      "        [1.1078],\n",
      "        [1.1066],\n",
      "        [1.1153],\n",
      "        [1.1025],\n",
      "        [1.1056],\n",
      "        [1.0716],\n",
      "        [1.0380],\n",
      "        [1.1251],\n",
      "        [1.0828],\n",
      "        [1.1131],\n",
      "        [1.0990],\n",
      "        [1.0714]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0937],\n",
      "        [1.0809],\n",
      "        [1.1235],\n",
      "        [1.1266],\n",
      "        [1.0768],\n",
      "        [1.0965],\n",
      "        [1.1210],\n",
      "        [1.0600],\n",
      "        [1.1111],\n",
      "        [1.1086],\n",
      "        [1.0921],\n",
      "        [1.0993],\n",
      "        [1.0608],\n",
      "        [0.9380],\n",
      "        [1.0955],\n",
      "        [1.1134],\n",
      "        [1.0881],\n",
      "        [1.1261],\n",
      "        [1.1052],\n",
      "        [1.0952],\n",
      "        [1.1225],\n",
      "        [1.1057],\n",
      "        [1.1197],\n",
      "        [1.0616],\n",
      "        [1.1291],\n",
      "        [1.0694],\n",
      "        [1.1092],\n",
      "        [1.1148],\n",
      "        [1.1161],\n",
      "        [1.0720],\n",
      "        [1.0998],\n",
      "        [1.1312],\n",
      "        [1.1228],\n",
      "        [1.1275],\n",
      "        [1.0778],\n",
      "        [1.0570],\n",
      "        [1.1236],\n",
      "        [1.0591],\n",
      "        [1.1055],\n",
      "        [1.1065],\n",
      "        [1.1054],\n",
      "        [1.1024],\n",
      "        [1.0851],\n",
      "        [1.0965],\n",
      "        [1.1074],\n",
      "        [1.1185],\n",
      "        [1.1152],\n",
      "        [1.1233],\n",
      "        [1.0987],\n",
      "        [1.1252],\n",
      "        [1.0765],\n",
      "        [1.0847],\n",
      "        [1.0945],\n",
      "        [1.1176],\n",
      "        [1.1040],\n",
      "        [1.0723],\n",
      "        [1.1266],\n",
      "        [1.1059],\n",
      "        [1.1183],\n",
      "        [1.0643],\n",
      "        [1.1222],\n",
      "        [1.0650],\n",
      "        [1.1072],\n",
      "        [1.1138],\n",
      "        [1.0994],\n",
      "        [1.1282],\n",
      "        [1.1119],\n",
      "        [1.1210],\n",
      "        [1.0924],\n",
      "        [1.0895],\n",
      "        [1.1169],\n",
      "        [1.1009],\n",
      "        [1.0738],\n",
      "        [1.1338],\n",
      "        [1.0916],\n",
      "        [1.1281],\n",
      "        [1.1150],\n",
      "        [1.1132],\n",
      "        [1.0558],\n",
      "        [1.1168],\n",
      "        [1.0697],\n",
      "        [1.1081],\n",
      "        [1.1296],\n",
      "        [1.0639],\n",
      "        [1.1010],\n",
      "        [1.0808],\n",
      "        [1.1001],\n",
      "        [1.0830],\n",
      "        [1.0944],\n",
      "        [1.0835],\n",
      "        [1.1063],\n",
      "        [1.0995],\n",
      "        [1.1143],\n",
      "        [1.0797],\n",
      "        [1.1170],\n",
      "        [1.0871],\n",
      "        [1.0926],\n",
      "        [1.1069],\n",
      "        [1.1210],\n",
      "        [1.1124],\n",
      "        [1.0949],\n",
      "        [1.1208],\n",
      "        [1.1298],\n",
      "        [1.0941],\n",
      "        [1.0876],\n",
      "        [1.1206],\n",
      "        [1.1121],\n",
      "        [1.1084],\n",
      "        [1.0921],\n",
      "        [1.1117],\n",
      "        [1.1209],\n",
      "        [1.1222],\n",
      "        [1.0911],\n",
      "        [1.0955],\n",
      "        [1.0627],\n",
      "        [1.1080],\n",
      "        [1.0742],\n",
      "        [1.0796],\n",
      "        [1.0900],\n",
      "        [1.1357],\n",
      "        [1.1166],\n",
      "        [1.0720],\n",
      "        [1.0809],\n",
      "        [1.0963],\n",
      "        [1.1215],\n",
      "        [1.0799],\n",
      "        [1.0908],\n",
      "        [1.0959]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1105],\n",
      "        [1.0859],\n",
      "        [1.0944],\n",
      "        [1.1283]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  17 | lr 0.00100 train_loss 2.12562 | val_loss 2.28999 | val_rmse 1.51327\n",
      "tensor([[1.1041],\n",
      "        [1.0797],\n",
      "        [1.1136],\n",
      "        [1.0929],\n",
      "        [1.0931],\n",
      "        [1.1076],\n",
      "        [1.0989],\n",
      "        [1.1268],\n",
      "        [1.1051],\n",
      "        [1.1129],\n",
      "        [1.1017],\n",
      "        [1.1211],\n",
      "        [1.1182],\n",
      "        [1.1004],\n",
      "        [1.0469],\n",
      "        [1.1250],\n",
      "        [1.1099],\n",
      "        [1.1134],\n",
      "        [1.1287],\n",
      "        [1.1003],\n",
      "        [1.1095],\n",
      "        [1.0752],\n",
      "        [1.1113],\n",
      "        [1.0735],\n",
      "        [1.0891],\n",
      "        [1.1118],\n",
      "        [1.1141],\n",
      "        [1.1172],\n",
      "        [1.1247],\n",
      "        [1.0815],\n",
      "        [1.0839],\n",
      "        [1.1004],\n",
      "        [1.0965],\n",
      "        [1.0988],\n",
      "        [1.1058],\n",
      "        [1.0906],\n",
      "        [1.0708],\n",
      "        [1.1037],\n",
      "        [1.1206],\n",
      "        [1.1287],\n",
      "        [1.0891],\n",
      "        [1.1268],\n",
      "        [1.1199],\n",
      "        [1.1038],\n",
      "        [1.1039],\n",
      "        [1.1060],\n",
      "        [1.1159],\n",
      "        [1.1191],\n",
      "        [1.1277],\n",
      "        [1.0937],\n",
      "        [1.1000],\n",
      "        [1.0986],\n",
      "        [1.1149],\n",
      "        [0.5100],\n",
      "        [1.1116],\n",
      "        [1.1118],\n",
      "        [1.0691],\n",
      "        [1.1142],\n",
      "        [1.1220],\n",
      "        [1.1042],\n",
      "        [1.1264],\n",
      "        [1.0551],\n",
      "        [1.0530],\n",
      "        [1.1157],\n",
      "        [1.1210],\n",
      "        [1.0579],\n",
      "        [1.1197],\n",
      "        [1.1159],\n",
      "        [1.0840],\n",
      "        [1.1073],\n",
      "        [1.1097],\n",
      "        [1.0853],\n",
      "        [1.1097],\n",
      "        [1.1214],\n",
      "        [1.1107],\n",
      "        [1.0344],\n",
      "        [1.1081],\n",
      "        [1.1279],\n",
      "        [1.1218],\n",
      "        [1.0912],\n",
      "        [1.0960],\n",
      "        [1.1087],\n",
      "        [1.1166],\n",
      "        [1.1111],\n",
      "        [1.0879],\n",
      "        [1.0960],\n",
      "        [1.1259],\n",
      "        [1.0936],\n",
      "        [1.0788],\n",
      "        [1.1222],\n",
      "        [1.1270],\n",
      "        [1.0996],\n",
      "        [1.1118],\n",
      "        [1.0772],\n",
      "        [1.0552],\n",
      "        [1.0707],\n",
      "        [1.1098],\n",
      "        [1.0831],\n",
      "        [1.0829],\n",
      "        [1.1029],\n",
      "        [1.0904],\n",
      "        [1.0919],\n",
      "        [1.0834],\n",
      "        [1.0925],\n",
      "        [1.0853],\n",
      "        [1.0912],\n",
      "        [1.0888],\n",
      "        [1.0987],\n",
      "        [1.0980],\n",
      "        [1.1229],\n",
      "        [1.0997],\n",
      "        [1.1032],\n",
      "        [1.1133],\n",
      "        [1.1196],\n",
      "        [1.1069],\n",
      "        [1.1045],\n",
      "        [1.0989],\n",
      "        [1.1238],\n",
      "        [1.1203],\n",
      "        [1.0820],\n",
      "        [1.1288],\n",
      "        [1.0918],\n",
      "        [1.1185],\n",
      "        [1.1034],\n",
      "        [1.0134],\n",
      "        [1.0613],\n",
      "        [1.0796],\n",
      "        [1.1043]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6921],\n",
      "        [1.1064],\n",
      "        [1.1055],\n",
      "        [1.1141],\n",
      "        [1.1153],\n",
      "        [1.0717],\n",
      "        [1.0695],\n",
      "        [1.0894],\n",
      "        [1.1072],\n",
      "        [1.1057],\n",
      "        [1.0674],\n",
      "        [1.1035],\n",
      "        [1.1100],\n",
      "        [1.0999],\n",
      "        [1.1138],\n",
      "        [1.0975],\n",
      "        [1.1135],\n",
      "        [1.1115],\n",
      "        [1.1220],\n",
      "        [1.1128],\n",
      "        [1.1037],\n",
      "        [1.1090],\n",
      "        [1.0958],\n",
      "        [1.1174],\n",
      "        [1.1020],\n",
      "        [1.1239],\n",
      "        [1.0569],\n",
      "        [1.0926],\n",
      "        [1.0804],\n",
      "        [1.1043],\n",
      "        [1.1063],\n",
      "        [1.1234],\n",
      "        [1.0686],\n",
      "        [1.0985],\n",
      "        [1.1065],\n",
      "        [1.0597],\n",
      "        [1.0736],\n",
      "        [1.0953],\n",
      "        [1.0442],\n",
      "        [1.0916],\n",
      "        [1.0800],\n",
      "        [1.0986],\n",
      "        [1.0907],\n",
      "        [1.1229],\n",
      "        [1.0885],\n",
      "        [1.0760],\n",
      "        [1.0629],\n",
      "        [1.0919],\n",
      "        [1.0866],\n",
      "        [1.0919],\n",
      "        [1.0901],\n",
      "        [1.0954],\n",
      "        [1.0677],\n",
      "        [1.1229],\n",
      "        [1.0881],\n",
      "        [1.0954],\n",
      "        [1.0758],\n",
      "        [1.1028],\n",
      "        [1.0801],\n",
      "        [1.0935],\n",
      "        [1.0930],\n",
      "        [1.0870],\n",
      "        [1.1127],\n",
      "        [1.1071],\n",
      "        [1.1253],\n",
      "        [1.1093],\n",
      "        [1.1116],\n",
      "        [1.1084],\n",
      "        [1.0839],\n",
      "        [1.1188],\n",
      "        [1.0748],\n",
      "        [1.1023],\n",
      "        [1.0812],\n",
      "        [1.1019],\n",
      "        [1.0512],\n",
      "        [1.0964],\n",
      "        [1.0697],\n",
      "        [1.0798],\n",
      "        [1.0681],\n",
      "        [1.0892],\n",
      "        [1.1172],\n",
      "        [1.0950],\n",
      "        [1.0696],\n",
      "        [1.0527],\n",
      "        [1.1106],\n",
      "        [1.1096],\n",
      "        [1.1034],\n",
      "        [1.1111],\n",
      "        [1.1194],\n",
      "        [1.0894],\n",
      "        [1.0675],\n",
      "        [1.0973],\n",
      "        [1.0948],\n",
      "        [1.0945],\n",
      "        [1.1180],\n",
      "        [1.0940],\n",
      "        [1.0697],\n",
      "        [1.0541],\n",
      "        [1.0992],\n",
      "        [1.1176],\n",
      "        [1.1105],\n",
      "        [1.0752],\n",
      "        [1.1191],\n",
      "        [1.0827],\n",
      "        [1.1142],\n",
      "        [1.0707],\n",
      "        [1.0898],\n",
      "        [1.0847],\n",
      "        [1.0695],\n",
      "        [1.1172],\n",
      "        [1.1060],\n",
      "        [1.0826],\n",
      "        [1.1160],\n",
      "        [1.1057],\n",
      "        [1.0829],\n",
      "        [1.1032],\n",
      "        [1.0580],\n",
      "        [1.1126],\n",
      "        [1.0949],\n",
      "        [1.1184],\n",
      "        [1.1080],\n",
      "        [1.0977],\n",
      "        [1.0735],\n",
      "        [1.1142],\n",
      "        [1.1206],\n",
      "        [1.1047],\n",
      "        [1.1008],\n",
      "        [1.0916]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0999],\n",
      "        [1.0738],\n",
      "        [1.0520],\n",
      "        [1.1016],\n",
      "        [1.1142],\n",
      "        [1.0597],\n",
      "        [1.0991],\n",
      "        [1.0953],\n",
      "        [1.0794],\n",
      "        [1.0753],\n",
      "        [1.1042],\n",
      "        [1.1146],\n",
      "        [1.0988],\n",
      "        [1.1059],\n",
      "        [1.1033],\n",
      "        [1.0664],\n",
      "        [1.0751],\n",
      "        [1.1138],\n",
      "        [1.1159],\n",
      "        [1.0946],\n",
      "        [1.1046],\n",
      "        [1.0951],\n",
      "        [1.1036],\n",
      "        [1.1181],\n",
      "        [1.0878],\n",
      "        [1.0616],\n",
      "        [1.0824],\n",
      "        [1.1016],\n",
      "        [1.0912],\n",
      "        [1.0518],\n",
      "        [1.0787],\n",
      "        [1.0592],\n",
      "        [1.0983],\n",
      "        [1.1057],\n",
      "        [1.1135],\n",
      "        [1.0633],\n",
      "        [1.1083],\n",
      "        [1.0989],\n",
      "        [1.0823],\n",
      "        [1.0829],\n",
      "        [1.1176],\n",
      "        [1.0862],\n",
      "        [1.0811],\n",
      "        [1.0907],\n",
      "        [1.0754],\n",
      "        [1.0823],\n",
      "        [1.0977],\n",
      "        [1.0843],\n",
      "        [1.0884],\n",
      "        [1.1051],\n",
      "        [1.0570],\n",
      "        [1.0762],\n",
      "        [1.0905],\n",
      "        [1.0263],\n",
      "        [1.1135],\n",
      "        [1.0930],\n",
      "        [1.0894],\n",
      "        [1.0582],\n",
      "        [1.1053],\n",
      "        [1.0983],\n",
      "        [1.0918],\n",
      "        [1.1023],\n",
      "        [1.1106],\n",
      "        [1.1079],\n",
      "        [1.0697],\n",
      "        [1.0954],\n",
      "        [1.1176],\n",
      "        [1.1186],\n",
      "        [1.1185],\n",
      "        [1.0973],\n",
      "        [1.0744],\n",
      "        [1.0699],\n",
      "        [1.1016],\n",
      "        [1.1154],\n",
      "        [1.0715],\n",
      "        [1.1177],\n",
      "        [1.0714],\n",
      "        [1.1060],\n",
      "        [1.1028],\n",
      "        [1.0930],\n",
      "        [1.1032],\n",
      "        [1.1180],\n",
      "        [1.0769],\n",
      "        [1.0651],\n",
      "        [1.0927],\n",
      "        [1.0819],\n",
      "        [1.0513],\n",
      "        [1.0883],\n",
      "        [1.0957],\n",
      "        [1.0969],\n",
      "        [1.0439],\n",
      "        [1.0542],\n",
      "        [1.0929],\n",
      "        [1.0659],\n",
      "        [1.0865],\n",
      "        [1.0747],\n",
      "        [1.0673],\n",
      "        [1.1106],\n",
      "        [1.0833],\n",
      "        [1.0894],\n",
      "        [1.1068],\n",
      "        [1.0814],\n",
      "        [1.0658],\n",
      "        [1.0608],\n",
      "        [1.1219],\n",
      "        [1.0801],\n",
      "        [1.1056],\n",
      "        [1.0881],\n",
      "        [1.0388],\n",
      "        [1.1188],\n",
      "        [1.0909],\n",
      "        [1.0997],\n",
      "        [1.1079],\n",
      "        [1.1136],\n",
      "        [1.1144],\n",
      "        [1.1142],\n",
      "        [1.0563],\n",
      "        [1.0897],\n",
      "        [1.1067],\n",
      "        [1.0880],\n",
      "        [1.1072],\n",
      "        [1.0936],\n",
      "        [1.0424],\n",
      "        [1.0684],\n",
      "        [1.1152],\n",
      "        [1.0954],\n",
      "        [1.0806],\n",
      "        [1.0565]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0989],\n",
      "        [1.0973],\n",
      "        [1.0509],\n",
      "        [1.0761],\n",
      "        [1.0868],\n",
      "        [1.0800],\n",
      "        [1.0279],\n",
      "        [1.0241],\n",
      "        [1.1065],\n",
      "        [1.0960],\n",
      "        [1.0991],\n",
      "        [1.0715],\n",
      "        [1.0930],\n",
      "        [1.1036],\n",
      "        [1.1113],\n",
      "        [1.0991],\n",
      "        [1.1078],\n",
      "        [1.1047],\n",
      "        [1.1065],\n",
      "        [1.1082],\n",
      "        [1.0879],\n",
      "        [1.0899],\n",
      "        [1.0697],\n",
      "        [1.1078],\n",
      "        [1.0636],\n",
      "        [1.0455],\n",
      "        [1.0917],\n",
      "        [1.0992],\n",
      "        [1.1039],\n",
      "        [1.1088],\n",
      "        [1.0814],\n",
      "        [1.0470],\n",
      "        [1.0865],\n",
      "        [1.0874],\n",
      "        [1.1108],\n",
      "        [1.0979],\n",
      "        [1.0859],\n",
      "        [1.0672],\n",
      "        [1.0949],\n",
      "        [1.1022],\n",
      "        [1.0843],\n",
      "        [1.0839],\n",
      "        [1.1029],\n",
      "        [1.0458],\n",
      "        [1.0443],\n",
      "        [1.0793],\n",
      "        [1.0615],\n",
      "        [1.1127],\n",
      "        [1.0935],\n",
      "        [1.0731],\n",
      "        [1.0330],\n",
      "        [1.0480],\n",
      "        [1.0951],\n",
      "        [1.1094],\n",
      "        [1.0355],\n",
      "        [1.0792],\n",
      "        [1.1007],\n",
      "        [1.0633],\n",
      "        [1.1003],\n",
      "        [1.0801],\n",
      "        [1.0978],\n",
      "        [1.0656],\n",
      "        [1.0658],\n",
      "        [1.0346],\n",
      "        [1.1104],\n",
      "        [1.1004],\n",
      "        [1.0968],\n",
      "        [1.0910],\n",
      "        [1.0686],\n",
      "        [1.0992],\n",
      "        [1.0963],\n",
      "        [1.0553],\n",
      "        [1.0655],\n",
      "        [1.0767],\n",
      "        [1.0711],\n",
      "        [1.0841],\n",
      "        [1.0763],\n",
      "        [1.0885],\n",
      "        [1.1090],\n",
      "        [1.0551],\n",
      "        [1.1042],\n",
      "        [1.1077],\n",
      "        [1.0988],\n",
      "        [1.1055],\n",
      "        [1.0731],\n",
      "        [1.0899],\n",
      "        [1.0639],\n",
      "        [1.0550],\n",
      "        [1.0862],\n",
      "        [1.1004],\n",
      "        [1.1030],\n",
      "        [1.0820],\n",
      "        [1.0800],\n",
      "        [1.0950],\n",
      "        [1.1038],\n",
      "        [1.0770],\n",
      "        [1.0953],\n",
      "        [1.0918],\n",
      "        [1.1101],\n",
      "        [1.1089],\n",
      "        [1.1040],\n",
      "        [1.1045],\n",
      "        [1.0811],\n",
      "        [1.0563],\n",
      "        [1.0812],\n",
      "        [1.0715],\n",
      "        [1.1065],\n",
      "        [1.0452],\n",
      "        [1.0925],\n",
      "        [1.1056],\n",
      "        [1.0960],\n",
      "        [1.0730],\n",
      "        [1.0503],\n",
      "        [1.0896],\n",
      "        [1.1068],\n",
      "        [1.0751],\n",
      "        [1.0908],\n",
      "        [1.0985],\n",
      "        [1.0948],\n",
      "        [1.0982],\n",
      "        [1.0977],\n",
      "        [1.1036],\n",
      "        [1.0637],\n",
      "        [1.1009],\n",
      "        [1.0803],\n",
      "        [1.0908],\n",
      "        [1.0981],\n",
      "        [1.0537]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0992],\n",
      "        [1.0506],\n",
      "        [1.0995],\n",
      "        [1.1118],\n",
      "        [1.1022],\n",
      "        [1.0841],\n",
      "        [1.0762],\n",
      "        [1.1085],\n",
      "        [1.0442],\n",
      "        [1.0804],\n",
      "        [1.1053],\n",
      "        [1.0847],\n",
      "        [1.0848],\n",
      "        [1.0731],\n",
      "        [1.0862],\n",
      "        [1.0573],\n",
      "        [1.0912],\n",
      "        [1.0970],\n",
      "        [1.0848],\n",
      "        [1.0707],\n",
      "        [1.0880],\n",
      "        [1.0964],\n",
      "        [1.0854],\n",
      "        [1.0687],\n",
      "        [1.0873],\n",
      "        [1.0883],\n",
      "        [1.0883],\n",
      "        [1.0492],\n",
      "        [1.1084],\n",
      "        [1.0759],\n",
      "        [1.0819],\n",
      "        [1.0983],\n",
      "        [1.0694],\n",
      "        [1.0756],\n",
      "        [1.0924],\n",
      "        [1.1085],\n",
      "        [1.0864],\n",
      "        [1.0904],\n",
      "        [1.0895],\n",
      "        [1.0715],\n",
      "        [1.1061],\n",
      "        [1.0862],\n",
      "        [1.0703],\n",
      "        [1.0579],\n",
      "        [1.0863],\n",
      "        [1.0439],\n",
      "        [1.0883],\n",
      "        [1.1011],\n",
      "        [1.0751],\n",
      "        [1.0646],\n",
      "        [1.0716],\n",
      "        [1.0523],\n",
      "        [1.0967],\n",
      "        [1.1016],\n",
      "        [1.0907],\n",
      "        [1.0673],\n",
      "        [1.0641],\n",
      "        [1.0818],\n",
      "        [1.0904],\n",
      "        [1.0557],\n",
      "        [1.0663],\n",
      "        [1.0929],\n",
      "        [1.0961],\n",
      "        [1.0905],\n",
      "        [1.1087],\n",
      "        [1.0536],\n",
      "        [1.0907],\n",
      "        [1.0837],\n",
      "        [1.0921],\n",
      "        [1.0976],\n",
      "        [1.0502],\n",
      "        [1.0855],\n",
      "        [1.0761],\n",
      "        [1.0950],\n",
      "        [1.0505],\n",
      "        [1.1067],\n",
      "        [1.0856],\n",
      "        [1.0898],\n",
      "        [1.0922],\n",
      "        [1.0938],\n",
      "        [1.0997],\n",
      "        [1.1058],\n",
      "        [1.0921],\n",
      "        [1.0663],\n",
      "        [1.0489],\n",
      "        [1.1014],\n",
      "        [1.0744],\n",
      "        [1.1055],\n",
      "        [1.0939],\n",
      "        [1.0954],\n",
      "        [1.0837],\n",
      "        [1.0564],\n",
      "        [1.0578],\n",
      "        [1.0903],\n",
      "        [1.0935],\n",
      "        [1.0562],\n",
      "        [1.0622],\n",
      "        [1.0655],\n",
      "        [1.0856],\n",
      "        [1.0913],\n",
      "        [1.0460],\n",
      "        [1.0828],\n",
      "        [1.0694],\n",
      "        [1.0872],\n",
      "        [1.0918],\n",
      "        [1.0425],\n",
      "        [1.0536],\n",
      "        [1.1085],\n",
      "        [1.0473],\n",
      "        [1.0525],\n",
      "        [1.0533],\n",
      "        [1.0932],\n",
      "        [1.0993],\n",
      "        [1.0897],\n",
      "        [1.0656],\n",
      "        [1.1063],\n",
      "        [1.0869],\n",
      "        [1.0875],\n",
      "        [1.0886],\n",
      "        [1.0938],\n",
      "        [1.0913],\n",
      "        [1.0839],\n",
      "        [1.0976],\n",
      "        [1.0687],\n",
      "        [1.0754],\n",
      "        [1.1050],\n",
      "        [1.0627],\n",
      "        [1.0617]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0916],\n",
      "        [1.0812],\n",
      "        [1.0900],\n",
      "        [1.0194],\n",
      "        [1.0815],\n",
      "        [1.0971],\n",
      "        [1.0717],\n",
      "        [1.0864],\n",
      "        [1.1031],\n",
      "        [1.0853],\n",
      "        [1.0629],\n",
      "        [1.0831],\n",
      "        [1.0431],\n",
      "        [1.0690],\n",
      "        [1.1054],\n",
      "        [1.0777],\n",
      "        [1.0720],\n",
      "        [1.0804],\n",
      "        [1.0692],\n",
      "        [1.0733],\n",
      "        [1.0917],\n",
      "        [1.0487],\n",
      "        [1.0577],\n",
      "        [1.1029],\n",
      "        [0.5376],\n",
      "        [1.0707],\n",
      "        [1.0734],\n",
      "        [1.0982],\n",
      "        [1.0873],\n",
      "        [1.0983],\n",
      "        [1.1041],\n",
      "        [1.0922],\n",
      "        [1.0860],\n",
      "        [1.1043],\n",
      "        [1.0525],\n",
      "        [1.0816],\n",
      "        [1.0761],\n",
      "        [1.1047],\n",
      "        [1.0655],\n",
      "        [1.0699],\n",
      "        [1.0946],\n",
      "        [1.0731],\n",
      "        [1.0229],\n",
      "        [1.1053],\n",
      "        [1.0680],\n",
      "        [1.0884],\n",
      "        [1.1035],\n",
      "        [1.1030],\n",
      "        [1.0825],\n",
      "        [1.0358],\n",
      "        [1.0759],\n",
      "        [1.0567],\n",
      "        [1.1005],\n",
      "        [1.0763],\n",
      "        [1.0790],\n",
      "        [1.0852],\n",
      "        [1.0978],\n",
      "        [1.0872],\n",
      "        [1.0959],\n",
      "        [1.0815],\n",
      "        [1.0455],\n",
      "        [1.0908],\n",
      "        [1.0952],\n",
      "        [1.1021],\n",
      "        [1.1057],\n",
      "        [1.0943],\n",
      "        [1.0759],\n",
      "        [1.0824],\n",
      "        [1.0785],\n",
      "        [1.0411],\n",
      "        [1.0697],\n",
      "        [1.1023],\n",
      "        [1.0354],\n",
      "        [1.0761],\n",
      "        [1.0733],\n",
      "        [1.0434],\n",
      "        [1.0809],\n",
      "        [1.1017],\n",
      "        [1.0786],\n",
      "        [1.0306],\n",
      "        [1.0836],\n",
      "        [1.0699],\n",
      "        [1.0334],\n",
      "        [1.0943],\n",
      "        [1.1039],\n",
      "        [1.0738],\n",
      "        [1.0468],\n",
      "        [1.0661],\n",
      "        [1.0930],\n",
      "        [1.0898],\n",
      "        [1.1002],\n",
      "        [1.0659],\n",
      "        [1.0969],\n",
      "        [1.0385],\n",
      "        [1.0582],\n",
      "        [0.9756],\n",
      "        [1.0725],\n",
      "        [1.0910],\n",
      "        [1.0709],\n",
      "        [1.0787],\n",
      "        [1.0705],\n",
      "        [1.0743],\n",
      "        [1.0911],\n",
      "        [1.0801],\n",
      "        [1.0939],\n",
      "        [1.0972],\n",
      "        [1.1073],\n",
      "        [1.0830],\n",
      "        [1.0510],\n",
      "        [1.0550],\n",
      "        [1.1029],\n",
      "        [1.0342],\n",
      "        [1.0759],\n",
      "        [1.0560],\n",
      "        [1.0447],\n",
      "        [1.0814],\n",
      "        [1.0945],\n",
      "        [1.0811],\n",
      "        [1.0690],\n",
      "        [1.0720],\n",
      "        [1.1056],\n",
      "        [1.0558],\n",
      "        [1.0968],\n",
      "        [1.0795],\n",
      "        [1.0585],\n",
      "        [1.1048],\n",
      "        [1.0685],\n",
      "        [1.0451]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0776],\n",
      "        [1.0655],\n",
      "        [1.0327],\n",
      "        [1.1006],\n",
      "        [1.0894],\n",
      "        [1.0655],\n",
      "        [1.0994],\n",
      "        [1.1021],\n",
      "        [1.0858],\n",
      "        [1.0511],\n",
      "        [1.0660],\n",
      "        [1.0895],\n",
      "        [1.0589],\n",
      "        [1.1028],\n",
      "        [1.1022],\n",
      "        [1.0762],\n",
      "        [1.0707],\n",
      "        [1.0938],\n",
      "        [1.0826],\n",
      "        [1.0706],\n",
      "        [1.0766],\n",
      "        [1.0675],\n",
      "        [1.0470],\n",
      "        [1.0785],\n",
      "        [1.0860],\n",
      "        [1.0385],\n",
      "        [1.0648],\n",
      "        [1.1033],\n",
      "        [1.0472],\n",
      "        [1.1002],\n",
      "        [1.0843],\n",
      "        [1.0424],\n",
      "        [1.0779],\n",
      "        [1.0909],\n",
      "        [1.0469],\n",
      "        [1.0651],\n",
      "        [1.0702],\n",
      "        [1.0752],\n",
      "        [1.0554],\n",
      "        [1.0821],\n",
      "        [1.0779],\n",
      "        [1.0899],\n",
      "        [1.0696],\n",
      "        [1.0441],\n",
      "        [1.1025],\n",
      "        [1.1056],\n",
      "        [1.0499],\n",
      "        [1.0378],\n",
      "        [1.0942],\n",
      "        [1.0882],\n",
      "        [1.0881],\n",
      "        [1.0771],\n",
      "        [1.0728],\n",
      "        [1.0770],\n",
      "        [1.0922],\n",
      "        [1.0993],\n",
      "        [1.0779],\n",
      "        [1.0187],\n",
      "        [1.0891],\n",
      "        [1.0777],\n",
      "        [1.1005],\n",
      "        [1.0586],\n",
      "        [1.0764],\n",
      "        [1.0547],\n",
      "        [1.0828],\n",
      "        [1.0833],\n",
      "        [1.0937],\n",
      "        [1.0789],\n",
      "        [1.0561],\n",
      "        [1.0843],\n",
      "        [1.0704],\n",
      "        [1.0486],\n",
      "        [1.0722],\n",
      "        [1.0801],\n",
      "        [1.1040],\n",
      "        [1.0458],\n",
      "        [1.0865],\n",
      "        [1.0211],\n",
      "        [1.1044],\n",
      "        [1.0303],\n",
      "        [1.0697],\n",
      "        [1.0415],\n",
      "        [1.0498],\n",
      "        [1.1016],\n",
      "        [1.0496],\n",
      "        [1.0423],\n",
      "        [1.0887],\n",
      "        [1.0643],\n",
      "        [1.0616],\n",
      "        [1.0362],\n",
      "        [1.0803],\n",
      "        [1.1017],\n",
      "        [1.0537],\n",
      "        [1.0652],\n",
      "        [1.0996],\n",
      "        [1.0920],\n",
      "        [1.0419],\n",
      "        [1.0628],\n",
      "        [1.0743],\n",
      "        [1.0155],\n",
      "        [1.0258],\n",
      "        [1.0924],\n",
      "        [1.0738],\n",
      "        [1.0906],\n",
      "        [1.0992],\n",
      "        [1.0509],\n",
      "        [1.0174],\n",
      "        [1.0722],\n",
      "        [1.0490],\n",
      "        [1.0948],\n",
      "        [1.0631],\n",
      "        [1.0748],\n",
      "        [1.0640],\n",
      "        [1.1022],\n",
      "        [1.1015],\n",
      "        [1.0792],\n",
      "        [1.0718],\n",
      "        [1.0568],\n",
      "        [1.0595],\n",
      "        [1.0623],\n",
      "        [1.0759],\n",
      "        [1.0852],\n",
      "        [1.0709],\n",
      "        [1.0896],\n",
      "        [1.0581],\n",
      "        [1.1039],\n",
      "        [1.0756],\n",
      "        [1.1075]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0862],\n",
      "        [1.0753],\n",
      "        [1.0587],\n",
      "        [1.0994]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  18 | lr 0.00100 train_loss 2.12696 | val_loss 2.29695 | val_rmse 1.51557\n",
      "tensor([[1.0889],\n",
      "        [1.0495],\n",
      "        [1.1005],\n",
      "        [1.0546],\n",
      "        [1.0930],\n",
      "        [1.0749],\n",
      "        [1.0912],\n",
      "        [1.0448],\n",
      "        [1.0930],\n",
      "        [0.1589],\n",
      "        [1.0823],\n",
      "        [1.0790],\n",
      "        [1.0877],\n",
      "        [1.0992],\n",
      "        [1.0755],\n",
      "        [1.1031],\n",
      "        [1.0784],\n",
      "        [1.1028],\n",
      "        [1.0593],\n",
      "        [1.0745],\n",
      "        [1.0572],\n",
      "        [1.0428],\n",
      "        [1.0687],\n",
      "        [1.0693],\n",
      "        [1.0724],\n",
      "        [1.0410],\n",
      "        [1.0708],\n",
      "        [1.0824],\n",
      "        [1.0994],\n",
      "        [1.0879],\n",
      "        [1.0642],\n",
      "        [1.0920],\n",
      "        [1.0867],\n",
      "        [1.0856],\n",
      "        [1.0922],\n",
      "        [1.0819],\n",
      "        [1.0769],\n",
      "        [1.0850],\n",
      "        [1.0766],\n",
      "        [1.1020],\n",
      "        [1.0909],\n",
      "        [1.0989],\n",
      "        [1.0647],\n",
      "        [1.0464],\n",
      "        [1.0779],\n",
      "        [1.0814],\n",
      "        [1.0563],\n",
      "        [1.0573],\n",
      "        [1.0240],\n",
      "        [1.0786],\n",
      "        [1.0760],\n",
      "        [1.0837],\n",
      "        [1.0937],\n",
      "        [1.0900],\n",
      "        [1.0312],\n",
      "        [1.0780],\n",
      "        [1.0822],\n",
      "        [1.1007],\n",
      "        [1.0774],\n",
      "        [1.1030],\n",
      "        [1.1019],\n",
      "        [1.0978],\n",
      "        [1.0761],\n",
      "        [1.0583],\n",
      "        [1.0748],\n",
      "        [1.0852],\n",
      "        [1.0808],\n",
      "        [1.0596],\n",
      "        [1.0737],\n",
      "        [1.0821],\n",
      "        [1.1007],\n",
      "        [1.0927],\n",
      "        [1.0441],\n",
      "        [1.0728],\n",
      "        [1.0315],\n",
      "        [1.0600],\n",
      "        [1.0900],\n",
      "        [1.0662],\n",
      "        [1.0864],\n",
      "        [1.0515],\n",
      "        [1.0711],\n",
      "        [1.0907],\n",
      "        [1.0709],\n",
      "        [1.0478],\n",
      "        [1.0932],\n",
      "        [1.0975],\n",
      "        [1.0897],\n",
      "        [1.0673],\n",
      "        [1.1029],\n",
      "        [1.0514],\n",
      "        [1.0682],\n",
      "        [1.0948],\n",
      "        [1.0514],\n",
      "        [1.0956],\n",
      "        [1.0962],\n",
      "        [1.0854],\n",
      "        [1.0590],\n",
      "        [1.0863],\n",
      "        [1.0988],\n",
      "        [1.0262],\n",
      "        [1.0757],\n",
      "        [1.0740],\n",
      "        [1.0900],\n",
      "        [1.0890],\n",
      "        [1.0787],\n",
      "        [1.1012],\n",
      "        [1.0869],\n",
      "        [1.1005],\n",
      "        [1.0922],\n",
      "        [1.0755],\n",
      "        [1.0499],\n",
      "        [1.0673],\n",
      "        [1.0892],\n",
      "        [1.0820],\n",
      "        [1.0901],\n",
      "        [1.0507],\n",
      "        [1.1027],\n",
      "        [1.0919],\n",
      "        [1.0984],\n",
      "        [1.0987],\n",
      "        [1.0820],\n",
      "        [1.0856],\n",
      "        [1.0704],\n",
      "        [1.1005],\n",
      "        [1.0513],\n",
      "        [1.0861],\n",
      "        [1.0781],\n",
      "        [1.0433]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0926],\n",
      "        [1.0906],\n",
      "        [1.0869],\n",
      "        [1.0749],\n",
      "        [1.0879],\n",
      "        [1.0515],\n",
      "        [1.0749],\n",
      "        [1.0960],\n",
      "        [1.0902],\n",
      "        [1.0860],\n",
      "        [1.0560],\n",
      "        [1.0834],\n",
      "        [1.0887],\n",
      "        [1.0439],\n",
      "        [1.0922],\n",
      "        [1.0708],\n",
      "        [1.0771],\n",
      "        [1.0800],\n",
      "        [1.0559],\n",
      "        [1.0863],\n",
      "        [1.0627],\n",
      "        [1.0954],\n",
      "        [1.0723],\n",
      "        [1.0650],\n",
      "        [1.0799],\n",
      "        [1.0413],\n",
      "        [1.0320],\n",
      "        [1.0534],\n",
      "        [1.0447],\n",
      "        [1.0527],\n",
      "        [1.0683],\n",
      "        [1.0807],\n",
      "        [1.0426],\n",
      "        [1.0701],\n",
      "        [1.0677],\n",
      "        [1.0666],\n",
      "        [1.0859],\n",
      "        [1.0920],\n",
      "        [1.0772],\n",
      "        [1.1005],\n",
      "        [1.0332],\n",
      "        [1.0882],\n",
      "        [1.0749],\n",
      "        [1.0981],\n",
      "        [1.0871],\n",
      "        [1.0720],\n",
      "        [1.0964],\n",
      "        [1.0900],\n",
      "        [1.0544],\n",
      "        [1.0761],\n",
      "        [1.0952],\n",
      "        [1.0629],\n",
      "        [1.1005],\n",
      "        [1.0274],\n",
      "        [1.0511],\n",
      "        [1.0893],\n",
      "        [1.0970],\n",
      "        [1.0758],\n",
      "        [1.0588],\n",
      "        [1.0458],\n",
      "        [1.0792],\n",
      "        [1.1015],\n",
      "        [1.0685],\n",
      "        [1.0363],\n",
      "        [1.0769],\n",
      "        [1.0950],\n",
      "        [1.0214],\n",
      "        [1.0884],\n",
      "        [1.0709],\n",
      "        [1.0737],\n",
      "        [1.0543],\n",
      "        [1.1022],\n",
      "        [1.0629],\n",
      "        [1.1012],\n",
      "        [1.0436],\n",
      "        [1.0671],\n",
      "        [1.0624],\n",
      "        [1.0662],\n",
      "        [1.0662],\n",
      "        [1.0881],\n",
      "        [1.0981],\n",
      "        [1.0731],\n",
      "        [1.0709],\n",
      "        [1.0718],\n",
      "        [1.1015],\n",
      "        [1.0640],\n",
      "        [1.0626],\n",
      "        [1.0535],\n",
      "        [1.0542],\n",
      "        [1.0561],\n",
      "        [1.0970],\n",
      "        [1.0679],\n",
      "        [1.0892],\n",
      "        [1.0518],\n",
      "        [1.0655],\n",
      "        [1.0692],\n",
      "        [1.0733],\n",
      "        [1.0865],\n",
      "        [1.0678],\n",
      "        [1.0525],\n",
      "        [1.0814],\n",
      "        [1.0916],\n",
      "        [1.1015],\n",
      "        [1.0647],\n",
      "        [1.1025],\n",
      "        [1.0706],\n",
      "        [1.0892],\n",
      "        [1.0805],\n",
      "        [1.0985],\n",
      "        [1.0949],\n",
      "        [1.0415],\n",
      "        [1.0864],\n",
      "        [1.0564],\n",
      "        [1.0878],\n",
      "        [1.0334],\n",
      "        [1.0922],\n",
      "        [1.0750],\n",
      "        [1.0535],\n",
      "        [1.0939],\n",
      "        [1.0518],\n",
      "        [1.0713],\n",
      "        [1.0825],\n",
      "        [1.0484],\n",
      "        [1.0934],\n",
      "        [1.0544],\n",
      "        [1.0759],\n",
      "        [1.0553],\n",
      "        [1.0759]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0654],\n",
      "        [1.0665],\n",
      "        [1.0719],\n",
      "        [1.0724],\n",
      "        [1.0326],\n",
      "        [1.0834],\n",
      "        [1.0758],\n",
      "        [1.0638],\n",
      "        [1.0689],\n",
      "        [1.0744],\n",
      "        [1.0716],\n",
      "        [1.0789],\n",
      "        [1.0814],\n",
      "        [1.0453],\n",
      "        [1.0778],\n",
      "        [1.0809],\n",
      "        [1.0637],\n",
      "        [1.0764],\n",
      "        [1.0765],\n",
      "        [1.0687],\n",
      "        [1.0698],\n",
      "        [1.0787],\n",
      "        [1.0777],\n",
      "        [1.0303],\n",
      "        [1.0920],\n",
      "        [1.0696],\n",
      "        [1.0884],\n",
      "        [1.0640],\n",
      "        [1.0914],\n",
      "        [1.0626],\n",
      "        [1.0992],\n",
      "        [1.0484],\n",
      "        [1.0659],\n",
      "        [1.0993],\n",
      "        [1.0857],\n",
      "        [1.0755],\n",
      "        [1.0548],\n",
      "        [1.0592],\n",
      "        [1.0738],\n",
      "        [1.0979],\n",
      "        [1.0768],\n",
      "        [1.0608],\n",
      "        [1.0753],\n",
      "        [1.0612],\n",
      "        [1.0426],\n",
      "        [1.0946],\n",
      "        [1.0263],\n",
      "        [1.0982],\n",
      "        [1.0724],\n",
      "        [1.0845],\n",
      "        [1.0398],\n",
      "        [1.0862],\n",
      "        [1.0489],\n",
      "        [1.0583],\n",
      "        [1.0945],\n",
      "        [1.0710],\n",
      "        [1.0261],\n",
      "        [1.0751],\n",
      "        [1.0406],\n",
      "        [1.0877],\n",
      "        [1.0924],\n",
      "        [1.0734],\n",
      "        [1.0811],\n",
      "        [1.0957],\n",
      "        [1.0859],\n",
      "        [1.1051],\n",
      "        [1.0903],\n",
      "        [1.0649],\n",
      "        [1.0850],\n",
      "        [1.0747],\n",
      "        [1.0894],\n",
      "        [1.0686],\n",
      "        [1.0946],\n",
      "        [1.0730],\n",
      "        [1.0809],\n",
      "        [1.0785],\n",
      "        [1.0539],\n",
      "        [1.0977],\n",
      "        [1.0578],\n",
      "        [1.0714],\n",
      "        [1.0427],\n",
      "        [1.0736],\n",
      "        [1.0663],\n",
      "        [1.0875],\n",
      "        [1.0450],\n",
      "        [1.0902],\n",
      "        [1.0792],\n",
      "        [1.0840],\n",
      "        [1.0806],\n",
      "        [1.0900],\n",
      "        [1.0937],\n",
      "        [1.0653],\n",
      "        [1.0501],\n",
      "        [1.0775],\n",
      "        [1.0588],\n",
      "        [1.0453],\n",
      "        [1.0408],\n",
      "        [1.0416],\n",
      "        [1.0136],\n",
      "        [1.0935],\n",
      "        [1.0909],\n",
      "        [1.0798],\n",
      "        [1.0747],\n",
      "        [1.0767],\n",
      "        [1.0956],\n",
      "        [1.0697],\n",
      "        [1.0652],\n",
      "        [1.0842],\n",
      "        [1.0840],\n",
      "        [1.0836],\n",
      "        [1.0675],\n",
      "        [1.0651],\n",
      "        [1.0770],\n",
      "        [1.0483],\n",
      "        [1.0860],\n",
      "        [1.0623],\n",
      "        [1.0685],\n",
      "        [1.0951],\n",
      "        [1.0372],\n",
      "        [1.0862],\n",
      "        [1.0366],\n",
      "        [1.0373],\n",
      "        [1.0478],\n",
      "        [1.0614],\n",
      "        [1.0595],\n",
      "        [1.0849],\n",
      "        [1.0645],\n",
      "        [1.0676]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0668],\n",
      "        [1.0228],\n",
      "        [1.0430],\n",
      "        [1.0278],\n",
      "        [1.0984],\n",
      "        [1.0794],\n",
      "        [1.0567],\n",
      "        [1.0423],\n",
      "        [1.0245],\n",
      "        [1.0461],\n",
      "        [1.0873],\n",
      "        [1.0950],\n",
      "        [1.0390],\n",
      "        [1.0425],\n",
      "        [1.0592],\n",
      "        [1.0603],\n",
      "        [1.0432],\n",
      "        [1.0861],\n",
      "        [1.0620],\n",
      "        [1.0836],\n",
      "        [1.0143],\n",
      "        [1.0416],\n",
      "        [1.0941],\n",
      "        [1.0963],\n",
      "        [1.0912],\n",
      "        [1.0473],\n",
      "        [1.0836],\n",
      "        [1.0906],\n",
      "        [1.0625],\n",
      "        [1.0463],\n",
      "        [1.0490],\n",
      "        [1.0609],\n",
      "        [1.0841],\n",
      "        [1.0424],\n",
      "        [1.0843],\n",
      "        [1.0348],\n",
      "        [1.0732],\n",
      "        [1.0400],\n",
      "        [1.0438],\n",
      "        [1.0949],\n",
      "        [1.0929],\n",
      "        [1.0478],\n",
      "        [1.0648],\n",
      "        [1.0759],\n",
      "        [1.0788],\n",
      "        [1.0536],\n",
      "        [1.0514],\n",
      "        [1.1021],\n",
      "        [1.0963],\n",
      "        [1.0536],\n",
      "        [1.0949],\n",
      "        [0.0663],\n",
      "        [1.0635],\n",
      "        [1.0795],\n",
      "        [1.0537],\n",
      "        [1.0651],\n",
      "        [1.0929],\n",
      "        [1.0727],\n",
      "        [1.0166],\n",
      "        [1.0581],\n",
      "        [1.0708],\n",
      "        [1.0434],\n",
      "        [1.0727],\n",
      "        [1.0961],\n",
      "        [1.0720],\n",
      "        [1.0516],\n",
      "        [1.0808],\n",
      "        [1.0847],\n",
      "        [1.0722],\n",
      "        [1.0793],\n",
      "        [1.0496],\n",
      "        [1.0280],\n",
      "        [1.0788],\n",
      "        [1.0863],\n",
      "        [1.0559],\n",
      "        [1.0894],\n",
      "        [1.0959],\n",
      "        [1.0770],\n",
      "        [1.0757],\n",
      "        [1.0455],\n",
      "        [1.0945],\n",
      "        [1.0864],\n",
      "        [1.0864],\n",
      "        [1.0790],\n",
      "        [1.0917],\n",
      "        [1.0841],\n",
      "        [1.0409],\n",
      "        [1.0727],\n",
      "        [1.0848],\n",
      "        [1.0790],\n",
      "        [1.0766],\n",
      "        [1.0435],\n",
      "        [1.0706],\n",
      "        [1.0596],\n",
      "        [1.0877],\n",
      "        [1.0888],\n",
      "        [1.0570],\n",
      "        [1.0689],\n",
      "        [1.0596],\n",
      "        [1.0990],\n",
      "        [1.0636],\n",
      "        [1.0860],\n",
      "        [1.0586],\n",
      "        [1.0800],\n",
      "        [1.0740],\n",
      "        [1.0920],\n",
      "        [1.0270],\n",
      "        [1.0983],\n",
      "        [1.0727],\n",
      "        [1.0597],\n",
      "        [1.0819],\n",
      "        [1.0851],\n",
      "        [1.0499],\n",
      "        [1.0629],\n",
      "        [1.0612],\n",
      "        [1.0634],\n",
      "        [1.0989],\n",
      "        [1.0514],\n",
      "        [1.1002],\n",
      "        [1.0985],\n",
      "        [1.0485],\n",
      "        [1.0920],\n",
      "        [1.0809],\n",
      "        [1.0434],\n",
      "        [1.0633],\n",
      "        [1.0610],\n",
      "        [1.0659],\n",
      "        [1.0702]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0332],\n",
      "        [1.0594],\n",
      "        [1.0470],\n",
      "        [1.0714],\n",
      "        [1.0793],\n",
      "        [1.0434],\n",
      "        [1.0884],\n",
      "        [1.0825],\n",
      "        [1.0745],\n",
      "        [1.0634],\n",
      "        [1.0694],\n",
      "        [1.0866],\n",
      "        [1.0836],\n",
      "        [1.0721],\n",
      "        [1.0771],\n",
      "        [1.0648],\n",
      "        [1.1032],\n",
      "        [1.0694],\n",
      "        [1.0898],\n",
      "        [1.0773],\n",
      "        [1.0744],\n",
      "        [1.0539],\n",
      "        [1.0344],\n",
      "        [1.0781],\n",
      "        [1.0718],\n",
      "        [1.0921],\n",
      "        [1.0905],\n",
      "        [1.0427],\n",
      "        [1.0863],\n",
      "        [1.0646],\n",
      "        [1.0982],\n",
      "        [1.0912],\n",
      "        [1.0519],\n",
      "        [1.0621],\n",
      "        [1.0498],\n",
      "        [1.0198],\n",
      "        [1.0325],\n",
      "        [1.0611],\n",
      "        [1.0898],\n",
      "        [1.0624],\n",
      "        [1.0673],\n",
      "        [1.0659],\n",
      "        [1.0875],\n",
      "        [1.0768],\n",
      "        [1.0856],\n",
      "        [1.0973],\n",
      "        [1.0923],\n",
      "        [1.0771],\n",
      "        [1.0551],\n",
      "        [1.0759],\n",
      "        [1.0844],\n",
      "        [1.0862],\n",
      "        [1.0706],\n",
      "        [1.0644],\n",
      "        [1.0774],\n",
      "        [1.0878],\n",
      "        [1.0838],\n",
      "        [1.0425],\n",
      "        [1.0875],\n",
      "        [1.0763],\n",
      "        [1.0646],\n",
      "        [1.0948],\n",
      "        [1.0758],\n",
      "        [1.0937],\n",
      "        [1.0490],\n",
      "        [1.0994],\n",
      "        [1.0652],\n",
      "        [1.0841],\n",
      "        [1.0997],\n",
      "        [1.0645],\n",
      "        [1.0905],\n",
      "        [1.0633],\n",
      "        [1.1004],\n",
      "        [1.1015],\n",
      "        [1.0704],\n",
      "        [1.0409],\n",
      "        [1.0868],\n",
      "        [1.0633],\n",
      "        [1.0863],\n",
      "        [1.0540],\n",
      "        [1.0989],\n",
      "        [1.0882],\n",
      "        [1.0649],\n",
      "        [1.0980],\n",
      "        [1.0976],\n",
      "        [1.0871],\n",
      "        [1.0873],\n",
      "        [1.0884],\n",
      "        [1.0505],\n",
      "        [1.0897],\n",
      "        [1.0776],\n",
      "        [1.0889],\n",
      "        [1.0567],\n",
      "        [1.0876],\n",
      "        [1.0826],\n",
      "        [1.0638],\n",
      "        [1.0591],\n",
      "        [1.0736],\n",
      "        [1.0631],\n",
      "        [1.0874],\n",
      "        [1.0500],\n",
      "        [1.0704],\n",
      "        [1.0595],\n",
      "        [1.0802],\n",
      "        [1.0621],\n",
      "        [1.0639],\n",
      "        [1.0226],\n",
      "        [1.0561],\n",
      "        [1.0780],\n",
      "        [1.0969],\n",
      "        [1.0892],\n",
      "        [1.0930],\n",
      "        [1.0610],\n",
      "        [1.0313],\n",
      "        [1.0966],\n",
      "        [1.0654],\n",
      "        [1.0774],\n",
      "        [1.0875],\n",
      "        [1.0329],\n",
      "        [1.0471],\n",
      "        [1.0312],\n",
      "        [1.0834],\n",
      "        [1.0441],\n",
      "        [1.0346],\n",
      "        [1.0966],\n",
      "        [1.0845],\n",
      "        [1.0566],\n",
      "        [1.0394]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1022],\n",
      "        [1.0814],\n",
      "        [1.0715],\n",
      "        [1.0633],\n",
      "        [1.0554],\n",
      "        [1.0656],\n",
      "        [1.0820],\n",
      "        [1.0639],\n",
      "        [1.0704],\n",
      "        [1.0785],\n",
      "        [1.0758],\n",
      "        [1.0626],\n",
      "        [1.0729],\n",
      "        [1.0577],\n",
      "        [1.0579],\n",
      "        [1.0590],\n",
      "        [1.0468],\n",
      "        [1.0780],\n",
      "        [1.0915],\n",
      "        [1.0784],\n",
      "        [1.0377],\n",
      "        [1.0826],\n",
      "        [1.0847],\n",
      "        [1.0958],\n",
      "        [1.0693],\n",
      "        [1.0717],\n",
      "        [1.0870],\n",
      "        [1.0811],\n",
      "        [1.0746],\n",
      "        [1.0457],\n",
      "        [1.0596],\n",
      "        [1.0809],\n",
      "        [1.0328],\n",
      "        [1.0764],\n",
      "        [1.0582],\n",
      "        [1.0809],\n",
      "        [1.0755],\n",
      "        [1.0608],\n",
      "        [1.0525],\n",
      "        [1.0454],\n",
      "        [1.0702],\n",
      "        [1.0728],\n",
      "        [1.0878],\n",
      "        [1.0632],\n",
      "        [1.0834],\n",
      "        [1.0264],\n",
      "        [1.0589],\n",
      "        [1.0801],\n",
      "        [1.1000],\n",
      "        [1.0704],\n",
      "        [1.0363],\n",
      "        [1.0674],\n",
      "        [1.0858],\n",
      "        [1.0854],\n",
      "        [1.0933],\n",
      "        [1.0264],\n",
      "        [1.0776],\n",
      "        [1.0596],\n",
      "        [1.0676],\n",
      "        [1.0718],\n",
      "        [1.0900],\n",
      "        [1.0671],\n",
      "        [1.0600],\n",
      "        [1.0792],\n",
      "        [1.0935],\n",
      "        [1.0943],\n",
      "        [1.1039],\n",
      "        [1.0742],\n",
      "        [1.0432],\n",
      "        [1.0738],\n",
      "        [1.0770],\n",
      "        [1.0979],\n",
      "        [1.0691],\n",
      "        [1.0509],\n",
      "        [1.1036],\n",
      "        [1.0544],\n",
      "        [1.0643],\n",
      "        [1.0603],\n",
      "        [1.0755],\n",
      "        [1.0889],\n",
      "        [1.0329],\n",
      "        [1.1029],\n",
      "        [1.0772],\n",
      "        [1.0728],\n",
      "        [1.0731],\n",
      "        [1.0890],\n",
      "        [1.0626],\n",
      "        [1.0778],\n",
      "        [1.1021],\n",
      "        [1.0744],\n",
      "        [0.9706],\n",
      "        [1.0607],\n",
      "        [1.0667],\n",
      "        [1.0617],\n",
      "        [1.0836],\n",
      "        [1.0694],\n",
      "        [1.0795],\n",
      "        [1.0714],\n",
      "        [1.0639],\n",
      "        [1.0365],\n",
      "        [1.0898],\n",
      "        [1.0969],\n",
      "        [1.0606],\n",
      "        [1.0917],\n",
      "        [1.0725],\n",
      "        [1.0635],\n",
      "        [1.1010],\n",
      "        [1.0128],\n",
      "        [1.0980],\n",
      "        [1.0824],\n",
      "        [1.1004],\n",
      "        [1.0785],\n",
      "        [1.1009],\n",
      "        [1.0902],\n",
      "        [1.0952],\n",
      "        [1.0704],\n",
      "        [1.0984],\n",
      "        [1.0784],\n",
      "        [1.0646],\n",
      "        [1.0582],\n",
      "        [1.0230],\n",
      "        [1.0771],\n",
      "        [1.0981],\n",
      "        [1.0898],\n",
      "        [1.0569],\n",
      "        [1.0803],\n",
      "        [1.0977],\n",
      "        [1.0343]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0731],\n",
      "        [1.0931],\n",
      "        [1.0886],\n",
      "        [1.0271],\n",
      "        [1.0666],\n",
      "        [1.0863],\n",
      "        [1.0915],\n",
      "        [1.0839],\n",
      "        [1.0805],\n",
      "        [1.0872],\n",
      "        [1.0775],\n",
      "        [1.0814],\n",
      "        [1.0493],\n",
      "        [1.0829],\n",
      "        [1.0548],\n",
      "        [1.0431],\n",
      "        [1.0629],\n",
      "        [1.0848],\n",
      "        [1.0836],\n",
      "        [1.0831],\n",
      "        [1.0918],\n",
      "        [1.0839],\n",
      "        [1.0895],\n",
      "        [1.0762],\n",
      "        [1.0604],\n",
      "        [1.0894],\n",
      "        [1.0981],\n",
      "        [1.1008],\n",
      "        [1.1023],\n",
      "        [1.0943],\n",
      "        [1.0920],\n",
      "        [1.0873],\n",
      "        [1.1026],\n",
      "        [1.0828],\n",
      "        [1.0503],\n",
      "        [1.0870],\n",
      "        [1.0579],\n",
      "        [1.0988],\n",
      "        [1.0897],\n",
      "        [1.0871],\n",
      "        [1.0841],\n",
      "        [1.0977],\n",
      "        [1.0717],\n",
      "        [1.0961],\n",
      "        [1.0895],\n",
      "        [1.0819],\n",
      "        [1.0973],\n",
      "        [1.0662],\n",
      "        [1.0817],\n",
      "        [1.0879],\n",
      "        [1.0518],\n",
      "        [1.0672],\n",
      "        [1.0534],\n",
      "        [1.0862],\n",
      "        [1.0832],\n",
      "        [1.0808],\n",
      "        [1.0660],\n",
      "        [1.0955],\n",
      "        [1.0696],\n",
      "        [1.0702],\n",
      "        [1.0972],\n",
      "        [1.0889],\n",
      "        [1.0476],\n",
      "        [1.1030],\n",
      "        [1.0779],\n",
      "        [1.0642],\n",
      "        [1.0716],\n",
      "        [1.0225],\n",
      "        [1.0981],\n",
      "        [1.0654],\n",
      "        [1.0531],\n",
      "        [1.0535],\n",
      "        [1.0790],\n",
      "        [1.0984],\n",
      "        [1.1031],\n",
      "        [1.0834],\n",
      "        [1.0736],\n",
      "        [1.0620],\n",
      "        [1.0768],\n",
      "        [1.0792],\n",
      "        [1.0466],\n",
      "        [1.1015],\n",
      "        [1.0805],\n",
      "        [1.0795],\n",
      "        [1.0800],\n",
      "        [1.0909],\n",
      "        [1.0635],\n",
      "        [1.0964],\n",
      "        [1.0661],\n",
      "        [1.0786],\n",
      "        [1.0829],\n",
      "        [1.0818],\n",
      "        [1.0041],\n",
      "        [1.1011],\n",
      "        [1.0143],\n",
      "        [1.0697],\n",
      "        [1.0556],\n",
      "        [1.0745],\n",
      "        [1.0785],\n",
      "        [1.0917],\n",
      "        [1.0857],\n",
      "        [1.0325],\n",
      "        [1.0631],\n",
      "        [1.0924],\n",
      "        [1.0920],\n",
      "        [1.0675],\n",
      "        [1.0777],\n",
      "        [1.0729],\n",
      "        [0.9705],\n",
      "        [1.0623],\n",
      "        [1.0680],\n",
      "        [1.0704],\n",
      "        [1.0825],\n",
      "        [1.0884],\n",
      "        [1.0836],\n",
      "        [1.0758],\n",
      "        [1.0627],\n",
      "        [1.0730],\n",
      "        [1.0779],\n",
      "        [1.0802],\n",
      "        [1.0969],\n",
      "        [1.0777],\n",
      "        [1.1040],\n",
      "        [1.0805],\n",
      "        [1.0446],\n",
      "        [1.0778],\n",
      "        [1.0907],\n",
      "        [1.0883]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0945],\n",
      "        [1.1039],\n",
      "        [1.0866],\n",
      "        [1.0722]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  19 | lr 0.00100 train_loss 2.12443 | val_loss 2.29575 | val_rmse 1.51517\n",
      "tensor([[1.0742],\n",
      "        [1.0822],\n",
      "        [1.0874],\n",
      "        [1.1071],\n",
      "        [1.0649],\n",
      "        [1.0708],\n",
      "        [1.0946],\n",
      "        [1.0985],\n",
      "        [1.0336],\n",
      "        [1.0667],\n",
      "        [1.0559],\n",
      "        [1.0875],\n",
      "        [1.0391],\n",
      "        [1.0661],\n",
      "        [1.0910],\n",
      "        [1.0535],\n",
      "        [1.1021],\n",
      "        [1.0929],\n",
      "        [1.0792],\n",
      "        [1.0928],\n",
      "        [1.0487],\n",
      "        [1.0977],\n",
      "        [1.0833],\n",
      "        [1.0666],\n",
      "        [1.0946],\n",
      "        [1.1070],\n",
      "        [1.0734],\n",
      "        [1.0968],\n",
      "        [1.0902],\n",
      "        [1.0446],\n",
      "        [1.0719],\n",
      "        [1.0797],\n",
      "        [1.0924],\n",
      "        [1.0933],\n",
      "        [1.0844],\n",
      "        [1.0858],\n",
      "        [1.0846],\n",
      "        [1.0776],\n",
      "        [1.1070],\n",
      "        [1.0733],\n",
      "        [1.0359],\n",
      "        [1.0715],\n",
      "        [1.0652],\n",
      "        [1.0682],\n",
      "        [1.0970],\n",
      "        [1.0836],\n",
      "        [1.0554],\n",
      "        [1.0971],\n",
      "        [1.1058],\n",
      "        [1.0616],\n",
      "        [1.0599],\n",
      "        [1.0791],\n",
      "        [1.0294],\n",
      "        [1.0718],\n",
      "        [1.0261],\n",
      "        [1.1020],\n",
      "        [1.1031],\n",
      "        [1.0979],\n",
      "        [1.0908],\n",
      "        [1.0894],\n",
      "        [1.0592],\n",
      "        [1.0983],\n",
      "        [1.0553],\n",
      "        [1.0950],\n",
      "        [1.0647],\n",
      "        [1.0869],\n",
      "        [1.0670],\n",
      "        [1.0933],\n",
      "        [1.1000],\n",
      "        [1.0825],\n",
      "        [1.0654],\n",
      "        [1.0993],\n",
      "        [1.0723],\n",
      "        [1.0591],\n",
      "        [1.0993],\n",
      "        [1.0889],\n",
      "        [1.0852],\n",
      "        [1.0630],\n",
      "        [1.0899],\n",
      "        [1.0909],\n",
      "        [1.1014],\n",
      "        [1.0977],\n",
      "        [1.0652],\n",
      "        [1.0850],\n",
      "        [1.0666],\n",
      "        [0.8059],\n",
      "        [1.0571],\n",
      "        [1.0768],\n",
      "        [1.1086],\n",
      "        [1.0374],\n",
      "        [1.0857],\n",
      "        [1.0356],\n",
      "        [1.0461],\n",
      "        [1.0258],\n",
      "        [1.0539],\n",
      "        [1.0709],\n",
      "        [1.0966],\n",
      "        [1.0913],\n",
      "        [1.0850],\n",
      "        [1.0786],\n",
      "        [1.0907],\n",
      "        [1.0772],\n",
      "        [1.0958],\n",
      "        [1.1066],\n",
      "        [1.0670],\n",
      "        [1.1060],\n",
      "        [1.0873],\n",
      "        [1.0762],\n",
      "        [1.0772],\n",
      "        [1.0777],\n",
      "        [1.0656],\n",
      "        [1.0910],\n",
      "        [1.0857],\n",
      "        [1.0803],\n",
      "        [1.1088],\n",
      "        [1.0686],\n",
      "        [1.0768],\n",
      "        [1.0602],\n",
      "        [1.0711],\n",
      "        [1.0984],\n",
      "        [1.0882],\n",
      "        [1.0769],\n",
      "        [1.0839],\n",
      "        [1.0924],\n",
      "        [1.0870],\n",
      "        [1.0884],\n",
      "        [1.0951],\n",
      "        [1.0627]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0973],\n",
      "        [1.0139],\n",
      "        [1.0438],\n",
      "        [1.0986],\n",
      "        [1.0893],\n",
      "        [1.1087],\n",
      "        [1.0547],\n",
      "        [1.0939],\n",
      "        [1.0864],\n",
      "        [1.0924],\n",
      "        [1.0455],\n",
      "        [1.0601],\n",
      "        [1.1082],\n",
      "        [1.1078],\n",
      "        [1.1047],\n",
      "        [1.0869],\n",
      "        [1.1004],\n",
      "        [0.3778],\n",
      "        [1.0987],\n",
      "        [1.0884],\n",
      "        [0.1862],\n",
      "        [1.1089],\n",
      "        [1.0829],\n",
      "        [1.0551],\n",
      "        [1.1085],\n",
      "        [1.0524],\n",
      "        [1.0608],\n",
      "        [1.0563],\n",
      "        [1.0668],\n",
      "        [1.0603],\n",
      "        [1.0530],\n",
      "        [1.0944],\n",
      "        [1.0645],\n",
      "        [1.0963],\n",
      "        [1.0798],\n",
      "        [1.0815],\n",
      "        [1.1049],\n",
      "        [1.0601],\n",
      "        [1.0828],\n",
      "        [1.0832],\n",
      "        [1.1006],\n",
      "        [1.0565],\n",
      "        [1.0350],\n",
      "        [1.1108],\n",
      "        [1.0336],\n",
      "        [1.0826],\n",
      "        [1.0963],\n",
      "        [1.0824],\n",
      "        [1.0614],\n",
      "        [1.0991],\n",
      "        [1.0556],\n",
      "        [1.1002],\n",
      "        [1.1024],\n",
      "        [1.0752],\n",
      "        [1.0772],\n",
      "        [1.0928],\n",
      "        [1.0626],\n",
      "        [1.0838],\n",
      "        [1.0713],\n",
      "        [1.0759],\n",
      "        [1.0876],\n",
      "        [1.0816],\n",
      "        [1.1010],\n",
      "        [1.0783],\n",
      "        [1.0977],\n",
      "        [1.0707],\n",
      "        [1.0848],\n",
      "        [1.0474],\n",
      "        [1.0777],\n",
      "        [1.1039],\n",
      "        [1.0745],\n",
      "        [1.0963],\n",
      "        [1.0589],\n",
      "        [1.1086],\n",
      "        [1.0555],\n",
      "        [1.1078],\n",
      "        [1.1080],\n",
      "        [1.0570],\n",
      "        [1.0580],\n",
      "        [1.0842],\n",
      "        [1.0413],\n",
      "        [1.0931],\n",
      "        [1.0684],\n",
      "        [1.0985],\n",
      "        [1.0743],\n",
      "        [1.0522],\n",
      "        [1.1030],\n",
      "        [1.0674],\n",
      "        [1.0529],\n",
      "        [1.0735],\n",
      "        [1.0707],\n",
      "        [1.0676],\n",
      "        [1.1000],\n",
      "        [1.0979],\n",
      "        [1.0669],\n",
      "        [1.0646],\n",
      "        [1.0962],\n",
      "        [1.1043],\n",
      "        [1.1039],\n",
      "        [1.1060],\n",
      "        [1.0064],\n",
      "        [1.0663],\n",
      "        [1.0773],\n",
      "        [1.1040],\n",
      "        [1.0606],\n",
      "        [1.0746],\n",
      "        [1.1020],\n",
      "        [1.0586],\n",
      "        [1.0858],\n",
      "        [1.0681],\n",
      "        [1.0839],\n",
      "        [1.0974],\n",
      "        [1.0716],\n",
      "        [1.0628],\n",
      "        [1.0891],\n",
      "        [1.0078],\n",
      "        [1.0937],\n",
      "        [1.0885],\n",
      "        [1.0795],\n",
      "        [1.0911],\n",
      "        [1.0492],\n",
      "        [1.1001],\n",
      "        [1.0668],\n",
      "        [0.1984],\n",
      "        [1.0870],\n",
      "        [1.0931],\n",
      "        [1.0769],\n",
      "        [1.0475]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0927],\n",
      "        [1.0796],\n",
      "        [1.0928],\n",
      "        [1.0971],\n",
      "        [1.0800],\n",
      "        [1.0558],\n",
      "        [1.0766],\n",
      "        [1.0872],\n",
      "        [1.0843],\n",
      "        [1.0805],\n",
      "        [1.1095],\n",
      "        [1.0820],\n",
      "        [1.1023],\n",
      "        [1.1091],\n",
      "        [1.1018],\n",
      "        [1.1101],\n",
      "        [1.0768],\n",
      "        [1.0463],\n",
      "        [1.1149],\n",
      "        [1.1105],\n",
      "        [1.0904],\n",
      "        [1.0644],\n",
      "        [1.0371],\n",
      "        [1.0756],\n",
      "        [1.1000],\n",
      "        [1.1144],\n",
      "        [1.0435],\n",
      "        [1.0775],\n",
      "        [1.0362],\n",
      "        [1.0962],\n",
      "        [1.1074],\n",
      "        [1.0543],\n",
      "        [1.0709],\n",
      "        [1.1094],\n",
      "        [1.0441],\n",
      "        [1.1035],\n",
      "        [1.0909],\n",
      "        [1.0773],\n",
      "        [1.0911],\n",
      "        [1.0911],\n",
      "        [1.0417],\n",
      "        [1.0820],\n",
      "        [1.0735],\n",
      "        [1.0980],\n",
      "        [1.0726],\n",
      "        [1.0654],\n",
      "        [1.0565],\n",
      "        [1.0879],\n",
      "        [1.0889],\n",
      "        [1.0648],\n",
      "        [1.0634],\n",
      "        [1.1002],\n",
      "        [1.0938],\n",
      "        [1.0959],\n",
      "        [1.0864],\n",
      "        [1.0845],\n",
      "        [1.0977],\n",
      "        [1.0934],\n",
      "        [1.0598],\n",
      "        [1.0683],\n",
      "        [1.0736],\n",
      "        [1.0452],\n",
      "        [1.0934],\n",
      "        [1.0741],\n",
      "        [1.0949],\n",
      "        [0.9977],\n",
      "        [1.1074],\n",
      "        [1.0693],\n",
      "        [1.0492],\n",
      "        [1.0853],\n",
      "        [1.1110],\n",
      "        [1.0952],\n",
      "        [1.0991],\n",
      "        [1.0907],\n",
      "        [1.1002],\n",
      "        [1.0697],\n",
      "        [1.1014],\n",
      "        [1.0917],\n",
      "        [1.1057],\n",
      "        [1.0680],\n",
      "        [1.0767],\n",
      "        [1.0819],\n",
      "        [1.1082],\n",
      "        [1.0362],\n",
      "        [1.0559],\n",
      "        [1.1006],\n",
      "        [1.0955],\n",
      "        [1.0873],\n",
      "        [1.0918],\n",
      "        [1.0741],\n",
      "        [1.0722],\n",
      "        [1.1098],\n",
      "        [1.0889],\n",
      "        [1.0992],\n",
      "        [1.0933],\n",
      "        [1.0916],\n",
      "        [1.0622],\n",
      "        [1.1108],\n",
      "        [1.0934],\n",
      "        [1.0787],\n",
      "        [1.0987],\n",
      "        [1.0989],\n",
      "        [1.0993],\n",
      "        [1.0716],\n",
      "        [1.0832],\n",
      "        [1.0655],\n",
      "        [1.1074],\n",
      "        [1.0754],\n",
      "        [1.0948],\n",
      "        [1.0582],\n",
      "        [1.1042],\n",
      "        [1.0818],\n",
      "        [1.1010],\n",
      "        [1.0924],\n",
      "        [1.1007],\n",
      "        [1.1068],\n",
      "        [1.0579],\n",
      "        [1.1097],\n",
      "        [1.0595],\n",
      "        [1.0846],\n",
      "        [1.0761],\n",
      "        [1.0411],\n",
      "        [1.0946],\n",
      "        [1.0508],\n",
      "        [1.1016],\n",
      "        [1.0409],\n",
      "        [1.1076],\n",
      "        [1.0479]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0946],\n",
      "        [1.0626],\n",
      "        [1.0954],\n",
      "        [1.0645],\n",
      "        [1.0660],\n",
      "        [1.0861],\n",
      "        [1.0745],\n",
      "        [1.0628],\n",
      "        [1.0481],\n",
      "        [1.0269],\n",
      "        [1.0796],\n",
      "        [1.0731],\n",
      "        [1.0475],\n",
      "        [1.0904],\n",
      "        [1.0743],\n",
      "        [1.0922],\n",
      "        [1.0992],\n",
      "        [1.0635],\n",
      "        [1.0876],\n",
      "        [1.0313],\n",
      "        [1.1038],\n",
      "        [1.1005],\n",
      "        [1.0477],\n",
      "        [1.0545],\n",
      "        [1.1009],\n",
      "        [1.0288],\n",
      "        [1.0771],\n",
      "        [1.0818],\n",
      "        [1.1081],\n",
      "        [1.0995],\n",
      "        [1.0824],\n",
      "        [1.0686],\n",
      "        [1.1105],\n",
      "        [1.0904],\n",
      "        [1.1078],\n",
      "        [1.0832],\n",
      "        [1.0599],\n",
      "        [1.0460],\n",
      "        [1.0623],\n",
      "        [1.0830],\n",
      "        [1.0696],\n",
      "        [1.0971],\n",
      "        [1.0811],\n",
      "        [1.0973],\n",
      "        [1.0950],\n",
      "        [1.0974],\n",
      "        [1.0490],\n",
      "        [1.1130],\n",
      "        [1.0278],\n",
      "        [1.0938],\n",
      "        [1.1147],\n",
      "        [1.0847],\n",
      "        [1.0790],\n",
      "        [1.0765],\n",
      "        [1.0876],\n",
      "        [1.0386],\n",
      "        [1.1150],\n",
      "        [1.0669],\n",
      "        [1.0992],\n",
      "        [1.1007],\n",
      "        [1.0988],\n",
      "        [1.0844],\n",
      "        [1.0838],\n",
      "        [1.1133],\n",
      "        [1.0860],\n",
      "        [1.0882],\n",
      "        [1.1009],\n",
      "        [1.0409],\n",
      "        [1.0723],\n",
      "        [1.0805],\n",
      "        [1.0563],\n",
      "        [1.1097],\n",
      "        [1.0842],\n",
      "        [1.0899],\n",
      "        [1.0941],\n",
      "        [1.0817],\n",
      "        [1.1061],\n",
      "        [1.0867],\n",
      "        [1.1104],\n",
      "        [1.0914],\n",
      "        [1.1031],\n",
      "        [1.1053],\n",
      "        [1.0801],\n",
      "        [1.0799],\n",
      "        [1.0800],\n",
      "        [1.0617],\n",
      "        [1.0595],\n",
      "        [1.0900],\n",
      "        [1.0460],\n",
      "        [1.1089],\n",
      "        [1.0956],\n",
      "        [1.1015],\n",
      "        [1.0970],\n",
      "        [1.1033],\n",
      "        [1.0991],\n",
      "        [1.0615],\n",
      "        [1.0681],\n",
      "        [1.0982],\n",
      "        [1.0858],\n",
      "        [1.0697],\n",
      "        [1.0939],\n",
      "        [1.0950],\n",
      "        [1.0375],\n",
      "        [1.0929],\n",
      "        [1.0691],\n",
      "        [1.0882],\n",
      "        [1.0729],\n",
      "        [1.0813],\n",
      "        [1.0944],\n",
      "        [1.0863],\n",
      "        [1.1027],\n",
      "        [1.0957],\n",
      "        [1.1038],\n",
      "        [1.0509],\n",
      "        [1.0514],\n",
      "        [1.0990],\n",
      "        [1.1101],\n",
      "        [1.0809],\n",
      "        [1.0966],\n",
      "        [1.0472],\n",
      "        [1.1113],\n",
      "        [1.0804],\n",
      "        [1.0610],\n",
      "        [1.1085],\n",
      "        [1.0240],\n",
      "        [1.0710],\n",
      "        [1.0992],\n",
      "        [1.0613]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.1008],\n",
      "        [ 1.0938],\n",
      "        [ 1.0478],\n",
      "        [ 1.1114],\n",
      "        [ 1.0842],\n",
      "        [ 1.1121],\n",
      "        [ 1.0687],\n",
      "        [ 1.0835],\n",
      "        [ 1.3327],\n",
      "        [ 1.0932],\n",
      "        [ 1.0833],\n",
      "        [ 1.0961],\n",
      "        [ 1.1029],\n",
      "        [ 1.0740],\n",
      "        [ 1.0877],\n",
      "        [ 1.0855],\n",
      "        [ 1.0961],\n",
      "        [ 1.0846],\n",
      "        [ 1.1086],\n",
      "        [ 1.0931],\n",
      "        [ 1.0620],\n",
      "        [ 1.0080],\n",
      "        [ 1.0536],\n",
      "        [ 1.0679],\n",
      "        [ 1.0974],\n",
      "        [ 1.0625],\n",
      "        [ 1.1006],\n",
      "        [ 1.0779],\n",
      "        [ 1.0830],\n",
      "        [ 1.1137],\n",
      "        [ 1.0782],\n",
      "        [ 1.0998],\n",
      "        [ 1.0597],\n",
      "        [ 1.0720],\n",
      "        [ 1.1091],\n",
      "        [ 1.0676],\n",
      "        [ 1.0966],\n",
      "        [ 1.0781],\n",
      "        [ 1.0575],\n",
      "        [ 1.1126],\n",
      "        [ 1.0975],\n",
      "        [ 1.1152],\n",
      "        [ 1.0723],\n",
      "        [ 1.1041],\n",
      "        [ 1.0965],\n",
      "        [ 1.0557],\n",
      "        [ 1.1175],\n",
      "        [ 1.0876],\n",
      "        [ 1.0736],\n",
      "        [ 1.1081],\n",
      "        [ 1.0817],\n",
      "        [ 1.1111],\n",
      "        [ 1.1132],\n",
      "        [ 1.1150],\n",
      "        [ 1.0679],\n",
      "        [ 1.0983],\n",
      "        [ 1.0749],\n",
      "        [ 1.1122],\n",
      "        [ 1.0490],\n",
      "        [ 1.1004],\n",
      "        [ 1.1131],\n",
      "        [ 1.1104],\n",
      "        [ 1.0915],\n",
      "        [ 1.1111],\n",
      "        [ 1.2591],\n",
      "        [ 1.0674],\n",
      "        [ 1.0870],\n",
      "        [ 1.0819],\n",
      "        [ 1.1038],\n",
      "        [ 1.0909],\n",
      "        [ 1.0774],\n",
      "        [ 1.0664],\n",
      "        [ 1.0772],\n",
      "        [ 1.0961],\n",
      "        [ 1.0808],\n",
      "        [ 1.0699],\n",
      "        [ 1.0677],\n",
      "        [ 1.0660],\n",
      "        [ 1.0253],\n",
      "        [ 1.0936],\n",
      "        [ 1.1096],\n",
      "        [ 1.1132],\n",
      "        [ 1.0940],\n",
      "        [ 1.1120],\n",
      "        [ 1.0718],\n",
      "        [ 1.0715],\n",
      "        [ 1.0741],\n",
      "        [ 1.0994],\n",
      "        [ 1.0693],\n",
      "        [ 1.1093],\n",
      "        [ 1.0526],\n",
      "        [ 1.0954],\n",
      "        [ 1.0956],\n",
      "        [ 1.0632],\n",
      "        [ 1.0711],\n",
      "        [ 1.0759],\n",
      "        [ 1.0906],\n",
      "        [ 1.0570],\n",
      "        [ 1.1131],\n",
      "        [-0.0045],\n",
      "        [ 1.0761],\n",
      "        [ 1.1040],\n",
      "        [ 1.0841],\n",
      "        [ 1.1096],\n",
      "        [ 1.0756],\n",
      "        [ 1.1113],\n",
      "        [ 1.0890],\n",
      "        [ 1.1139],\n",
      "        [ 1.1087],\n",
      "        [ 1.1117],\n",
      "        [ 1.0787],\n",
      "        [ 1.0659],\n",
      "        [ 1.0877],\n",
      "        [ 1.1017],\n",
      "        [ 1.0471],\n",
      "        [ 1.1090],\n",
      "        [ 1.0822],\n",
      "        [ 1.0789],\n",
      "        [ 1.0994],\n",
      "        [ 1.0858],\n",
      "        [ 1.1083],\n",
      "        [ 1.1064],\n",
      "        [ 1.1062],\n",
      "        [ 1.0804],\n",
      "        [ 1.0567],\n",
      "        [ 1.1043],\n",
      "        [ 1.1016],\n",
      "        [ 1.1151]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0504],\n",
      "        [1.0593],\n",
      "        [1.0788],\n",
      "        [1.0731],\n",
      "        [1.1083],\n",
      "        [1.0805],\n",
      "        [1.0967],\n",
      "        [1.1000],\n",
      "        [1.0688],\n",
      "        [1.0773],\n",
      "        [1.1138],\n",
      "        [1.1121],\n",
      "        [1.0955],\n",
      "        [1.0729],\n",
      "        [1.1035],\n",
      "        [1.1107],\n",
      "        [1.0887],\n",
      "        [1.1084],\n",
      "        [1.0509],\n",
      "        [1.0936],\n",
      "        [1.0359],\n",
      "        [1.0924],\n",
      "        [1.0659],\n",
      "        [1.0968],\n",
      "        [1.0911],\n",
      "        [1.0899],\n",
      "        [1.0910],\n",
      "        [1.0814],\n",
      "        [1.0660],\n",
      "        [1.0715],\n",
      "        [1.0789],\n",
      "        [1.0715],\n",
      "        [1.1029],\n",
      "        [1.0883],\n",
      "        [1.0877],\n",
      "        [1.0624],\n",
      "        [1.0236],\n",
      "        [1.0864],\n",
      "        [1.1110],\n",
      "        [1.1008],\n",
      "        [1.0970],\n",
      "        [1.1132],\n",
      "        [1.1139],\n",
      "        [1.0648],\n",
      "        [1.1028],\n",
      "        [1.0981],\n",
      "        [1.1004],\n",
      "        [1.1183],\n",
      "        [1.1065],\n",
      "        [1.0700],\n",
      "        [1.0967],\n",
      "        [1.0571],\n",
      "        [1.0601],\n",
      "        [1.0939],\n",
      "        [1.0652],\n",
      "        [1.0453],\n",
      "        [1.1146],\n",
      "        [1.0759],\n",
      "        [1.0603],\n",
      "        [1.0716],\n",
      "        [1.1031],\n",
      "        [1.0952],\n",
      "        [1.1016],\n",
      "        [1.0965],\n",
      "        [1.0905],\n",
      "        [1.1064],\n",
      "        [1.0952],\n",
      "        [1.0929],\n",
      "        [1.0983],\n",
      "        [1.0790],\n",
      "        [1.0896],\n",
      "        [1.0955],\n",
      "        [1.0935],\n",
      "        [1.0970],\n",
      "        [1.1095],\n",
      "        [1.0900],\n",
      "        [1.0737],\n",
      "        [1.0937],\n",
      "        [1.0928],\n",
      "        [1.1083],\n",
      "        [1.0559],\n",
      "        [1.0990],\n",
      "        [1.0820],\n",
      "        [1.1018],\n",
      "        [1.0748],\n",
      "        [1.0841],\n",
      "        [1.0788],\n",
      "        [1.0682],\n",
      "        [1.1057],\n",
      "        [1.0771],\n",
      "        [1.1132],\n",
      "        [1.1044],\n",
      "        [1.1005],\n",
      "        [1.0782],\n",
      "        [1.1066],\n",
      "        [1.0684],\n",
      "        [1.0997],\n",
      "        [1.0691],\n",
      "        [1.1017],\n",
      "        [1.1097],\n",
      "        [1.0575],\n",
      "        [1.0641],\n",
      "        [1.1064],\n",
      "        [1.1042],\n",
      "        [1.0828],\n",
      "        [1.0907],\n",
      "        [1.0742],\n",
      "        [1.0721],\n",
      "        [1.0774],\n",
      "        [1.0777],\n",
      "        [1.0639],\n",
      "        [1.0569],\n",
      "        [1.0788],\n",
      "        [1.1034],\n",
      "        [1.0982],\n",
      "        [1.0642],\n",
      "        [1.0807],\n",
      "        [1.1135],\n",
      "        [1.0690],\n",
      "        [1.0694],\n",
      "        [1.1121],\n",
      "        [1.0922],\n",
      "        [1.0979],\n",
      "        [1.0799],\n",
      "        [1.0786],\n",
      "        [1.0697],\n",
      "        [1.0576],\n",
      "        [1.0651]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0848],\n",
      "        [1.1012],\n",
      "        [1.0905],\n",
      "        [1.1124],\n",
      "        [1.0815],\n",
      "        [1.0714],\n",
      "        [1.1079],\n",
      "        [1.0847],\n",
      "        [1.0869],\n",
      "        [1.0986],\n",
      "        [1.0948],\n",
      "        [1.0611],\n",
      "        [1.1173],\n",
      "        [1.1010],\n",
      "        [1.0799],\n",
      "        [1.0655],\n",
      "        [1.1068],\n",
      "        [1.1009],\n",
      "        [1.0794],\n",
      "        [1.0977],\n",
      "        [1.0469],\n",
      "        [1.0831],\n",
      "        [1.0986],\n",
      "        [1.1068],\n",
      "        [1.1006],\n",
      "        [1.0696],\n",
      "        [1.1113],\n",
      "        [1.0957],\n",
      "        [1.1111],\n",
      "        [1.0495],\n",
      "        [1.0688],\n",
      "        [1.1178],\n",
      "        [1.1045],\n",
      "        [1.0769],\n",
      "        [1.0859],\n",
      "        [1.0512],\n",
      "        [1.0664],\n",
      "        [1.0671],\n",
      "        [1.0763],\n",
      "        [1.1069],\n",
      "        [1.0736],\n",
      "        [1.1098],\n",
      "        [1.0811],\n",
      "        [1.1054],\n",
      "        [1.0498],\n",
      "        [1.0768],\n",
      "        [1.0879],\n",
      "        [1.0816],\n",
      "        [1.0814],\n",
      "        [1.0741],\n",
      "        [1.0950],\n",
      "        [1.0817],\n",
      "        [1.0987],\n",
      "        [1.1053],\n",
      "        [1.1046],\n",
      "        [1.0549],\n",
      "        [1.1116],\n",
      "        [1.0801],\n",
      "        [1.0921],\n",
      "        [1.1089],\n",
      "        [1.1164],\n",
      "        [1.0342],\n",
      "        [1.1117],\n",
      "        [1.0904],\n",
      "        [1.0709],\n",
      "        [1.1132],\n",
      "        [1.1148],\n",
      "        [1.0952],\n",
      "        [1.0861],\n",
      "        [1.1118],\n",
      "        [1.0752],\n",
      "        [1.1208],\n",
      "        [1.1057],\n",
      "        [1.0897],\n",
      "        [1.0528],\n",
      "        [1.1002],\n",
      "        [1.0975],\n",
      "        [1.0801],\n",
      "        [1.1009],\n",
      "        [1.0909],\n",
      "        [1.0949],\n",
      "        [1.0730],\n",
      "        [1.1099],\n",
      "        [1.0777],\n",
      "        [1.1003],\n",
      "        [1.0867],\n",
      "        [1.0723],\n",
      "        [1.0916],\n",
      "        [1.0905],\n",
      "        [1.0844],\n",
      "        [1.1017],\n",
      "        [1.0892],\n",
      "        [1.0820],\n",
      "        [1.0620],\n",
      "        [1.0697],\n",
      "        [1.0893],\n",
      "        [1.0946],\n",
      "        [0.4894],\n",
      "        [1.0872],\n",
      "        [1.0879],\n",
      "        [1.0765],\n",
      "        [1.0454],\n",
      "        [1.1050],\n",
      "        [1.1015],\n",
      "        [1.1207],\n",
      "        [1.0964],\n",
      "        [1.1038],\n",
      "        [1.1005],\n",
      "        [1.1143],\n",
      "        [1.0781],\n",
      "        [1.1150],\n",
      "        [1.0555],\n",
      "        [1.0661],\n",
      "        [1.0453],\n",
      "        [1.0828],\n",
      "        [1.0697],\n",
      "        [1.1113],\n",
      "        [1.1117],\n",
      "        [1.0858],\n",
      "        [1.0455],\n",
      "        [1.0884],\n",
      "        [1.1070],\n",
      "        [1.0771],\n",
      "        [1.0720],\n",
      "        [1.0851],\n",
      "        [1.0823],\n",
      "        [1.0707],\n",
      "        [1.0829]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0695],\n",
      "        [1.1150],\n",
      "        [1.0996],\n",
      "        [1.0777]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  20 | lr 0.00100 train_loss 2.11960 | val_loss 2.29166 | val_rmse 1.51382\n",
      "tensor([[1.1177],\n",
      "        [1.0988],\n",
      "        [1.1047],\n",
      "        [1.1169],\n",
      "        [1.0565],\n",
      "        [1.0851],\n",
      "        [1.0794],\n",
      "        [1.0868],\n",
      "        [1.0555],\n",
      "        [1.0265],\n",
      "        [1.1036],\n",
      "        [1.0971],\n",
      "        [1.1002],\n",
      "        [1.0488],\n",
      "        [1.0922],\n",
      "        [1.0909],\n",
      "        [1.0966],\n",
      "        [1.0708],\n",
      "        [1.0981],\n",
      "        [1.0837],\n",
      "        [1.1230],\n",
      "        [1.1039],\n",
      "        [1.0831],\n",
      "        [1.1173],\n",
      "        [1.1029],\n",
      "        [1.0821],\n",
      "        [1.1062],\n",
      "        [1.0892],\n",
      "        [1.0845],\n",
      "        [1.1034],\n",
      "        [1.0989],\n",
      "        [1.0861],\n",
      "        [1.0817],\n",
      "        [1.1086],\n",
      "        [1.0776],\n",
      "        [1.1193],\n",
      "        [1.1151],\n",
      "        [1.0441],\n",
      "        [1.0998],\n",
      "        [1.1204],\n",
      "        [1.1237],\n",
      "        [1.1004],\n",
      "        [1.1214],\n",
      "        [1.1171],\n",
      "        [1.0992],\n",
      "        [1.1060],\n",
      "        [1.1170],\n",
      "        [1.0874],\n",
      "        [1.1138],\n",
      "        [1.0924],\n",
      "        [1.0768],\n",
      "        [1.0768],\n",
      "        [1.1134],\n",
      "        [1.0685],\n",
      "        [1.1026],\n",
      "        [1.1224],\n",
      "        [1.0440],\n",
      "        [1.0353],\n",
      "        [1.1105],\n",
      "        [1.1070],\n",
      "        [1.1257],\n",
      "        [1.1217],\n",
      "        [1.0779],\n",
      "        [1.1038],\n",
      "        [1.0910],\n",
      "        [1.1163],\n",
      "        [1.1081],\n",
      "        [1.0870],\n",
      "        [1.1144],\n",
      "        [1.0567],\n",
      "        [1.1231],\n",
      "        [1.0658],\n",
      "        [1.1090],\n",
      "        [1.0775],\n",
      "        [1.1051],\n",
      "        [1.0980],\n",
      "        [1.1157],\n",
      "        [1.1040],\n",
      "        [1.0846],\n",
      "        [1.0951],\n",
      "        [1.1200],\n",
      "        [1.0820],\n",
      "        [1.0842],\n",
      "        [1.1212],\n",
      "        [1.0317],\n",
      "        [1.1142],\n",
      "        [1.0888],\n",
      "        [1.0767],\n",
      "        [1.1058],\n",
      "        [1.1107],\n",
      "        [1.1100],\n",
      "        [1.0617],\n",
      "        [1.0923],\n",
      "        [1.0796],\n",
      "        [1.0920],\n",
      "        [1.1031],\n",
      "        [1.0878],\n",
      "        [1.0737],\n",
      "        [1.0870],\n",
      "        [1.0708],\n",
      "        [1.1192],\n",
      "        [1.0370],\n",
      "        [1.1056],\n",
      "        [1.0530],\n",
      "        [1.0962],\n",
      "        [1.0966],\n",
      "        [1.1215],\n",
      "        [1.1110],\n",
      "        [1.0910],\n",
      "        [1.0932],\n",
      "        [1.0608],\n",
      "        [1.0731],\n",
      "        [1.1112],\n",
      "        [1.0948],\n",
      "        [1.1084],\n",
      "        [1.1180],\n",
      "        [1.0812],\n",
      "        [1.0931],\n",
      "        [1.1058],\n",
      "        [1.0752],\n",
      "        [1.0860],\n",
      "        [1.1205],\n",
      "        [1.1002],\n",
      "        [1.0995],\n",
      "        [1.0915],\n",
      "        [1.1006],\n",
      "        [1.1040],\n",
      "        [1.0752]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0485],\n",
      "        [1.1068],\n",
      "        [1.1126],\n",
      "        [1.1239],\n",
      "        [1.1220],\n",
      "        [1.1052],\n",
      "        [1.1122],\n",
      "        [1.1004],\n",
      "        [1.0987],\n",
      "        [1.0530],\n",
      "        [1.1112],\n",
      "        [1.0984],\n",
      "        [1.0714],\n",
      "        [1.0842],\n",
      "        [1.0937],\n",
      "        [1.0935],\n",
      "        [1.1025],\n",
      "        [1.1025],\n",
      "        [1.0934],\n",
      "        [1.0810],\n",
      "        [1.1077],\n",
      "        [1.0861],\n",
      "        [1.0984],\n",
      "        [1.1095],\n",
      "        [1.1046],\n",
      "        [1.0514],\n",
      "        [1.0802],\n",
      "        [1.0524],\n",
      "        [1.0606],\n",
      "        [1.1147],\n",
      "        [1.1083],\n",
      "        [1.0889],\n",
      "        [1.1258],\n",
      "        [1.0995],\n",
      "        [1.0539],\n",
      "        [1.1235],\n",
      "        [1.1102],\n",
      "        [1.1100],\n",
      "        [1.0435],\n",
      "        [1.0439],\n",
      "        [1.1210],\n",
      "        [1.0925],\n",
      "        [1.1015],\n",
      "        [1.1056],\n",
      "        [1.1053],\n",
      "        [1.0832],\n",
      "        [1.0906],\n",
      "        [1.1013],\n",
      "        [1.0866],\n",
      "        [1.1119],\n",
      "        [1.1084],\n",
      "        [1.0788],\n",
      "        [1.1099],\n",
      "        [1.1009],\n",
      "        [1.0790],\n",
      "        [1.0797],\n",
      "        [1.0649],\n",
      "        [1.1097],\n",
      "        [1.0723],\n",
      "        [1.0769],\n",
      "        [1.0770],\n",
      "        [1.0772],\n",
      "        [1.1132],\n",
      "        [1.0628],\n",
      "        [1.1086],\n",
      "        [1.1000],\n",
      "        [1.0783],\n",
      "        [1.1224],\n",
      "        [1.1141],\n",
      "        [1.0819],\n",
      "        [1.0715],\n",
      "        [1.0612],\n",
      "        [1.0826],\n",
      "        [1.0965],\n",
      "        [1.1257],\n",
      "        [1.1108],\n",
      "        [1.0932],\n",
      "        [1.0947],\n",
      "        [1.1174],\n",
      "        [1.1093],\n",
      "        [1.0803],\n",
      "        [1.1093],\n",
      "        [1.1099],\n",
      "        [1.1181],\n",
      "        [1.1119],\n",
      "        [1.0675],\n",
      "        [1.0894],\n",
      "        [1.1168],\n",
      "        [1.1119],\n",
      "        [1.1047],\n",
      "        [1.0953],\n",
      "        [1.0990],\n",
      "        [1.0861],\n",
      "        [1.0841],\n",
      "        [1.0838],\n",
      "        [1.1100],\n",
      "        [1.1219],\n",
      "        [1.1004],\n",
      "        [1.0350],\n",
      "        [1.0917],\n",
      "        [1.1096],\n",
      "        [1.1086],\n",
      "        [1.0786],\n",
      "        [1.1204],\n",
      "        [1.0698],\n",
      "        [1.0999],\n",
      "        [1.1251],\n",
      "        [1.0886],\n",
      "        [1.1065],\n",
      "        [1.0927],\n",
      "        [1.0991],\n",
      "        [1.1083],\n",
      "        [1.0790],\n",
      "        [1.1256],\n",
      "        [1.0969],\n",
      "        [1.1115],\n",
      "        [1.0977],\n",
      "        [1.0200],\n",
      "        [1.1114],\n",
      "        [1.0738],\n",
      "        [1.1084],\n",
      "        [1.1153],\n",
      "        [1.1067],\n",
      "        [1.0611],\n",
      "        [1.1180],\n",
      "        [1.0694],\n",
      "        [1.1038],\n",
      "        [1.0763]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1104],\n",
      "        [1.1274],\n",
      "        [1.1272],\n",
      "        [1.1295],\n",
      "        [1.1163],\n",
      "        [1.0514],\n",
      "        [1.0812],\n",
      "        [1.1112],\n",
      "        [1.1005],\n",
      "        [1.0856],\n",
      "        [1.1142],\n",
      "        [1.1288],\n",
      "        [1.0606],\n",
      "        [1.0638],\n",
      "        [1.1117],\n",
      "        [1.1130],\n",
      "        [1.1212],\n",
      "        [1.0959],\n",
      "        [1.0704],\n",
      "        [1.0831],\n",
      "        [1.0985],\n",
      "        [1.0909],\n",
      "        [1.0989],\n",
      "        [1.0866],\n",
      "        [1.0820],\n",
      "        [1.1226],\n",
      "        [1.1094],\n",
      "        [1.1135],\n",
      "        [1.1213],\n",
      "        [1.0809],\n",
      "        [1.1107],\n",
      "        [1.0863],\n",
      "        [1.1030],\n",
      "        [1.1282],\n",
      "        [1.0910],\n",
      "        [1.0835],\n",
      "        [1.0788],\n",
      "        [1.1249],\n",
      "        [1.1019],\n",
      "        [1.1165],\n",
      "        [1.0781],\n",
      "        [1.0965],\n",
      "        [1.0752],\n",
      "        [1.0970],\n",
      "        [1.1011],\n",
      "        [1.0204],\n",
      "        [1.0845],\n",
      "        [1.0201],\n",
      "        [1.1250],\n",
      "        [1.0772],\n",
      "        [1.1109],\n",
      "        [1.0936],\n",
      "        [1.0910],\n",
      "        [1.1072],\n",
      "        [1.1070],\n",
      "        [1.1178],\n",
      "        [1.1092],\n",
      "        [1.1213],\n",
      "        [1.0967],\n",
      "        [1.1026],\n",
      "        [1.0899],\n",
      "        [1.0960],\n",
      "        [1.1142],\n",
      "        [1.0922],\n",
      "        [1.1222],\n",
      "        [1.0692],\n",
      "        [1.0932],\n",
      "        [1.1061],\n",
      "        [1.1079],\n",
      "        [1.1052],\n",
      "        [1.1078],\n",
      "        [1.0471],\n",
      "        [0.2691],\n",
      "        [1.1166],\n",
      "        [1.0907],\n",
      "        [1.0791],\n",
      "        [1.1244],\n",
      "        [1.1003],\n",
      "        [1.1162],\n",
      "        [1.1039],\n",
      "        [1.0970],\n",
      "        [1.1122],\n",
      "        [1.1063],\n",
      "        [1.0654],\n",
      "        [1.0969],\n",
      "        [1.0271],\n",
      "        [1.0890],\n",
      "        [1.0988],\n",
      "        [1.1269],\n",
      "        [1.0891],\n",
      "        [1.1282],\n",
      "        [1.0811],\n",
      "        [1.0230],\n",
      "        [1.0879],\n",
      "        [1.0692],\n",
      "        [1.1087],\n",
      "        [1.1061],\n",
      "        [1.0628],\n",
      "        [1.1028],\n",
      "        [1.1153],\n",
      "        [1.1063],\n",
      "        [1.1225],\n",
      "        [1.1031],\n",
      "        [1.1136],\n",
      "        [1.1036],\n",
      "        [1.1051],\n",
      "        [1.1040],\n",
      "        [1.0785],\n",
      "        [1.0622],\n",
      "        [1.0784],\n",
      "        [1.0672],\n",
      "        [1.1127],\n",
      "        [1.1002],\n",
      "        [1.1113],\n",
      "        [1.0779],\n",
      "        [1.0784],\n",
      "        [1.1196],\n",
      "        [1.1135],\n",
      "        [1.0824],\n",
      "        [1.1119],\n",
      "        [1.1017],\n",
      "        [1.1247],\n",
      "        [1.0998],\n",
      "        [1.1236],\n",
      "        [1.0819],\n",
      "        [1.0864],\n",
      "        [1.0817],\n",
      "        [1.1178]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1117],\n",
      "        [1.1229],\n",
      "        [1.0859],\n",
      "        [1.0953],\n",
      "        [1.1133],\n",
      "        [1.1266],\n",
      "        [1.0812],\n",
      "        [1.1029],\n",
      "        [1.0986],\n",
      "        [1.1268],\n",
      "        [1.0818],\n",
      "        [1.1215],\n",
      "        [1.0662],\n",
      "        [1.0864],\n",
      "        [1.0906],\n",
      "        [1.0706],\n",
      "        [1.1032],\n",
      "        [1.0946],\n",
      "        [1.1019],\n",
      "        [1.1021],\n",
      "        [1.1266],\n",
      "        [1.1224],\n",
      "        [1.1327],\n",
      "        [1.0821],\n",
      "        [1.1063],\n",
      "        [1.0789],\n",
      "        [1.1030],\n",
      "        [1.0769],\n",
      "        [1.1004],\n",
      "        [1.1050],\n",
      "        [1.1190],\n",
      "        [1.1129],\n",
      "        [1.1180],\n",
      "        [1.1085],\n",
      "        [1.1228],\n",
      "        [1.0777],\n",
      "        [1.0979],\n",
      "        [1.1185],\n",
      "        [1.1098],\n",
      "        [1.0923],\n",
      "        [1.0735],\n",
      "        [1.1070],\n",
      "        [1.1272],\n",
      "        [1.1041],\n",
      "        [1.1175],\n",
      "        [1.0549],\n",
      "        [1.1171],\n",
      "        [1.0847],\n",
      "        [1.1157],\n",
      "        [1.1130],\n",
      "        [1.1188],\n",
      "        [1.1159],\n",
      "        [1.1231],\n",
      "        [1.1093],\n",
      "        [1.1268],\n",
      "        [1.1295],\n",
      "        [1.0781],\n",
      "        [1.1246],\n",
      "        [1.1073],\n",
      "        [1.0967],\n",
      "        [1.0996],\n",
      "        [1.0903],\n",
      "        [1.1023],\n",
      "        [1.0992],\n",
      "        [1.0799],\n",
      "        [1.0878],\n",
      "        [1.0904],\n",
      "        [1.1285],\n",
      "        [1.1127],\n",
      "        [1.1144],\n",
      "        [1.1043],\n",
      "        [1.1067],\n",
      "        [1.1201],\n",
      "        [1.0773],\n",
      "        [1.1110],\n",
      "        [1.1263],\n",
      "        [1.0887],\n",
      "        [1.0735],\n",
      "        [1.1079],\n",
      "        [1.1181],\n",
      "        [1.1105],\n",
      "        [1.0855],\n",
      "        [1.0687],\n",
      "        [1.1024],\n",
      "        [1.1119],\n",
      "        [1.1019],\n",
      "        [1.0749],\n",
      "        [1.1120],\n",
      "        [1.1122],\n",
      "        [1.1166],\n",
      "        [1.1099],\n",
      "        [1.1156],\n",
      "        [1.1069],\n",
      "        [1.1251],\n",
      "        [1.1321],\n",
      "        [1.0582],\n",
      "        [1.0771],\n",
      "        [1.1244],\n",
      "        [1.0722],\n",
      "        [1.1043],\n",
      "        [1.0982],\n",
      "        [1.0618],\n",
      "        [1.0853],\n",
      "        [1.0728],\n",
      "        [1.0830],\n",
      "        [1.1017],\n",
      "        [1.0784],\n",
      "        [1.1165],\n",
      "        [1.1282],\n",
      "        [1.0544],\n",
      "        [1.1204],\n",
      "        [1.1011],\n",
      "        [1.1231],\n",
      "        [1.0869],\n",
      "        [1.1265],\n",
      "        [1.0906],\n",
      "        [1.1304],\n",
      "        [1.0820],\n",
      "        [1.0980],\n",
      "        [1.1324],\n",
      "        [1.0927],\n",
      "        [1.1220],\n",
      "        [1.1126],\n",
      "        [1.0733],\n",
      "        [1.0917],\n",
      "        [1.0889],\n",
      "        [1.1360],\n",
      "        [1.0935]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0903],\n",
      "        [1.0891],\n",
      "        [1.0791],\n",
      "        [1.1175],\n",
      "        [1.1144],\n",
      "        [1.1095],\n",
      "        [1.1261],\n",
      "        [1.1294],\n",
      "        [1.1160],\n",
      "        [1.1321],\n",
      "        [1.1124],\n",
      "        [1.1056],\n",
      "        [1.1140],\n",
      "        [1.1034],\n",
      "        [1.0781],\n",
      "        [1.1303],\n",
      "        [1.0878],\n",
      "        [1.1176],\n",
      "        [1.1108],\n",
      "        [1.1333],\n",
      "        [1.0987],\n",
      "        [1.1147],\n",
      "        [1.0830],\n",
      "        [1.0939],\n",
      "        [1.1198],\n",
      "        [1.1003],\n",
      "        [1.1327],\n",
      "        [1.1121],\n",
      "        [1.0754],\n",
      "        [1.1214],\n",
      "        [1.1040],\n",
      "        [1.1161],\n",
      "        [1.1204],\n",
      "        [1.0518],\n",
      "        [1.1096],\n",
      "        [1.1255],\n",
      "        [1.1139],\n",
      "        [1.0670],\n",
      "        [1.1128],\n",
      "        [1.1309],\n",
      "        [1.0948],\n",
      "        [1.0357],\n",
      "        [1.0837],\n",
      "        [1.1300],\n",
      "        [1.1258],\n",
      "        [1.1199],\n",
      "        [1.0648],\n",
      "        [1.0916],\n",
      "        [1.0795],\n",
      "        [1.1277],\n",
      "        [1.1226],\n",
      "        [1.0903],\n",
      "        [1.0760],\n",
      "        [1.1314],\n",
      "        [1.1160],\n",
      "        [1.1255],\n",
      "        [1.0931],\n",
      "        [1.0757],\n",
      "        [1.0901],\n",
      "        [1.1153],\n",
      "        [1.1128],\n",
      "        [1.1053],\n",
      "        [1.1347],\n",
      "        [1.1147],\n",
      "        [1.0972],\n",
      "        [1.0838],\n",
      "        [1.1358],\n",
      "        [1.1144],\n",
      "        [1.1190],\n",
      "        [1.1120],\n",
      "        [1.1197],\n",
      "        [1.0983],\n",
      "        [1.0955],\n",
      "        [1.1117],\n",
      "        [1.1264],\n",
      "        [1.1158],\n",
      "        [1.1162],\n",
      "        [1.1327],\n",
      "        [1.0932],\n",
      "        [1.1240],\n",
      "        [1.0780],\n",
      "        [1.0910],\n",
      "        [1.1025],\n",
      "        [1.0883],\n",
      "        [1.1348],\n",
      "        [1.0956],\n",
      "        [1.1131],\n",
      "        [1.0645],\n",
      "        [1.0945],\n",
      "        [1.0944],\n",
      "        [1.0845],\n",
      "        [1.0768],\n",
      "        [1.0751],\n",
      "        [1.1216],\n",
      "        [1.1253],\n",
      "        [1.1256],\n",
      "        [1.1140],\n",
      "        [1.1052],\n",
      "        [1.1240],\n",
      "        [1.1073],\n",
      "        [1.1145],\n",
      "        [1.1305],\n",
      "        [1.1302],\n",
      "        [1.1107],\n",
      "        [1.1076],\n",
      "        [1.0893],\n",
      "        [1.0880],\n",
      "        [1.1277],\n",
      "        [1.1158],\n",
      "        [1.0623],\n",
      "        [1.1201],\n",
      "        [1.1023],\n",
      "        [1.1275],\n",
      "        [1.0767],\n",
      "        [1.0900],\n",
      "        [1.1349],\n",
      "        [1.0575],\n",
      "        [1.1183],\n",
      "        [1.1079],\n",
      "        [1.0526],\n",
      "        [1.1301],\n",
      "        [1.1320],\n",
      "        [1.0944],\n",
      "        [1.1052],\n",
      "        [1.1165],\n",
      "        [1.1165],\n",
      "        [1.0882],\n",
      "        [1.0961]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1259],\n",
      "        [1.0603],\n",
      "        [1.0932],\n",
      "        [1.1339],\n",
      "        [1.1075],\n",
      "        [1.1248],\n",
      "        [1.0831],\n",
      "        [1.1049],\n",
      "        [1.0877],\n",
      "        [1.1032],\n",
      "        [1.1113],\n",
      "        [1.0798],\n",
      "        [1.1140],\n",
      "        [1.1368],\n",
      "        [1.1320],\n",
      "        [1.1104],\n",
      "        [1.1351],\n",
      "        [1.1325],\n",
      "        [1.1276],\n",
      "        [1.1364],\n",
      "        [1.0856],\n",
      "        [1.0971],\n",
      "        [1.1322],\n",
      "        [1.1221],\n",
      "        [1.1115],\n",
      "        [1.1083],\n",
      "        [1.0697],\n",
      "        [1.0687],\n",
      "        [1.1148],\n",
      "        [1.0652],\n",
      "        [1.1058],\n",
      "        [1.0956],\n",
      "        [1.1102],\n",
      "        [1.1307],\n",
      "        [1.1191],\n",
      "        [1.1161],\n",
      "        [1.1194],\n",
      "        [1.1079],\n",
      "        [1.0901],\n",
      "        [1.1217],\n",
      "        [1.0827],\n",
      "        [1.1245],\n",
      "        [1.0822],\n",
      "        [1.1357],\n",
      "        [1.0827],\n",
      "        [1.1338],\n",
      "        [1.0749],\n",
      "        [1.0935],\n",
      "        [1.1194],\n",
      "        [1.0921],\n",
      "        [1.1155],\n",
      "        [1.1094],\n",
      "        [1.0906],\n",
      "        [1.0960],\n",
      "        [1.1320],\n",
      "        [1.0790],\n",
      "        [1.1005],\n",
      "        [1.1170],\n",
      "        [1.1006],\n",
      "        [1.1312],\n",
      "        [1.0665],\n",
      "        [1.0812],\n",
      "        [1.1132],\n",
      "        [1.1184],\n",
      "        [1.1241],\n",
      "        [1.1369],\n",
      "        [1.1093],\n",
      "        [1.1167],\n",
      "        [1.1138],\n",
      "        [1.0855],\n",
      "        [1.1312],\n",
      "        [1.1104],\n",
      "        [1.0745],\n",
      "        [1.1198],\n",
      "        [1.0988],\n",
      "        [1.1160],\n",
      "        [1.0949],\n",
      "        [1.0905],\n",
      "        [1.0850],\n",
      "        [1.1107],\n",
      "        [1.1235],\n",
      "        [1.1395],\n",
      "        [1.1234],\n",
      "        [1.1017],\n",
      "        [1.1305],\n",
      "        [1.1214],\n",
      "        [1.1016],\n",
      "        [1.1264],\n",
      "        [1.0797],\n",
      "        [1.1187],\n",
      "        [1.1186],\n",
      "        [1.0770],\n",
      "        [1.1035],\n",
      "        [1.1200],\n",
      "        [1.1150],\n",
      "        [1.1193],\n",
      "        [1.1296],\n",
      "        [1.0889],\n",
      "        [1.1088],\n",
      "        [1.0913],\n",
      "        [1.0827],\n",
      "        [1.0866],\n",
      "        [1.1260],\n",
      "        [1.0896],\n",
      "        [1.1102],\n",
      "        [1.1290],\n",
      "        [1.0817],\n",
      "        [1.1084],\n",
      "        [1.0786],\n",
      "        [1.1091],\n",
      "        [1.1223],\n",
      "        [1.1308],\n",
      "        [1.1296],\n",
      "        [1.1080],\n",
      "        [1.0995],\n",
      "        [1.1071],\n",
      "        [1.1005],\n",
      "        [1.1096],\n",
      "        [1.1302],\n",
      "        [1.1334],\n",
      "        [1.1084],\n",
      "        [1.1246],\n",
      "        [1.1065],\n",
      "        [1.1339],\n",
      "        [1.1086],\n",
      "        [1.1262],\n",
      "        [1.1102],\n",
      "        [1.0902]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1346],\n",
      "        [1.0968],\n",
      "        [1.1063],\n",
      "        [1.1099],\n",
      "        [1.1106],\n",
      "        [1.1325],\n",
      "        [1.0816],\n",
      "        [1.1050],\n",
      "        [1.1110],\n",
      "        [1.0989],\n",
      "        [1.1203],\n",
      "        [1.1382],\n",
      "        [1.1043],\n",
      "        [1.0813],\n",
      "        [1.1362],\n",
      "        [1.1173],\n",
      "        [1.1240],\n",
      "        [1.1133],\n",
      "        [1.0575],\n",
      "        [1.1011],\n",
      "        [1.1207],\n",
      "        [1.0852],\n",
      "        [1.0954],\n",
      "        [1.0996],\n",
      "        [1.1347],\n",
      "        [1.0972],\n",
      "        [1.1203],\n",
      "        [1.0453],\n",
      "        [1.1282],\n",
      "        [1.1204],\n",
      "        [1.0686],\n",
      "        [1.1135],\n",
      "        [1.1213],\n",
      "        [1.1058],\n",
      "        [1.0795],\n",
      "        [1.0865],\n",
      "        [1.1288],\n",
      "        [1.0966],\n",
      "        [1.1256],\n",
      "        [1.1290],\n",
      "        [1.1299],\n",
      "        [1.0916],\n",
      "        [1.0765],\n",
      "        [1.1185],\n",
      "        [1.1126],\n",
      "        [1.1135],\n",
      "        [1.0882],\n",
      "        [1.0807],\n",
      "        [1.0841],\n",
      "        [1.1034],\n",
      "        [1.0514],\n",
      "        [1.0755],\n",
      "        [1.0996],\n",
      "        [1.1340],\n",
      "        [1.1079],\n",
      "        [1.1102],\n",
      "        [1.1051],\n",
      "        [1.0825],\n",
      "        [1.1189],\n",
      "        [1.1333],\n",
      "        [1.1337],\n",
      "        [1.1124],\n",
      "        [1.1393],\n",
      "        [1.1143],\n",
      "        [1.1243],\n",
      "        [1.0595],\n",
      "        [1.0506],\n",
      "        [1.0833],\n",
      "        [1.1195],\n",
      "        [1.1384],\n",
      "        [1.1143],\n",
      "        [1.1178],\n",
      "        [1.1252],\n",
      "        [1.1026],\n",
      "        [1.1222],\n",
      "        [1.1091],\n",
      "        [1.0843],\n",
      "        [1.1329],\n",
      "        [1.1316],\n",
      "        [1.1012],\n",
      "        [1.1217],\n",
      "        [1.0880],\n",
      "        [1.1275],\n",
      "        [1.0944],\n",
      "        [1.1166],\n",
      "        [0.1346],\n",
      "        [1.1263],\n",
      "        [1.1190],\n",
      "        [1.1163],\n",
      "        [1.0795],\n",
      "        [1.1274],\n",
      "        [1.1076],\n",
      "        [1.1363],\n",
      "        [1.1147],\n",
      "        [1.1233],\n",
      "        [1.0743],\n",
      "        [1.1293],\n",
      "        [1.1053],\n",
      "        [1.0650],\n",
      "        [1.0972],\n",
      "        [1.1237],\n",
      "        [1.0873],\n",
      "        [1.0989],\n",
      "        [1.1013],\n",
      "        [1.1215],\n",
      "        [1.0878],\n",
      "        [1.1084],\n",
      "        [1.0969],\n",
      "        [1.1269],\n",
      "        [1.0997],\n",
      "        [1.1216],\n",
      "        [1.0888],\n",
      "        [1.1277],\n",
      "        [1.1187],\n",
      "        [1.0949],\n",
      "        [1.1108],\n",
      "        [1.1097],\n",
      "        [1.1339],\n",
      "        [1.1143],\n",
      "        [1.1369],\n",
      "        [1.0719],\n",
      "        [1.0977],\n",
      "        [1.0914],\n",
      "        [1.0930],\n",
      "        [1.1139],\n",
      "        [1.1357],\n",
      "        [1.1153],\n",
      "        [1.1148]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0939],\n",
      "        [1.0402],\n",
      "        [1.0974],\n",
      "        [1.1321]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  21 | lr 0.00100 train_loss 2.12167 | val_loss 2.28757 | val_rmse 1.51247\n",
      "tensor([[1.1010],\n",
      "        [1.0780],\n",
      "        [1.0901],\n",
      "        [1.1156],\n",
      "        [1.1106],\n",
      "        [1.0893],\n",
      "        [1.1060],\n",
      "        [1.1176],\n",
      "        [1.0946],\n",
      "        [1.0699],\n",
      "        [1.1298],\n",
      "        [1.1311],\n",
      "        [1.1029],\n",
      "        [1.1253],\n",
      "        [1.1337],\n",
      "        [1.1013],\n",
      "        [1.1182],\n",
      "        [1.1087],\n",
      "        [1.1074],\n",
      "        [1.0695],\n",
      "        [1.0701],\n",
      "        [1.1323],\n",
      "        [1.1316],\n",
      "        [1.1206],\n",
      "        [1.0805],\n",
      "        [1.1208],\n",
      "        [1.1328],\n",
      "        [1.1071],\n",
      "        [1.1232],\n",
      "        [1.1309],\n",
      "        [1.1294],\n",
      "        [1.0722],\n",
      "        [1.1083],\n",
      "        [1.1260],\n",
      "        [1.0770],\n",
      "        [1.0961],\n",
      "        [1.1183],\n",
      "        [1.0633],\n",
      "        [1.0894],\n",
      "        [1.0817],\n",
      "        [1.1188],\n",
      "        [1.1026],\n",
      "        [1.1227],\n",
      "        [1.0947],\n",
      "        [1.0791],\n",
      "        [1.1154],\n",
      "        [1.1292],\n",
      "        [1.1037],\n",
      "        [1.1086],\n",
      "        [1.1175],\n",
      "        [1.0814],\n",
      "        [1.1317],\n",
      "        [1.0858],\n",
      "        [1.0768],\n",
      "        [1.1312],\n",
      "        [1.1078],\n",
      "        [1.1235],\n",
      "        [1.0868],\n",
      "        [1.1106],\n",
      "        [1.1233],\n",
      "        [1.0288],\n",
      "        [1.1175],\n",
      "        [1.1303],\n",
      "        [1.1339],\n",
      "        [1.0838],\n",
      "        [1.0669],\n",
      "        [1.1017],\n",
      "        [1.1148],\n",
      "        [1.1218],\n",
      "        [1.1277],\n",
      "        [1.1178],\n",
      "        [1.1056],\n",
      "        [1.0902],\n",
      "        [1.0784],\n",
      "        [1.1359],\n",
      "        [1.1109],\n",
      "        [1.0842],\n",
      "        [1.0962],\n",
      "        [1.0916],\n",
      "        [1.1093],\n",
      "        [1.0897],\n",
      "        [1.1025],\n",
      "        [1.0438],\n",
      "        [1.1049],\n",
      "        [1.1106],\n",
      "        [1.0982],\n",
      "        [1.0797],\n",
      "        [1.1355],\n",
      "        [1.0830],\n",
      "        [1.0453],\n",
      "        [1.1152],\n",
      "        [1.1285],\n",
      "        [1.0767],\n",
      "        [1.1144],\n",
      "        [1.1082],\n",
      "        [1.1283],\n",
      "        [1.1009],\n",
      "        [1.1089],\n",
      "        [1.1013],\n",
      "        [1.0967],\n",
      "        [1.1353],\n",
      "        [1.1393],\n",
      "        [1.1003],\n",
      "        [1.1049],\n",
      "        [1.0975],\n",
      "        [1.1124],\n",
      "        [1.1206],\n",
      "        [1.1376],\n",
      "        [1.1365],\n",
      "        [1.1326],\n",
      "        [1.0967],\n",
      "        [1.0878],\n",
      "        [1.1300],\n",
      "        [1.1108],\n",
      "        [1.1029],\n",
      "        [1.0899],\n",
      "        [1.1261],\n",
      "        [1.1227],\n",
      "        [1.0971],\n",
      "        [1.1310],\n",
      "        [1.1352],\n",
      "        [1.1360],\n",
      "        [1.1225],\n",
      "        [1.0943],\n",
      "        [1.1354],\n",
      "        [1.0926],\n",
      "        [1.1410],\n",
      "        [1.0394]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1033],\n",
      "        [1.1151],\n",
      "        [1.1077],\n",
      "        [1.1105],\n",
      "        [1.1184],\n",
      "        [1.0968],\n",
      "        [1.1275],\n",
      "        [1.0811],\n",
      "        [1.1130],\n",
      "        [1.1297],\n",
      "        [1.1221],\n",
      "        [1.0771],\n",
      "        [1.1331],\n",
      "        [1.1045],\n",
      "        [1.1005],\n",
      "        [1.1212],\n",
      "        [1.1148],\n",
      "        [1.0496],\n",
      "        [1.1215],\n",
      "        [1.1336],\n",
      "        [1.1069],\n",
      "        [1.0722],\n",
      "        [1.1080],\n",
      "        [1.1203],\n",
      "        [1.1178],\n",
      "        [1.1311],\n",
      "        [1.1021],\n",
      "        [1.1272],\n",
      "        [1.0864],\n",
      "        [1.1029],\n",
      "        [1.0876],\n",
      "        [1.0761],\n",
      "        [1.1170],\n",
      "        [1.1124],\n",
      "        [1.1360],\n",
      "        [1.1022],\n",
      "        [1.1116],\n",
      "        [1.1300],\n",
      "        [1.1293],\n",
      "        [1.0538],\n",
      "        [1.0872],\n",
      "        [1.1157],\n",
      "        [1.0305],\n",
      "        [1.0763],\n",
      "        [1.1152],\n",
      "        [1.0861],\n",
      "        [1.1231],\n",
      "        [1.1131],\n",
      "        [1.0946],\n",
      "        [1.1004],\n",
      "        [1.1219],\n",
      "        [1.1189],\n",
      "        [1.1104],\n",
      "        [1.0728],\n",
      "        [1.1342],\n",
      "        [1.0499],\n",
      "        [1.1208],\n",
      "        [1.1172],\n",
      "        [1.1223],\n",
      "        [1.1261],\n",
      "        [1.1350],\n",
      "        [1.1235],\n",
      "        [1.1194],\n",
      "        [1.0840],\n",
      "        [1.1370],\n",
      "        [1.1112],\n",
      "        [1.0955],\n",
      "        [1.1263],\n",
      "        [1.0838],\n",
      "        [1.1176],\n",
      "        [1.0748],\n",
      "        [1.0876],\n",
      "        [1.0755],\n",
      "        [1.0734],\n",
      "        [1.0686],\n",
      "        [1.0893],\n",
      "        [1.1148],\n",
      "        [1.1267],\n",
      "        [1.0977],\n",
      "        [1.1239],\n",
      "        [1.0748],\n",
      "        [1.0734],\n",
      "        [1.0794],\n",
      "        [1.1050],\n",
      "        [1.0946],\n",
      "        [1.1362],\n",
      "        [1.1139],\n",
      "        [1.1107],\n",
      "        [1.1062],\n",
      "        [1.1197],\n",
      "        [1.1038],\n",
      "        [1.1214],\n",
      "        [1.1159],\n",
      "        [1.1339],\n",
      "        [1.1136],\n",
      "        [1.0989],\n",
      "        [1.0939],\n",
      "        [1.0592],\n",
      "        [1.1072],\n",
      "        [1.1026],\n",
      "        [1.1271],\n",
      "        [1.1333],\n",
      "        [1.1104],\n",
      "        [1.1321],\n",
      "        [1.1282],\n",
      "        [1.1362],\n",
      "        [1.1370],\n",
      "        [1.0852],\n",
      "        [1.1049],\n",
      "        [1.1127],\n",
      "        [1.1208],\n",
      "        [1.4331],\n",
      "        [1.0924],\n",
      "        [1.0473],\n",
      "        [1.1041],\n",
      "        [1.1159],\n",
      "        [1.0829],\n",
      "        [1.1049],\n",
      "        [1.1260],\n",
      "        [1.0522],\n",
      "        [1.0664],\n",
      "        [1.0912],\n",
      "        [1.1106],\n",
      "        [1.0638],\n",
      "        [1.1200],\n",
      "        [1.0897],\n",
      "        [1.1106],\n",
      "        [1.0936]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1141],\n",
      "        [1.1349],\n",
      "        [1.1034],\n",
      "        [1.1104],\n",
      "        [1.1216],\n",
      "        [1.1363],\n",
      "        [1.0917],\n",
      "        [1.1071],\n",
      "        [1.0871],\n",
      "        [1.1271],\n",
      "        [1.1228],\n",
      "        [1.0869],\n",
      "        [1.1071],\n",
      "        [1.1291],\n",
      "        [1.0637],\n",
      "        [1.0733],\n",
      "        [1.1306],\n",
      "        [1.0903],\n",
      "        [1.0967],\n",
      "        [1.1291],\n",
      "        [1.0837],\n",
      "        [1.0692],\n",
      "        [1.1292],\n",
      "        [1.1219],\n",
      "        [1.1267],\n",
      "        [1.1004],\n",
      "        [1.1073],\n",
      "        [1.1116],\n",
      "        [1.1326],\n",
      "        [1.1182],\n",
      "        [1.0661],\n",
      "        [1.1224],\n",
      "        [1.1227],\n",
      "        [1.0612],\n",
      "        [1.0976],\n",
      "        [1.0988],\n",
      "        [1.0431],\n",
      "        [1.1149],\n",
      "        [1.1097],\n",
      "        [1.0845],\n",
      "        [1.1106],\n",
      "        [1.1178],\n",
      "        [1.1317],\n",
      "        [1.1280],\n",
      "        [1.0756],\n",
      "        [1.0743],\n",
      "        [1.1048],\n",
      "        [1.1151],\n",
      "        [1.1164],\n",
      "        [1.1065],\n",
      "        [1.1117],\n",
      "        [1.1258],\n",
      "        [1.1122],\n",
      "        [1.1017],\n",
      "        [1.1240],\n",
      "        [1.0810],\n",
      "        [1.0869],\n",
      "        [1.0970],\n",
      "        [1.1228],\n",
      "        [1.1319],\n",
      "        [1.0540],\n",
      "        [1.0915],\n",
      "        [1.1283],\n",
      "        [1.1127],\n",
      "        [1.1400],\n",
      "        [1.0677],\n",
      "        [1.1142],\n",
      "        [1.1161],\n",
      "        [1.1198],\n",
      "        [1.0796],\n",
      "        [1.1357],\n",
      "        [1.1350],\n",
      "        [1.1344],\n",
      "        [1.1203],\n",
      "        [1.1279],\n",
      "        [1.0563],\n",
      "        [1.0287],\n",
      "        [1.1113],\n",
      "        [1.1055],\n",
      "        [1.1234],\n",
      "        [1.0865],\n",
      "        [1.1232],\n",
      "        [1.1075],\n",
      "        [1.0647],\n",
      "        [1.1039],\n",
      "        [1.1313],\n",
      "        [1.1256],\n",
      "        [1.0752],\n",
      "        [1.0795],\n",
      "        [1.1121],\n",
      "        [1.1184],\n",
      "        [1.0894],\n",
      "        [1.1089],\n",
      "        [1.1089],\n",
      "        [1.0713],\n",
      "        [1.1127],\n",
      "        [1.1195],\n",
      "        [1.1046],\n",
      "        [1.0884],\n",
      "        [1.0892],\n",
      "        [1.0920],\n",
      "        [1.0679],\n",
      "        [1.0911],\n",
      "        [1.1184],\n",
      "        [1.0832],\n",
      "        [1.1146],\n",
      "        [1.1368],\n",
      "        [1.0554],\n",
      "        [1.0491],\n",
      "        [1.1167],\n",
      "        [1.1053],\n",
      "        [1.1104],\n",
      "        [1.0917],\n",
      "        [1.0723],\n",
      "        [1.0731],\n",
      "        [1.1282],\n",
      "        [1.0742],\n",
      "        [1.0919],\n",
      "        [1.0895],\n",
      "        [1.0980],\n",
      "        [1.1243],\n",
      "        [1.1034],\n",
      "        [1.1165],\n",
      "        [1.1277],\n",
      "        [1.1291],\n",
      "        [1.1046],\n",
      "        [1.1235],\n",
      "        [1.1233]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0808],\n",
      "        [1.1242],\n",
      "        [1.1246],\n",
      "        [1.1237],\n",
      "        [1.1336],\n",
      "        [1.1339],\n",
      "        [1.0906],\n",
      "        [1.1322],\n",
      "        [1.1212],\n",
      "        [1.1075],\n",
      "        [1.1323],\n",
      "        [1.0982],\n",
      "        [1.1223],\n",
      "        [1.1107],\n",
      "        [1.0448],\n",
      "        [1.1344],\n",
      "        [1.1002],\n",
      "        [1.0884],\n",
      "        [1.1250],\n",
      "        [1.0810],\n",
      "        [1.1173],\n",
      "        [1.0763],\n",
      "        [1.1202],\n",
      "        [1.1197],\n",
      "        [1.1237],\n",
      "        [1.1067],\n",
      "        [1.1116],\n",
      "        [1.0829],\n",
      "        [1.1101],\n",
      "        [1.0793],\n",
      "        [1.1196],\n",
      "        [1.1348],\n",
      "        [1.1252],\n",
      "        [1.1043],\n",
      "        [1.0597],\n",
      "        [1.0297],\n",
      "        [1.1128],\n",
      "        [1.1073],\n",
      "        [1.1086],\n",
      "        [1.1403],\n",
      "        [1.1180],\n",
      "        [1.1106],\n",
      "        [1.1314],\n",
      "        [1.1169],\n",
      "        [1.1360],\n",
      "        [1.0718],\n",
      "        [1.1173],\n",
      "        [1.1370],\n",
      "        [1.1294],\n",
      "        [1.1314],\n",
      "        [1.1235],\n",
      "        [1.1129],\n",
      "        [1.0670],\n",
      "        [1.1064],\n",
      "        [1.1280],\n",
      "        [1.1144],\n",
      "        [1.1036],\n",
      "        [1.0676],\n",
      "        [1.0964],\n",
      "        [1.0944],\n",
      "        [1.0734],\n",
      "        [1.0885],\n",
      "        [1.0974],\n",
      "        [1.1271],\n",
      "        [1.1308],\n",
      "        [1.1087],\n",
      "        [1.1212],\n",
      "        [1.0501],\n",
      "        [1.0928],\n",
      "        [1.0950],\n",
      "        [1.0948],\n",
      "        [1.1114],\n",
      "        [1.1149],\n",
      "        [1.1094],\n",
      "        [1.1209],\n",
      "        [1.1263],\n",
      "        [1.0763],\n",
      "        [1.1172],\n",
      "        [1.1223],\n",
      "        [1.0970],\n",
      "        [1.1337],\n",
      "        [1.1253],\n",
      "        [1.0529],\n",
      "        [1.1202],\n",
      "        [1.1300],\n",
      "        [1.0722],\n",
      "        [1.1308],\n",
      "        [1.1140],\n",
      "        [1.0761],\n",
      "        [1.1301],\n",
      "        [1.0781],\n",
      "        [1.1136],\n",
      "        [1.0866],\n",
      "        [1.0960],\n",
      "        [1.1089],\n",
      "        [1.1193],\n",
      "        [1.1229],\n",
      "        [1.1370],\n",
      "        [1.1272],\n",
      "        [1.1278],\n",
      "        [1.1187],\n",
      "        [1.1213],\n",
      "        [1.0880],\n",
      "        [1.1022],\n",
      "        [1.0977],\n",
      "        [1.1131],\n",
      "        [1.1013],\n",
      "        [0.0229],\n",
      "        [1.1140],\n",
      "        [1.1038],\n",
      "        [1.0930],\n",
      "        [1.0581],\n",
      "        [1.1371],\n",
      "        [1.0779],\n",
      "        [1.1213],\n",
      "        [1.1334],\n",
      "        [1.0859],\n",
      "        [1.1049],\n",
      "        [1.1033],\n",
      "        [1.1052],\n",
      "        [1.0880],\n",
      "        [1.1206],\n",
      "        [1.1019],\n",
      "        [1.1026],\n",
      "        [1.0956],\n",
      "        [1.0654],\n",
      "        [1.1240],\n",
      "        [1.1228]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1077],\n",
      "        [1.1159],\n",
      "        [1.1120],\n",
      "        [1.1060],\n",
      "        [1.0769],\n",
      "        [1.1145],\n",
      "        [1.1324],\n",
      "        [1.1301],\n",
      "        [1.1099],\n",
      "        [1.1305],\n",
      "        [1.0687],\n",
      "        [1.0747],\n",
      "        [1.1113],\n",
      "        [1.1065],\n",
      "        [1.1154],\n",
      "        [1.1225],\n",
      "        [1.1164],\n",
      "        [1.0859],\n",
      "        [1.1013],\n",
      "        [1.0902],\n",
      "        [1.1158],\n",
      "        [1.0996],\n",
      "        [1.1101],\n",
      "        [1.1184],\n",
      "        [1.1060],\n",
      "        [1.1192],\n",
      "        [1.1000],\n",
      "        [1.1157],\n",
      "        [1.0867],\n",
      "        [1.1288],\n",
      "        [1.1258],\n",
      "        [1.1151],\n",
      "        [1.1081],\n",
      "        [1.0893],\n",
      "        [1.1055],\n",
      "        [1.1013],\n",
      "        [1.0975],\n",
      "        [1.0961],\n",
      "        [1.1096],\n",
      "        [1.1354],\n",
      "        [1.0923],\n",
      "        [1.0988],\n",
      "        [1.0814],\n",
      "        [1.1268],\n",
      "        [1.1076],\n",
      "        [1.1192],\n",
      "        [1.0873],\n",
      "        [1.1164],\n",
      "        [1.1240],\n",
      "        [1.0993],\n",
      "        [1.1005],\n",
      "        [1.1220],\n",
      "        [1.0956],\n",
      "        [1.0952],\n",
      "        [1.1332],\n",
      "        [1.0930],\n",
      "        [1.1050],\n",
      "        [1.1132],\n",
      "        [1.1243],\n",
      "        [1.1356],\n",
      "        [1.1200],\n",
      "        [1.1160],\n",
      "        [1.1222],\n",
      "        [1.0716],\n",
      "        [1.0813],\n",
      "        [1.1125],\n",
      "        [1.1020],\n",
      "        [1.1136],\n",
      "        [1.1098],\n",
      "        [1.0900],\n",
      "        [1.1254],\n",
      "        [1.1067],\n",
      "        [1.1113],\n",
      "        [1.0984],\n",
      "        [1.1200],\n",
      "        [1.0955],\n",
      "        [1.1112],\n",
      "        [1.0930],\n",
      "        [1.0842],\n",
      "        [1.1122],\n",
      "        [1.1303],\n",
      "        [1.1130],\n",
      "        [1.0955],\n",
      "        [1.1080],\n",
      "        [1.0989],\n",
      "        [1.0891],\n",
      "        [1.1241],\n",
      "        [1.0739],\n",
      "        [1.0973],\n",
      "        [1.1153],\n",
      "        [1.1188],\n",
      "        [1.1329],\n",
      "        [1.0977],\n",
      "        [1.1073],\n",
      "        [1.1292],\n",
      "        [1.1251],\n",
      "        [1.1257],\n",
      "        [1.1015],\n",
      "        [1.0754],\n",
      "        [1.1359],\n",
      "        [1.1335],\n",
      "        [1.1142],\n",
      "        [1.0915],\n",
      "        [1.0946],\n",
      "        [1.0888],\n",
      "        [1.0810],\n",
      "        [1.1010],\n",
      "        [1.1259],\n",
      "        [1.1127],\n",
      "        [1.1152],\n",
      "        [1.0755],\n",
      "        [1.1193],\n",
      "        [1.0654],\n",
      "        [1.0798],\n",
      "        [1.1069],\n",
      "        [1.1139],\n",
      "        [1.0895],\n",
      "        [1.1051],\n",
      "        [1.0886],\n",
      "        [1.1125],\n",
      "        [1.0885],\n",
      "        [1.1213],\n",
      "        [1.1170],\n",
      "        [1.1353],\n",
      "        [1.1304],\n",
      "        [1.0905],\n",
      "        [1.1283],\n",
      "        [1.1075]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1285],\n",
      "        [1.0964],\n",
      "        [1.0851],\n",
      "        [1.1143],\n",
      "        [1.0527],\n",
      "        [1.1179],\n",
      "        [1.1328],\n",
      "        [1.1050],\n",
      "        [1.0989],\n",
      "        [1.0981],\n",
      "        [1.0899],\n",
      "        [1.1207],\n",
      "        [1.1047],\n",
      "        [1.0772],\n",
      "        [1.1182],\n",
      "        [1.1330],\n",
      "        [1.0698],\n",
      "        [1.1053],\n",
      "        [1.1177],\n",
      "        [1.1110],\n",
      "        [1.1290],\n",
      "        [1.1254],\n",
      "        [1.1285],\n",
      "        [1.0809],\n",
      "        [1.1120],\n",
      "        [1.0768],\n",
      "        [1.1033],\n",
      "        [1.0777],\n",
      "        [1.1078],\n",
      "        [1.1076],\n",
      "        [1.1075],\n",
      "        [1.1243],\n",
      "        [1.1092],\n",
      "        [1.0978],\n",
      "        [1.0747],\n",
      "        [1.1304],\n",
      "        [1.1217],\n",
      "        [1.1312],\n",
      "        [1.0785],\n",
      "        [1.1282],\n",
      "        [1.1116],\n",
      "        [1.1055],\n",
      "        [1.1080],\n",
      "        [1.1289],\n",
      "        [1.1098],\n",
      "        [1.1013],\n",
      "        [1.0765],\n",
      "        [1.1083],\n",
      "        [1.0904],\n",
      "        [1.1305],\n",
      "        [1.1102],\n",
      "        [1.1020],\n",
      "        [1.1108],\n",
      "        [1.1199],\n",
      "        [1.1331],\n",
      "        [1.0626],\n",
      "        [1.0778],\n",
      "        [1.1199],\n",
      "        [1.1198],\n",
      "        [1.1048],\n",
      "        [1.1260],\n",
      "        [1.0978],\n",
      "        [1.1307],\n",
      "        [1.1204],\n",
      "        [1.1179],\n",
      "        [1.1199],\n",
      "        [1.0813],\n",
      "        [1.1266],\n",
      "        [1.0763],\n",
      "        [1.0830],\n",
      "        [1.1165],\n",
      "        [1.1171],\n",
      "        [1.1223],\n",
      "        [1.0943],\n",
      "        [1.0109],\n",
      "        [1.1174],\n",
      "        [1.1091],\n",
      "        [1.1080],\n",
      "        [1.0867],\n",
      "        [1.1311],\n",
      "        [1.0967],\n",
      "        [1.1066],\n",
      "        [1.1194],\n",
      "        [1.1034],\n",
      "        [1.1092],\n",
      "        [1.0961],\n",
      "        [1.1201],\n",
      "        [1.1132],\n",
      "        [1.1084],\n",
      "        [1.1341],\n",
      "        [1.1149],\n",
      "        [1.0761],\n",
      "        [1.0960],\n",
      "        [1.1102],\n",
      "        [1.1022],\n",
      "        [1.0609],\n",
      "        [1.0999],\n",
      "        [1.0997],\n",
      "        [1.1010],\n",
      "        [1.1067],\n",
      "        [1.0725],\n",
      "        [1.1214],\n",
      "        [1.1265],\n",
      "        [1.1021],\n",
      "        [1.0987],\n",
      "        [1.1171],\n",
      "        [1.1332],\n",
      "        [1.1345],\n",
      "        [1.1177],\n",
      "        [1.1288],\n",
      "        [1.1033],\n",
      "        [1.1080],\n",
      "        [1.1150],\n",
      "        [1.1144],\n",
      "        [1.0895],\n",
      "        [1.1130],\n",
      "        [1.1109],\n",
      "        [0.3136],\n",
      "        [1.1126],\n",
      "        [1.1287],\n",
      "        [1.1127],\n",
      "        [1.1216],\n",
      "        [1.1334],\n",
      "        [1.1100],\n",
      "        [1.1259],\n",
      "        [1.1320],\n",
      "        [1.0856],\n",
      "        [1.0855]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0906],\n",
      "        [1.0619],\n",
      "        [1.0591],\n",
      "        [1.1303],\n",
      "        [1.1118],\n",
      "        [1.1029],\n",
      "        [1.1127],\n",
      "        [1.0718],\n",
      "        [1.1003],\n",
      "        [1.1034],\n",
      "        [1.1287],\n",
      "        [1.1246],\n",
      "        [1.1256],\n",
      "        [1.1045],\n",
      "        [1.1316],\n",
      "        [1.0874],\n",
      "        [1.1263],\n",
      "        [1.1151],\n",
      "        [1.0830],\n",
      "        [1.1078],\n",
      "        [1.1197],\n",
      "        [1.0908],\n",
      "        [1.1225],\n",
      "        [1.1283],\n",
      "        [1.1285],\n",
      "        [1.1012],\n",
      "        [1.1185],\n",
      "        [1.1233],\n",
      "        [1.1085],\n",
      "        [1.1271],\n",
      "        [1.1190],\n",
      "        [1.1268],\n",
      "        [1.1016],\n",
      "        [1.1300],\n",
      "        [1.1042],\n",
      "        [1.1130],\n",
      "        [1.1063],\n",
      "        [1.1262],\n",
      "        [1.1142],\n",
      "        [1.1208],\n",
      "        [1.1254],\n",
      "        [1.1056],\n",
      "        [1.0995],\n",
      "        [1.0870],\n",
      "        [1.1246],\n",
      "        [1.0825],\n",
      "        [1.0913],\n",
      "        [1.1144],\n",
      "        [1.1043],\n",
      "        [1.1071],\n",
      "        [1.0986],\n",
      "        [1.1068],\n",
      "        [1.1282],\n",
      "        [1.0916],\n",
      "        [1.1237],\n",
      "        [1.1249],\n",
      "        [1.0882],\n",
      "        [1.1246],\n",
      "        [1.0937],\n",
      "        [1.0963],\n",
      "        [1.1065],\n",
      "        [1.1151],\n",
      "        [1.1217],\n",
      "        [1.0804],\n",
      "        [1.0879],\n",
      "        [1.1183],\n",
      "        [1.1304],\n",
      "        [1.1281],\n",
      "        [1.0856],\n",
      "        [1.1156],\n",
      "        [1.1111],\n",
      "        [1.0941],\n",
      "        [1.1176],\n",
      "        [1.0824],\n",
      "        [1.1234],\n",
      "        [1.1110],\n",
      "        [1.1073],\n",
      "        [1.1252],\n",
      "        [1.1082],\n",
      "        [1.1268],\n",
      "        [1.1135],\n",
      "        [1.1042],\n",
      "        [1.1062],\n",
      "        [1.1294],\n",
      "        [1.1048],\n",
      "        [1.0670],\n",
      "        [1.1087],\n",
      "        [1.1217],\n",
      "        [1.0657],\n",
      "        [1.1096],\n",
      "        [1.1134],\n",
      "        [1.1325],\n",
      "        [1.0875],\n",
      "        [1.1059],\n",
      "        [1.0877],\n",
      "        [1.1135],\n",
      "        [1.1225],\n",
      "        [1.1283],\n",
      "        [1.0903],\n",
      "        [1.1208],\n",
      "        [1.0831],\n",
      "        [1.1227],\n",
      "        [1.4325],\n",
      "        [1.0712],\n",
      "        [1.1166],\n",
      "        [1.1166],\n",
      "        [1.1207],\n",
      "        [1.0908],\n",
      "        [1.1089],\n",
      "        [1.1053],\n",
      "        [1.1323],\n",
      "        [1.0362],\n",
      "        [1.1182],\n",
      "        [1.0512],\n",
      "        [1.0915],\n",
      "        [1.1171],\n",
      "        [1.0761],\n",
      "        [1.1239],\n",
      "        [1.1283],\n",
      "        [1.0871],\n",
      "        [1.0753],\n",
      "        [1.0736],\n",
      "        [1.1235],\n",
      "        [1.0871],\n",
      "        [1.0993],\n",
      "        [1.1197],\n",
      "        [1.0818],\n",
      "        [1.0910]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1249],\n",
      "        [1.0924],\n",
      "        [1.1065],\n",
      "        [1.1176]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  22 | lr 0.00100 train_loss 2.12315 | val_loss 2.28913 | val_rmse 1.51299\n",
      "tensor([[1.1063],\n",
      "        [1.0683],\n",
      "        [1.0507],\n",
      "        [1.1238],\n",
      "        [1.1218],\n",
      "        [1.1178],\n",
      "        [1.0650],\n",
      "        [1.0485],\n",
      "        [1.1261],\n",
      "        [1.1298],\n",
      "        [1.0845],\n",
      "        [1.0934],\n",
      "        [1.1031],\n",
      "        [1.1121],\n",
      "        [1.1094],\n",
      "        [1.1239],\n",
      "        [1.1191],\n",
      "        [1.1040],\n",
      "        [1.0907],\n",
      "        [1.0970],\n",
      "        [1.0921],\n",
      "        [1.1086],\n",
      "        [1.0922],\n",
      "        [1.0640],\n",
      "        [1.1284],\n",
      "        [1.0901],\n",
      "        [1.1302],\n",
      "        [1.0788],\n",
      "        [1.0586],\n",
      "        [1.1087],\n",
      "        [1.1143],\n",
      "        [1.0683],\n",
      "        [1.0954],\n",
      "        [1.1140],\n",
      "        [1.1136],\n",
      "        [1.0557],\n",
      "        [1.1113],\n",
      "        [1.1100],\n",
      "        [1.1131],\n",
      "        [1.0941],\n",
      "        [1.1195],\n",
      "        [1.0982],\n",
      "        [1.0789],\n",
      "        [1.0827],\n",
      "        [1.1004],\n",
      "        [1.1270],\n",
      "        [1.1202],\n",
      "        [1.1076],\n",
      "        [1.1050],\n",
      "        [1.1264],\n",
      "        [1.1078],\n",
      "        [1.0981],\n",
      "        [1.0635],\n",
      "        [1.0972],\n",
      "        [1.0776],\n",
      "        [1.1201],\n",
      "        [1.1311],\n",
      "        [1.0864],\n",
      "        [1.0645],\n",
      "        [1.1173],\n",
      "        [1.1144],\n",
      "        [1.0893],\n",
      "        [1.0873],\n",
      "        [1.0613],\n",
      "        [1.0974],\n",
      "        [1.1203],\n",
      "        [1.1302],\n",
      "        [1.0973],\n",
      "        [1.1112],\n",
      "        [1.1251],\n",
      "        [1.1154],\n",
      "        [1.1041],\n",
      "        [1.0951],\n",
      "        [1.0946],\n",
      "        [1.0599],\n",
      "        [1.1108],\n",
      "        [1.1349],\n",
      "        [1.1302],\n",
      "        [1.0989],\n",
      "        [1.1020],\n",
      "        [1.1215],\n",
      "        [1.0919],\n",
      "        [1.1163],\n",
      "        [1.1237],\n",
      "        [1.1030],\n",
      "        [1.0655],\n",
      "        [1.0745],\n",
      "        [1.0903],\n",
      "        [1.0996],\n",
      "        [1.0963],\n",
      "        [1.1027],\n",
      "        [1.1189],\n",
      "        [1.1097],\n",
      "        [1.1091],\n",
      "        [1.0963],\n",
      "        [1.1220],\n",
      "        [1.1081],\n",
      "        [1.0721],\n",
      "        [1.0968],\n",
      "        [1.1013],\n",
      "        [1.1086],\n",
      "        [1.0871],\n",
      "        [1.1038],\n",
      "        [1.1006],\n",
      "        [1.1287],\n",
      "        [1.1011],\n",
      "        [1.0891],\n",
      "        [1.1086],\n",
      "        [1.1286],\n",
      "        [1.1278],\n",
      "        [1.1183],\n",
      "        [1.0816],\n",
      "        [1.0929],\n",
      "        [1.0921],\n",
      "        [1.1154],\n",
      "        [1.1254],\n",
      "        [1.0775],\n",
      "        [1.0977],\n",
      "        [1.0943],\n",
      "        [1.0545],\n",
      "        [1.1313],\n",
      "        [1.1102],\n",
      "        [1.1048],\n",
      "        [1.1022],\n",
      "        [1.1122],\n",
      "        [1.1259],\n",
      "        [1.1289],\n",
      "        [1.1045]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0992],\n",
      "        [1.1214],\n",
      "        [1.0408],\n",
      "        [1.0931],\n",
      "        [1.1208],\n",
      "        [1.1016],\n",
      "        [1.1233],\n",
      "        [1.0957],\n",
      "        [1.1029],\n",
      "        [1.0963],\n",
      "        [1.0961],\n",
      "        [1.0990],\n",
      "        [1.1143],\n",
      "        [1.1151],\n",
      "        [1.1039],\n",
      "        [1.0836],\n",
      "        [1.0995],\n",
      "        [1.1103],\n",
      "        [1.0917],\n",
      "        [1.1127],\n",
      "        [1.0990],\n",
      "        [1.0985],\n",
      "        [1.1086],\n",
      "        [1.1069],\n",
      "        [1.1206],\n",
      "        [1.0735],\n",
      "        [1.1078],\n",
      "        [1.1135],\n",
      "        [1.0603],\n",
      "        [1.1053],\n",
      "        [1.1121],\n",
      "        [1.1049],\n",
      "        [1.1038],\n",
      "        [1.1250],\n",
      "        [1.1033],\n",
      "        [1.1083],\n",
      "        [1.0660],\n",
      "        [1.1119],\n",
      "        [1.1162],\n",
      "        [1.1165],\n",
      "        [1.1088],\n",
      "        [1.1203],\n",
      "        [1.1330],\n",
      "        [1.0855],\n",
      "        [1.1117],\n",
      "        [1.1212],\n",
      "        [1.0848],\n",
      "        [1.0714],\n",
      "        [1.1045],\n",
      "        [1.1305],\n",
      "        [1.1100],\n",
      "        [1.1108],\n",
      "        [1.0425],\n",
      "        [1.1019],\n",
      "        [1.0798],\n",
      "        [1.1187],\n",
      "        [1.1110],\n",
      "        [1.0699],\n",
      "        [1.0996],\n",
      "        [1.0880],\n",
      "        [1.0985],\n",
      "        [0.1506],\n",
      "        [1.0668],\n",
      "        [1.1311],\n",
      "        [1.1229],\n",
      "        [1.0695],\n",
      "        [1.1276],\n",
      "        [1.1021],\n",
      "        [1.1102],\n",
      "        [1.1098],\n",
      "        [1.1278],\n",
      "        [1.0808],\n",
      "        [1.1118],\n",
      "        [1.1183],\n",
      "        [1.1289],\n",
      "        [1.0855],\n",
      "        [1.1085],\n",
      "        [1.1280],\n",
      "        [1.0654],\n",
      "        [1.0976],\n",
      "        [1.1214],\n",
      "        [1.0691],\n",
      "        [1.1110],\n",
      "        [1.1252],\n",
      "        [1.0580],\n",
      "        [1.0776],\n",
      "        [1.0915],\n",
      "        [1.1139],\n",
      "        [1.1182],\n",
      "        [1.1045],\n",
      "        [1.1199],\n",
      "        [1.1108],\n",
      "        [1.1064],\n",
      "        [1.1119],\n",
      "        [1.1180],\n",
      "        [1.1217],\n",
      "        [1.1056],\n",
      "        [1.0954],\n",
      "        [1.1318],\n",
      "        [1.0881],\n",
      "        [1.1224],\n",
      "        [1.0860],\n",
      "        [1.1028],\n",
      "        [1.1132],\n",
      "        [1.0651],\n",
      "        [1.1170],\n",
      "        [1.1152],\n",
      "        [1.0895],\n",
      "        [1.1161],\n",
      "        [1.1242],\n",
      "        [1.1196],\n",
      "        [1.0906],\n",
      "        [1.1179],\n",
      "        [1.0651],\n",
      "        [0.8924],\n",
      "        [1.1043],\n",
      "        [1.0780],\n",
      "        [1.0956],\n",
      "        [1.1228],\n",
      "        [1.1118],\n",
      "        [1.1096],\n",
      "        [1.0541],\n",
      "        [1.1182],\n",
      "        [1.1008],\n",
      "        [1.1161],\n",
      "        [1.0485],\n",
      "        [1.0549],\n",
      "        [1.0577]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0755],\n",
      "        [1.1089],\n",
      "        [1.0659],\n",
      "        [1.1041],\n",
      "        [1.1249],\n",
      "        [1.0765],\n",
      "        [1.0881],\n",
      "        [1.1267],\n",
      "        [1.1049],\n",
      "        [1.0954],\n",
      "        [1.1027],\n",
      "        [1.1071],\n",
      "        [1.1208],\n",
      "        [1.1160],\n",
      "        [1.0899],\n",
      "        [1.1095],\n",
      "        [1.1070],\n",
      "        [1.1107],\n",
      "        [1.1141],\n",
      "        [1.0806],\n",
      "        [1.1064],\n",
      "        [1.1187],\n",
      "        [1.1026],\n",
      "        [1.1119],\n",
      "        [1.1160],\n",
      "        [1.1029],\n",
      "        [1.1132],\n",
      "        [1.0748],\n",
      "        [1.0819],\n",
      "        [1.0750],\n",
      "        [1.0971],\n",
      "        [1.0978],\n",
      "        [1.1238],\n",
      "        [1.0913],\n",
      "        [1.1063],\n",
      "        [1.1175],\n",
      "        [1.1139],\n",
      "        [1.1043],\n",
      "        [1.1207],\n",
      "        [1.0769],\n",
      "        [1.1152],\n",
      "        [1.0959],\n",
      "        [1.1101],\n",
      "        [1.0934],\n",
      "        [1.1121],\n",
      "        [1.0950],\n",
      "        [1.1003],\n",
      "        [1.1271],\n",
      "        [1.0881],\n",
      "        [1.1103],\n",
      "        [1.1315],\n",
      "        [1.1168],\n",
      "        [1.0576],\n",
      "        [1.1299],\n",
      "        [1.0692],\n",
      "        [1.0753],\n",
      "        [1.1023],\n",
      "        [1.1072],\n",
      "        [1.0467],\n",
      "        [1.1310],\n",
      "        [1.0811],\n",
      "        [1.1047],\n",
      "        [1.1078],\n",
      "        [1.1200],\n",
      "        [1.0616],\n",
      "        [1.1069],\n",
      "        [1.0785],\n",
      "        [1.0737],\n",
      "        [1.1170],\n",
      "        [1.1269],\n",
      "        [1.0991],\n",
      "        [1.0911],\n",
      "        [1.1011],\n",
      "        [1.0924],\n",
      "        [1.0827],\n",
      "        [1.0840],\n",
      "        [1.0818],\n",
      "        [1.0742],\n",
      "        [1.0980],\n",
      "        [1.1168],\n",
      "        [1.0691],\n",
      "        [1.1288],\n",
      "        [1.1272],\n",
      "        [1.1005],\n",
      "        [1.0822],\n",
      "        [1.1056],\n",
      "        [1.1094],\n",
      "        [1.1171],\n",
      "        [1.1127],\n",
      "        [1.0992],\n",
      "        [1.1206],\n",
      "        [1.1243],\n",
      "        [1.1295],\n",
      "        [1.1214],\n",
      "        [1.1164],\n",
      "        [1.0472],\n",
      "        [1.1148],\n",
      "        [1.0983],\n",
      "        [1.1023],\n",
      "        [1.1211],\n",
      "        [1.1113],\n",
      "        [1.1262],\n",
      "        [1.0756],\n",
      "        [1.0957],\n",
      "        [1.0688],\n",
      "        [1.0900],\n",
      "        [1.1315],\n",
      "        [1.0853],\n",
      "        [1.1008],\n",
      "        [1.0652],\n",
      "        [1.0910],\n",
      "        [1.0762],\n",
      "        [1.0979],\n",
      "        [1.0943],\n",
      "        [1.0632],\n",
      "        [1.0719],\n",
      "        [1.1019],\n",
      "        [1.0879],\n",
      "        [1.0975],\n",
      "        [1.0940],\n",
      "        [1.1011],\n",
      "        [1.0883],\n",
      "        [1.0807],\n",
      "        [1.1060],\n",
      "        [1.0600],\n",
      "        [1.0562],\n",
      "        [1.0909],\n",
      "        [1.0879]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.1177],\n",
      "        [ 1.0822],\n",
      "        [ 1.1163],\n",
      "        [-0.0017],\n",
      "        [ 1.1046],\n",
      "        [ 1.1072],\n",
      "        [ 1.1096],\n",
      "        [ 1.0948],\n",
      "        [ 1.0839],\n",
      "        [ 1.0995],\n",
      "        [ 1.1271],\n",
      "        [ 1.1092],\n",
      "        [ 1.1036],\n",
      "        [ 1.1170],\n",
      "        [ 1.0842],\n",
      "        [ 1.0861],\n",
      "        [ 1.0893],\n",
      "        [ 1.1119],\n",
      "        [ 1.0790],\n",
      "        [ 1.0866],\n",
      "        [ 1.1053],\n",
      "        [ 1.1086],\n",
      "        [ 1.0869],\n",
      "        [ 1.0960],\n",
      "        [ 1.0917],\n",
      "        [ 1.1058],\n",
      "        [ 1.0755],\n",
      "        [ 1.1028],\n",
      "        [ 1.0996],\n",
      "        [ 1.1052],\n",
      "        [ 1.1230],\n",
      "        [ 1.0783],\n",
      "        [ 1.1246],\n",
      "        [ 1.1165],\n",
      "        [ 1.0621],\n",
      "        [ 1.1225],\n",
      "        [ 1.1153],\n",
      "        [ 1.0535],\n",
      "        [ 1.0941],\n",
      "        [ 1.0797],\n",
      "        [ 1.0521],\n",
      "        [ 1.0965],\n",
      "        [ 1.0990],\n",
      "        [ 1.0958],\n",
      "        [ 1.0939],\n",
      "        [ 1.1177],\n",
      "        [ 1.1226],\n",
      "        [ 1.1044],\n",
      "        [ 1.0787],\n",
      "        [ 1.0745],\n",
      "        [ 1.1173],\n",
      "        [ 1.1124],\n",
      "        [ 1.0413],\n",
      "        [ 1.1154],\n",
      "        [ 1.1080],\n",
      "        [ 1.1138],\n",
      "        [ 1.0755],\n",
      "        [ 1.0695],\n",
      "        [ 1.1269],\n",
      "        [ 1.1181],\n",
      "        [ 1.0686],\n",
      "        [ 1.0919],\n",
      "        [ 1.1245],\n",
      "        [ 1.0799],\n",
      "        [ 1.1260],\n",
      "        [ 1.0714],\n",
      "        [ 1.0717],\n",
      "        [ 1.1077],\n",
      "        [ 1.1000],\n",
      "        [ 1.0584],\n",
      "        [ 1.0930],\n",
      "        [ 1.1291],\n",
      "        [ 1.0932],\n",
      "        [ 1.1274],\n",
      "        [ 1.1050],\n",
      "        [ 1.1098],\n",
      "        [ 1.0609],\n",
      "        [ 1.1153],\n",
      "        [ 1.1249],\n",
      "        [ 1.1329],\n",
      "        [ 1.0908],\n",
      "        [ 1.1261],\n",
      "        [ 1.0929],\n",
      "        [ 1.1020],\n",
      "        [ 1.0761],\n",
      "        [ 1.1133],\n",
      "        [ 1.0903],\n",
      "        [ 1.1013],\n",
      "        [ 1.0685],\n",
      "        [ 1.0978],\n",
      "        [ 1.0657],\n",
      "        [ 1.1104],\n",
      "        [ 1.0781],\n",
      "        [ 1.0986],\n",
      "        [ 1.0799],\n",
      "        [ 1.1095],\n",
      "        [ 1.1055],\n",
      "        [ 1.0743],\n",
      "        [ 1.0882],\n",
      "        [ 1.1057],\n",
      "        [ 1.1295],\n",
      "        [ 1.0835],\n",
      "        [ 1.0829],\n",
      "        [ 1.1255],\n",
      "        [ 1.1087],\n",
      "        [ 1.1192],\n",
      "        [ 1.1216],\n",
      "        [ 1.0807],\n",
      "        [ 1.0561],\n",
      "        [ 1.0985],\n",
      "        [ 1.1267],\n",
      "        [ 1.0951],\n",
      "        [ 1.1041],\n",
      "        [ 1.1016],\n",
      "        [ 1.1123],\n",
      "        [ 1.0982],\n",
      "        [ 1.0202],\n",
      "        [ 1.0970],\n",
      "        [ 1.1093],\n",
      "        [ 1.1253],\n",
      "        [ 1.1015],\n",
      "        [ 1.1273],\n",
      "        [ 1.1204],\n",
      "        [ 1.1082],\n",
      "        [ 1.1086],\n",
      "        [ 1.1252],\n",
      "        [ 1.1276],\n",
      "        [ 1.1089]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0998],\n",
      "        [1.0988],\n",
      "        [1.0990],\n",
      "        [1.1058],\n",
      "        [1.1195],\n",
      "        [1.1192],\n",
      "        [1.0896],\n",
      "        [1.1111],\n",
      "        [1.0818],\n",
      "        [1.0940],\n",
      "        [1.1195],\n",
      "        [1.1112],\n",
      "        [1.0901],\n",
      "        [1.1290],\n",
      "        [1.0626],\n",
      "        [1.1012],\n",
      "        [1.0674],\n",
      "        [1.1008],\n",
      "        [1.1127],\n",
      "        [1.1104],\n",
      "        [1.1169],\n",
      "        [1.1020],\n",
      "        [1.1125],\n",
      "        [1.1289],\n",
      "        [1.1182],\n",
      "        [1.0767],\n",
      "        [1.0894],\n",
      "        [1.1046],\n",
      "        [1.1105],\n",
      "        [1.1002],\n",
      "        [1.1174],\n",
      "        [1.0849],\n",
      "        [1.1167],\n",
      "        [1.1144],\n",
      "        [1.0972],\n",
      "        [1.1154],\n",
      "        [1.1284],\n",
      "        [1.0911],\n",
      "        [1.1229],\n",
      "        [1.1230],\n",
      "        [1.1133],\n",
      "        [1.1059],\n",
      "        [1.0847],\n",
      "        [1.1102],\n",
      "        [2.7897],\n",
      "        [1.1051],\n",
      "        [1.0965],\n",
      "        [1.0963],\n",
      "        [1.0889],\n",
      "        [1.1071],\n",
      "        [1.0705],\n",
      "        [1.1052],\n",
      "        [1.1020],\n",
      "        [1.1089],\n",
      "        [1.1033],\n",
      "        [1.1278],\n",
      "        [1.0587],\n",
      "        [1.0798],\n",
      "        [1.1034],\n",
      "        [1.1245],\n",
      "        [1.1078],\n",
      "        [1.0990],\n",
      "        [1.1171],\n",
      "        [1.1181],\n",
      "        [1.0753],\n",
      "        [1.1045],\n",
      "        [1.0987],\n",
      "        [1.0919],\n",
      "        [1.1232],\n",
      "        [1.1259],\n",
      "        [1.0810],\n",
      "        [1.0595],\n",
      "        [1.0737],\n",
      "        [1.0768],\n",
      "        [1.1060],\n",
      "        [1.1289],\n",
      "        [1.1155],\n",
      "        [1.1227],\n",
      "        [1.1231],\n",
      "        [1.1132],\n",
      "        [1.0992],\n",
      "        [1.1062],\n",
      "        [1.1020],\n",
      "        [1.0785],\n",
      "        [1.1024],\n",
      "        [1.1289],\n",
      "        [1.0943],\n",
      "        [1.1276],\n",
      "        [1.0411],\n",
      "        [1.1032],\n",
      "        [1.0946],\n",
      "        [1.1225],\n",
      "        [1.0787],\n",
      "        [1.1010],\n",
      "        [1.0943],\n",
      "        [1.1255],\n",
      "        [1.1114],\n",
      "        [1.1146],\n",
      "        [1.1037],\n",
      "        [1.0952],\n",
      "        [1.0728],\n",
      "        [1.0853],\n",
      "        [1.0895],\n",
      "        [1.0994],\n",
      "        [1.1047],\n",
      "        [1.0871],\n",
      "        [1.1083],\n",
      "        [1.1168],\n",
      "        [3.0654],\n",
      "        [1.0790],\n",
      "        [1.0874],\n",
      "        [1.0878],\n",
      "        [1.1198],\n",
      "        [1.1113],\n",
      "        [1.0470],\n",
      "        [1.1128],\n",
      "        [1.0943],\n",
      "        [1.1181],\n",
      "        [1.1012],\n",
      "        [1.0486],\n",
      "        [1.0826],\n",
      "        [1.0806],\n",
      "        [1.1323],\n",
      "        [1.1123],\n",
      "        [1.0823],\n",
      "        [1.1204],\n",
      "        [1.0735],\n",
      "        [1.1238]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1016],\n",
      "        [1.1171],\n",
      "        [1.1199],\n",
      "        [1.1192],\n",
      "        [1.1202],\n",
      "        [1.0550],\n",
      "        [1.1086],\n",
      "        [1.0587],\n",
      "        [1.0891],\n",
      "        [1.0744],\n",
      "        [1.0687],\n",
      "        [1.1253],\n",
      "        [1.1203],\n",
      "        [1.0689],\n",
      "        [1.0632],\n",
      "        [1.1123],\n",
      "        [1.1146],\n",
      "        [1.1119],\n",
      "        [1.1155],\n",
      "        [1.1129],\n",
      "        [1.1252],\n",
      "        [1.1232],\n",
      "        [1.0874],\n",
      "        [1.1229],\n",
      "        [1.1143],\n",
      "        [1.1221],\n",
      "        [0.4975],\n",
      "        [1.0744],\n",
      "        [1.0911],\n",
      "        [1.0853],\n",
      "        [1.0912],\n",
      "        [1.1239],\n",
      "        [1.0856],\n",
      "        [1.1203],\n",
      "        [1.1175],\n",
      "        [1.0687],\n",
      "        [1.1125],\n",
      "        [1.0883],\n",
      "        [1.1285],\n",
      "        [1.1102],\n",
      "        [1.0703],\n",
      "        [1.1010],\n",
      "        [1.0765],\n",
      "        [1.0659],\n",
      "        [1.0991],\n",
      "        [1.0992],\n",
      "        [1.0907],\n",
      "        [1.0366],\n",
      "        [1.0987],\n",
      "        [1.1178],\n",
      "        [1.1168],\n",
      "        [1.1236],\n",
      "        [1.1189],\n",
      "        [1.1064],\n",
      "        [1.1117],\n",
      "        [1.0860],\n",
      "        [1.0808],\n",
      "        [1.1181],\n",
      "        [1.0761],\n",
      "        [1.1123],\n",
      "        [1.0897],\n",
      "        [1.0724],\n",
      "        [1.0928],\n",
      "        [1.1174],\n",
      "        [1.1059],\n",
      "        [1.0735],\n",
      "        [1.0903],\n",
      "        [1.0749],\n",
      "        [1.0619],\n",
      "        [1.1247],\n",
      "        [1.1239],\n",
      "        [1.1229],\n",
      "        [1.1178],\n",
      "        [1.1104],\n",
      "        [1.0859],\n",
      "        [1.0319],\n",
      "        [1.1076],\n",
      "        [1.1195],\n",
      "        [1.0771],\n",
      "        [1.1004],\n",
      "        [1.0565],\n",
      "        [1.0637],\n",
      "        [1.1121],\n",
      "        [1.1179],\n",
      "        [1.0931],\n",
      "        [1.1030],\n",
      "        [1.1287],\n",
      "        [1.1089],\n",
      "        [1.0977],\n",
      "        [1.0995],\n",
      "        [1.0730],\n",
      "        [1.1046],\n",
      "        [1.0809],\n",
      "        [1.0771],\n",
      "        [1.1060],\n",
      "        [1.0971],\n",
      "        [1.0953],\n",
      "        [1.0976],\n",
      "        [1.1058],\n",
      "        [1.1211],\n",
      "        [1.0987],\n",
      "        [1.1094],\n",
      "        [1.1288],\n",
      "        [1.1106],\n",
      "        [1.1160],\n",
      "        [1.0956],\n",
      "        [1.1100],\n",
      "        [1.1011],\n",
      "        [1.0788],\n",
      "        [1.1275],\n",
      "        [1.0860],\n",
      "        [1.1090],\n",
      "        [1.1161],\n",
      "        [1.0922],\n",
      "        [1.1004],\n",
      "        [1.1155],\n",
      "        [1.1174],\n",
      "        [1.0939],\n",
      "        [1.1116],\n",
      "        [1.1123],\n",
      "        [1.1140],\n",
      "        [1.1078],\n",
      "        [1.1269],\n",
      "        [1.1218],\n",
      "        [1.0933],\n",
      "        [1.1056],\n",
      "        [1.1038],\n",
      "        [1.0733]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1008],\n",
      "        [1.1161],\n",
      "        [1.1124],\n",
      "        [1.0714],\n",
      "        [1.0909],\n",
      "        [1.0993],\n",
      "        [1.0764],\n",
      "        [1.1171],\n",
      "        [1.0759],\n",
      "        [1.0798],\n",
      "        [1.1177],\n",
      "        [1.0878],\n",
      "        [1.0775],\n",
      "        [1.0480],\n",
      "        [1.1114],\n",
      "        [1.0965],\n",
      "        [1.1027],\n",
      "        [1.0956],\n",
      "        [1.1284],\n",
      "        [1.1127],\n",
      "        [1.1268],\n",
      "        [1.0947],\n",
      "        [1.0908],\n",
      "        [1.0765],\n",
      "        [1.0444],\n",
      "        [1.0738],\n",
      "        [1.0917],\n",
      "        [1.0979],\n",
      "        [1.1285],\n",
      "        [1.0829],\n",
      "        [1.1099],\n",
      "        [1.0828],\n",
      "        [1.0912],\n",
      "        [1.1148],\n",
      "        [1.1048],\n",
      "        [1.1025],\n",
      "        [1.0812],\n",
      "        [1.0851],\n",
      "        [1.1220],\n",
      "        [1.0728],\n",
      "        [1.0740],\n",
      "        [1.1214],\n",
      "        [1.1266],\n",
      "        [1.0536],\n",
      "        [1.0994],\n",
      "        [1.0989],\n",
      "        [1.0610],\n",
      "        [1.1213],\n",
      "        [1.1077],\n",
      "        [1.0631],\n",
      "        [1.1142],\n",
      "        [1.1005],\n",
      "        [1.1101],\n",
      "        [1.1137],\n",
      "        [1.0980],\n",
      "        [1.1173],\n",
      "        [1.0859],\n",
      "        [1.0805],\n",
      "        [1.0990],\n",
      "        [1.1004],\n",
      "        [1.1245],\n",
      "        [1.0368],\n",
      "        [1.0700],\n",
      "        [1.1053],\n",
      "        [1.0999],\n",
      "        [1.1182],\n",
      "        [1.1023],\n",
      "        [1.0961],\n",
      "        [1.1033],\n",
      "        [1.1074],\n",
      "        [1.1040],\n",
      "        [1.0569],\n",
      "        [1.1117],\n",
      "        [1.1278],\n",
      "        [1.0940],\n",
      "        [1.0993],\n",
      "        [1.0808],\n",
      "        [1.0815],\n",
      "        [1.1252],\n",
      "        [1.0470],\n",
      "        [1.0913],\n",
      "        [1.0767],\n",
      "        [1.0895],\n",
      "        [1.1148],\n",
      "        [1.0768],\n",
      "        [1.0602],\n",
      "        [1.0770],\n",
      "        [1.1132],\n",
      "        [1.0973],\n",
      "        [1.0980],\n",
      "        [1.1069],\n",
      "        [1.1019],\n",
      "        [1.0846],\n",
      "        [1.1253],\n",
      "        [1.0849],\n",
      "        [1.1224],\n",
      "        [1.1174],\n",
      "        [1.1028],\n",
      "        [1.0872],\n",
      "        [1.0681],\n",
      "        [1.1284],\n",
      "        [1.0937],\n",
      "        [1.0610],\n",
      "        [1.0786],\n",
      "        [1.1078],\n",
      "        [1.1042],\n",
      "        [1.0804],\n",
      "        [0.9974],\n",
      "        [1.1105],\n",
      "        [1.0927],\n",
      "        [1.1125],\n",
      "        [1.0898],\n",
      "        [1.0962],\n",
      "        [1.0816],\n",
      "        [1.1269],\n",
      "        [1.1184],\n",
      "        [1.1137],\n",
      "        [1.1064],\n",
      "        [1.0892],\n",
      "        [1.1182],\n",
      "        [1.0728],\n",
      "        [1.1249],\n",
      "        [1.0644],\n",
      "        [1.0989],\n",
      "        [1.1164],\n",
      "        [1.0967],\n",
      "        [1.1049],\n",
      "        [1.0985]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1083],\n",
      "        [1.0700],\n",
      "        [1.1269],\n",
      "        [1.1046]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  23 | lr 0.00100 train_loss 2.13600 | val_loss 2.28974 | val_rmse 1.51319\n",
      "tensor([[1.1077],\n",
      "        [1.1297],\n",
      "        [1.1190],\n",
      "        [1.1000],\n",
      "        [1.1027],\n",
      "        [1.0888],\n",
      "        [1.1288],\n",
      "        [1.0871],\n",
      "        [1.1288],\n",
      "        [1.0676],\n",
      "        [1.0921],\n",
      "        [1.0914],\n",
      "        [1.0928],\n",
      "        [1.0364],\n",
      "        [1.0867],\n",
      "        [1.1145],\n",
      "        [1.1105],\n",
      "        [1.1199],\n",
      "        [1.1127],\n",
      "        [1.1082],\n",
      "        [1.1283],\n",
      "        [1.0751],\n",
      "        [1.1154],\n",
      "        [1.0996],\n",
      "        [1.0681],\n",
      "        [1.1186],\n",
      "        [1.1190],\n",
      "        [1.0758],\n",
      "        [1.1002],\n",
      "        [1.0940],\n",
      "        [1.0667],\n",
      "        [1.1065],\n",
      "        [1.0882],\n",
      "        [1.0961],\n",
      "        [1.1125],\n",
      "        [1.1105],\n",
      "        [1.1181],\n",
      "        [1.0653],\n",
      "        [1.1010],\n",
      "        [1.1000],\n",
      "        [1.1073],\n",
      "        [1.1247],\n",
      "        [1.1112],\n",
      "        [1.0927],\n",
      "        [1.0765],\n",
      "        [1.1223],\n",
      "        [1.1185],\n",
      "        [1.0943],\n",
      "        [1.1128],\n",
      "        [1.0846],\n",
      "        [1.1168],\n",
      "        [1.0960],\n",
      "        [1.0649],\n",
      "        [1.0757],\n",
      "        [1.1090],\n",
      "        [1.1161],\n",
      "        [1.0490],\n",
      "        [1.1060],\n",
      "        [1.0299],\n",
      "        [1.0883],\n",
      "        [1.0959],\n",
      "        [1.0873],\n",
      "        [1.1096],\n",
      "        [1.1066],\n",
      "        [1.1180],\n",
      "        [1.0906],\n",
      "        [1.0787],\n",
      "        [1.0821],\n",
      "        [1.0979],\n",
      "        [1.1137],\n",
      "        [1.1285],\n",
      "        [1.0951],\n",
      "        [1.0987],\n",
      "        [1.0415],\n",
      "        [1.1009],\n",
      "        [1.0972],\n",
      "        [1.1300],\n",
      "        [1.0897],\n",
      "        [1.0616],\n",
      "        [1.1123],\n",
      "        [1.1000],\n",
      "        [1.1146],\n",
      "        [1.1171],\n",
      "        [1.1158],\n",
      "        [1.1027],\n",
      "        [1.0965],\n",
      "        [1.1123],\n",
      "        [1.0807],\n",
      "        [1.1229],\n",
      "        [1.1130],\n",
      "        [1.1099],\n",
      "        [1.0815],\n",
      "        [1.1072],\n",
      "        [1.1105],\n",
      "        [1.1150],\n",
      "        [1.1177],\n",
      "        [1.0980],\n",
      "        [1.0793],\n",
      "        [1.0967],\n",
      "        [1.1168],\n",
      "        [1.1059],\n",
      "        [1.1188],\n",
      "        [1.1238],\n",
      "        [1.0821],\n",
      "        [1.0915],\n",
      "        [1.0926],\n",
      "        [1.0836],\n",
      "        [1.0513],\n",
      "        [1.0835],\n",
      "        [1.1101],\n",
      "        [1.0907],\n",
      "        [1.1255],\n",
      "        [1.1032],\n",
      "        [1.0937],\n",
      "        [1.1017],\n",
      "        [1.0796],\n",
      "        [1.0925],\n",
      "        [1.0643],\n",
      "        [1.0964],\n",
      "        [1.0785],\n",
      "        [1.0908],\n",
      "        [1.1158],\n",
      "        [1.1181],\n",
      "        [1.0852],\n",
      "        [1.1226],\n",
      "        [1.0955],\n",
      "        [1.0864],\n",
      "        [1.0998]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1011],\n",
      "        [1.1189],\n",
      "        [1.0420],\n",
      "        [1.0741],\n",
      "        [1.0942],\n",
      "        [1.0974],\n",
      "        [1.1019],\n",
      "        [1.1129],\n",
      "        [1.1031],\n",
      "        [1.0741],\n",
      "        [1.0492],\n",
      "        [1.0842],\n",
      "        [1.1148],\n",
      "        [1.1005],\n",
      "        [1.1050],\n",
      "        [1.0832],\n",
      "        [1.0974],\n",
      "        [1.1215],\n",
      "        [1.0951],\n",
      "        [1.1254],\n",
      "        [1.1062],\n",
      "        [1.0829],\n",
      "        [1.0937],\n",
      "        [1.0982],\n",
      "        [1.0601],\n",
      "        [1.1113],\n",
      "        [1.1301],\n",
      "        [1.0942],\n",
      "        [1.0579],\n",
      "        [1.1270],\n",
      "        [1.0618],\n",
      "        [1.0843],\n",
      "        [1.0723],\n",
      "        [1.1180],\n",
      "        [1.0874],\n",
      "        [1.0590],\n",
      "        [1.1178],\n",
      "        [1.1023],\n",
      "        [1.0931],\n",
      "        [1.1132],\n",
      "        [1.0614],\n",
      "        [1.1296],\n",
      "        [1.1169],\n",
      "        [1.1065],\n",
      "        [1.0995],\n",
      "        [1.1164],\n",
      "        [1.1143],\n",
      "        [1.1000],\n",
      "        [1.1071],\n",
      "        [1.0664],\n",
      "        [1.1269],\n",
      "        [1.1206],\n",
      "        [1.1182],\n",
      "        [1.0877],\n",
      "        [1.1029],\n",
      "        [1.1170],\n",
      "        [1.0829],\n",
      "        [1.1050],\n",
      "        [1.1151],\n",
      "        [1.0967],\n",
      "        [1.1013],\n",
      "        [1.1156],\n",
      "        [1.0996],\n",
      "        [1.0952],\n",
      "        [1.1176],\n",
      "        [1.1052],\n",
      "        [1.0914],\n",
      "        [1.1093],\n",
      "        [1.1293],\n",
      "        [1.0723],\n",
      "        [1.1051],\n",
      "        [1.1222],\n",
      "        [1.1022],\n",
      "        [1.0860],\n",
      "        [1.1151],\n",
      "        [1.0751],\n",
      "        [1.0704],\n",
      "        [1.0828],\n",
      "        [1.1022],\n",
      "        [1.1203],\n",
      "        [1.1164],\n",
      "        [1.1137],\n",
      "        [1.1282],\n",
      "        [1.1259],\n",
      "        [1.1135],\n",
      "        [1.1171],\n",
      "        [1.0536],\n",
      "        [1.1255],\n",
      "        [1.1067],\n",
      "        [1.1143],\n",
      "        [1.1044],\n",
      "        [1.0792],\n",
      "        [1.0807],\n",
      "        [1.1061],\n",
      "        [1.1049],\n",
      "        [1.0865],\n",
      "        [1.0728],\n",
      "        [1.1273],\n",
      "        [1.1004],\n",
      "        [1.1199],\n",
      "        [1.1080],\n",
      "        [1.0854],\n",
      "        [1.1107],\n",
      "        [1.0995],\n",
      "        [1.1071],\n",
      "        [1.0888],\n",
      "        [1.1079],\n",
      "        [1.1175],\n",
      "        [1.0936],\n",
      "        [1.1201],\n",
      "        [1.1120],\n",
      "        [1.0780],\n",
      "        [1.1041],\n",
      "        [1.1101],\n",
      "        [1.1036],\n",
      "        [1.1037],\n",
      "        [1.1015],\n",
      "        [1.1042],\n",
      "        [1.1003],\n",
      "        [1.0920],\n",
      "        [1.1200],\n",
      "        [1.1089],\n",
      "        [1.0903],\n",
      "        [1.0763],\n",
      "        [1.0823],\n",
      "        [1.0852],\n",
      "        [1.0373],\n",
      "        [1.1156]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0855],\n",
      "        [1.1309],\n",
      "        [1.1247],\n",
      "        [1.1271],\n",
      "        [1.0937],\n",
      "        [1.1250],\n",
      "        [1.1144],\n",
      "        [1.1185],\n",
      "        [1.0735],\n",
      "        [1.0943],\n",
      "        [1.0731],\n",
      "        [1.0785],\n",
      "        [1.0983],\n",
      "        [1.0897],\n",
      "        [1.1084],\n",
      "        [1.1018],\n",
      "        [1.0813],\n",
      "        [1.1281],\n",
      "        [1.1167],\n",
      "        [1.1064],\n",
      "        [1.0886],\n",
      "        [1.1303],\n",
      "        [1.1053],\n",
      "        [1.1295],\n",
      "        [1.1294],\n",
      "        [1.1173],\n",
      "        [1.0991],\n",
      "        [1.0883],\n",
      "        [1.1078],\n",
      "        [1.0793],\n",
      "        [1.1000],\n",
      "        [1.1117],\n",
      "        [1.0786],\n",
      "        [1.0915],\n",
      "        [1.1242],\n",
      "        [1.0962],\n",
      "        [1.1132],\n",
      "        [1.1036],\n",
      "        [1.1023],\n",
      "        [1.0775],\n",
      "        [1.0925],\n",
      "        [1.0935],\n",
      "        [1.1124],\n",
      "        [1.1036],\n",
      "        [1.0954],\n",
      "        [1.0890],\n",
      "        [1.1281],\n",
      "        [1.0959],\n",
      "        [1.1093],\n",
      "        [1.1210],\n",
      "        [1.1053],\n",
      "        [1.0445],\n",
      "        [1.1284],\n",
      "        [1.0897],\n",
      "        [1.0851],\n",
      "        [1.1260],\n",
      "        [1.1116],\n",
      "        [1.1275],\n",
      "        [1.0947],\n",
      "        [1.1288],\n",
      "        [1.0512],\n",
      "        [1.1253],\n",
      "        [1.0677],\n",
      "        [1.0926],\n",
      "        [1.0896],\n",
      "        [1.0928],\n",
      "        [1.0903],\n",
      "        [1.1289],\n",
      "        [1.1237],\n",
      "        [1.0526],\n",
      "        [1.1149],\n",
      "        [1.1222],\n",
      "        [1.0473],\n",
      "        [1.0646],\n",
      "        [1.1193],\n",
      "        [1.0977],\n",
      "        [1.1019],\n",
      "        [1.1041],\n",
      "        [1.0650],\n",
      "        [1.1191],\n",
      "        [1.1017],\n",
      "        [1.1105],\n",
      "        [1.1179],\n",
      "        [1.0863],\n",
      "        [1.1181],\n",
      "        [1.1051],\n",
      "        [1.0798],\n",
      "        [1.1128],\n",
      "        [1.1220],\n",
      "        [1.0912],\n",
      "        [1.0943],\n",
      "        [1.0718],\n",
      "        [1.0633],\n",
      "        [1.1215],\n",
      "        [1.1040],\n",
      "        [1.1249],\n",
      "        [1.1020],\n",
      "        [1.1179],\n",
      "        [1.0929],\n",
      "        [1.0722],\n",
      "        [1.0762],\n",
      "        [1.1303],\n",
      "        [1.1266],\n",
      "        [1.0999],\n",
      "        [1.0997],\n",
      "        [1.0599],\n",
      "        [1.0312],\n",
      "        [1.0751],\n",
      "        [1.0913],\n",
      "        [1.1250],\n",
      "        [1.1199],\n",
      "        [1.0718],\n",
      "        [1.1221],\n",
      "        [1.0808],\n",
      "        [1.1304],\n",
      "        [1.1045],\n",
      "        [1.1211],\n",
      "        [1.0877],\n",
      "        [1.0829],\n",
      "        [1.1154],\n",
      "        [1.1040],\n",
      "        [1.1246],\n",
      "        [1.0776],\n",
      "        [1.0795],\n",
      "        [1.0847],\n",
      "        [1.1198],\n",
      "        [1.1099],\n",
      "        [1.0686]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1152],\n",
      "        [1.1012],\n",
      "        [0.4481],\n",
      "        [1.1303],\n",
      "        [1.1157],\n",
      "        [1.1001],\n",
      "        [1.0892],\n",
      "        [1.1173],\n",
      "        [1.1148],\n",
      "        [1.1150],\n",
      "        [1.1087],\n",
      "        [1.0755],\n",
      "        [1.1193],\n",
      "        [1.0881],\n",
      "        [1.1127],\n",
      "        [1.0737],\n",
      "        [1.0970],\n",
      "        [1.0683],\n",
      "        [1.0700],\n",
      "        [1.1080],\n",
      "        [1.0850],\n",
      "        [1.0962],\n",
      "        [1.1056],\n",
      "        [1.1253],\n",
      "        [1.0710],\n",
      "        [1.0999],\n",
      "        [1.1225],\n",
      "        [1.1157],\n",
      "        [1.1294],\n",
      "        [1.1176],\n",
      "        [1.1249],\n",
      "        [1.1169],\n",
      "        [1.0757],\n",
      "        [1.0830],\n",
      "        [1.0830],\n",
      "        [1.1273],\n",
      "        [1.0568],\n",
      "        [1.1101],\n",
      "        [1.0854],\n",
      "        [1.1222],\n",
      "        [1.0893],\n",
      "        [1.1023],\n",
      "        [1.1159],\n",
      "        [1.1316],\n",
      "        [1.1249],\n",
      "        [1.0958],\n",
      "        [1.0369],\n",
      "        [0.9891],\n",
      "        [1.0969],\n",
      "        [1.1015],\n",
      "        [1.1066],\n",
      "        [1.0882],\n",
      "        [1.1061],\n",
      "        [1.0691],\n",
      "        [1.1087],\n",
      "        [1.1141],\n",
      "        [1.0871],\n",
      "        [1.1263],\n",
      "        [1.0950],\n",
      "        [1.1191],\n",
      "        [1.1293],\n",
      "        [1.0880],\n",
      "        [1.1189],\n",
      "        [1.0941],\n",
      "        [1.1183],\n",
      "        [1.1030],\n",
      "        [1.1200],\n",
      "        [1.0883],\n",
      "        [1.0929],\n",
      "        [1.1206],\n",
      "        [1.1098],\n",
      "        [1.1158],\n",
      "        [1.1077],\n",
      "        [1.0731],\n",
      "        [1.1284],\n",
      "        [1.1133],\n",
      "        [1.0656],\n",
      "        [1.0970],\n",
      "        [1.1016],\n",
      "        [1.1024],\n",
      "        [1.1084],\n",
      "        [1.1121],\n",
      "        [0.3696],\n",
      "        [1.1305],\n",
      "        [1.0721],\n",
      "        [1.1281],\n",
      "        [1.1314],\n",
      "        [1.0928],\n",
      "        [1.1000],\n",
      "        [1.1241],\n",
      "        [1.0543],\n",
      "        [1.0855],\n",
      "        [1.0836],\n",
      "        [1.0809],\n",
      "        [1.1198],\n",
      "        [1.1052],\n",
      "        [1.1092],\n",
      "        [1.1206],\n",
      "        [1.1237],\n",
      "        [1.1244],\n",
      "        [1.1133],\n",
      "        [1.0705],\n",
      "        [1.0932],\n",
      "        [1.1115],\n",
      "        [1.1046],\n",
      "        [1.0649],\n",
      "        [1.0846],\n",
      "        [1.0693],\n",
      "        [1.0972],\n",
      "        [1.1026],\n",
      "        [1.0888],\n",
      "        [1.1204],\n",
      "        [1.0902],\n",
      "        [1.0723],\n",
      "        [1.1184],\n",
      "        [1.0860],\n",
      "        [1.0987],\n",
      "        [1.1211],\n",
      "        [1.0999],\n",
      "        [1.1062],\n",
      "        [1.1251],\n",
      "        [1.0828],\n",
      "        [1.0613],\n",
      "        [1.0495],\n",
      "        [1.1087],\n",
      "        [1.0828],\n",
      "        [1.0674],\n",
      "        [1.1154]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1149],\n",
      "        [1.0564],\n",
      "        [1.1021],\n",
      "        [1.0935],\n",
      "        [1.0802],\n",
      "        [1.0787],\n",
      "        [1.1302],\n",
      "        [1.1186],\n",
      "        [1.0972],\n",
      "        [1.1014],\n",
      "        [1.1257],\n",
      "        [1.1117],\n",
      "        [1.1107],\n",
      "        [1.0969],\n",
      "        [1.1049],\n",
      "        [1.0289],\n",
      "        [1.1130],\n",
      "        [1.1261],\n",
      "        [1.0447],\n",
      "        [1.1134],\n",
      "        [1.0755],\n",
      "        [1.0518],\n",
      "        [1.1287],\n",
      "        [1.0995],\n",
      "        [1.0925],\n",
      "        [1.1053],\n",
      "        [1.0878],\n",
      "        [1.0745],\n",
      "        [1.1126],\n",
      "        [1.0822],\n",
      "        [1.1033],\n",
      "        [1.1243],\n",
      "        [1.0975],\n",
      "        [1.0632],\n",
      "        [1.1112],\n",
      "        [1.1146],\n",
      "        [1.1102],\n",
      "        [1.1269],\n",
      "        [1.0731],\n",
      "        [1.0589],\n",
      "        [1.1028],\n",
      "        [1.0870],\n",
      "        [1.1126],\n",
      "        [1.1150],\n",
      "        [1.0683],\n",
      "        [1.0661],\n",
      "        [1.0810],\n",
      "        [1.0604],\n",
      "        [1.0948],\n",
      "        [1.0683],\n",
      "        [1.1106],\n",
      "        [1.0991],\n",
      "        [1.1163],\n",
      "        [1.1138],\n",
      "        [1.0948],\n",
      "        [1.1031],\n",
      "        [1.1268],\n",
      "        [1.0724],\n",
      "        [1.1064],\n",
      "        [1.1032],\n",
      "        [1.0963],\n",
      "        [1.1282],\n",
      "        [1.0807],\n",
      "        [1.1204],\n",
      "        [1.1311],\n",
      "        [1.1012],\n",
      "        [1.0691],\n",
      "        [1.1187],\n",
      "        [1.1287],\n",
      "        [1.0737],\n",
      "        [1.0880],\n",
      "        [1.1160],\n",
      "        [1.1281],\n",
      "        [1.1112],\n",
      "        [1.0565],\n",
      "        [1.0822],\n",
      "        [1.1114],\n",
      "        [1.0961],\n",
      "        [1.0753],\n",
      "        [1.0671],\n",
      "        [1.0684],\n",
      "        [1.1183],\n",
      "        [1.1173],\n",
      "        [1.0813],\n",
      "        [1.0803],\n",
      "        [1.0964],\n",
      "        [1.1268],\n",
      "        [1.1173],\n",
      "        [1.1170],\n",
      "        [1.0459],\n",
      "        [1.1156],\n",
      "        [1.1022],\n",
      "        [0.0511],\n",
      "        [1.1044],\n",
      "        [1.0918],\n",
      "        [1.0989],\n",
      "        [1.0896],\n",
      "        [1.1030],\n",
      "        [1.1306],\n",
      "        [1.1054],\n",
      "        [1.1147],\n",
      "        [1.1041],\n",
      "        [1.0907],\n",
      "        [1.1027],\n",
      "        [1.0834],\n",
      "        [1.0936],\n",
      "        [1.1168],\n",
      "        [1.1050],\n",
      "        [1.1237],\n",
      "        [1.1149],\n",
      "        [1.1304],\n",
      "        [1.0957],\n",
      "        [1.1071],\n",
      "        [1.1074],\n",
      "        [1.1191],\n",
      "        [1.0998],\n",
      "        [1.1163],\n",
      "        [1.0970],\n",
      "        [1.1224],\n",
      "        [1.1119],\n",
      "        [1.1193],\n",
      "        [1.1028],\n",
      "        [1.0719],\n",
      "        [1.1104],\n",
      "        [1.0971],\n",
      "        [1.0165],\n",
      "        [1.1108],\n",
      "        [1.0764]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1042],\n",
      "        [1.1151],\n",
      "        [1.1127],\n",
      "        [1.1036],\n",
      "        [1.1077],\n",
      "        [1.1115],\n",
      "        [1.1273],\n",
      "        [1.0998],\n",
      "        [1.1104],\n",
      "        [1.1276],\n",
      "        [1.1107],\n",
      "        [1.1091],\n",
      "        [1.1029],\n",
      "        [1.1108],\n",
      "        [1.1226],\n",
      "        [1.1013],\n",
      "        [1.1282],\n",
      "        [1.1015],\n",
      "        [1.1155],\n",
      "        [1.0882],\n",
      "        [1.1096],\n",
      "        [1.0950],\n",
      "        [1.1142],\n",
      "        [1.0806],\n",
      "        [1.1068],\n",
      "        [1.1294],\n",
      "        [1.1258],\n",
      "        [1.1042],\n",
      "        [1.1013],\n",
      "        [1.0707],\n",
      "        [1.0896],\n",
      "        [1.1267],\n",
      "        [1.0953],\n",
      "        [1.0730],\n",
      "        [1.1220],\n",
      "        [1.0633],\n",
      "        [1.0969],\n",
      "        [1.1036],\n",
      "        [1.0754],\n",
      "        [1.0821],\n",
      "        [1.1012],\n",
      "        [1.0989],\n",
      "        [1.0831],\n",
      "        [1.1236],\n",
      "        [1.1257],\n",
      "        [1.1072],\n",
      "        [1.1161],\n",
      "        [1.1312],\n",
      "        [1.0853],\n",
      "        [1.1270],\n",
      "        [1.0975],\n",
      "        [1.1167],\n",
      "        [1.1088],\n",
      "        [1.1067],\n",
      "        [1.1224],\n",
      "        [1.1209],\n",
      "        [1.1216],\n",
      "        [1.1033],\n",
      "        [1.1236],\n",
      "        [1.1268],\n",
      "        [1.1140],\n",
      "        [1.1018],\n",
      "        [1.0950],\n",
      "        [1.1050],\n",
      "        [1.1276],\n",
      "        [1.0988],\n",
      "        [1.0642],\n",
      "        [1.1161],\n",
      "        [1.0680],\n",
      "        [1.0988],\n",
      "        [1.0843],\n",
      "        [1.1157],\n",
      "        [1.1127],\n",
      "        [1.0426],\n",
      "        [1.1033],\n",
      "        [1.1225],\n",
      "        [1.1167],\n",
      "        [1.1106],\n",
      "        [1.0695],\n",
      "        [1.0886],\n",
      "        [1.0610],\n",
      "        [1.0902],\n",
      "        [1.1312],\n",
      "        [1.0768],\n",
      "        [1.1164],\n",
      "        [1.0973],\n",
      "        [1.0591],\n",
      "        [1.1189],\n",
      "        [1.0794],\n",
      "        [1.1008],\n",
      "        [1.1061],\n",
      "        [1.1323],\n",
      "        [1.1195],\n",
      "        [1.1264],\n",
      "        [1.0827],\n",
      "        [1.0403],\n",
      "        [1.0272],\n",
      "        [1.1255],\n",
      "        [1.1122],\n",
      "        [1.1050],\n",
      "        [1.0974],\n",
      "        [1.1280],\n",
      "        [1.1103],\n",
      "        [1.1061],\n",
      "        [1.1178],\n",
      "        [1.0387],\n",
      "        [1.0887],\n",
      "        [1.1274],\n",
      "        [1.1258],\n",
      "        [1.0701],\n",
      "        [1.0835],\n",
      "        [1.1200],\n",
      "        [1.1264],\n",
      "        [1.1241],\n",
      "        [1.1267],\n",
      "        [1.1112],\n",
      "        [1.1098],\n",
      "        [1.1029],\n",
      "        [1.1269],\n",
      "        [1.0913],\n",
      "        [1.0739],\n",
      "        [1.1070],\n",
      "        [1.0715],\n",
      "        [1.1181],\n",
      "        [1.0829],\n",
      "        [1.1226],\n",
      "        [1.1239],\n",
      "        [1.1182]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0773],\n",
      "        [1.1323],\n",
      "        [1.1117],\n",
      "        [1.0630],\n",
      "        [1.1235],\n",
      "        [1.1257],\n",
      "        [1.1133],\n",
      "        [1.1202],\n",
      "        [1.0587],\n",
      "        [1.1170],\n",
      "        [1.0724],\n",
      "        [1.0847],\n",
      "        [1.1129],\n",
      "        [1.0707],\n",
      "        [1.1160],\n",
      "        [1.1232],\n",
      "        [1.0822],\n",
      "        [1.1068],\n",
      "        [1.1171],\n",
      "        [1.0985],\n",
      "        [1.0993],\n",
      "        [1.0838],\n",
      "        [1.1005],\n",
      "        [1.1088],\n",
      "        [1.0773],\n",
      "        [1.1201],\n",
      "        [1.0900],\n",
      "        [1.1332],\n",
      "        [1.1081],\n",
      "        [1.1250],\n",
      "        [1.1189],\n",
      "        [1.0634],\n",
      "        [1.0761],\n",
      "        [1.0900],\n",
      "        [1.1173],\n",
      "        [1.0610],\n",
      "        [1.0587],\n",
      "        [1.0937],\n",
      "        [1.1283],\n",
      "        [1.1267],\n",
      "        [1.0723],\n",
      "        [1.1075],\n",
      "        [1.1133],\n",
      "        [1.1104],\n",
      "        [1.0834],\n",
      "        [0.9216],\n",
      "        [1.0911],\n",
      "        [1.1084],\n",
      "        [1.1160],\n",
      "        [1.0805],\n",
      "        [1.1074],\n",
      "        [1.0796],\n",
      "        [1.0491],\n",
      "        [1.1106],\n",
      "        [1.0921],\n",
      "        [1.0975],\n",
      "        [1.0927],\n",
      "        [1.0982],\n",
      "        [1.1094],\n",
      "        [1.0927],\n",
      "        [1.1082],\n",
      "        [1.1182],\n",
      "        [1.1041],\n",
      "        [1.1103],\n",
      "        [1.0943],\n",
      "        [1.1323],\n",
      "        [1.1197],\n",
      "        [1.1165],\n",
      "        [1.0318],\n",
      "        [1.0673],\n",
      "        [1.0738],\n",
      "        [1.0541],\n",
      "        [1.1220],\n",
      "        [1.0921],\n",
      "        [1.0608],\n",
      "        [1.1198],\n",
      "        [1.1174],\n",
      "        [1.0869],\n",
      "        [1.0910],\n",
      "        [1.0981],\n",
      "        [1.1174],\n",
      "        [1.0920],\n",
      "        [1.1151],\n",
      "        [1.0899],\n",
      "        [1.1168],\n",
      "        [1.0919],\n",
      "        [1.0822],\n",
      "        [1.0931],\n",
      "        [1.1183],\n",
      "        [1.0791],\n",
      "        [1.0919],\n",
      "        [1.0988],\n",
      "        [1.1113],\n",
      "        [1.1055],\n",
      "        [1.1111],\n",
      "        [1.1135],\n",
      "        [1.1178],\n",
      "        [1.0995],\n",
      "        [1.1001],\n",
      "        [1.1228],\n",
      "        [1.1316],\n",
      "        [1.0985],\n",
      "        [1.1082],\n",
      "        [1.0868],\n",
      "        [1.0970],\n",
      "        [1.1167],\n",
      "        [1.0884],\n",
      "        [1.1118],\n",
      "        [1.1281],\n",
      "        [1.0751],\n",
      "        [1.1322],\n",
      "        [1.0818],\n",
      "        [1.1278],\n",
      "        [1.1036],\n",
      "        [1.0804],\n",
      "        [1.0792],\n",
      "        [1.0851],\n",
      "        [1.1076],\n",
      "        [1.1088],\n",
      "        [1.0887],\n",
      "        [1.1035],\n",
      "        [1.0867],\n",
      "        [1.1317],\n",
      "        [1.1284],\n",
      "        [1.1324],\n",
      "        [1.0690],\n",
      "        [1.1246],\n",
      "        [1.1279]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1006],\n",
      "        [1.0994],\n",
      "        [1.1019],\n",
      "        [1.1146]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  24 | lr 0.00100 train_loss 2.12233 | val_loss 2.28892 | val_rmse 1.51292\n",
      "tensor([[1.0938],\n",
      "        [1.1083],\n",
      "        [1.1203],\n",
      "        [1.0938],\n",
      "        [1.0741],\n",
      "        [1.1329],\n",
      "        [1.0776],\n",
      "        [1.1084],\n",
      "        [1.0831],\n",
      "        [1.1222],\n",
      "        [1.1297],\n",
      "        [1.0882],\n",
      "        [1.1100],\n",
      "        [1.1072],\n",
      "        [1.1225],\n",
      "        [1.0983],\n",
      "        [1.0677],\n",
      "        [1.1250],\n",
      "        [1.0856],\n",
      "        [1.1021],\n",
      "        [1.1039],\n",
      "        [1.0701],\n",
      "        [1.0979],\n",
      "        [1.1277],\n",
      "        [1.1153],\n",
      "        [1.0764],\n",
      "        [1.0736],\n",
      "        [1.1164],\n",
      "        [1.0741],\n",
      "        [1.1182],\n",
      "        [1.1298],\n",
      "        [1.1259],\n",
      "        [1.1201],\n",
      "        [1.1279],\n",
      "        [1.1289],\n",
      "        [1.0619],\n",
      "        [1.1222],\n",
      "        [1.0543],\n",
      "        [1.1130],\n",
      "        [1.1090],\n",
      "        [1.1241],\n",
      "        [1.1051],\n",
      "        [1.1091],\n",
      "        [1.1156],\n",
      "        [1.0883],\n",
      "        [1.0816],\n",
      "        [1.1004],\n",
      "        [1.1019],\n",
      "        [1.0927],\n",
      "        [1.0800],\n",
      "        [1.0832],\n",
      "        [1.0868],\n",
      "        [1.1351],\n",
      "        [1.1089],\n",
      "        [1.0941],\n",
      "        [1.0903],\n",
      "        [1.1288],\n",
      "        [1.1221],\n",
      "        [1.0977],\n",
      "        [1.1228],\n",
      "        [1.0845],\n",
      "        [1.0179],\n",
      "        [1.1077],\n",
      "        [1.0758],\n",
      "        [1.0833],\n",
      "        [1.0837],\n",
      "        [1.1159],\n",
      "        [1.1150],\n",
      "        [1.0874],\n",
      "        [1.1159],\n",
      "        [1.1012],\n",
      "        [1.0929],\n",
      "        [1.1016],\n",
      "        [1.0498],\n",
      "        [1.0938],\n",
      "        [1.0792],\n",
      "        [1.1055],\n",
      "        [1.0982],\n",
      "        [1.1127],\n",
      "        [1.1057],\n",
      "        [1.1354],\n",
      "        [1.0737],\n",
      "        [1.0483],\n",
      "        [1.1254],\n",
      "        [1.0908],\n",
      "        [1.0469],\n",
      "        [1.0960],\n",
      "        [1.1038],\n",
      "        [1.1151],\n",
      "        [1.0821],\n",
      "        [1.1023],\n",
      "        [1.1255],\n",
      "        [1.0870],\n",
      "        [1.1133],\n",
      "        [1.1146],\n",
      "        [1.1048],\n",
      "        [1.1101],\n",
      "        [1.0686],\n",
      "        [1.1090],\n",
      "        [1.1070],\n",
      "        [1.0944],\n",
      "        [1.0812],\n",
      "        [1.0413],\n",
      "        [1.1242],\n",
      "        [1.0886],\n",
      "        [1.0971],\n",
      "        [1.0913],\n",
      "        [1.1137],\n",
      "        [1.1051],\n",
      "        [1.0985],\n",
      "        [1.1079],\n",
      "        [1.1058],\n",
      "        [1.0968],\n",
      "        [1.1161],\n",
      "        [1.1237],\n",
      "        [1.1022],\n",
      "        [1.1268],\n",
      "        [1.0989],\n",
      "        [1.1179],\n",
      "        [1.1163],\n",
      "        [1.1174],\n",
      "        [1.0827],\n",
      "        [1.1025],\n",
      "        [1.1062],\n",
      "        [1.1064],\n",
      "        [1.1030],\n",
      "        [1.0958],\n",
      "        [1.0753]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1218],\n",
      "        [1.0710],\n",
      "        [1.0785],\n",
      "        [1.0882],\n",
      "        [1.1207],\n",
      "        [1.1000],\n",
      "        [1.0669],\n",
      "        [1.1286],\n",
      "        [1.1210],\n",
      "        [1.1011],\n",
      "        [1.0937],\n",
      "        [1.1295],\n",
      "        [1.1088],\n",
      "        [1.1242],\n",
      "        [1.1021],\n",
      "        [1.0644],\n",
      "        [1.0581],\n",
      "        [1.1055],\n",
      "        [1.0972],\n",
      "        [1.1010],\n",
      "        [1.1203],\n",
      "        [1.1169],\n",
      "        [1.0665],\n",
      "        [1.1089],\n",
      "        [1.0706],\n",
      "        [1.0867],\n",
      "        [1.0878],\n",
      "        [1.0759],\n",
      "        [1.1004],\n",
      "        [1.1041],\n",
      "        [1.1255],\n",
      "        [1.0969],\n",
      "        [1.1142],\n",
      "        [1.1047],\n",
      "        [1.0791],\n",
      "        [1.1028],\n",
      "        [1.0943],\n",
      "        [1.0677],\n",
      "        [1.1145],\n",
      "        [1.0901],\n",
      "        [1.1180],\n",
      "        [1.0558],\n",
      "        [1.1132],\n",
      "        [1.0889],\n",
      "        [1.1250],\n",
      "        [1.0995],\n",
      "        [1.0937],\n",
      "        [1.1015],\n",
      "        [1.1043],\n",
      "        [1.1007],\n",
      "        [1.1148],\n",
      "        [1.1308],\n",
      "        [1.1080],\n",
      "        [1.0992],\n",
      "        [1.1028],\n",
      "        [1.1183],\n",
      "        [1.0381],\n",
      "        [1.1047],\n",
      "        [1.0618],\n",
      "        [1.1147],\n",
      "        [1.1326],\n",
      "        [1.0786],\n",
      "        [1.1053],\n",
      "        [1.0823],\n",
      "        [1.1138],\n",
      "        [1.1312],\n",
      "        [1.1106],\n",
      "        [1.1117],\n",
      "        [1.0804],\n",
      "        [0.1854],\n",
      "        [1.1202],\n",
      "        [1.1051],\n",
      "        [1.1032],\n",
      "        [1.1172],\n",
      "        [1.0880],\n",
      "        [1.1281],\n",
      "        [1.1188],\n",
      "        [1.0866],\n",
      "        [1.0886],\n",
      "        [1.0933],\n",
      "        [1.0733],\n",
      "        [1.0973],\n",
      "        [1.0754],\n",
      "        [1.1160],\n",
      "        [1.0733],\n",
      "        [1.1214],\n",
      "        [1.1288],\n",
      "        [1.0449],\n",
      "        [1.1232],\n",
      "        [1.1261],\n",
      "        [1.1270],\n",
      "        [1.1069],\n",
      "        [1.0965],\n",
      "        [1.1123],\n",
      "        [1.1158],\n",
      "        [1.0929],\n",
      "        [1.1318],\n",
      "        [1.1164],\n",
      "        [1.1192],\n",
      "        [1.0883],\n",
      "        [1.1263],\n",
      "        [1.0834],\n",
      "        [1.1006],\n",
      "        [1.1081],\n",
      "        [1.0994],\n",
      "        [1.1132],\n",
      "        [1.1286],\n",
      "        [1.1049],\n",
      "        [1.1004],\n",
      "        [1.0777],\n",
      "        [1.0935],\n",
      "        [1.0893],\n",
      "        [1.1212],\n",
      "        [1.1136],\n",
      "        [1.0924],\n",
      "        [1.1177],\n",
      "        [1.1157],\n",
      "        [1.1199],\n",
      "        [1.1089],\n",
      "        [1.1204],\n",
      "        [1.0846],\n",
      "        [1.0688],\n",
      "        [1.1171],\n",
      "        [1.0519],\n",
      "        [1.0983],\n",
      "        [1.1294],\n",
      "        [1.0364],\n",
      "        [1.0894]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1090],\n",
      "        [1.0729],\n",
      "        [1.0951],\n",
      "        [1.1027],\n",
      "        [1.0857],\n",
      "        [1.0882],\n",
      "        [1.1260],\n",
      "        [1.0884],\n",
      "        [1.1144],\n",
      "        [1.0707],\n",
      "        [1.0888],\n",
      "        [1.0929],\n",
      "        [1.1119],\n",
      "        [1.1216],\n",
      "        [1.0935],\n",
      "        [1.1023],\n",
      "        [1.0944],\n",
      "        [1.1170],\n",
      "        [1.1100],\n",
      "        [1.1216],\n",
      "        [1.1129],\n",
      "        [1.1246],\n",
      "        [1.1222],\n",
      "        [1.0860],\n",
      "        [1.0942],\n",
      "        [1.1186],\n",
      "        [1.0943],\n",
      "        [1.1044],\n",
      "        [1.0605],\n",
      "        [1.1067],\n",
      "        [1.1067],\n",
      "        [1.1179],\n",
      "        [1.0915],\n",
      "        [1.0893],\n",
      "        [1.1153],\n",
      "        [1.1006],\n",
      "        [1.1053],\n",
      "        [1.0825],\n",
      "        [1.0924],\n",
      "        [1.1221],\n",
      "        [1.0909],\n",
      "        [1.0824],\n",
      "        [1.1202],\n",
      "        [1.1136],\n",
      "        [1.1106],\n",
      "        [1.0816],\n",
      "        [1.1071],\n",
      "        [1.0919],\n",
      "        [1.0941],\n",
      "        [1.0679],\n",
      "        [1.1155],\n",
      "        [1.0721],\n",
      "        [1.1289],\n",
      "        [1.1219],\n",
      "        [1.0830],\n",
      "        [1.1246],\n",
      "        [1.0892],\n",
      "        [1.0694],\n",
      "        [1.1230],\n",
      "        [1.1222],\n",
      "        [1.1103],\n",
      "        [1.1099],\n",
      "        [1.0698],\n",
      "        [1.1151],\n",
      "        [1.1141],\n",
      "        [1.0737],\n",
      "        [1.0737],\n",
      "        [1.0626],\n",
      "        [1.0801],\n",
      "        [1.0871],\n",
      "        [1.1192],\n",
      "        [1.0820],\n",
      "        [1.1292],\n",
      "        [1.0565],\n",
      "        [1.1137],\n",
      "        [1.0966],\n",
      "        [1.1051],\n",
      "        [1.1157],\n",
      "        [1.0710],\n",
      "        [1.1047],\n",
      "        [1.1293],\n",
      "        [1.1145],\n",
      "        [1.1231],\n",
      "        [1.1234],\n",
      "        [1.1052],\n",
      "        [1.1318],\n",
      "        [1.0886],\n",
      "        [1.0958],\n",
      "        [1.1019],\n",
      "        [1.1295],\n",
      "        [1.0961],\n",
      "        [1.0951],\n",
      "        [1.0944],\n",
      "        [1.0849],\n",
      "        [1.1282],\n",
      "        [1.0979],\n",
      "        [1.1033],\n",
      "        [1.0399],\n",
      "        [0.7459],\n",
      "        [1.0878],\n",
      "        [1.1246],\n",
      "        [1.1112],\n",
      "        [1.1073],\n",
      "        [1.1066],\n",
      "        [1.1258],\n",
      "        [1.1193],\n",
      "        [1.1187],\n",
      "        [1.0898],\n",
      "        [1.1317],\n",
      "        [1.1178],\n",
      "        [1.1142],\n",
      "        [1.0945],\n",
      "        [1.1119],\n",
      "        [1.0770],\n",
      "        [1.0980],\n",
      "        [1.0810],\n",
      "        [1.1276],\n",
      "        [1.0672],\n",
      "        [1.0489],\n",
      "        [1.0578],\n",
      "        [1.1019],\n",
      "        [1.1001],\n",
      "        [1.0788],\n",
      "        [1.1125],\n",
      "        [1.0806],\n",
      "        [1.1316],\n",
      "        [1.0767],\n",
      "        [1.1118]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1158],\n",
      "        [1.0497],\n",
      "        [1.1023],\n",
      "        [1.1094],\n",
      "        [1.1020],\n",
      "        [1.0977],\n",
      "        [1.0726],\n",
      "        [1.1107],\n",
      "        [1.0800],\n",
      "        [1.0609],\n",
      "        [1.1136],\n",
      "        [1.0783],\n",
      "        [1.0963],\n",
      "        [1.1034],\n",
      "        [1.1107],\n",
      "        [1.0615],\n",
      "        [1.0837],\n",
      "        [1.1286],\n",
      "        [1.1105],\n",
      "        [1.0991],\n",
      "        [1.1161],\n",
      "        [1.1089],\n",
      "        [1.1255],\n",
      "        [1.0824],\n",
      "        [1.1225],\n",
      "        [1.0776],\n",
      "        [1.0978],\n",
      "        [1.0710],\n",
      "        [1.1130],\n",
      "        [1.0832],\n",
      "        [1.1180],\n",
      "        [1.1030],\n",
      "        [1.0581],\n",
      "        [1.1071],\n",
      "        [1.0524],\n",
      "        [1.1079],\n",
      "        [1.1239],\n",
      "        [1.0876],\n",
      "        [1.1280],\n",
      "        [1.1035],\n",
      "        [1.0852],\n",
      "        [1.0872],\n",
      "        [1.0899],\n",
      "        [1.0642],\n",
      "        [1.1058],\n",
      "        [1.1243],\n",
      "        [1.1107],\n",
      "        [1.0708],\n",
      "        [1.1135],\n",
      "        [1.1302],\n",
      "        [1.0993],\n",
      "        [1.1128],\n",
      "        [0.2635],\n",
      "        [1.0940],\n",
      "        [1.0952],\n",
      "        [1.1136],\n",
      "        [1.1169],\n",
      "        [1.1129],\n",
      "        [1.0809],\n",
      "        [1.1029],\n",
      "        [1.1071],\n",
      "        [1.1023],\n",
      "        [1.0824],\n",
      "        [1.0586],\n",
      "        [1.1007],\n",
      "        [1.1079],\n",
      "        [1.1010],\n",
      "        [1.1278],\n",
      "        [1.0880],\n",
      "        [1.1122],\n",
      "        [1.1345],\n",
      "        [1.1112],\n",
      "        [1.1086],\n",
      "        [1.0886],\n",
      "        [1.0872],\n",
      "        [1.1000],\n",
      "        [1.1036],\n",
      "        [1.0881],\n",
      "        [1.1145],\n",
      "        [1.1241],\n",
      "        [1.0926],\n",
      "        [1.1324],\n",
      "        [1.1031],\n",
      "        [1.0833],\n",
      "        [1.1088],\n",
      "        [1.0630],\n",
      "        [1.1101],\n",
      "        [1.1208],\n",
      "        [1.1193],\n",
      "        [1.0953],\n",
      "        [1.0948],\n",
      "        [1.0866],\n",
      "        [1.1273],\n",
      "        [1.1139],\n",
      "        [1.1014],\n",
      "        [1.1050],\n",
      "        [1.1142],\n",
      "        [1.0900],\n",
      "        [1.1172],\n",
      "        [1.0606],\n",
      "        [1.1027],\n",
      "        [1.0961],\n",
      "        [1.0722],\n",
      "        [1.0962],\n",
      "        [1.0582],\n",
      "        [1.1222],\n",
      "        [1.1130],\n",
      "        [1.0902],\n",
      "        [1.0854],\n",
      "        [1.0809],\n",
      "        [1.0804],\n",
      "        [1.0862],\n",
      "        [1.1228],\n",
      "        [1.1215],\n",
      "        [1.1209],\n",
      "        [1.1140],\n",
      "        [1.0933],\n",
      "        [1.1092],\n",
      "        [1.1118],\n",
      "        [1.1246],\n",
      "        [1.0923],\n",
      "        [1.1228],\n",
      "        [1.1322],\n",
      "        [1.1011],\n",
      "        [1.0802],\n",
      "        [1.1300],\n",
      "        [1.0895],\n",
      "        [1.1141]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1163],\n",
      "        [1.0943],\n",
      "        [1.0997],\n",
      "        [1.1022],\n",
      "        [1.0598],\n",
      "        [0.9904],\n",
      "        [1.0834],\n",
      "        [1.0947],\n",
      "        [1.1019],\n",
      "        [1.1270],\n",
      "        [1.1103],\n",
      "        [1.1265],\n",
      "        [1.0962],\n",
      "        [1.1075],\n",
      "        [1.1175],\n",
      "        [1.0829],\n",
      "        [1.1229],\n",
      "        [1.1183],\n",
      "        [1.1118],\n",
      "        [1.1330],\n",
      "        [1.0701],\n",
      "        [1.0626],\n",
      "        [1.1136],\n",
      "        [1.1241],\n",
      "        [1.0648],\n",
      "        [1.0636],\n",
      "        [1.1075],\n",
      "        [1.0869],\n",
      "        [1.0717],\n",
      "        [1.0824],\n",
      "        [1.1021],\n",
      "        [1.1061],\n",
      "        [1.1137],\n",
      "        [1.1182],\n",
      "        [1.0918],\n",
      "        [1.1276],\n",
      "        [1.1246],\n",
      "        [1.1180],\n",
      "        [1.1250],\n",
      "        [1.0823],\n",
      "        [1.1310],\n",
      "        [1.0977],\n",
      "        [1.1067],\n",
      "        [1.0888],\n",
      "        [1.0331],\n",
      "        [1.1220],\n",
      "        [1.1197],\n",
      "        [1.1196],\n",
      "        [1.1294],\n",
      "        [1.1252],\n",
      "        [1.0889],\n",
      "        [1.1142],\n",
      "        [1.0969],\n",
      "        [1.1263],\n",
      "        [1.1038],\n",
      "        [1.1113],\n",
      "        [1.1195],\n",
      "        [1.1017],\n",
      "        [1.1120],\n",
      "        [1.1315],\n",
      "        [1.1273],\n",
      "        [1.1222],\n",
      "        [1.1296],\n",
      "        [1.1073],\n",
      "        [1.0843],\n",
      "        [1.1137],\n",
      "        [1.1364],\n",
      "        [1.0953],\n",
      "        [1.1277],\n",
      "        [1.1334],\n",
      "        [1.1139],\n",
      "        [1.1138],\n",
      "        [1.1198],\n",
      "        [1.1046],\n",
      "        [1.1099],\n",
      "        [1.0826],\n",
      "        [1.1209],\n",
      "        [1.1255],\n",
      "        [1.1339],\n",
      "        [1.1005],\n",
      "        [1.0757],\n",
      "        [1.0870],\n",
      "        [1.0564],\n",
      "        [1.0871],\n",
      "        [1.0760],\n",
      "        [1.1225],\n",
      "        [1.0933],\n",
      "        [1.1099],\n",
      "        [1.0987],\n",
      "        [1.0736],\n",
      "        [1.1140],\n",
      "        [1.0970],\n",
      "        [1.1220],\n",
      "        [1.1182],\n",
      "        [1.0897],\n",
      "        [1.1051],\n",
      "        [1.0994],\n",
      "        [1.1315],\n",
      "        [1.1006],\n",
      "        [1.0990],\n",
      "        [1.0975],\n",
      "        [1.1264],\n",
      "        [1.1017],\n",
      "        [1.1135],\n",
      "        [1.0886],\n",
      "        [1.1115],\n",
      "        [1.1153],\n",
      "        [1.1306],\n",
      "        [1.0946],\n",
      "        [1.0561],\n",
      "        [1.1124],\n",
      "        [1.0644],\n",
      "        [1.0548],\n",
      "        [1.1181],\n",
      "        [1.1187],\n",
      "        [1.0650],\n",
      "        [1.1110],\n",
      "        [1.1041],\n",
      "        [1.1242],\n",
      "        [1.0984],\n",
      "        [1.0849],\n",
      "        [1.1247],\n",
      "        [1.1249],\n",
      "        [1.0711],\n",
      "        [1.0982],\n",
      "        [1.1188],\n",
      "        [1.0752],\n",
      "        [1.0804]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1319],\n",
      "        [1.0812],\n",
      "        [1.1078],\n",
      "        [1.1182],\n",
      "        [1.0911],\n",
      "        [1.0449],\n",
      "        [1.1206],\n",
      "        [1.1064],\n",
      "        [1.1181],\n",
      "        [1.0758],\n",
      "        [1.0857],\n",
      "        [1.0985],\n",
      "        [1.1021],\n",
      "        [1.0935],\n",
      "        [1.0825],\n",
      "        [1.1274],\n",
      "        [1.0996],\n",
      "        [1.1104],\n",
      "        [1.1274],\n",
      "        [1.1217],\n",
      "        [1.0952],\n",
      "        [1.0930],\n",
      "        [1.0730],\n",
      "        [1.0971],\n",
      "        [1.1181],\n",
      "        [1.1109],\n",
      "        [1.1112],\n",
      "        [1.1097],\n",
      "        [1.0975],\n",
      "        [1.1360],\n",
      "        [1.0922],\n",
      "        [1.1140],\n",
      "        [1.0928],\n",
      "        [1.1110],\n",
      "        [1.1138],\n",
      "        [1.0437],\n",
      "        [1.1082],\n",
      "        [1.1102],\n",
      "        [1.1099],\n",
      "        [1.1218],\n",
      "        [1.1024],\n",
      "        [1.1151],\n",
      "        [1.1140],\n",
      "        [1.1139],\n",
      "        [1.0831],\n",
      "        [1.0969],\n",
      "        [1.1096],\n",
      "        [1.1029],\n",
      "        [1.0609],\n",
      "        [1.1126],\n",
      "        [1.0686],\n",
      "        [1.1136],\n",
      "        [1.1063],\n",
      "        [1.1205],\n",
      "        [1.1051],\n",
      "        [1.0929],\n",
      "        [1.1280],\n",
      "        [1.0976],\n",
      "        [1.1283],\n",
      "        [1.1003],\n",
      "        [1.1194],\n",
      "        [1.1140],\n",
      "        [1.1098],\n",
      "        [1.1186],\n",
      "        [1.1183],\n",
      "        [1.1056],\n",
      "        [1.1168],\n",
      "        [1.0708],\n",
      "        [1.1013],\n",
      "        [1.1194],\n",
      "        [1.0888],\n",
      "        [1.0766],\n",
      "        [1.0842],\n",
      "        [1.1032],\n",
      "        [1.1261],\n",
      "        [1.1019],\n",
      "        [1.0565],\n",
      "        [1.1325],\n",
      "        [1.1241],\n",
      "        [1.0809],\n",
      "        [1.1112],\n",
      "        [1.1140],\n",
      "        [1.0494],\n",
      "        [1.1050],\n",
      "        [1.1335],\n",
      "        [1.1250],\n",
      "        [1.0980],\n",
      "        [1.0979],\n",
      "        [1.1215],\n",
      "        [1.0911],\n",
      "        [1.1132],\n",
      "        [1.1212],\n",
      "        [1.0742],\n",
      "        [1.1227],\n",
      "        [1.1232],\n",
      "        [1.0699],\n",
      "        [1.0684],\n",
      "        [1.1203],\n",
      "        [1.1220],\n",
      "        [1.1304],\n",
      "        [1.1254],\n",
      "        [1.1165],\n",
      "        [1.1127],\n",
      "        [1.0839],\n",
      "        [1.1356],\n",
      "        [1.0914],\n",
      "        [1.1018],\n",
      "        [1.1344],\n",
      "        [1.1031],\n",
      "        [1.0724],\n",
      "        [1.0945],\n",
      "        [1.1260],\n",
      "        [1.1292],\n",
      "        [1.1209],\n",
      "        [1.1111],\n",
      "        [1.1001],\n",
      "        [1.0989],\n",
      "        [1.0759],\n",
      "        [1.1130],\n",
      "        [1.1268],\n",
      "        [1.0953],\n",
      "        [1.1103],\n",
      "        [1.1112],\n",
      "        [1.1323],\n",
      "        [1.1314],\n",
      "        [1.0809],\n",
      "        [1.1146],\n",
      "        [1.1125]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0636],\n",
      "        [1.1090],\n",
      "        [1.1127],\n",
      "        [1.1035],\n",
      "        [1.1038],\n",
      "        [1.0882],\n",
      "        [1.1220],\n",
      "        [1.0746],\n",
      "        [1.0839],\n",
      "        [1.1184],\n",
      "        [1.0815],\n",
      "        [1.1316],\n",
      "        [1.0881],\n",
      "        [1.0945],\n",
      "        [1.1277],\n",
      "        [1.0913],\n",
      "        [1.1141],\n",
      "        [1.0791],\n",
      "        [1.1197],\n",
      "        [1.1248],\n",
      "        [1.1125],\n",
      "        [1.1049],\n",
      "        [1.1098],\n",
      "        [1.1343],\n",
      "        [1.0756],\n",
      "        [1.1179],\n",
      "        [1.0965],\n",
      "        [1.1031],\n",
      "        [1.1168],\n",
      "        [1.1045],\n",
      "        [1.1284],\n",
      "        [1.0848],\n",
      "        [1.0512],\n",
      "        [1.1309],\n",
      "        [1.0738],\n",
      "        [1.1032],\n",
      "        [1.1181],\n",
      "        [1.0938],\n",
      "        [1.1322],\n",
      "        [1.0996],\n",
      "        [1.0933],\n",
      "        [1.0486],\n",
      "        [1.1083],\n",
      "        [1.0761],\n",
      "        [1.1187],\n",
      "        [1.1028],\n",
      "        [1.0486],\n",
      "        [1.1046],\n",
      "        [1.1227],\n",
      "        [1.0785],\n",
      "        [1.0997],\n",
      "        [1.0749],\n",
      "        [1.1145],\n",
      "        [1.0737],\n",
      "        [1.0895],\n",
      "        [1.0754],\n",
      "        [1.0899],\n",
      "        [1.1330],\n",
      "        [1.1314],\n",
      "        [1.1024],\n",
      "        [1.1235],\n",
      "        [1.1064],\n",
      "        [1.1116],\n",
      "        [1.0574],\n",
      "        [1.1213],\n",
      "        [1.0598],\n",
      "        [1.0937],\n",
      "        [1.1232],\n",
      "        [1.1161],\n",
      "        [1.1053],\n",
      "        [1.1245],\n",
      "        [1.1130],\n",
      "        [1.1140],\n",
      "        [1.1170],\n",
      "        [1.1011],\n",
      "        [1.1225],\n",
      "        [1.1300],\n",
      "        [1.0744],\n",
      "        [1.1293],\n",
      "        [1.1298],\n",
      "        [1.0940],\n",
      "        [1.1060],\n",
      "        [1.0609],\n",
      "        [1.0685],\n",
      "        [1.0977],\n",
      "        [1.1344],\n",
      "        [1.1157],\n",
      "        [1.1065],\n",
      "        [1.1201],\n",
      "        [1.0959],\n",
      "        [1.1135],\n",
      "        [1.0893],\n",
      "        [1.1260],\n",
      "        [1.0923],\n",
      "        [1.1166],\n",
      "        [1.1155],\n",
      "        [1.0923],\n",
      "        [1.1096],\n",
      "        [1.1195],\n",
      "        [1.1250],\n",
      "        [1.1344],\n",
      "        [1.0536],\n",
      "        [1.0865],\n",
      "        [1.1213],\n",
      "        [1.0939],\n",
      "        [1.0844],\n",
      "        [1.1160],\n",
      "        [1.1100],\n",
      "        [1.1209],\n",
      "        [1.1078],\n",
      "        [1.1155],\n",
      "        [1.0732],\n",
      "        [1.0901],\n",
      "        [1.0689],\n",
      "        [1.1320],\n",
      "        [1.1299],\n",
      "        [1.0994],\n",
      "        [1.0758],\n",
      "        [1.1225],\n",
      "        [1.1136],\n",
      "        [1.0558],\n",
      "        [1.1083],\n",
      "        [1.0678],\n",
      "        [1.1304],\n",
      "        [1.0878],\n",
      "        [1.0586],\n",
      "        [1.0984],\n",
      "        [1.0891]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1119],\n",
      "        [1.1198],\n",
      "        [1.0826],\n",
      "        [1.1013]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  25 | lr 0.00100 train_loss 2.12414 | val_loss 2.28880 | val_rmse 1.51288\n",
      "tensor([[1.0983],\n",
      "        [1.1195],\n",
      "        [1.0865],\n",
      "        [1.1079],\n",
      "        [1.1205],\n",
      "        [1.1175],\n",
      "        [1.1253],\n",
      "        [1.1155],\n",
      "        [1.1147],\n",
      "        [1.1057],\n",
      "        [1.0593],\n",
      "        [1.1328],\n",
      "        [1.1302],\n",
      "        [1.1314],\n",
      "        [1.0979],\n",
      "        [1.0794],\n",
      "        [1.1244],\n",
      "        [1.1170],\n",
      "        [1.1053],\n",
      "        [1.1292],\n",
      "        [1.1271],\n",
      "        [1.0761],\n",
      "        [1.0666],\n",
      "        [1.1176],\n",
      "        [1.0776],\n",
      "        [1.1253],\n",
      "        [1.1287],\n",
      "        [1.1211],\n",
      "        [1.0973],\n",
      "        [1.1174],\n",
      "        [1.1271],\n",
      "        [1.0955],\n",
      "        [1.1110],\n",
      "        [1.0660],\n",
      "        [1.0964],\n",
      "        [1.1278],\n",
      "        [1.0800],\n",
      "        [1.0740],\n",
      "        [1.0997],\n",
      "        [1.0632],\n",
      "        [1.1138],\n",
      "        [1.1016],\n",
      "        [1.1072],\n",
      "        [1.1095],\n",
      "        [1.0898],\n",
      "        [1.1130],\n",
      "        [1.1324],\n",
      "        [1.0648],\n",
      "        [1.1250],\n",
      "        [1.0853],\n",
      "        [1.0965],\n",
      "        [1.1246],\n",
      "        [1.0876],\n",
      "        [1.1236],\n",
      "        [1.1335],\n",
      "        [1.1017],\n",
      "        [1.0854],\n",
      "        [1.0880],\n",
      "        [1.1316],\n",
      "        [1.1265],\n",
      "        [1.0878],\n",
      "        [1.0464],\n",
      "        [1.1106],\n",
      "        [1.0821],\n",
      "        [1.0935],\n",
      "        [1.1094],\n",
      "        [1.1310],\n",
      "        [1.0905],\n",
      "        [1.0959],\n",
      "        [1.1215],\n",
      "        [1.0937],\n",
      "        [1.1091],\n",
      "        [1.0959],\n",
      "        [1.1018],\n",
      "        [1.0718],\n",
      "        [1.1157],\n",
      "        [1.1082],\n",
      "        [1.0766],\n",
      "        [1.0779],\n",
      "        [1.1013],\n",
      "        [1.1081],\n",
      "        [1.0898],\n",
      "        [1.0913],\n",
      "        [1.1095],\n",
      "        [1.1272],\n",
      "        [1.0739],\n",
      "        [1.1292],\n",
      "        [1.1275],\n",
      "        [1.0996],\n",
      "        [1.1136],\n",
      "        [1.1326],\n",
      "        [1.0884],\n",
      "        [1.1274],\n",
      "        [1.1332],\n",
      "        [1.1068],\n",
      "        [1.0646],\n",
      "        [1.1060],\n",
      "        [1.0911],\n",
      "        [1.0351],\n",
      "        [1.0956],\n",
      "        [1.0696],\n",
      "        [1.0763],\n",
      "        [1.1288],\n",
      "        [1.0967],\n",
      "        [1.0804],\n",
      "        [1.1093],\n",
      "        [1.1053],\n",
      "        [0.4172],\n",
      "        [1.1318],\n",
      "        [1.0891],\n",
      "        [1.1082],\n",
      "        [1.1060],\n",
      "        [1.0962],\n",
      "        [1.1161],\n",
      "        [1.1324],\n",
      "        [1.0725],\n",
      "        [1.0770],\n",
      "        [1.1145],\n",
      "        [1.0798],\n",
      "        [1.0632],\n",
      "        [1.0874],\n",
      "        [1.0981],\n",
      "        [1.1169],\n",
      "        [1.1030],\n",
      "        [1.1313],\n",
      "        [1.1225],\n",
      "        [1.0895],\n",
      "        [1.1086]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0779],\n",
      "        [1.1107],\n",
      "        [1.1125],\n",
      "        [1.1263],\n",
      "        [1.1160],\n",
      "        [1.1055],\n",
      "        [1.1027],\n",
      "        [1.1004],\n",
      "        [1.0464],\n",
      "        [1.0841],\n",
      "        [1.1083],\n",
      "        [1.1194],\n",
      "        [1.1015],\n",
      "        [1.0833],\n",
      "        [1.1264],\n",
      "        [1.0926],\n",
      "        [1.0827],\n",
      "        [1.1272],\n",
      "        [1.0779],\n",
      "        [1.0874],\n",
      "        [1.0375],\n",
      "        [1.0460],\n",
      "        [1.0961],\n",
      "        [1.1010],\n",
      "        [1.0582],\n",
      "        [1.1218],\n",
      "        [1.0722],\n",
      "        [1.0807],\n",
      "        [1.0960],\n",
      "        [1.1187],\n",
      "        [1.1159],\n",
      "        [1.1153],\n",
      "        [1.0710],\n",
      "        [1.0663],\n",
      "        [1.1097],\n",
      "        [1.1182],\n",
      "        [1.1203],\n",
      "        [1.1246],\n",
      "        [1.1044],\n",
      "        [1.1292],\n",
      "        [1.0986],\n",
      "        [1.1246],\n",
      "        [1.1021],\n",
      "        [1.1296],\n",
      "        [1.0811],\n",
      "        [1.1216],\n",
      "        [1.0956],\n",
      "        [1.1175],\n",
      "        [1.1045],\n",
      "        [1.1066],\n",
      "        [1.1220],\n",
      "        [1.0864],\n",
      "        [1.1290],\n",
      "        [1.0970],\n",
      "        [1.1031],\n",
      "        [1.1272],\n",
      "        [1.1073],\n",
      "        [1.1284],\n",
      "        [1.0858],\n",
      "        [1.1095],\n",
      "        [1.1080],\n",
      "        [1.0938],\n",
      "        [1.1209],\n",
      "        [1.0789],\n",
      "        [1.1296],\n",
      "        [1.1158],\n",
      "        [1.1053],\n",
      "        [1.1089],\n",
      "        [1.0759],\n",
      "        [1.1259],\n",
      "        [1.0650],\n",
      "        [1.0812],\n",
      "        [1.0652],\n",
      "        [1.1257],\n",
      "        [1.1105],\n",
      "        [1.1341],\n",
      "        [1.1301],\n",
      "        [1.0904],\n",
      "        [1.1100],\n",
      "        [1.1276],\n",
      "        [1.1234],\n",
      "        [1.1235],\n",
      "        [1.0743],\n",
      "        [1.1145],\n",
      "        [1.0729],\n",
      "        [1.0958],\n",
      "        [1.1306],\n",
      "        [1.1134],\n",
      "        [1.0441],\n",
      "        [1.1195],\n",
      "        [1.0770],\n",
      "        [1.1035],\n",
      "        [1.0806],\n",
      "        [1.0948],\n",
      "        [1.1306],\n",
      "        [1.0976],\n",
      "        [1.0887],\n",
      "        [1.1009],\n",
      "        [1.0882],\n",
      "        [1.1162],\n",
      "        [1.1070],\n",
      "        [1.0790],\n",
      "        [1.0941],\n",
      "        [1.1132],\n",
      "        [1.1096],\n",
      "        [1.1214],\n",
      "        [1.1152],\n",
      "        [1.1076],\n",
      "        [1.1034],\n",
      "        [1.0946],\n",
      "        [1.0914],\n",
      "        [1.0806],\n",
      "        [1.0999],\n",
      "        [1.0844],\n",
      "        [1.0914],\n",
      "        [1.1071],\n",
      "        [1.0553],\n",
      "        [1.1265],\n",
      "        [1.0449],\n",
      "        [1.0856],\n",
      "        [1.0547],\n",
      "        [1.1258],\n",
      "        [1.1184],\n",
      "        [1.0928],\n",
      "        [1.1033],\n",
      "        [1.0884],\n",
      "        [1.0989],\n",
      "        [1.0879]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1160],\n",
      "        [1.1169],\n",
      "        [1.1323],\n",
      "        [1.0778],\n",
      "        [1.1143],\n",
      "        [1.1296],\n",
      "        [1.1108],\n",
      "        [1.0966],\n",
      "        [1.1159],\n",
      "        [1.0977],\n",
      "        [1.1170],\n",
      "        [1.1119],\n",
      "        [0.1786],\n",
      "        [1.1105],\n",
      "        [1.1045],\n",
      "        [1.1080],\n",
      "        [1.0595],\n",
      "        [1.1290],\n",
      "        [1.0427],\n",
      "        [1.1080],\n",
      "        [1.0779],\n",
      "        [1.0882],\n",
      "        [1.0978],\n",
      "        [0.2469],\n",
      "        [1.1264],\n",
      "        [1.1158],\n",
      "        [1.1089],\n",
      "        [1.1296],\n",
      "        [1.1153],\n",
      "        [1.1285],\n",
      "        [1.0796],\n",
      "        [1.0471],\n",
      "        [1.1113],\n",
      "        [1.0880],\n",
      "        [1.1183],\n",
      "        [1.0408],\n",
      "        [1.0660],\n",
      "        [1.1304],\n",
      "        [1.1225],\n",
      "        [1.1051],\n",
      "        [1.0971],\n",
      "        [1.0938],\n",
      "        [1.1136],\n",
      "        [1.1187],\n",
      "        [1.1126],\n",
      "        [1.0899],\n",
      "        [1.1026],\n",
      "        [1.0983],\n",
      "        [1.0691],\n",
      "        [1.1238],\n",
      "        [1.0894],\n",
      "        [1.1001],\n",
      "        [1.0655],\n",
      "        [1.1273],\n",
      "        [1.0926],\n",
      "        [1.0461],\n",
      "        [1.1212],\n",
      "        [1.1235],\n",
      "        [1.0835],\n",
      "        [1.0684],\n",
      "        [1.0786],\n",
      "        [1.0680],\n",
      "        [1.0498],\n",
      "        [1.1049],\n",
      "        [1.1144],\n",
      "        [1.0994],\n",
      "        [1.1035],\n",
      "        [1.0842],\n",
      "        [1.1091],\n",
      "        [1.0914],\n",
      "        [1.0649],\n",
      "        [1.0360],\n",
      "        [1.0899],\n",
      "        [1.0638],\n",
      "        [1.1139],\n",
      "        [1.0964],\n",
      "        [1.1319],\n",
      "        [1.1203],\n",
      "        [1.1001],\n",
      "        [1.0655],\n",
      "        [1.1065],\n",
      "        [1.0943],\n",
      "        [1.1181],\n",
      "        [1.1145],\n",
      "        [1.0997],\n",
      "        [1.0978],\n",
      "        [1.0780],\n",
      "        [1.1021],\n",
      "        [1.1088],\n",
      "        [1.0998],\n",
      "        [1.1062],\n",
      "        [1.1311],\n",
      "        [1.0865],\n",
      "        [1.1146],\n",
      "        [1.1322],\n",
      "        [1.1095],\n",
      "        [1.1028],\n",
      "        [1.1018],\n",
      "        [1.0860],\n",
      "        [1.1157],\n",
      "        [1.0954],\n",
      "        [1.1068],\n",
      "        [1.0832],\n",
      "        [1.1154],\n",
      "        [1.1199],\n",
      "        [1.0880],\n",
      "        [1.0922],\n",
      "        [1.0937],\n",
      "        [1.1029],\n",
      "        [1.1150],\n",
      "        [1.1290],\n",
      "        [1.1161],\n",
      "        [1.0954],\n",
      "        [1.0982],\n",
      "        [1.1153],\n",
      "        [1.1290],\n",
      "        [1.1024],\n",
      "        [1.0903],\n",
      "        [1.1194],\n",
      "        [1.0795],\n",
      "        [1.0759],\n",
      "        [1.0694],\n",
      "        [1.0821],\n",
      "        [1.0529],\n",
      "        [1.1206],\n",
      "        [1.0910],\n",
      "        [1.0770],\n",
      "        [1.0931]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0885],\n",
      "        [1.0733],\n",
      "        [1.1098],\n",
      "        [1.1008],\n",
      "        [1.1094],\n",
      "        [1.0924],\n",
      "        [1.1238],\n",
      "        [1.1077],\n",
      "        [1.1202],\n",
      "        [1.0965],\n",
      "        [1.0293],\n",
      "        [1.1147],\n",
      "        [1.0701],\n",
      "        [1.1186],\n",
      "        [1.1263],\n",
      "        [1.1211],\n",
      "        [1.0933],\n",
      "        [1.0924],\n",
      "        [1.1178],\n",
      "        [1.1248],\n",
      "        [1.0918],\n",
      "        [1.1153],\n",
      "        [1.0901],\n",
      "        [1.1115],\n",
      "        [1.1095],\n",
      "        [1.0952],\n",
      "        [1.1057],\n",
      "        [1.0671],\n",
      "        [1.1097],\n",
      "        [1.0921],\n",
      "        [1.1015],\n",
      "        [1.1091],\n",
      "        [1.1245],\n",
      "        [1.1177],\n",
      "        [1.0726],\n",
      "        [1.0907],\n",
      "        [1.1116],\n",
      "        [1.1184],\n",
      "        [1.1159],\n",
      "        [1.1165],\n",
      "        [1.1110],\n",
      "        [1.0801],\n",
      "        [1.1097],\n",
      "        [1.1125],\n",
      "        [1.0782],\n",
      "        [1.0970],\n",
      "        [1.1262],\n",
      "        [1.1254],\n",
      "        [1.0829],\n",
      "        [1.0929],\n",
      "        [1.0769],\n",
      "        [1.0859],\n",
      "        [1.0859],\n",
      "        [1.1229],\n",
      "        [1.1090],\n",
      "        [1.1219],\n",
      "        [1.0996],\n",
      "        [1.1015],\n",
      "        [1.0661],\n",
      "        [1.1118],\n",
      "        [1.0884],\n",
      "        [1.0995],\n",
      "        [1.1037],\n",
      "        [1.1195],\n",
      "        [1.0840],\n",
      "        [1.1264],\n",
      "        [1.0844],\n",
      "        [1.0874],\n",
      "        [1.0980],\n",
      "        [1.0907],\n",
      "        [1.0945],\n",
      "        [1.1046],\n",
      "        [1.1092],\n",
      "        [1.0524],\n",
      "        [1.0957],\n",
      "        [1.1265],\n",
      "        [1.0988],\n",
      "        [1.0598],\n",
      "        [1.0843],\n",
      "        [1.0850],\n",
      "        [1.0863],\n",
      "        [1.0913],\n",
      "        [1.0609],\n",
      "        [1.1118],\n",
      "        [1.1105],\n",
      "        [1.0973],\n",
      "        [1.0818],\n",
      "        [1.1201],\n",
      "        [1.1241],\n",
      "        [1.1130],\n",
      "        [1.1016],\n",
      "        [1.0963],\n",
      "        [1.1265],\n",
      "        [1.0747],\n",
      "        [1.1120],\n",
      "        [1.0712],\n",
      "        [1.0867],\n",
      "        [1.0315],\n",
      "        [1.1176],\n",
      "        [1.1075],\n",
      "        [1.0727],\n",
      "        [1.1071],\n",
      "        [1.1146],\n",
      "        [1.1105],\n",
      "        [1.0252],\n",
      "        [1.0886],\n",
      "        [1.1139],\n",
      "        [1.1061],\n",
      "        [1.1056],\n",
      "        [1.0550],\n",
      "        [1.0999],\n",
      "        [1.1209],\n",
      "        [1.1247],\n",
      "        [1.0944],\n",
      "        [1.0978],\n",
      "        [1.1139],\n",
      "        [1.0858],\n",
      "        [1.0772],\n",
      "        [1.0611],\n",
      "        [1.0741],\n",
      "        [1.0810],\n",
      "        [1.0404],\n",
      "        [1.1172],\n",
      "        [1.1005],\n",
      "        [1.0959],\n",
      "        [1.1040],\n",
      "        [1.0732],\n",
      "        [1.0898]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1087],\n",
      "        [1.1202],\n",
      "        [1.1154],\n",
      "        [1.0898],\n",
      "        [1.0780],\n",
      "        [1.0963],\n",
      "        [1.1164],\n",
      "        [1.1033],\n",
      "        [1.0963],\n",
      "        [1.1056],\n",
      "        [1.1210],\n",
      "        [1.1045],\n",
      "        [1.0984],\n",
      "        [1.0844],\n",
      "        [1.1093],\n",
      "        [1.1175],\n",
      "        [1.1196],\n",
      "        [1.0825],\n",
      "        [1.1046],\n",
      "        [1.1072],\n",
      "        [1.0887],\n",
      "        [1.0648],\n",
      "        [1.1158],\n",
      "        [1.1057],\n",
      "        [1.0277],\n",
      "        [1.0684],\n",
      "        [1.0884],\n",
      "        [1.0905],\n",
      "        [1.0868],\n",
      "        [1.0726],\n",
      "        [1.0766],\n",
      "        [1.0552],\n",
      "        [1.1097],\n",
      "        [1.0869],\n",
      "        [1.1103],\n",
      "        [1.1130],\n",
      "        [1.0935],\n",
      "        [1.0795],\n",
      "        [1.0828],\n",
      "        [1.0775],\n",
      "        [1.1182],\n",
      "        [1.0683],\n",
      "        [1.1274],\n",
      "        [1.1285],\n",
      "        [1.0789],\n",
      "        [1.0813],\n",
      "        [1.1057],\n",
      "        [1.0793],\n",
      "        [1.1152],\n",
      "        [1.0946],\n",
      "        [1.0826],\n",
      "        [1.0483],\n",
      "        [1.0768],\n",
      "        [1.1221],\n",
      "        [1.0746],\n",
      "        [1.1033],\n",
      "        [1.0776],\n",
      "        [1.1133],\n",
      "        [1.0881],\n",
      "        [1.0598],\n",
      "        [1.0811],\n",
      "        [1.0900],\n",
      "        [1.1103],\n",
      "        [1.1180],\n",
      "        [1.0651],\n",
      "        [1.1031],\n",
      "        [1.0996],\n",
      "        [1.0874],\n",
      "        [1.0788],\n",
      "        [1.0732],\n",
      "        [1.0965],\n",
      "        [1.0903],\n",
      "        [1.0964],\n",
      "        [1.0736],\n",
      "        [1.0779],\n",
      "        [1.0398],\n",
      "        [1.1033],\n",
      "        [1.0715],\n",
      "        [1.0785],\n",
      "        [1.1223],\n",
      "        [1.0653],\n",
      "        [1.0916],\n",
      "        [1.0944],\n",
      "        [1.0859],\n",
      "        [1.0890],\n",
      "        [1.0542],\n",
      "        [1.1032],\n",
      "        [1.1126],\n",
      "        [1.1100],\n",
      "        [1.0872],\n",
      "        [1.0631],\n",
      "        [1.0956],\n",
      "        [1.0908],\n",
      "        [1.1204],\n",
      "        [1.0703],\n",
      "        [1.0602],\n",
      "        [1.1024],\n",
      "        [1.1117],\n",
      "        [1.0983],\n",
      "        [0.2731],\n",
      "        [1.0850],\n",
      "        [1.0867],\n",
      "        [1.1239],\n",
      "        [1.0521],\n",
      "        [1.1108],\n",
      "        [1.1238],\n",
      "        [1.0847],\n",
      "        [1.0732],\n",
      "        [1.1025],\n",
      "        [1.0884],\n",
      "        [1.0988],\n",
      "        [1.1127],\n",
      "        [1.0970],\n",
      "        [1.1112],\n",
      "        [1.0889],\n",
      "        [1.0461],\n",
      "        [1.1239],\n",
      "        [1.0885],\n",
      "        [1.0989],\n",
      "        [1.1061],\n",
      "        [1.1059],\n",
      "        [1.0959],\n",
      "        [1.0713],\n",
      "        [1.0677],\n",
      "        [1.0858],\n",
      "        [1.0613],\n",
      "        [1.1098],\n",
      "        [1.0629]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0933],\n",
      "        [1.1160],\n",
      "        [1.1220],\n",
      "        [1.0892],\n",
      "        [1.1034],\n",
      "        [1.1081],\n",
      "        [1.1101],\n",
      "        [1.0583],\n",
      "        [1.1009],\n",
      "        [1.0892],\n",
      "        [1.0592],\n",
      "        [1.0898],\n",
      "        [1.0614],\n",
      "        [1.1055],\n",
      "        [1.0951],\n",
      "        [1.0890],\n",
      "        [1.0825],\n",
      "        [1.1087],\n",
      "        [1.1099],\n",
      "        [1.1205],\n",
      "        [1.1181],\n",
      "        [1.1235],\n",
      "        [1.1139],\n",
      "        [1.1175],\n",
      "        [1.0711],\n",
      "        [1.0860],\n",
      "        [1.0724],\n",
      "        [1.0996],\n",
      "        [1.1147],\n",
      "        [1.0819],\n",
      "        [1.1100],\n",
      "        [1.0787],\n",
      "        [1.0866],\n",
      "        [1.0888],\n",
      "        [1.0530],\n",
      "        [1.0971],\n",
      "        [1.0994],\n",
      "        [1.0861],\n",
      "        [1.0820],\n",
      "        [1.0971],\n",
      "        [1.0808],\n",
      "        [1.0734],\n",
      "        [1.1221],\n",
      "        [1.1044],\n",
      "        [1.1094],\n",
      "        [1.1079],\n",
      "        [1.0919],\n",
      "        [1.0811],\n",
      "        [1.1077],\n",
      "        [1.0755],\n",
      "        [1.1131],\n",
      "        [1.1026],\n",
      "        [1.0668],\n",
      "        [1.0975],\n",
      "        [1.1009],\n",
      "        [1.0930],\n",
      "        [1.0834],\n",
      "        [1.1023],\n",
      "        [1.1113],\n",
      "        [1.0871],\n",
      "        [1.0841],\n",
      "        [1.1204],\n",
      "        [1.0822],\n",
      "        [1.0888],\n",
      "        [1.1103],\n",
      "        [1.1199],\n",
      "        [1.0728],\n",
      "        [1.0766],\n",
      "        [1.1124],\n",
      "        [1.0985],\n",
      "        [1.1216],\n",
      "        [1.1039],\n",
      "        [1.0790],\n",
      "        [1.1246],\n",
      "        [1.0984],\n",
      "        [1.1192],\n",
      "        [1.0767],\n",
      "        [1.1007],\n",
      "        [1.0894],\n",
      "        [1.0942],\n",
      "        [1.1108],\n",
      "        [1.0516],\n",
      "        [1.0687],\n",
      "        [1.0945],\n",
      "        [1.0795],\n",
      "        [1.0589],\n",
      "        [1.1010],\n",
      "        [1.1119],\n",
      "        [1.1086],\n",
      "        [1.1020],\n",
      "        [1.0531],\n",
      "        [1.1018],\n",
      "        [1.0996],\n",
      "        [1.0659],\n",
      "        [1.1156],\n",
      "        [1.1090],\n",
      "        [1.1062],\n",
      "        [1.1028],\n",
      "        [1.0466],\n",
      "        [1.1248],\n",
      "        [1.1200],\n",
      "        [1.0755],\n",
      "        [1.1121],\n",
      "        [1.0929],\n",
      "        [1.1106],\n",
      "        [1.1055],\n",
      "        [1.1021],\n",
      "        [1.1055],\n",
      "        [1.1033],\n",
      "        [1.0680],\n",
      "        [1.0655],\n",
      "        [1.1137],\n",
      "        [1.1215],\n",
      "        [1.1212],\n",
      "        [1.0936],\n",
      "        [1.0255],\n",
      "        [1.1220],\n",
      "        [1.0460],\n",
      "        [1.1097],\n",
      "        [1.0926],\n",
      "        [1.1122],\n",
      "        [1.0867],\n",
      "        [1.0897],\n",
      "        [1.0932],\n",
      "        [1.1227],\n",
      "        [1.1217],\n",
      "        [1.0984],\n",
      "        [1.0418]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0724],\n",
      "        [1.0736],\n",
      "        [1.1128],\n",
      "        [1.0843],\n",
      "        [1.1051],\n",
      "        [1.0713],\n",
      "        [1.0861],\n",
      "        [1.1122],\n",
      "        [1.1204],\n",
      "        [1.0615],\n",
      "        [1.0767],\n",
      "        [1.0869],\n",
      "        [1.0870],\n",
      "        [1.0723],\n",
      "        [1.1005],\n",
      "        [1.0427],\n",
      "        [1.1094],\n",
      "        [1.0141],\n",
      "        [1.1101],\n",
      "        [1.0844],\n",
      "        [1.0853],\n",
      "        [1.1003],\n",
      "        [1.1173],\n",
      "        [1.0819],\n",
      "        [1.0892],\n",
      "        [1.0859],\n",
      "        [1.0805],\n",
      "        [1.1094],\n",
      "        [1.0782],\n",
      "        [1.1238],\n",
      "        [1.1040],\n",
      "        [1.0943],\n",
      "        [1.0871],\n",
      "        [1.0629],\n",
      "        [1.1026],\n",
      "        [1.1108],\n",
      "        [1.0835],\n",
      "        [1.0961],\n",
      "        [1.0853],\n",
      "        [1.0709],\n",
      "        [1.0805],\n",
      "        [1.0848],\n",
      "        [1.1118],\n",
      "        [1.1136],\n",
      "        [1.0821],\n",
      "        [1.0990],\n",
      "        [1.1186],\n",
      "        [1.0567],\n",
      "        [1.0959],\n",
      "        [1.1230],\n",
      "        [1.1144],\n",
      "        [1.1222],\n",
      "        [1.1171],\n",
      "        [1.0876],\n",
      "        [1.1213],\n",
      "        [1.0933],\n",
      "        [1.0891],\n",
      "        [1.0895],\n",
      "        [1.0905],\n",
      "        [1.1112],\n",
      "        [1.1009],\n",
      "        [1.1224],\n",
      "        [1.0894],\n",
      "        [1.0816],\n",
      "        [1.0967],\n",
      "        [1.0946],\n",
      "        [1.0954],\n",
      "        [1.1220],\n",
      "        [1.0888],\n",
      "        [1.1220],\n",
      "        [1.0811],\n",
      "        [1.1057],\n",
      "        [1.1194],\n",
      "        [1.0526],\n",
      "        [1.1122],\n",
      "        [1.0934],\n",
      "        [1.0989],\n",
      "        [1.0957],\n",
      "        [1.1142],\n",
      "        [1.0996],\n",
      "        [1.1064],\n",
      "        [1.0653],\n",
      "        [1.1061],\n",
      "        [1.1056],\n",
      "        [1.0617],\n",
      "        [1.0903],\n",
      "        [1.0713],\n",
      "        [1.1175],\n",
      "        [1.0423],\n",
      "        [1.0989],\n",
      "        [1.0998],\n",
      "        [1.0679],\n",
      "        [1.1173],\n",
      "        [1.1190],\n",
      "        [1.0965],\n",
      "        [1.1194],\n",
      "        [1.0639],\n",
      "        [1.0655],\n",
      "        [1.0878],\n",
      "        [1.0994],\n",
      "        [1.0706],\n",
      "        [1.0851],\n",
      "        [1.0541],\n",
      "        [1.0842],\n",
      "        [1.1137],\n",
      "        [1.0804],\n",
      "        [1.1001],\n",
      "        [1.1140],\n",
      "        [1.1224],\n",
      "        [1.0743],\n",
      "        [1.1193],\n",
      "        [1.0405],\n",
      "        [1.0724],\n",
      "        [1.0713],\n",
      "        [1.0916],\n",
      "        [1.1005],\n",
      "        [1.1020],\n",
      "        [1.1241],\n",
      "        [1.0561],\n",
      "        [1.1209],\n",
      "        [1.0636],\n",
      "        [1.1100],\n",
      "        [1.1102],\n",
      "        [1.0927],\n",
      "        [1.0847],\n",
      "        [1.1241],\n",
      "        [1.1045],\n",
      "        [1.0823]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1122],\n",
      "        [1.1052],\n",
      "        [1.0745],\n",
      "        [1.0910]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  26 | lr 0.00100 train_loss 2.11908 | val_loss 2.28905 | val_rmse 1.51296\n",
      "tensor([[1.1117],\n",
      "        [1.0766],\n",
      "        [1.0714],\n",
      "        [1.1026],\n",
      "        [1.1024],\n",
      "        [1.0772],\n",
      "        [1.1174],\n",
      "        [1.1195],\n",
      "        [1.1163],\n",
      "        [1.1030],\n",
      "        [1.1012],\n",
      "        [1.1205],\n",
      "        [0.3502],\n",
      "        [1.1056],\n",
      "        [1.1061],\n",
      "        [1.0426],\n",
      "        [1.0956],\n",
      "        [1.0939],\n",
      "        [1.0995],\n",
      "        [1.0612],\n",
      "        [1.1220],\n",
      "        [1.1254],\n",
      "        [1.1050],\n",
      "        [1.0745],\n",
      "        [1.1025],\n",
      "        [1.0623],\n",
      "        [1.0872],\n",
      "        [1.1267],\n",
      "        [1.0577],\n",
      "        [1.0997],\n",
      "        [1.1281],\n",
      "        [1.0756],\n",
      "        [1.0958],\n",
      "        [1.0943],\n",
      "        [1.0957],\n",
      "        [1.1136],\n",
      "        [1.1163],\n",
      "        [1.1265],\n",
      "        [1.1214],\n",
      "        [1.0895],\n",
      "        [1.1310],\n",
      "        [1.0430],\n",
      "        [1.1229],\n",
      "        [1.1094],\n",
      "        [1.0783],\n",
      "        [1.1095],\n",
      "        [1.1208],\n",
      "        [1.1307],\n",
      "        [1.1220],\n",
      "        [1.1159],\n",
      "        [1.1183],\n",
      "        [1.1113],\n",
      "        [1.1216],\n",
      "        [1.1226],\n",
      "        [1.1344],\n",
      "        [1.0520],\n",
      "        [1.0788],\n",
      "        [1.1090],\n",
      "        [1.0969],\n",
      "        [1.0537],\n",
      "        [1.0886],\n",
      "        [1.1026],\n",
      "        [1.0894],\n",
      "        [1.0940],\n",
      "        [1.1104],\n",
      "        [1.1264],\n",
      "        [1.0885],\n",
      "        [1.1300],\n",
      "        [1.0981],\n",
      "        [1.0884],\n",
      "        [1.0930],\n",
      "        [1.0905],\n",
      "        [1.1168],\n",
      "        [1.1091],\n",
      "        [1.0843],\n",
      "        [1.1169],\n",
      "        [1.1097],\n",
      "        [1.1092],\n",
      "        [1.0941],\n",
      "        [1.0895],\n",
      "        [1.1115],\n",
      "        [1.0877],\n",
      "        [1.0920],\n",
      "        [1.1112],\n",
      "        [1.0747],\n",
      "        [1.0921],\n",
      "        [1.0820],\n",
      "        [1.0088],\n",
      "        [1.1184],\n",
      "        [1.0847],\n",
      "        [1.1110],\n",
      "        [1.1188],\n",
      "        [1.0898],\n",
      "        [1.0768],\n",
      "        [1.1080],\n",
      "        [1.0897],\n",
      "        [1.1281],\n",
      "        [1.1163],\n",
      "        [1.0946],\n",
      "        [1.1172],\n",
      "        [1.1225],\n",
      "        [1.0889],\n",
      "        [1.1073],\n",
      "        [1.1166],\n",
      "        [1.1219],\n",
      "        [1.1159],\n",
      "        [1.0770],\n",
      "        [1.1305],\n",
      "        [1.1202],\n",
      "        [1.0883],\n",
      "        [1.1034],\n",
      "        [1.1218],\n",
      "        [1.0778],\n",
      "        [1.1314],\n",
      "        [1.1196],\n",
      "        [1.0471],\n",
      "        [1.0445],\n",
      "        [1.1079],\n",
      "        [1.1071],\n",
      "        [1.1260],\n",
      "        [1.1054],\n",
      "        [1.1041],\n",
      "        [1.0984],\n",
      "        [1.1130],\n",
      "        [1.1185],\n",
      "        [1.1001],\n",
      "        [1.0954],\n",
      "        [1.0943]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1075],\n",
      "        [1.1053],\n",
      "        [1.1206],\n",
      "        [1.1198],\n",
      "        [1.0954],\n",
      "        [1.0978],\n",
      "        [1.1010],\n",
      "        [1.1063],\n",
      "        [1.1384],\n",
      "        [1.1143],\n",
      "        [1.0971],\n",
      "        [1.1181],\n",
      "        [1.1175],\n",
      "        [1.0671],\n",
      "        [1.0887],\n",
      "        [1.0649],\n",
      "        [1.1230],\n",
      "        [1.0853],\n",
      "        [1.0939],\n",
      "        [1.0741],\n",
      "        [1.1059],\n",
      "        [1.1174],\n",
      "        [1.0873],\n",
      "        [1.1008],\n",
      "        [1.1096],\n",
      "        [1.1327],\n",
      "        [1.1339],\n",
      "        [1.1274],\n",
      "        [1.1096],\n",
      "        [1.1354],\n",
      "        [1.1317],\n",
      "        [1.1308],\n",
      "        [1.1155],\n",
      "        [1.1015],\n",
      "        [1.0807],\n",
      "        [1.0862],\n",
      "        [1.1191],\n",
      "        [1.1300],\n",
      "        [1.0977],\n",
      "        [1.1328],\n",
      "        [1.1109],\n",
      "        [1.1162],\n",
      "        [1.0826],\n",
      "        [1.0889],\n",
      "        [1.1133],\n",
      "        [1.1068],\n",
      "        [1.1327],\n",
      "        [1.1026],\n",
      "        [1.1020],\n",
      "        [1.1247],\n",
      "        [1.1260],\n",
      "        [1.1266],\n",
      "        [1.1297],\n",
      "        [1.0950],\n",
      "        [1.1041],\n",
      "        [1.1246],\n",
      "        [1.1328],\n",
      "        [1.1219],\n",
      "        [1.0794],\n",
      "        [1.1162],\n",
      "        [1.1180],\n",
      "        [1.1109],\n",
      "        [1.1255],\n",
      "        [1.1009],\n",
      "        [1.0922],\n",
      "        [1.1050],\n",
      "        [1.1207],\n",
      "        [1.0849],\n",
      "        [1.1372],\n",
      "        [1.0790],\n",
      "        [1.1282],\n",
      "        [1.1259],\n",
      "        [1.1348],\n",
      "        [1.0880],\n",
      "        [1.1157],\n",
      "        [1.0889],\n",
      "        [1.0819],\n",
      "        [1.1113],\n",
      "        [1.1332],\n",
      "        [1.0976],\n",
      "        [1.1045],\n",
      "        [1.0919],\n",
      "        [1.1303],\n",
      "        [1.1180],\n",
      "        [1.0940],\n",
      "        [1.1230],\n",
      "        [1.1323],\n",
      "        [1.1361],\n",
      "        [1.1336],\n",
      "        [1.0863],\n",
      "        [1.1039],\n",
      "        [1.0977],\n",
      "        [1.0724],\n",
      "        [1.1089],\n",
      "        [1.0751],\n",
      "        [1.0986],\n",
      "        [1.0890],\n",
      "        [1.0954],\n",
      "        [1.1002],\n",
      "        [1.1372],\n",
      "        [1.1404],\n",
      "        [1.1209],\n",
      "        [1.1119],\n",
      "        [1.1282],\n",
      "        [1.1236],\n",
      "        [1.1190],\n",
      "        [1.1137],\n",
      "        [1.0697],\n",
      "        [1.1340],\n",
      "        [1.1202],\n",
      "        [1.1192],\n",
      "        [1.1269],\n",
      "        [1.0917],\n",
      "        [1.0995],\n",
      "        [1.0787],\n",
      "        [1.1185],\n",
      "        [1.1013],\n",
      "        [1.1381],\n",
      "        [1.1285],\n",
      "        [1.1366],\n",
      "        [1.1290],\n",
      "        [1.1239],\n",
      "        [1.1139],\n",
      "        [1.0976],\n",
      "        [1.1235],\n",
      "        [1.1336],\n",
      "        [1.0995],\n",
      "        [1.0770]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1248],\n",
      "        [1.0969],\n",
      "        [1.1089],\n",
      "        [1.1142],\n",
      "        [1.1180],\n",
      "        [1.1292],\n",
      "        [1.0926],\n",
      "        [1.1317],\n",
      "        [1.1331],\n",
      "        [1.0721],\n",
      "        [1.0780],\n",
      "        [1.0907],\n",
      "        [1.0720],\n",
      "        [1.1111],\n",
      "        [1.0931],\n",
      "        [1.1124],\n",
      "        [1.0917],\n",
      "        [1.1110],\n",
      "        [1.0889],\n",
      "        [1.1237],\n",
      "        [1.0686],\n",
      "        [1.0979],\n",
      "        [1.0508],\n",
      "        [1.1301],\n",
      "        [1.0997],\n",
      "        [1.1013],\n",
      "        [1.0941],\n",
      "        [1.1417],\n",
      "        [1.1327],\n",
      "        [1.1389],\n",
      "        [1.1223],\n",
      "        [1.1191],\n",
      "        [1.0757],\n",
      "        [1.1014],\n",
      "        [1.0660],\n",
      "        [1.1470],\n",
      "        [1.1092],\n",
      "        [1.0992],\n",
      "        [1.1099],\n",
      "        [1.1205],\n",
      "        [1.1085],\n",
      "        [1.1207],\n",
      "        [1.0659],\n",
      "        [1.1177],\n",
      "        [1.1192],\n",
      "        [1.1328],\n",
      "        [1.1305],\n",
      "        [1.1400],\n",
      "        [1.0605],\n",
      "        [1.1078],\n",
      "        [1.0727],\n",
      "        [1.1291],\n",
      "        [1.1343],\n",
      "        [1.0842],\n",
      "        [1.1317],\n",
      "        [1.1289],\n",
      "        [1.1112],\n",
      "        [1.1384],\n",
      "        [1.1135],\n",
      "        [1.1433],\n",
      "        [1.1105],\n",
      "        [1.0865],\n",
      "        [1.0947],\n",
      "        [1.1106],\n",
      "        [1.1166],\n",
      "        [1.1209],\n",
      "        [1.1341],\n",
      "        [1.0490],\n",
      "        [1.0982],\n",
      "        [1.1300],\n",
      "        [1.1067],\n",
      "        [1.1069],\n",
      "        [1.1304],\n",
      "        [1.0978],\n",
      "        [1.1136],\n",
      "        [1.0960],\n",
      "        [1.1055],\n",
      "        [1.1344],\n",
      "        [1.0825],\n",
      "        [1.0500],\n",
      "        [1.0909],\n",
      "        [1.1437],\n",
      "        [1.1094],\n",
      "        [1.1324],\n",
      "        [1.1144],\n",
      "        [1.1329],\n",
      "        [1.1119],\n",
      "        [1.0985],\n",
      "        [1.1245],\n",
      "        [1.0917],\n",
      "        [1.1210],\n",
      "        [1.1392],\n",
      "        [1.1383],\n",
      "        [1.1315],\n",
      "        [1.1379],\n",
      "        [1.1016],\n",
      "        [1.1192],\n",
      "        [1.1320],\n",
      "        [1.1344],\n",
      "        [1.0496],\n",
      "        [1.1353],\n",
      "        [1.1197],\n",
      "        [1.1267],\n",
      "        [1.0867],\n",
      "        [1.1436],\n",
      "        [1.0919],\n",
      "        [1.1294],\n",
      "        [1.1261],\n",
      "        [1.1248],\n",
      "        [1.1305],\n",
      "        [1.1020],\n",
      "        [1.1392],\n",
      "        [1.1199],\n",
      "        [1.1436],\n",
      "        [1.1149],\n",
      "        [1.1378],\n",
      "        [1.1035],\n",
      "        [1.1171],\n",
      "        [1.1189],\n",
      "        [1.1217],\n",
      "        [1.1252],\n",
      "        [1.1113],\n",
      "        [1.1325],\n",
      "        [1.1112],\n",
      "        [1.1405],\n",
      "        [1.0948],\n",
      "        [1.1246],\n",
      "        [1.0966]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1235],\n",
      "        [1.1317],\n",
      "        [1.1188],\n",
      "        [1.0962],\n",
      "        [1.1086],\n",
      "        [1.1389],\n",
      "        [1.1162],\n",
      "        [1.1500],\n",
      "        [1.1279],\n",
      "        [1.0923],\n",
      "        [1.1142],\n",
      "        [1.1351],\n",
      "        [1.1172],\n",
      "        [1.0907],\n",
      "        [1.1243],\n",
      "        [1.1075],\n",
      "        [1.0978],\n",
      "        [1.1480],\n",
      "        [1.1446],\n",
      "        [1.0569],\n",
      "        [1.1181],\n",
      "        [1.1106],\n",
      "        [1.1200],\n",
      "        [1.1080],\n",
      "        [1.1421],\n",
      "        [1.1256],\n",
      "        [1.1257],\n",
      "        [1.1212],\n",
      "        [1.1479],\n",
      "        [1.1052],\n",
      "        [1.1434],\n",
      "        [1.0954],\n",
      "        [1.1329],\n",
      "        [1.1459],\n",
      "        [1.1004],\n",
      "        [1.1296],\n",
      "        [1.1233],\n",
      "        [1.1326],\n",
      "        [1.0898],\n",
      "        [1.1137],\n",
      "        [1.1051],\n",
      "        [1.1126],\n",
      "        [1.1034],\n",
      "        [1.1419],\n",
      "        [1.1045],\n",
      "        [1.1194],\n",
      "        [1.1480],\n",
      "        [1.1070],\n",
      "        [1.1298],\n",
      "        [1.0905],\n",
      "        [1.1295],\n",
      "        [1.1170],\n",
      "        [1.1346],\n",
      "        [1.1434],\n",
      "        [1.1222],\n",
      "        [1.1180],\n",
      "        [1.1288],\n",
      "        [1.0669],\n",
      "        [1.0934],\n",
      "        [1.0572],\n",
      "        [1.1255],\n",
      "        [1.1064],\n",
      "        [1.1280],\n",
      "        [1.1224],\n",
      "        [1.1445],\n",
      "        [1.1115],\n",
      "        [1.1323],\n",
      "        [1.1127],\n",
      "        [1.1150],\n",
      "        [1.1435],\n",
      "        [1.1162],\n",
      "        [1.1016],\n",
      "        [1.1373],\n",
      "        [1.1196],\n",
      "        [1.1403],\n",
      "        [1.1253],\n",
      "        [1.1128],\n",
      "        [1.1395],\n",
      "        [1.1500],\n",
      "        [1.0917],\n",
      "        [1.0833],\n",
      "        [1.1162],\n",
      "        [1.0951],\n",
      "        [1.1149],\n",
      "        [1.1462],\n",
      "        [1.1361],\n",
      "        [1.1394],\n",
      "        [1.1248],\n",
      "        [1.1305],\n",
      "        [1.1343],\n",
      "        [1.1122],\n",
      "        [1.1240],\n",
      "        [1.1334],\n",
      "        [1.1075],\n",
      "        [1.1075],\n",
      "        [1.1365],\n",
      "        [1.1464],\n",
      "        [1.1287],\n",
      "        [1.1189],\n",
      "        [1.1313],\n",
      "        [1.1053],\n",
      "        [1.1309],\n",
      "        [1.1345],\n",
      "        [1.1349],\n",
      "        [1.1145],\n",
      "        [1.0674],\n",
      "        [1.1194],\n",
      "        [1.1397],\n",
      "        [1.0813],\n",
      "        [1.1151],\n",
      "        [1.1032],\n",
      "        [1.1479],\n",
      "        [1.0598],\n",
      "        [1.1100],\n",
      "        [1.1238],\n",
      "        [1.1435],\n",
      "        [1.1446],\n",
      "        [1.1299],\n",
      "        [1.1430],\n",
      "        [1.1101],\n",
      "        [1.1219],\n",
      "        [1.1206],\n",
      "        [1.0976],\n",
      "        [1.1035],\n",
      "        [1.1136],\n",
      "        [1.1327],\n",
      "        [1.1321],\n",
      "        [1.1352]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1431],\n",
      "        [1.1320],\n",
      "        [1.1141],\n",
      "        [1.1039],\n",
      "        [1.0865],\n",
      "        [1.1392],\n",
      "        [1.1230],\n",
      "        [1.1320],\n",
      "        [1.1404],\n",
      "        [1.1395],\n",
      "        [1.1201],\n",
      "        [1.1503],\n",
      "        [1.1039],\n",
      "        [1.1332],\n",
      "        [1.1396],\n",
      "        [1.1167],\n",
      "        [1.1058],\n",
      "        [1.1572],\n",
      "        [1.0815],\n",
      "        [1.1220],\n",
      "        [1.1417],\n",
      "        [1.1362],\n",
      "        [1.0825],\n",
      "        [1.0984],\n",
      "        [1.1368],\n",
      "        [1.1453],\n",
      "        [1.1117],\n",
      "        [1.1050],\n",
      "        [1.1391],\n",
      "        [1.1572],\n",
      "        [1.1268],\n",
      "        [1.1517],\n",
      "        [1.1285],\n",
      "        [1.1359],\n",
      "        [1.0749],\n",
      "        [1.1295],\n",
      "        [1.1196],\n",
      "        [1.1407],\n",
      "        [1.1454],\n",
      "        [1.1531],\n",
      "        [1.1103],\n",
      "        [1.1489],\n",
      "        [1.0853],\n",
      "        [1.0897],\n",
      "        [1.0691],\n",
      "        [1.1512],\n",
      "        [1.0781],\n",
      "        [1.0887],\n",
      "        [1.0893],\n",
      "        [1.1455],\n",
      "        [1.1273],\n",
      "        [1.1393],\n",
      "        [1.1021],\n",
      "        [1.0933],\n",
      "        [1.1131],\n",
      "        [1.1340],\n",
      "        [1.1396],\n",
      "        [1.1460],\n",
      "        [1.1357],\n",
      "        [1.1452],\n",
      "        [1.1272],\n",
      "        [1.1572],\n",
      "        [1.1216],\n",
      "        [1.0830],\n",
      "        [1.1511],\n",
      "        [1.1008],\n",
      "        [1.0864],\n",
      "        [1.1182],\n",
      "        [1.1416],\n",
      "        [1.0976],\n",
      "        [1.1146],\n",
      "        [1.1201],\n",
      "        [1.1162],\n",
      "        [1.1402],\n",
      "        [1.1260],\n",
      "        [1.1448],\n",
      "        [1.1154],\n",
      "        [1.1173],\n",
      "        [1.0953],\n",
      "        [1.1397],\n",
      "        [1.1560],\n",
      "        [1.1490],\n",
      "        [1.1311],\n",
      "        [1.1211],\n",
      "        [1.1337],\n",
      "        [1.1515],\n",
      "        [1.1263],\n",
      "        [1.1327],\n",
      "        [1.1415],\n",
      "        [1.1165],\n",
      "        [1.1470],\n",
      "        [1.1125],\n",
      "        [1.1546],\n",
      "        [1.1333],\n",
      "        [1.1222],\n",
      "        [1.0931],\n",
      "        [1.0770],\n",
      "        [1.1519],\n",
      "        [1.1293],\n",
      "        [1.1397],\n",
      "        [1.1480],\n",
      "        [1.1329],\n",
      "        [1.1410],\n",
      "        [1.1548],\n",
      "        [1.1425],\n",
      "        [1.1111],\n",
      "        [1.1357],\n",
      "        [1.0935],\n",
      "        [1.1280],\n",
      "        [1.1021],\n",
      "        [1.1306],\n",
      "        [1.1523],\n",
      "        [1.1404],\n",
      "        [1.1010],\n",
      "        [1.1257],\n",
      "        [1.1402],\n",
      "        [1.1295],\n",
      "        [1.1226],\n",
      "        [1.1370],\n",
      "        [1.1368],\n",
      "        [1.1453],\n",
      "        [1.1497],\n",
      "        [1.1529],\n",
      "        [1.1133],\n",
      "        [1.0846],\n",
      "        [1.1492],\n",
      "        [1.1377],\n",
      "        [1.1155]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1333],\n",
      "        [1.1229],\n",
      "        [1.1339],\n",
      "        [1.1598],\n",
      "        [1.1455],\n",
      "        [1.1055],\n",
      "        [1.0630],\n",
      "        [1.1145],\n",
      "        [1.1189],\n",
      "        [1.1350],\n",
      "        [1.1528],\n",
      "        [1.1508],\n",
      "        [1.1439],\n",
      "        [1.1039],\n",
      "        [1.1545],\n",
      "        [1.1463],\n",
      "        [1.1241],\n",
      "        [1.1227],\n",
      "        [1.1288],\n",
      "        [1.0806],\n",
      "        [1.1163],\n",
      "        [1.1176],\n",
      "        [1.1590],\n",
      "        [1.1508],\n",
      "        [1.1558],\n",
      "        [1.1380],\n",
      "        [1.1445],\n",
      "        [1.1409],\n",
      "        [1.0867],\n",
      "        [1.1400],\n",
      "        [1.1102],\n",
      "        [1.0841],\n",
      "        [1.1554],\n",
      "        [1.0982],\n",
      "        [1.1355],\n",
      "        [1.1192],\n",
      "        [1.1380],\n",
      "        [1.1577],\n",
      "        [1.1109],\n",
      "        [1.0982],\n",
      "        [1.1403],\n",
      "        [1.1415],\n",
      "        [1.1469],\n",
      "        [1.1353],\n",
      "        [1.1364],\n",
      "        [1.1187],\n",
      "        [1.1363],\n",
      "        [1.1389],\n",
      "        [1.1343],\n",
      "        [1.1312],\n",
      "        [1.1450],\n",
      "        [1.0998],\n",
      "        [1.1564],\n",
      "        [1.1192],\n",
      "        [1.1480],\n",
      "        [1.1343],\n",
      "        [1.1189],\n",
      "        [1.1446],\n",
      "        [1.0775],\n",
      "        [1.1319],\n",
      "        [1.1584],\n",
      "        [1.1291],\n",
      "        [1.1387],\n",
      "        [1.1388],\n",
      "        [1.1428],\n",
      "        [1.1438],\n",
      "        [1.1412],\n",
      "        [1.1088],\n",
      "        [1.1342],\n",
      "        [1.1497],\n",
      "        [1.1344],\n",
      "        [1.1571],\n",
      "        [1.1511],\n",
      "        [1.1189],\n",
      "        [1.1233],\n",
      "        [1.1470],\n",
      "        [1.0777],\n",
      "        [1.1490],\n",
      "        [1.1210],\n",
      "        [1.1509],\n",
      "        [1.1394],\n",
      "        [1.1310],\n",
      "        [1.1416],\n",
      "        [1.1420],\n",
      "        [1.1460],\n",
      "        [1.1254],\n",
      "        [1.1619],\n",
      "        [1.1412],\n",
      "        [1.1606],\n",
      "        [1.1319],\n",
      "        [1.1216],\n",
      "        [1.1461],\n",
      "        [1.1411],\n",
      "        [1.1335],\n",
      "        [1.1260],\n",
      "        [1.1601],\n",
      "        [1.1543],\n",
      "        [1.1593],\n",
      "        [1.1285],\n",
      "        [0.1248],\n",
      "        [1.0990],\n",
      "        [1.1018],\n",
      "        [1.1536],\n",
      "        [1.1286],\n",
      "        [1.1271],\n",
      "        [1.1115],\n",
      "        [1.1581],\n",
      "        [1.1013],\n",
      "        [1.1513],\n",
      "        [1.1399],\n",
      "        [1.1320],\n",
      "        [1.1367],\n",
      "        [1.1063],\n",
      "        [1.1422],\n",
      "        [1.1555],\n",
      "        [1.1332],\n",
      "        [1.1314],\n",
      "        [1.1427],\n",
      "        [1.1617],\n",
      "        [1.1319],\n",
      "        [1.1092],\n",
      "        [1.1590],\n",
      "        [1.1596],\n",
      "        [1.1159],\n",
      "        [1.1274],\n",
      "        [1.1208],\n",
      "        [1.0915],\n",
      "        [1.0747]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1221],\n",
      "        [1.1431],\n",
      "        [1.1338],\n",
      "        [1.1415],\n",
      "        [1.1333],\n",
      "        [1.1059],\n",
      "        [1.1009],\n",
      "        [1.1446],\n",
      "        [1.1558],\n",
      "        [1.1458],\n",
      "        [1.1371],\n",
      "        [1.1323],\n",
      "        [1.0880],\n",
      "        [1.1133],\n",
      "        [1.1195],\n",
      "        [1.1553],\n",
      "        [1.1295],\n",
      "        [1.1010],\n",
      "        [1.1289],\n",
      "        [1.1595],\n",
      "        [1.1623],\n",
      "        [1.1445],\n",
      "        [1.1151],\n",
      "        [1.1434],\n",
      "        [1.1164],\n",
      "        [1.1260],\n",
      "        [1.1252],\n",
      "        [1.1382],\n",
      "        [1.1618],\n",
      "        [1.1252],\n",
      "        [1.1137],\n",
      "        [1.1332],\n",
      "        [1.1160],\n",
      "        [1.1311],\n",
      "        [1.1361],\n",
      "        [1.1540],\n",
      "        [1.1365],\n",
      "        [1.1349],\n",
      "        [1.1155],\n",
      "        [1.1426],\n",
      "        [1.1498],\n",
      "        [1.0862],\n",
      "        [1.1485],\n",
      "        [1.1145],\n",
      "        [1.1471],\n",
      "        [1.1583],\n",
      "        [1.1190],\n",
      "        [1.1214],\n",
      "        [1.1365],\n",
      "        [1.0925],\n",
      "        [1.1445],\n",
      "        [1.1269],\n",
      "        [1.1131],\n",
      "        [1.1129],\n",
      "        [1.0800],\n",
      "        [1.1568],\n",
      "        [1.1143],\n",
      "        [1.1540],\n",
      "        [1.1574],\n",
      "        [1.1409],\n",
      "        [1.1388],\n",
      "        [1.1569],\n",
      "        [1.1519],\n",
      "        [1.1135],\n",
      "        [1.1553],\n",
      "        [1.1433],\n",
      "        [1.1584],\n",
      "        [1.1650],\n",
      "        [1.1323],\n",
      "        [1.1337],\n",
      "        [1.1004],\n",
      "        [1.1156],\n",
      "        [1.1277],\n",
      "        [1.1524],\n",
      "        [1.1210],\n",
      "        [1.1266],\n",
      "        [1.1590],\n",
      "        [1.1294],\n",
      "        [1.1250],\n",
      "        [1.1306],\n",
      "        [1.1582],\n",
      "        [1.1272],\n",
      "        [1.1297],\n",
      "        [1.1353],\n",
      "        [1.1479],\n",
      "        [1.1444],\n",
      "        [1.1108],\n",
      "        [1.1297],\n",
      "        [1.1588],\n",
      "        [1.1054],\n",
      "        [1.1500],\n",
      "        [1.0614],\n",
      "        [1.1477],\n",
      "        [1.1368],\n",
      "        [1.1463],\n",
      "        [1.1141],\n",
      "        [1.1359],\n",
      "        [1.1373],\n",
      "        [1.1639],\n",
      "        [1.1431],\n",
      "        [1.1242],\n",
      "        [1.1442],\n",
      "        [1.1353],\n",
      "        [1.1357],\n",
      "        [1.1666],\n",
      "        [1.1439],\n",
      "        [1.1303],\n",
      "        [1.1454],\n",
      "        [1.1367],\n",
      "        [1.1485],\n",
      "        [1.1452],\n",
      "        [1.1175],\n",
      "        [1.1529],\n",
      "        [1.1489],\n",
      "        [1.1604],\n",
      "        [1.1631],\n",
      "        [1.1317],\n",
      "        [1.1142],\n",
      "        [1.1521],\n",
      "        [1.1382],\n",
      "        [1.0919],\n",
      "        [1.1651],\n",
      "        [1.1387],\n",
      "        [1.1382],\n",
      "        [1.1328],\n",
      "        [1.1322],\n",
      "        [1.1499],\n",
      "        [1.1566]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1426],\n",
      "        [1.1405],\n",
      "        [1.1504],\n",
      "        [1.1685]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  27 | lr 0.00100 train_loss 2.13134 | val_loss 2.27920 | val_rmse 1.50970\n",
      "tensor([[1.1374],\n",
      "        [1.1089],\n",
      "        [1.1721],\n",
      "        [1.1595],\n",
      "        [1.1418],\n",
      "        [1.1546],\n",
      "        [1.1396],\n",
      "        [1.1528],\n",
      "        [1.1224],\n",
      "        [1.1805],\n",
      "        [1.1358],\n",
      "        [1.1392],\n",
      "        [1.1720],\n",
      "        [1.1649],\n",
      "        [1.1737],\n",
      "        [1.1324],\n",
      "        [1.1182],\n",
      "        [1.1403],\n",
      "        [1.1722],\n",
      "        [1.1236],\n",
      "        [1.1509],\n",
      "        [1.1499],\n",
      "        [1.1287],\n",
      "        [1.1651],\n",
      "        [1.1645],\n",
      "        [1.1792],\n",
      "        [1.1802],\n",
      "        [1.1754],\n",
      "        [1.1628],\n",
      "        [1.1472],\n",
      "        [1.1326],\n",
      "        [1.1679],\n",
      "        [1.1537],\n",
      "        [1.1335],\n",
      "        [1.1718],\n",
      "        [1.1451],\n",
      "        [1.1523],\n",
      "        [1.1600],\n",
      "        [1.1589],\n",
      "        [1.1151],\n",
      "        [1.1199],\n",
      "        [1.1277],\n",
      "        [1.1746],\n",
      "        [1.1776],\n",
      "        [1.1435],\n",
      "        [1.1015],\n",
      "        [1.1635],\n",
      "        [1.1686],\n",
      "        [1.1742],\n",
      "        [1.1781],\n",
      "        [1.1281],\n",
      "        [1.1404],\n",
      "        [1.1230],\n",
      "        [1.1267],\n",
      "        [1.1310],\n",
      "        [1.1059],\n",
      "        [1.1467],\n",
      "        [1.0900],\n",
      "        [1.1537],\n",
      "        [1.1541],\n",
      "        [1.1523],\n",
      "        [1.1588],\n",
      "        [1.1794],\n",
      "        [1.1672],\n",
      "        [1.1233],\n",
      "        [1.1456],\n",
      "        [1.1720],\n",
      "        [1.1570],\n",
      "        [1.1561],\n",
      "        [1.1382],\n",
      "        [1.1677],\n",
      "        [1.1753],\n",
      "        [1.1780],\n",
      "        [1.1187],\n",
      "        [1.1643],\n",
      "        [1.1343],\n",
      "        [1.1472],\n",
      "        [1.1629],\n",
      "        [1.1453],\n",
      "        [1.1248],\n",
      "        [1.1475],\n",
      "        [1.1629],\n",
      "        [1.0768],\n",
      "        [1.1238],\n",
      "        [1.1450],\n",
      "        [1.1299],\n",
      "        [1.1442],\n",
      "        [1.1711],\n",
      "        [1.1229],\n",
      "        [1.1303],\n",
      "        [1.1618],\n",
      "        [1.1562],\n",
      "        [1.1467],\n",
      "        [1.1650],\n",
      "        [1.1732],\n",
      "        [1.1646],\n",
      "        [1.1538],\n",
      "        [1.1541],\n",
      "        [1.1558],\n",
      "        [1.1642],\n",
      "        [1.1751],\n",
      "        [1.1679],\n",
      "        [1.1466],\n",
      "        [1.1098],\n",
      "        [1.1740],\n",
      "        [1.1630],\n",
      "        [1.1488],\n",
      "        [1.1462],\n",
      "        [1.1527],\n",
      "        [1.1733],\n",
      "        [1.1358],\n",
      "        [1.1429],\n",
      "        [1.0904],\n",
      "        [1.1648],\n",
      "        [1.1255],\n",
      "        [1.1424],\n",
      "        [1.1415],\n",
      "        [1.1707],\n",
      "        [1.1731],\n",
      "        [1.1441],\n",
      "        [1.1545],\n",
      "        [1.1415],\n",
      "        [1.0909],\n",
      "        [1.1570],\n",
      "        [1.1381],\n",
      "        [1.1674],\n",
      "        [1.1517],\n",
      "        [1.1525]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1598],\n",
      "        [1.1212],\n",
      "        [1.1932],\n",
      "        [1.1548],\n",
      "        [1.1722],\n",
      "        [1.1664],\n",
      "        [1.1891],\n",
      "        [1.1645],\n",
      "        [1.1884],\n",
      "        [1.1703],\n",
      "        [1.1734],\n",
      "        [1.1572],\n",
      "        [1.1415],\n",
      "        [1.1642],\n",
      "        [1.1194],\n",
      "        [1.1574],\n",
      "        [1.1634],\n",
      "        [1.1833],\n",
      "        [1.1813],\n",
      "        [1.1639],\n",
      "        [1.1486],\n",
      "        [1.1725],\n",
      "        [1.1734],\n",
      "        [1.1580],\n",
      "        [1.1419],\n",
      "        [1.1520],\n",
      "        [1.1800],\n",
      "        [1.1446],\n",
      "        [1.1445],\n",
      "        [1.1781],\n",
      "        [1.1511],\n",
      "        [1.1177],\n",
      "        [1.1476],\n",
      "        [1.1203],\n",
      "        [1.1783],\n",
      "        [1.1691],\n",
      "        [1.1727],\n",
      "        [1.1774],\n",
      "        [1.1574],\n",
      "        [1.1635],\n",
      "        [1.1775],\n",
      "        [1.1408],\n",
      "        [1.1560],\n",
      "        [1.1328],\n",
      "        [1.1653],\n",
      "        [1.1652],\n",
      "        [1.1649],\n",
      "        [1.1879],\n",
      "        [1.1080],\n",
      "        [1.1733],\n",
      "        [1.1713],\n",
      "        [1.1708],\n",
      "        [1.1100],\n",
      "        [1.1887],\n",
      "        [1.1910],\n",
      "        [1.1504],\n",
      "        [1.1517],\n",
      "        [1.0966],\n",
      "        [1.1800],\n",
      "        [1.1453],\n",
      "        [1.1458],\n",
      "        [1.1704],\n",
      "        [1.1855],\n",
      "        [1.1370],\n",
      "        [1.1823],\n",
      "        [1.1598],\n",
      "        [1.1322],\n",
      "        [1.1767],\n",
      "        [1.1263],\n",
      "        [1.1806],\n",
      "        [1.1678],\n",
      "        [1.1761],\n",
      "        [1.1797],\n",
      "        [1.1494],\n",
      "        [1.1616],\n",
      "        [1.1213],\n",
      "        [1.1425],\n",
      "        [1.1845],\n",
      "        [1.1796],\n",
      "        [1.1828],\n",
      "        [1.1426],\n",
      "        [1.1451],\n",
      "        [1.1771],\n",
      "        [1.1792],\n",
      "        [1.1583],\n",
      "        [1.1639],\n",
      "        [1.0802],\n",
      "        [1.1820],\n",
      "        [1.1505],\n",
      "        [1.1773],\n",
      "        [1.1395],\n",
      "        [1.1419],\n",
      "        [1.1661],\n",
      "        [1.1340],\n",
      "        [1.1666],\n",
      "        [1.1760],\n",
      "        [1.1831],\n",
      "        [1.1690],\n",
      "        [1.1305],\n",
      "        [1.1533],\n",
      "        [1.1745],\n",
      "        [1.1487],\n",
      "        [1.1774],\n",
      "        [1.1457],\n",
      "        [1.1899],\n",
      "        [1.1889],\n",
      "        [1.1688],\n",
      "        [1.1621],\n",
      "        [1.1915],\n",
      "        [1.1909],\n",
      "        [1.1517],\n",
      "        [1.1888],\n",
      "        [1.1596],\n",
      "        [1.1648],\n",
      "        [1.1618],\n",
      "        [1.1767],\n",
      "        [1.1373],\n",
      "        [1.1598],\n",
      "        [1.1912],\n",
      "        [1.1756],\n",
      "        [1.1822],\n",
      "        [1.1661],\n",
      "        [1.1523],\n",
      "        [1.1893],\n",
      "        [1.1915],\n",
      "        [1.1742],\n",
      "        [1.1686],\n",
      "        [1.1396]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1373],\n",
      "        [1.1674],\n",
      "        [1.1712],\n",
      "        [1.1828],\n",
      "        [1.1546],\n",
      "        [1.1582],\n",
      "        [1.1362],\n",
      "        [1.1983],\n",
      "        [1.1351],\n",
      "        [1.1669],\n",
      "        [1.1443],\n",
      "        [1.1531],\n",
      "        [1.1115],\n",
      "        [1.1410],\n",
      "        [1.1959],\n",
      "        [1.1518],\n",
      "        [1.1513],\n",
      "        [1.1602],\n",
      "        [1.1220],\n",
      "        [1.1915],\n",
      "        [1.1539],\n",
      "        [1.1315],\n",
      "        [1.1794],\n",
      "        [1.1309],\n",
      "        [1.1851],\n",
      "        [1.1509],\n",
      "        [1.1924],\n",
      "        [1.1633],\n",
      "        [1.1806],\n",
      "        [1.1785],\n",
      "        [1.1821],\n",
      "        [1.1820],\n",
      "        [1.1363],\n",
      "        [1.1647],\n",
      "        [1.1699],\n",
      "        [1.1993],\n",
      "        [1.1889],\n",
      "        [1.1439],\n",
      "        [1.1988],\n",
      "        [1.1840],\n",
      "        [1.1524],\n",
      "        [1.1408],\n",
      "        [1.1793],\n",
      "        [1.1794],\n",
      "        [1.1752],\n",
      "        [1.1692],\n",
      "        [1.1245],\n",
      "        [1.1785],\n",
      "        [1.1869],\n",
      "        [1.1622],\n",
      "        [1.1837],\n",
      "        [1.1949],\n",
      "        [1.1386],\n",
      "        [1.1462],\n",
      "        [1.1507],\n",
      "        [1.1683],\n",
      "        [1.1843],\n",
      "        [1.1924],\n",
      "        [1.1874],\n",
      "        [1.1566],\n",
      "        [1.1845],\n",
      "        [1.2023],\n",
      "        [1.1636],\n",
      "        [1.1910],\n",
      "        [1.1465],\n",
      "        [1.1392],\n",
      "        [1.1972],\n",
      "        [1.1957],\n",
      "        [1.1622],\n",
      "        [1.1752],\n",
      "        [1.1993],\n",
      "        [1.1897],\n",
      "        [1.1973],\n",
      "        [1.1740],\n",
      "        [1.1572],\n",
      "        [1.1651],\n",
      "        [1.1479],\n",
      "        [1.2036],\n",
      "        [1.1493],\n",
      "        [1.1355],\n",
      "        [1.1543],\n",
      "        [1.1484],\n",
      "        [1.1741],\n",
      "        [1.1784],\n",
      "        [1.1753],\n",
      "        [1.1552],\n",
      "        [1.1188],\n",
      "        [1.1434],\n",
      "        [1.1804],\n",
      "        [1.1724],\n",
      "        [1.1799],\n",
      "        [1.1454],\n",
      "        [1.1949],\n",
      "        [1.1671],\n",
      "        [1.1919],\n",
      "        [1.1946],\n",
      "        [1.1868],\n",
      "        [1.1575],\n",
      "        [1.1914],\n",
      "        [1.2020],\n",
      "        [1.1844],\n",
      "        [1.1944],\n",
      "        [1.1862],\n",
      "        [1.1695],\n",
      "        [1.1798],\n",
      "        [1.1512],\n",
      "        [1.1549],\n",
      "        [1.1858],\n",
      "        [1.1428],\n",
      "        [1.1742],\n",
      "        [1.1513],\n",
      "        [1.1700],\n",
      "        [1.1707],\n",
      "        [1.1721],\n",
      "        [1.1605],\n",
      "        [1.1342],\n",
      "        [1.1999],\n",
      "        [1.1791],\n",
      "        [1.1837],\n",
      "        [1.1941],\n",
      "        [1.1670],\n",
      "        [1.1857],\n",
      "        [1.1821],\n",
      "        [1.1943],\n",
      "        [1.1850],\n",
      "        [1.1966],\n",
      "        [1.1985],\n",
      "        [1.1588]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1627],\n",
      "        [1.2099],\n",
      "        [1.1835],\n",
      "        [1.2080],\n",
      "        [1.1948],\n",
      "        [1.1831],\n",
      "        [1.1485],\n",
      "        [1.1331],\n",
      "        [1.2037],\n",
      "        [1.2029],\n",
      "        [1.1978],\n",
      "        [1.2033],\n",
      "        [1.1656],\n",
      "        [1.1545],\n",
      "        [1.1615],\n",
      "        [1.1891],\n",
      "        [1.1820],\n",
      "        [1.1730],\n",
      "        [1.1852],\n",
      "        [1.2038],\n",
      "        [1.1999],\n",
      "        [1.1969],\n",
      "        [1.2020],\n",
      "        [1.2018],\n",
      "        [1.1839],\n",
      "        [1.1923],\n",
      "        [1.2020],\n",
      "        [1.1865],\n",
      "        [1.1991],\n",
      "        [1.1874],\n",
      "        [1.1832],\n",
      "        [1.1934],\n",
      "        [1.1854],\n",
      "        [1.1290],\n",
      "        [1.1677],\n",
      "        [1.1775],\n",
      "        [1.1925],\n",
      "        [1.1698],\n",
      "        [1.1766],\n",
      "        [1.1830],\n",
      "        [1.1642],\n",
      "        [1.1762],\n",
      "        [1.1773],\n",
      "        [1.1596],\n",
      "        [1.1323],\n",
      "        [1.1417],\n",
      "        [1.1763],\n",
      "        [1.1284],\n",
      "        [1.1918],\n",
      "        [1.1552],\n",
      "        [1.1823],\n",
      "        [1.1990],\n",
      "        [1.1459],\n",
      "        [1.1935],\n",
      "        [1.1817],\n",
      "        [1.1797],\n",
      "        [1.1797],\n",
      "        [1.1603],\n",
      "        [1.2006],\n",
      "        [1.2045],\n",
      "        [1.1719],\n",
      "        [1.1573],\n",
      "        [1.1917],\n",
      "        [1.1494],\n",
      "        [1.1713],\n",
      "        [1.2063],\n",
      "        [1.2106],\n",
      "        [1.1644],\n",
      "        [1.1381],\n",
      "        [1.1709],\n",
      "        [1.1841],\n",
      "        [1.2084],\n",
      "        [1.1709],\n",
      "        [1.2044],\n",
      "        [1.1998],\n",
      "        [1.1819],\n",
      "        [1.1789],\n",
      "        [1.1908],\n",
      "        [1.1837],\n",
      "        [1.1273],\n",
      "        [1.1724],\n",
      "        [1.1516],\n",
      "        [1.2052],\n",
      "        [1.2084],\n",
      "        [1.1602],\n",
      "        [1.1853],\n",
      "        [1.2029],\n",
      "        [1.2074],\n",
      "        [1.1755],\n",
      "        [1.1858],\n",
      "        [1.1473],\n",
      "        [1.1689],\n",
      "        [1.1955],\n",
      "        [1.1451],\n",
      "        [1.1824],\n",
      "        [1.1746],\n",
      "        [1.1902],\n",
      "        [1.1907],\n",
      "        [1.2025],\n",
      "        [1.1815],\n",
      "        [1.1984],\n",
      "        [1.1615],\n",
      "        [1.1396],\n",
      "        [1.1961],\n",
      "        [1.1666],\n",
      "        [1.1893],\n",
      "        [1.1637],\n",
      "        [1.1225],\n",
      "        [1.2059],\n",
      "        [1.1837],\n",
      "        [1.1386],\n",
      "        [1.1496],\n",
      "        [1.1265],\n",
      "        [1.1881],\n",
      "        [1.1806],\n",
      "        [1.1791],\n",
      "        [1.1832],\n",
      "        [1.1807],\n",
      "        [1.1665],\n",
      "        [1.1337],\n",
      "        [1.2108],\n",
      "        [1.1693],\n",
      "        [1.1973],\n",
      "        [1.1724],\n",
      "        [1.2768],\n",
      "        [1.2034],\n",
      "        [1.1360],\n",
      "        [1.1668]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2010],\n",
      "        [1.2150],\n",
      "        [1.1861],\n",
      "        [1.1297],\n",
      "        [1.1405],\n",
      "        [1.1850],\n",
      "        [1.2078],\n",
      "        [1.1973],\n",
      "        [1.1833],\n",
      "        [1.2165],\n",
      "        [1.1480],\n",
      "        [1.1804],\n",
      "        [1.2000],\n",
      "        [1.2029],\n",
      "        [1.2110],\n",
      "        [1.2091],\n",
      "        [1.1697],\n",
      "        [1.1712],\n",
      "        [1.2031],\n",
      "        [1.2134],\n",
      "        [1.1840],\n",
      "        [1.1972],\n",
      "        [1.1598],\n",
      "        [1.2013],\n",
      "        [1.1447],\n",
      "        [1.2081],\n",
      "        [1.1852],\n",
      "        [1.1565],\n",
      "        [1.1698],\n",
      "        [1.1889],\n",
      "        [1.1822],\n",
      "        [1.2033],\n",
      "        [1.2130],\n",
      "        [1.1713],\n",
      "        [1.2043],\n",
      "        [1.2012],\n",
      "        [1.1821],\n",
      "        [1.1948],\n",
      "        [1.1330],\n",
      "        [1.2066],\n",
      "        [1.1658],\n",
      "        [1.1606],\n",
      "        [1.1694],\n",
      "        [1.1968],\n",
      "        [1.2089],\n",
      "        [1.1722],\n",
      "        [1.1133],\n",
      "        [1.1846],\n",
      "        [1.2067],\n",
      "        [1.1856],\n",
      "        [1.1808],\n",
      "        [1.1580],\n",
      "        [1.2137],\n",
      "        [1.1966],\n",
      "        [1.2194],\n",
      "        [1.1712],\n",
      "        [1.2142],\n",
      "        [1.1654],\n",
      "        [1.1880],\n",
      "        [1.1495],\n",
      "        [1.1827],\n",
      "        [1.1952],\n",
      "        [1.1761],\n",
      "        [1.1806],\n",
      "        [1.1976],\n",
      "        [1.1817],\n",
      "        [1.1909],\n",
      "        [1.1942],\n",
      "        [0.1429],\n",
      "        [1.2061],\n",
      "        [1.1768],\n",
      "        [1.1732],\n",
      "        [1.1375],\n",
      "        [1.1975],\n",
      "        [1.2005],\n",
      "        [1.1805],\n",
      "        [1.1913],\n",
      "        [1.1911],\n",
      "        [1.2182],\n",
      "        [1.2083],\n",
      "        [1.2099],\n",
      "        [1.1640],\n",
      "        [1.2109],\n",
      "        [1.1848],\n",
      "        [1.2025],\n",
      "        [1.1782],\n",
      "        [1.1943],\n",
      "        [1.2048],\n",
      "        [1.2049],\n",
      "        [1.2016],\n",
      "        [1.1596],\n",
      "        [1.1788],\n",
      "        [1.1782],\n",
      "        [1.1757],\n",
      "        [1.1844],\n",
      "        [1.2037],\n",
      "        [1.1189],\n",
      "        [1.2137],\n",
      "        [1.1766],\n",
      "        [1.1944],\n",
      "        [1.1850],\n",
      "        [1.2163],\n",
      "        [1.1774],\n",
      "        [1.1725],\n",
      "        [1.2120],\n",
      "        [1.2124],\n",
      "        [1.2045],\n",
      "        [1.2081],\n",
      "        [1.1983],\n",
      "        [1.1893],\n",
      "        [1.1643],\n",
      "        [1.2062],\n",
      "        [1.1952],\n",
      "        [1.1970],\n",
      "        [1.1193],\n",
      "        [1.1682],\n",
      "        [1.1472],\n",
      "        [1.1914],\n",
      "        [1.2082],\n",
      "        [1.1704],\n",
      "        [1.2038],\n",
      "        [1.1680],\n",
      "        [1.1846],\n",
      "        [1.1994],\n",
      "        [1.1994],\n",
      "        [1.1477],\n",
      "        [1.1865],\n",
      "        [1.1651]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1918],\n",
      "        [1.2123],\n",
      "        [1.1845],\n",
      "        [1.2207],\n",
      "        [1.2137],\n",
      "        [1.1900],\n",
      "        [1.1751],\n",
      "        [1.1642],\n",
      "        [1.2050],\n",
      "        [1.1923],\n",
      "        [1.2194],\n",
      "        [1.2100],\n",
      "        [1.2204],\n",
      "        [1.1814],\n",
      "        [1.1911],\n",
      "        [1.1807],\n",
      "        [1.2148],\n",
      "        [1.2033],\n",
      "        [1.1485],\n",
      "        [1.2202],\n",
      "        [1.1277],\n",
      "        [1.1684],\n",
      "        [1.1821],\n",
      "        [1.1860],\n",
      "        [1.2003],\n",
      "        [1.2221],\n",
      "        [1.2087],\n",
      "        [1.1725],\n",
      "        [1.1951],\n",
      "        [1.2185],\n",
      "        [1.2060],\n",
      "        [1.1884],\n",
      "        [1.1793],\n",
      "        [1.1978],\n",
      "        [1.1548],\n",
      "        [1.2036],\n",
      "        [1.1948],\n",
      "        [1.2113],\n",
      "        [1.1835],\n",
      "        [1.2168],\n",
      "        [1.1624],\n",
      "        [1.1897],\n",
      "        [1.2098],\n",
      "        [1.1813],\n",
      "        [1.2261],\n",
      "        [1.2166],\n",
      "        [1.1678],\n",
      "        [1.1809],\n",
      "        [1.2169],\n",
      "        [1.1889],\n",
      "        [1.2016],\n",
      "        [1.1467],\n",
      "        [1.1858],\n",
      "        [1.2015],\n",
      "        [1.1690],\n",
      "        [1.1683],\n",
      "        [1.2023],\n",
      "        [1.2239],\n",
      "        [1.2084],\n",
      "        [1.1610],\n",
      "        [1.1882],\n",
      "        [1.1781],\n",
      "        [1.1592],\n",
      "        [1.1461],\n",
      "        [1.1685],\n",
      "        [1.1341],\n",
      "        [1.1895],\n",
      "        [1.2145],\n",
      "        [1.1638],\n",
      "        [1.2028],\n",
      "        [1.2215],\n",
      "        [1.1511],\n",
      "        [1.2053],\n",
      "        [1.2228],\n",
      "        [1.2165],\n",
      "        [1.1898],\n",
      "        [1.1623],\n",
      "        [1.1736],\n",
      "        [1.1848],\n",
      "        [1.2117],\n",
      "        [1.1442],\n",
      "        [1.1993],\n",
      "        [1.2105],\n",
      "        [1.1802],\n",
      "        [1.1943],\n",
      "        [1.2023],\n",
      "        [1.1826],\n",
      "        [1.1989],\n",
      "        [1.1497],\n",
      "        [1.1843],\n",
      "        [1.2175],\n",
      "        [1.2222],\n",
      "        [1.1656],\n",
      "        [1.2052],\n",
      "        [1.1677],\n",
      "        [1.2002],\n",
      "        [1.1140],\n",
      "        [1.2129],\n",
      "        [1.2262],\n",
      "        [1.1585],\n",
      "        [1.1802],\n",
      "        [1.1907],\n",
      "        [1.1535],\n",
      "        [1.2077],\n",
      "        [1.1255],\n",
      "        [1.1547],\n",
      "        [1.2008],\n",
      "        [1.1675],\n",
      "        [1.2066],\n",
      "        [1.2167],\n",
      "        [1.2102],\n",
      "        [1.2152],\n",
      "        [1.1875],\n",
      "        [1.2036],\n",
      "        [1.2076],\n",
      "        [1.2037],\n",
      "        [1.2073],\n",
      "        [1.2161],\n",
      "        [1.2043],\n",
      "        [1.2212],\n",
      "        [1.2127],\n",
      "        [1.2195],\n",
      "        [1.1200],\n",
      "        [1.2116],\n",
      "        [1.1570],\n",
      "        [1.1806],\n",
      "        [1.2083],\n",
      "        [1.2058]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2032],\n",
      "        [1.2033],\n",
      "        [1.1856],\n",
      "        [1.1816],\n",
      "        [1.2149],\n",
      "        [1.2120],\n",
      "        [1.1971],\n",
      "        [1.2171],\n",
      "        [1.2273],\n",
      "        [1.2128],\n",
      "        [1.2016],\n",
      "        [1.2296],\n",
      "        [1.1817],\n",
      "        [1.2194],\n",
      "        [1.1982],\n",
      "        [1.1975],\n",
      "        [1.1824],\n",
      "        [1.1976],\n",
      "        [1.1481],\n",
      "        [1.2013],\n",
      "        [1.1923],\n",
      "        [1.1759],\n",
      "        [1.2063],\n",
      "        [1.2180],\n",
      "        [1.2115],\n",
      "        [1.1817],\n",
      "        [1.1712],\n",
      "        [1.1771],\n",
      "        [1.2194],\n",
      "        [1.2022],\n",
      "        [1.2060],\n",
      "        [1.2010],\n",
      "        [1.2311],\n",
      "        [1.1973],\n",
      "        [1.1711],\n",
      "        [1.2304],\n",
      "        [1.1913],\n",
      "        [1.1682],\n",
      "        [1.2093],\n",
      "        [1.1888],\n",
      "        [1.1753],\n",
      "        [1.2171],\n",
      "        [1.2183],\n",
      "        [1.1563],\n",
      "        [1.1917],\n",
      "        [1.1874],\n",
      "        [1.2127],\n",
      "        [1.2181],\n",
      "        [1.2291],\n",
      "        [1.2181],\n",
      "        [1.1759],\n",
      "        [1.1666],\n",
      "        [1.1881],\n",
      "        [1.1980],\n",
      "        [1.2033],\n",
      "        [1.1902],\n",
      "        [1.1929],\n",
      "        [1.1031],\n",
      "        [1.2213],\n",
      "        [1.1882],\n",
      "        [1.2038],\n",
      "        [1.2141],\n",
      "        [1.2199],\n",
      "        [1.1836],\n",
      "        [1.2123],\n",
      "        [1.1940],\n",
      "        [1.1976],\n",
      "        [1.2106],\n",
      "        [1.2203],\n",
      "        [1.2132],\n",
      "        [1.1614],\n",
      "        [1.1996],\n",
      "        [1.1931],\n",
      "        [1.2138],\n",
      "        [1.2045],\n",
      "        [1.1695],\n",
      "        [1.1932],\n",
      "        [1.2253],\n",
      "        [1.2271],\n",
      "        [1.1872],\n",
      "        [1.2227],\n",
      "        [1.1784],\n",
      "        [1.2104],\n",
      "        [1.1942],\n",
      "        [1.1726],\n",
      "        [1.2126],\n",
      "        [1.2279],\n",
      "        [1.1206],\n",
      "        [1.2214],\n",
      "        [1.2170],\n",
      "        [1.1987],\n",
      "        [1.2023],\n",
      "        [1.1576],\n",
      "        [1.2034],\n",
      "        [1.1964],\n",
      "        [1.2020],\n",
      "        [1.1708],\n",
      "        [1.1964],\n",
      "        [1.2022],\n",
      "        [1.1809],\n",
      "        [1.1536],\n",
      "        [1.1706],\n",
      "        [1.1717],\n",
      "        [1.2059],\n",
      "        [1.2247],\n",
      "        [1.2287],\n",
      "        [1.1571],\n",
      "        [1.2151],\n",
      "        [1.1671],\n",
      "        [1.1787],\n",
      "        [1.1934],\n",
      "        [1.1626],\n",
      "        [1.2091],\n",
      "        [1.2139],\n",
      "        [1.2199],\n",
      "        [1.2347],\n",
      "        [1.2230],\n",
      "        [1.2196],\n",
      "        [1.2281],\n",
      "        [1.2286],\n",
      "        [1.2312],\n",
      "        [1.1871],\n",
      "        [1.1985],\n",
      "        [1.1838],\n",
      "        [1.2155],\n",
      "        [1.1887],\n",
      "        [1.2035],\n",
      "        [1.1934]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2078],\n",
      "        [1.1788],\n",
      "        [1.1848],\n",
      "        [1.1240]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  28 | lr 0.00100 train_loss 2.13210 | val_loss 2.27372 | val_rmse 1.50789\n",
      "tensor([[1.2125],\n",
      "        [1.2016],\n",
      "        [1.1800],\n",
      "        [1.1841],\n",
      "        [1.1355],\n",
      "        [1.2074],\n",
      "        [1.1913],\n",
      "        [1.1932],\n",
      "        [1.2259],\n",
      "        [1.1927],\n",
      "        [1.2228],\n",
      "        [1.1776],\n",
      "        [1.2111],\n",
      "        [1.1981],\n",
      "        [1.1231],\n",
      "        [1.2102],\n",
      "        [1.1652],\n",
      "        [1.1796],\n",
      "        [1.2183],\n",
      "        [1.2009],\n",
      "        [1.2262],\n",
      "        [1.1606],\n",
      "        [1.2153],\n",
      "        [1.1953],\n",
      "        [1.2184],\n",
      "        [1.2292],\n",
      "        [1.1994],\n",
      "        [1.1785],\n",
      "        [1.2015],\n",
      "        [1.1313],\n",
      "        [1.1808],\n",
      "        [1.2108],\n",
      "        [1.2108],\n",
      "        [1.1812],\n",
      "        [1.2108],\n",
      "        [1.1794],\n",
      "        [1.1416],\n",
      "        [1.1839],\n",
      "        [1.1949],\n",
      "        [1.2264],\n",
      "        [1.2080],\n",
      "        [1.1957],\n",
      "        [1.1688],\n",
      "        [1.2017],\n",
      "        [1.2231],\n",
      "        [1.2302],\n",
      "        [1.2212],\n",
      "        [1.1953],\n",
      "        [1.2253],\n",
      "        [1.2245],\n",
      "        [1.2207],\n",
      "        [1.1858],\n",
      "        [1.1832],\n",
      "        [1.2041],\n",
      "        [1.2001],\n",
      "        [1.1918],\n",
      "        [1.1876],\n",
      "        [1.2102],\n",
      "        [1.1815],\n",
      "        [1.2199],\n",
      "        [1.1332],\n",
      "        [1.2091],\n",
      "        [1.2065],\n",
      "        [1.1903],\n",
      "        [1.1620],\n",
      "        [1.1694],\n",
      "        [1.1793],\n",
      "        [1.2228],\n",
      "        [1.2049],\n",
      "        [1.1438],\n",
      "        [1.2178],\n",
      "        [1.1606],\n",
      "        [1.2017],\n",
      "        [1.2142],\n",
      "        [1.1938],\n",
      "        [1.2063],\n",
      "        [1.2187],\n",
      "        [1.1791],\n",
      "        [1.1947],\n",
      "        [1.1935],\n",
      "        [1.1731],\n",
      "        [1.2158],\n",
      "        [1.1914],\n",
      "        [1.1910],\n",
      "        [1.2085],\n",
      "        [1.1970],\n",
      "        [1.2036],\n",
      "        [1.2027],\n",
      "        [1.2039],\n",
      "        [1.1915],\n",
      "        [1.1963],\n",
      "        [1.1942],\n",
      "        [1.2152],\n",
      "        [1.1897],\n",
      "        [1.1777],\n",
      "        [1.1463],\n",
      "        [1.1703],\n",
      "        [1.2284],\n",
      "        [1.1999],\n",
      "        [1.1771],\n",
      "        [1.1728],\n",
      "        [1.2085],\n",
      "        [1.1799],\n",
      "        [1.2224],\n",
      "        [1.1730],\n",
      "        [1.2158],\n",
      "        [1.2182],\n",
      "        [1.1843],\n",
      "        [1.2014],\n",
      "        [1.1617],\n",
      "        [1.1583],\n",
      "        [1.2042],\n",
      "        [1.2062],\n",
      "        [1.2141],\n",
      "        [1.2119],\n",
      "        [1.2108],\n",
      "        [1.2279],\n",
      "        [1.2122],\n",
      "        [1.1879],\n",
      "        [1.2220],\n",
      "        [1.1737],\n",
      "        [1.2275],\n",
      "        [1.2013],\n",
      "        [1.2000],\n",
      "        [1.1938],\n",
      "        [1.1534],\n",
      "        [1.2042],\n",
      "        [1.2056]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2132],\n",
      "        [1.1616],\n",
      "        [1.1829],\n",
      "        [1.2216],\n",
      "        [1.1810],\n",
      "        [1.2233],\n",
      "        [1.1450],\n",
      "        [1.2015],\n",
      "        [1.2232],\n",
      "        [1.2016],\n",
      "        [1.2058],\n",
      "        [1.2231],\n",
      "        [1.1668],\n",
      "        [1.1881],\n",
      "        [1.1878],\n",
      "        [1.2187],\n",
      "        [1.1880],\n",
      "        [1.1877],\n",
      "        [1.1404],\n",
      "        [1.1515],\n",
      "        [1.1975],\n",
      "        [1.2176],\n",
      "        [1.2031],\n",
      "        [1.2181],\n",
      "        [1.2103],\n",
      "        [1.2077],\n",
      "        [1.2102],\n",
      "        [1.1538],\n",
      "        [1.1791],\n",
      "        [1.1855],\n",
      "        [1.2063],\n",
      "        [1.2103],\n",
      "        [1.2214],\n",
      "        [1.1977],\n",
      "        [1.1772],\n",
      "        [1.1694],\n",
      "        [1.1863],\n",
      "        [1.1598],\n",
      "        [1.1728],\n",
      "        [1.2116],\n",
      "        [1.1465],\n",
      "        [1.1595],\n",
      "        [1.2066],\n",
      "        [1.2035],\n",
      "        [1.1884],\n",
      "        [1.1922],\n",
      "        [1.1686],\n",
      "        [1.1825],\n",
      "        [1.2247],\n",
      "        [1.2231],\n",
      "        [1.2080],\n",
      "        [1.2102],\n",
      "        [1.2034],\n",
      "        [1.1847],\n",
      "        [1.2134],\n",
      "        [1.2221],\n",
      "        [1.2242],\n",
      "        [1.1864],\n",
      "        [1.1959],\n",
      "        [1.2076],\n",
      "        [1.1661],\n",
      "        [1.2003],\n",
      "        [1.1825],\n",
      "        [1.1790],\n",
      "        [1.1419],\n",
      "        [1.1793],\n",
      "        [1.2012],\n",
      "        [1.2022],\n",
      "        [1.2100],\n",
      "        [1.1981],\n",
      "        [1.2051],\n",
      "        [1.1761],\n",
      "        [1.2002],\n",
      "        [1.1659],\n",
      "        [1.1558],\n",
      "        [1.1501],\n",
      "        [1.1837],\n",
      "        [1.1731],\n",
      "        [1.2249],\n",
      "        [1.1439],\n",
      "        [1.1848],\n",
      "        [1.1637],\n",
      "        [1.1515],\n",
      "        [1.2125],\n",
      "        [1.1896],\n",
      "        [1.2025],\n",
      "        [1.2098],\n",
      "        [1.2115],\n",
      "        [1.1727],\n",
      "        [1.1632],\n",
      "        [1.1710],\n",
      "        [1.1574],\n",
      "        [1.2095],\n",
      "        [1.1833],\n",
      "        [1.1944],\n",
      "        [1.2189],\n",
      "        [1.2102],\n",
      "        [1.1870],\n",
      "        [1.2098],\n",
      "        [1.1921],\n",
      "        [1.2015],\n",
      "        [1.1267],\n",
      "        [1.2167],\n",
      "        [1.1820],\n",
      "        [1.1616],\n",
      "        [1.1983],\n",
      "        [1.1835],\n",
      "        [1.1944],\n",
      "        [1.2230],\n",
      "        [1.1879],\n",
      "        [1.1944],\n",
      "        [1.1800],\n",
      "        [1.2129],\n",
      "        [1.1533],\n",
      "        [1.1686],\n",
      "        [1.1817],\n",
      "        [1.2082],\n",
      "        [1.1420],\n",
      "        [1.1927],\n",
      "        [1.1525],\n",
      "        [1.2176],\n",
      "        [1.2226],\n",
      "        [1.1131],\n",
      "        [1.1992],\n",
      "        [1.1865],\n",
      "        [1.1778],\n",
      "        [1.1497],\n",
      "        [1.2142]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2100e+00],\n",
      "        [1.1798e+00],\n",
      "        [1.1929e+00],\n",
      "        [1.1353e+00],\n",
      "        [1.1841e+00],\n",
      "        [1.2176e+00],\n",
      "        [1.2085e+00],\n",
      "        [1.1748e+00],\n",
      "        [1.1707e+00],\n",
      "        [1.1918e+00],\n",
      "        [1.1844e+00],\n",
      "        [1.2140e+00],\n",
      "        [1.2066e+00],\n",
      "        [1.2144e+00],\n",
      "        [1.1887e+00],\n",
      "        [1.1829e+00],\n",
      "        [1.2129e+00],\n",
      "        [1.1966e+00],\n",
      "        [1.2152e+00],\n",
      "        [1.2033e+00],\n",
      "        [1.2050e+00],\n",
      "        [1.1822e+00],\n",
      "        [1.2086e+00],\n",
      "        [1.2170e+00],\n",
      "        [1.2165e+00],\n",
      "        [1.1939e+00],\n",
      "        [1.1674e+00],\n",
      "        [1.1924e+00],\n",
      "        [1.1976e+00],\n",
      "        [1.1943e+00],\n",
      "        [1.2149e+00],\n",
      "        [1.1795e+00],\n",
      "        [1.1874e+00],\n",
      "        [1.1688e+00],\n",
      "        [1.1627e+00],\n",
      "        [1.1940e+00],\n",
      "        [1.1731e+00],\n",
      "        [1.1978e+00],\n",
      "        [1.2190e+00],\n",
      "        [1.1819e+00],\n",
      "        [1.2002e+00],\n",
      "        [1.1679e+00],\n",
      "        [1.2170e+00],\n",
      "        [1.1769e+00],\n",
      "        [1.1743e+00],\n",
      "        [1.2016e+00],\n",
      "        [1.1615e+00],\n",
      "        [1.2066e+00],\n",
      "        [1.1832e+00],\n",
      "        [1.1616e+00],\n",
      "        [1.1684e+00],\n",
      "        [1.1472e+00],\n",
      "        [1.2046e+00],\n",
      "        [1.1898e+00],\n",
      "        [1.2109e+00],\n",
      "        [1.2162e+00],\n",
      "        [1.1595e+00],\n",
      "        [1.1773e+00],\n",
      "        [1.1936e+00],\n",
      "        [1.1760e+00],\n",
      "        [1.2065e+00],\n",
      "        [1.2151e+00],\n",
      "        [1.1720e+00],\n",
      "        [1.1807e+00],\n",
      "        [1.1400e+00],\n",
      "        [1.1763e+00],\n",
      "        [1.2135e+00],\n",
      "        [1.2159e+00],\n",
      "        [1.2087e+00],\n",
      "        [1.1676e+00],\n",
      "        [1.2168e+00],\n",
      "        [1.2000e+00],\n",
      "        [1.2091e+00],\n",
      "        [1.1309e+00],\n",
      "        [1.2190e+00],\n",
      "        [1.2048e+00],\n",
      "        [1.2138e+00],\n",
      "        [1.1971e+00],\n",
      "        [1.2083e+00],\n",
      "        [1.1684e+00],\n",
      "        [1.1769e+00],\n",
      "        [1.1952e+00],\n",
      "        [1.1700e+00],\n",
      "        [1.1932e+00],\n",
      "        [1.2129e+00],\n",
      "        [1.2051e+00],\n",
      "        [1.2160e+00],\n",
      "        [1.1800e+00],\n",
      "        [1.1906e+00],\n",
      "        [1.1827e+00],\n",
      "        [1.1953e+00],\n",
      "        [1.1466e+00],\n",
      "        [1.1363e+00],\n",
      "        [1.1761e+00],\n",
      "        [1.2078e+00],\n",
      "        [1.2175e+00],\n",
      "        [1.1840e+00],\n",
      "        [1.1751e+00],\n",
      "        [1.2066e+00],\n",
      "        [1.2157e+00],\n",
      "        [1.2168e+00],\n",
      "        [1.1653e+00],\n",
      "        [1.1689e+00],\n",
      "        [1.1941e+00],\n",
      "        [1.1958e+00],\n",
      "        [1.1687e+00],\n",
      "        [1.1547e+00],\n",
      "        [1.1895e+00],\n",
      "        [8.4925e-05],\n",
      "        [1.2010e+00],\n",
      "        [1.1491e+00],\n",
      "        [1.1428e+00],\n",
      "        [1.1984e+00],\n",
      "        [1.1660e+00],\n",
      "        [1.2076e+00],\n",
      "        [1.2190e+00],\n",
      "        [1.1939e+00],\n",
      "        [1.1960e+00],\n",
      "        [1.1877e+00],\n",
      "        [1.1744e+00],\n",
      "        [1.1958e+00],\n",
      "        [1.1940e+00],\n",
      "        [1.2014e+00],\n",
      "        [1.2183e+00],\n",
      "        [1.1882e+00],\n",
      "        [1.1593e+00],\n",
      "        [1.1902e+00],\n",
      "        [1.1942e+00]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1988],\n",
      "        [1.1974],\n",
      "        [1.1758],\n",
      "        [1.1690],\n",
      "        [1.1772],\n",
      "        [1.1312],\n",
      "        [1.1768],\n",
      "        [1.1890],\n",
      "        [1.1588],\n",
      "        [1.1545],\n",
      "        [1.1827],\n",
      "        [1.1745],\n",
      "        [1.2010],\n",
      "        [1.1124],\n",
      "        [1.1690],\n",
      "        [1.2027],\n",
      "        [1.1887],\n",
      "        [1.1478],\n",
      "        [1.1555],\n",
      "        [1.2101],\n",
      "        [1.1678],\n",
      "        [1.1861],\n",
      "        [1.1527],\n",
      "        [1.1663],\n",
      "        [1.1776],\n",
      "        [1.1816],\n",
      "        [1.1478],\n",
      "        [1.1894],\n",
      "        [1.1995],\n",
      "        [1.1981],\n",
      "        [1.1789],\n",
      "        [1.1973],\n",
      "        [1.1796],\n",
      "        [1.1953],\n",
      "        [1.1490],\n",
      "        [1.1945],\n",
      "        [1.1734],\n",
      "        [1.1588],\n",
      "        [1.1609],\n",
      "        [1.1457],\n",
      "        [1.2130],\n",
      "        [1.1961],\n",
      "        [1.2033],\n",
      "        [1.1583],\n",
      "        [1.1446],\n",
      "        [1.1551],\n",
      "        [1.1781],\n",
      "        [1.1644],\n",
      "        [1.1684],\n",
      "        [1.1825],\n",
      "        [1.1932],\n",
      "        [1.2007],\n",
      "        [1.1626],\n",
      "        [1.2073],\n",
      "        [1.2076],\n",
      "        [1.1268],\n",
      "        [1.1768],\n",
      "        [1.1902],\n",
      "        [1.1874],\n",
      "        [1.1747],\n",
      "        [1.1732],\n",
      "        [1.1673],\n",
      "        [1.1759],\n",
      "        [1.1655],\n",
      "        [1.2029],\n",
      "        [1.2111],\n",
      "        [1.1473],\n",
      "        [1.2067],\n",
      "        [1.1700],\n",
      "        [1.1654],\n",
      "        [1.1176],\n",
      "        [1.1889],\n",
      "        [1.1556],\n",
      "        [1.1719],\n",
      "        [1.1666],\n",
      "        [1.1484],\n",
      "        [1.1428],\n",
      "        [1.1947],\n",
      "        [1.1771],\n",
      "        [1.1879],\n",
      "        [1.1870],\n",
      "        [1.2102],\n",
      "        [1.1975],\n",
      "        [1.1957],\n",
      "        [1.1772],\n",
      "        [1.2055],\n",
      "        [1.1777],\n",
      "        [1.1543],\n",
      "        [1.1606],\n",
      "        [1.1705],\n",
      "        [1.2007],\n",
      "        [1.2086],\n",
      "        [1.1861],\n",
      "        [1.1998],\n",
      "        [1.1963],\n",
      "        [1.1487],\n",
      "        [0.0954],\n",
      "        [1.1249],\n",
      "        [1.1727],\n",
      "        [1.1950],\n",
      "        [1.1419],\n",
      "        [1.1612],\n",
      "        [1.1900],\n",
      "        [1.1242],\n",
      "        [1.1909],\n",
      "        [1.1669],\n",
      "        [1.1557],\n",
      "        [1.1824],\n",
      "        [1.1611],\n",
      "        [1.1617],\n",
      "        [1.1662],\n",
      "        [1.1514],\n",
      "        [1.2002],\n",
      "        [1.1740],\n",
      "        [1.1899],\n",
      "        [1.1720],\n",
      "        [1.1360],\n",
      "        [1.1459],\n",
      "        [1.1859],\n",
      "        [1.1719],\n",
      "        [1.1312],\n",
      "        [1.1888],\n",
      "        [1.2069],\n",
      "        [1.1653],\n",
      "        [1.1844],\n",
      "        [1.1615],\n",
      "        [1.1659],\n",
      "        [1.1392]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1211],\n",
      "        [1.2073],\n",
      "        [1.1940],\n",
      "        [1.1620],\n",
      "        [1.1627],\n",
      "        [1.1851],\n",
      "        [1.2035],\n",
      "        [1.1732],\n",
      "        [1.1885],\n",
      "        [1.1844],\n",
      "        [1.1366],\n",
      "        [1.1670],\n",
      "        [1.1851],\n",
      "        [1.1749],\n",
      "        [1.1376],\n",
      "        [1.1875],\n",
      "        [1.1884],\n",
      "        [1.1929],\n",
      "        [1.1675],\n",
      "        [1.1554],\n",
      "        [1.1824],\n",
      "        [1.1868],\n",
      "        [1.2050],\n",
      "        [1.1917],\n",
      "        [1.1246],\n",
      "        [1.1977],\n",
      "        [1.1704],\n",
      "        [1.1851],\n",
      "        [1.1902],\n",
      "        [1.1665],\n",
      "        [1.1799],\n",
      "        [1.1538],\n",
      "        [1.1488],\n",
      "        [1.1570],\n",
      "        [1.1822],\n",
      "        [1.1464],\n",
      "        [1.1789],\n",
      "        [1.1480],\n",
      "        [1.2046],\n",
      "        [1.1745],\n",
      "        [1.1418],\n",
      "        [1.1808],\n",
      "        [1.1581],\n",
      "        [1.1564],\n",
      "        [1.1905],\n",
      "        [1.1973],\n",
      "        [1.1597],\n",
      "        [1.1495],\n",
      "        [1.2014],\n",
      "        [1.1816],\n",
      "        [1.1710],\n",
      "        [1.1255],\n",
      "        [1.1742],\n",
      "        [1.1803],\n",
      "        [1.1695],\n",
      "        [1.1244],\n",
      "        [1.1829],\n",
      "        [1.1660],\n",
      "        [1.1845],\n",
      "        [1.1073],\n",
      "        [1.1929],\n",
      "        [1.1695],\n",
      "        [1.2002],\n",
      "        [1.1680],\n",
      "        [1.1862],\n",
      "        [1.1796],\n",
      "        [1.1855],\n",
      "        [1.1445],\n",
      "        [1.1274],\n",
      "        [1.2030],\n",
      "        [1.1854],\n",
      "        [1.1896],\n",
      "        [1.1670],\n",
      "        [1.1597],\n",
      "        [1.1939],\n",
      "        [1.2029],\n",
      "        [1.1679],\n",
      "        [1.1800],\n",
      "        [1.1586],\n",
      "        [1.1815],\n",
      "        [1.2013],\n",
      "        [1.1944],\n",
      "        [1.1877],\n",
      "        [1.1690],\n",
      "        [1.1789],\n",
      "        [1.2059],\n",
      "        [1.1500],\n",
      "        [1.1362],\n",
      "        [1.2001],\n",
      "        [1.1216],\n",
      "        [1.1389],\n",
      "        [1.1755],\n",
      "        [1.1395],\n",
      "        [1.1664],\n",
      "        [1.1903],\n",
      "        [1.1605],\n",
      "        [1.1639],\n",
      "        [1.1777],\n",
      "        [1.1536],\n",
      "        [1.1950],\n",
      "        [1.2001],\n",
      "        [1.1502],\n",
      "        [1.2000],\n",
      "        [1.1452],\n",
      "        [1.2056],\n",
      "        [1.1767],\n",
      "        [1.1389],\n",
      "        [1.1722],\n",
      "        [1.1590],\n",
      "        [1.1282],\n",
      "        [1.1788],\n",
      "        [1.1682],\n",
      "        [1.1274],\n",
      "        [1.1341],\n",
      "        [1.2061],\n",
      "        [1.1353],\n",
      "        [1.1851],\n",
      "        [1.1622],\n",
      "        [1.1454],\n",
      "        [1.1957],\n",
      "        [1.2027],\n",
      "        [1.2030],\n",
      "        [1.1545],\n",
      "        [1.1766],\n",
      "        [1.1456],\n",
      "        [1.2041],\n",
      "        [1.1465],\n",
      "        [1.1802]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1751],\n",
      "        [1.1758],\n",
      "        [1.1673],\n",
      "        [1.1817],\n",
      "        [1.1800],\n",
      "        [1.1322],\n",
      "        [1.1744],\n",
      "        [1.1661],\n",
      "        [1.1561],\n",
      "        [1.1554],\n",
      "        [1.1754],\n",
      "        [1.1544],\n",
      "        [1.1701],\n",
      "        [1.1906],\n",
      "        [1.1071],\n",
      "        [1.1201],\n",
      "        [1.1618],\n",
      "        [1.1735],\n",
      "        [1.1901],\n",
      "        [1.1611],\n",
      "        [1.1579],\n",
      "        [1.1798],\n",
      "        [1.1672],\n",
      "        [1.1612],\n",
      "        [1.0977],\n",
      "        [1.1953],\n",
      "        [1.1508],\n",
      "        [1.1751],\n",
      "        [1.1606],\n",
      "        [1.1144],\n",
      "        [1.1816],\n",
      "        [1.1794],\n",
      "        [1.1716],\n",
      "        [1.1471],\n",
      "        [1.1316],\n",
      "        [1.1859],\n",
      "        [1.1852],\n",
      "        [1.1815],\n",
      "        [1.1626],\n",
      "        [1.1665],\n",
      "        [1.1684],\n",
      "        [1.1743],\n",
      "        [1.1424],\n",
      "        [1.1297],\n",
      "        [1.1764],\n",
      "        [1.1862],\n",
      "        [1.1683],\n",
      "        [1.1600],\n",
      "        [1.1463],\n",
      "        [1.1816],\n",
      "        [1.1476],\n",
      "        [1.1784],\n",
      "        [1.1860],\n",
      "        [1.1843],\n",
      "        [1.1692],\n",
      "        [1.1533],\n",
      "        [1.1921],\n",
      "        [1.1704],\n",
      "        [1.1894],\n",
      "        [1.1165],\n",
      "        [1.1838],\n",
      "        [1.1740],\n",
      "        [1.1635],\n",
      "        [1.1402],\n",
      "        [1.1738],\n",
      "        [1.1856],\n",
      "        [1.1963],\n",
      "        [1.1337],\n",
      "        [1.1590],\n",
      "        [1.1686],\n",
      "        [1.1591],\n",
      "        [1.1606],\n",
      "        [1.1998],\n",
      "        [1.1423],\n",
      "        [1.1650],\n",
      "        [1.1732],\n",
      "        [1.1310],\n",
      "        [1.1831],\n",
      "        [1.1563],\n",
      "        [1.1660],\n",
      "        [1.1842],\n",
      "        [1.1416],\n",
      "        [1.1902],\n",
      "        [1.1909],\n",
      "        [1.1833],\n",
      "        [1.1209],\n",
      "        [1.1817],\n",
      "        [1.1647],\n",
      "        [1.1893],\n",
      "        [1.1964],\n",
      "        [1.1781],\n",
      "        [1.1505],\n",
      "        [1.1990],\n",
      "        [1.1669],\n",
      "        [1.1837],\n",
      "        [1.1676],\n",
      "        [1.1498],\n",
      "        [1.1472],\n",
      "        [1.1621],\n",
      "        [1.1933],\n",
      "        [1.1604],\n",
      "        [1.1614],\n",
      "        [1.1663],\n",
      "        [1.1987],\n",
      "        [1.1864],\n",
      "        [1.1444],\n",
      "        [1.1525],\n",
      "        [1.1907],\n",
      "        [1.2001],\n",
      "        [1.1570],\n",
      "        [1.1271],\n",
      "        [1.1977],\n",
      "        [1.1897],\n",
      "        [1.1663],\n",
      "        [1.1692],\n",
      "        [1.1909],\n",
      "        [1.1847],\n",
      "        [1.1593],\n",
      "        [1.1546],\n",
      "        [1.1873],\n",
      "        [1.1488],\n",
      "        [1.1851],\n",
      "        [1.1824],\n",
      "        [1.1471],\n",
      "        [1.1538],\n",
      "        [1.1919],\n",
      "        [1.1632],\n",
      "        [1.1884]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1676],\n",
      "        [1.1082],\n",
      "        [1.1950],\n",
      "        [1.1830],\n",
      "        [1.1503],\n",
      "        [1.1885],\n",
      "        [1.1800],\n",
      "        [1.1528],\n",
      "        [1.1612],\n",
      "        [1.1671],\n",
      "        [1.1779],\n",
      "        [1.1948],\n",
      "        [1.1252],\n",
      "        [1.1514],\n",
      "        [1.1560],\n",
      "        [1.1581],\n",
      "        [1.1805],\n",
      "        [1.1537],\n",
      "        [1.1634],\n",
      "        [1.1589],\n",
      "        [1.1748],\n",
      "        [1.1544],\n",
      "        [1.1741],\n",
      "        [1.1229],\n",
      "        [1.1371],\n",
      "        [1.1557],\n",
      "        [1.1940],\n",
      "        [1.1741],\n",
      "        [1.1547],\n",
      "        [1.1422],\n",
      "        [1.1551],\n",
      "        [1.1416],\n",
      "        [1.1839],\n",
      "        [1.1696],\n",
      "        [1.1546],\n",
      "        [1.1511],\n",
      "        [1.1829],\n",
      "        [1.1706],\n",
      "        [1.1860],\n",
      "        [1.1658],\n",
      "        [1.1115],\n",
      "        [1.1578],\n",
      "        [1.1852],\n",
      "        [1.1856],\n",
      "        [1.1408],\n",
      "        [1.1887],\n",
      "        [1.1560],\n",
      "        [1.1218],\n",
      "        [1.1943],\n",
      "        [1.1901],\n",
      "        [1.1593],\n",
      "        [1.1723],\n",
      "        [1.1560],\n",
      "        [1.1873],\n",
      "        [1.1711],\n",
      "        [1.1467],\n",
      "        [1.1063],\n",
      "        [1.1715],\n",
      "        [1.1944],\n",
      "        [1.1624],\n",
      "        [1.1739],\n",
      "        [1.1826],\n",
      "        [1.1888],\n",
      "        [1.1309],\n",
      "        [1.1680],\n",
      "        [1.1787],\n",
      "        [1.1700],\n",
      "        [1.1473],\n",
      "        [1.1861],\n",
      "        [1.1565],\n",
      "        [1.1223],\n",
      "        [1.1593],\n",
      "        [1.1938],\n",
      "        [1.1907],\n",
      "        [1.1789],\n",
      "        [1.1869],\n",
      "        [1.1821],\n",
      "        [1.1756],\n",
      "        [1.1657],\n",
      "        [1.1766],\n",
      "        [1.1750],\n",
      "        [1.1604],\n",
      "        [1.1709],\n",
      "        [1.1655],\n",
      "        [1.1446],\n",
      "        [1.1917],\n",
      "        [1.1836],\n",
      "        [1.1845],\n",
      "        [1.1654],\n",
      "        [1.1942],\n",
      "        [1.1842],\n",
      "        [1.1691],\n",
      "        [1.1289],\n",
      "        [1.1733],\n",
      "        [1.1253],\n",
      "        [1.1765],\n",
      "        [1.1478],\n",
      "        [1.1921],\n",
      "        [1.1953],\n",
      "        [1.1889],\n",
      "        [1.1759],\n",
      "        [1.1751],\n",
      "        [1.1821],\n",
      "        [1.1948],\n",
      "        [1.1556],\n",
      "        [1.1453],\n",
      "        [1.1320],\n",
      "        [1.1766],\n",
      "        [1.1553],\n",
      "        [0.0354],\n",
      "        [1.1878],\n",
      "        [1.1611],\n",
      "        [1.1442],\n",
      "        [1.1651],\n",
      "        [1.1879],\n",
      "        [1.1775],\n",
      "        [1.1821],\n",
      "        [1.1586],\n",
      "        [1.1578],\n",
      "        [1.1173],\n",
      "        [1.1616],\n",
      "        [1.1542],\n",
      "        [1.1876],\n",
      "        [1.1700],\n",
      "        [1.1476],\n",
      "        [1.1663],\n",
      "        [1.1172],\n",
      "        [1.1682]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0869],\n",
      "        [1.1882],\n",
      "        [1.1436],\n",
      "        [1.1822]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  29 | lr 0.00100 train_loss 2.13451 | val_loss 2.27926 | val_rmse 1.50972\n",
      "tensor([[1.1405],\n",
      "        [1.1590],\n",
      "        [1.1316],\n",
      "        [1.1445],\n",
      "        [1.1263],\n",
      "        [1.1535],\n",
      "        [1.1390],\n",
      "        [1.1243],\n",
      "        [1.1777],\n",
      "        [1.1151],\n",
      "        [1.1164],\n",
      "        [1.1646],\n",
      "        [1.1450],\n",
      "        [1.1644],\n",
      "        [1.1745],\n",
      "        [1.1659],\n",
      "        [1.1658],\n",
      "        [1.0974],\n",
      "        [1.1601],\n",
      "        [1.1262],\n",
      "        [1.1666],\n",
      "        [1.1687],\n",
      "        [1.1355],\n",
      "        [1.1461],\n",
      "        [1.1468],\n",
      "        [1.1348],\n",
      "        [1.1690],\n",
      "        [1.1364],\n",
      "        [1.1667],\n",
      "        [1.1216],\n",
      "        [1.1737],\n",
      "        [1.1444],\n",
      "        [1.1448],\n",
      "        [1.1515],\n",
      "        [1.1768],\n",
      "        [1.1422],\n",
      "        [1.1551],\n",
      "        [1.1337],\n",
      "        [1.1580],\n",
      "        [1.0672],\n",
      "        [1.1346],\n",
      "        [1.1284],\n",
      "        [1.1035],\n",
      "        [1.1377],\n",
      "        [1.1786],\n",
      "        [1.0945],\n",
      "        [1.1334],\n",
      "        [1.1408],\n",
      "        [1.1462],\n",
      "        [1.1235],\n",
      "        [1.1206],\n",
      "        [1.1666],\n",
      "        [1.1543],\n",
      "        [1.1501],\n",
      "        [1.1336],\n",
      "        [1.1630],\n",
      "        [1.1330],\n",
      "        [1.1762],\n",
      "        [1.1107],\n",
      "        [1.1205],\n",
      "        [1.1831],\n",
      "        [1.1676],\n",
      "        [1.1675],\n",
      "        [1.1547],\n",
      "        [1.1407],\n",
      "        [1.1345],\n",
      "        [1.1367],\n",
      "        [1.1596],\n",
      "        [1.1265],\n",
      "        [1.1676],\n",
      "        [1.1187],\n",
      "        [1.1695],\n",
      "        [1.1620],\n",
      "        [1.1665],\n",
      "        [1.1227],\n",
      "        [1.1370],\n",
      "        [1.1687],\n",
      "        [1.1462],\n",
      "        [1.1426],\n",
      "        [1.1554],\n",
      "        [1.1444],\n",
      "        [1.1630],\n",
      "        [1.1420],\n",
      "        [1.1533],\n",
      "        [1.1392],\n",
      "        [1.1600],\n",
      "        [1.0867],\n",
      "        [1.1299],\n",
      "        [1.1590],\n",
      "        [1.1675],\n",
      "        [1.1586],\n",
      "        [1.1794],\n",
      "        [1.1455],\n",
      "        [1.1718],\n",
      "        [1.1716],\n",
      "        [1.1449],\n",
      "        [1.1661],\n",
      "        [1.1700],\n",
      "        [1.1675],\n",
      "        [1.1324],\n",
      "        [1.1167],\n",
      "        [1.1664],\n",
      "        [1.1509],\n",
      "        [1.1645],\n",
      "        [1.0909],\n",
      "        [1.1182],\n",
      "        [1.1486],\n",
      "        [1.0819],\n",
      "        [1.1270],\n",
      "        [1.1534],\n",
      "        [1.1803],\n",
      "        [1.1556],\n",
      "        [1.1641],\n",
      "        [1.1732],\n",
      "        [1.1474],\n",
      "        [1.1454],\n",
      "        [1.1621],\n",
      "        [1.1476],\n",
      "        [1.1760],\n",
      "        [1.1772],\n",
      "        [1.0915],\n",
      "        [1.1214],\n",
      "        [1.1648],\n",
      "        [1.1431],\n",
      "        [1.1642],\n",
      "        [1.1804],\n",
      "        [1.1706],\n",
      "        [1.1345]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1678],\n",
      "        [1.1607],\n",
      "        [1.1005],\n",
      "        [1.1332],\n",
      "        [1.1179],\n",
      "        [1.1626],\n",
      "        [1.1505],\n",
      "        [1.1518],\n",
      "        [1.1182],\n",
      "        [1.1061],\n",
      "        [1.1368],\n",
      "        [1.1312],\n",
      "        [1.1606],\n",
      "        [1.1551],\n",
      "        [1.1453],\n",
      "        [1.1565],\n",
      "        [1.1542],\n",
      "        [1.1304],\n",
      "        [1.1245],\n",
      "        [1.1066],\n",
      "        [1.1347],\n",
      "        [1.0763],\n",
      "        [1.1375],\n",
      "        [1.1406],\n",
      "        [1.1327],\n",
      "        [1.1564],\n",
      "        [1.1442],\n",
      "        [1.1611],\n",
      "        [1.1430],\n",
      "        [1.1554],\n",
      "        [1.1060],\n",
      "        [1.1603],\n",
      "        [1.1399],\n",
      "        [1.1555],\n",
      "        [1.1343],\n",
      "        [1.1645],\n",
      "        [1.1503],\n",
      "        [1.1628],\n",
      "        [1.1545],\n",
      "        [1.1479],\n",
      "        [1.1517],\n",
      "        [1.1100],\n",
      "        [1.1459],\n",
      "        [1.1710],\n",
      "        [1.1524],\n",
      "        [1.1624],\n",
      "        [1.1725],\n",
      "        [1.1710],\n",
      "        [1.0777],\n",
      "        [1.1755],\n",
      "        [1.1417],\n",
      "        [1.0883],\n",
      "        [1.1729],\n",
      "        [1.1584],\n",
      "        [1.1527],\n",
      "        [1.1594],\n",
      "        [1.1461],\n",
      "        [1.1704],\n",
      "        [1.1501],\n",
      "        [1.0728],\n",
      "        [1.1723],\n",
      "        [1.1641],\n",
      "        [1.1568],\n",
      "        [1.1638],\n",
      "        [1.1208],\n",
      "        [1.1451],\n",
      "        [1.1477],\n",
      "        [1.1441],\n",
      "        [1.1194],\n",
      "        [1.0950],\n",
      "        [1.1610],\n",
      "        [1.1605],\n",
      "        [1.1239],\n",
      "        [1.1544],\n",
      "        [1.0865],\n",
      "        [1.1303],\n",
      "        [1.1731],\n",
      "        [1.1377],\n",
      "        [1.1725],\n",
      "        [1.1702],\n",
      "        [1.1526],\n",
      "        [1.1631],\n",
      "        [1.1229],\n",
      "        [1.1523],\n",
      "        [1.1621],\n",
      "        [1.1180],\n",
      "        [1.1704],\n",
      "        [1.1668],\n",
      "        [1.1420],\n",
      "        [1.1722],\n",
      "        [1.1637],\n",
      "        [1.1510],\n",
      "        [1.1311],\n",
      "        [1.1340],\n",
      "        [1.1710],\n",
      "        [1.1645],\n",
      "        [1.1526],\n",
      "        [1.1341],\n",
      "        [1.1437],\n",
      "        [1.1286],\n",
      "        [1.1352],\n",
      "        [1.1658],\n",
      "        [1.1438],\n",
      "        [1.1629],\n",
      "        [1.1359],\n",
      "        [1.1534],\n",
      "        [1.1335],\n",
      "        [1.1544],\n",
      "        [1.1235],\n",
      "        [1.1284],\n",
      "        [1.1621],\n",
      "        [1.1592],\n",
      "        [1.1227],\n",
      "        [1.1008],\n",
      "        [1.0571],\n",
      "        [1.1187],\n",
      "        [1.1537],\n",
      "        [1.1366],\n",
      "        [1.1480],\n",
      "        [1.1324],\n",
      "        [1.1525],\n",
      "        [1.1430],\n",
      "        [1.1537],\n",
      "        [1.1126],\n",
      "        [1.1505],\n",
      "        [1.1294],\n",
      "        [1.1520],\n",
      "        [1.1176]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1087],\n",
      "        [1.1283],\n",
      "        [1.1070],\n",
      "        [1.1012],\n",
      "        [1.1266],\n",
      "        [1.1197],\n",
      "        [1.1512],\n",
      "        [1.1246],\n",
      "        [1.1109],\n",
      "        [1.1356],\n",
      "        [1.1056],\n",
      "        [1.0971],\n",
      "        [1.1292],\n",
      "        [1.1537],\n",
      "        [1.1567],\n",
      "        [1.1453],\n",
      "        [1.1264],\n",
      "        [1.1330],\n",
      "        [1.1478],\n",
      "        [1.1401],\n",
      "        [1.1443],\n",
      "        [1.1011],\n",
      "        [1.1081],\n",
      "        [1.0822],\n",
      "        [1.1103],\n",
      "        [1.1133],\n",
      "        [1.1281],\n",
      "        [1.1527],\n",
      "        [1.1606],\n",
      "        [1.1666],\n",
      "        [1.1489],\n",
      "        [1.1180],\n",
      "        [1.1645],\n",
      "        [1.1616],\n",
      "        [1.1277],\n",
      "        [1.1526],\n",
      "        [1.0711],\n",
      "        [1.1506],\n",
      "        [1.1165],\n",
      "        [1.1402],\n",
      "        [1.1214],\n",
      "        [1.1318],\n",
      "        [1.1272],\n",
      "        [1.1036],\n",
      "        [1.1321],\n",
      "        [1.1472],\n",
      "        [1.1645],\n",
      "        [1.1185],\n",
      "        [1.1490],\n",
      "        [1.1406],\n",
      "        [1.1660],\n",
      "        [1.1233],\n",
      "        [1.1229],\n",
      "        [1.1618],\n",
      "        [1.1363],\n",
      "        [1.1339],\n",
      "        [1.1374],\n",
      "        [1.1028],\n",
      "        [1.0691],\n",
      "        [1.1397],\n",
      "        [1.1687],\n",
      "        [1.0898],\n",
      "        [1.1348],\n",
      "        [1.1561],\n",
      "        [1.1290],\n",
      "        [1.1566],\n",
      "        [1.1266],\n",
      "        [1.1324],\n",
      "        [1.1326],\n",
      "        [1.1486],\n",
      "        [1.1566],\n",
      "        [1.1272],\n",
      "        [1.1340],\n",
      "        [1.1623],\n",
      "        [1.0950],\n",
      "        [1.1487],\n",
      "        [1.1473],\n",
      "        [1.1307],\n",
      "        [1.1299],\n",
      "        [1.1610],\n",
      "        [1.1400],\n",
      "        [1.1386],\n",
      "        [1.1219],\n",
      "        [1.1530],\n",
      "        [1.1402],\n",
      "        [1.1452],\n",
      "        [1.1658],\n",
      "        [1.1536],\n",
      "        [1.1614],\n",
      "        [1.1497],\n",
      "        [1.1247],\n",
      "        [1.1435],\n",
      "        [1.1337],\n",
      "        [1.1189],\n",
      "        [1.1431],\n",
      "        [1.1242],\n",
      "        [1.1125],\n",
      "        [1.1522],\n",
      "        [1.1206],\n",
      "        [1.1130],\n",
      "        [1.1455],\n",
      "        [1.1492],\n",
      "        [1.1478],\n",
      "        [1.1248],\n",
      "        [1.1547],\n",
      "        [1.1246],\n",
      "        [1.1274],\n",
      "        [1.1671],\n",
      "        [1.1311],\n",
      "        [1.1601],\n",
      "        [1.1273],\n",
      "        [1.1169],\n",
      "        [1.1497],\n",
      "        [1.1002],\n",
      "        [1.1019],\n",
      "        [1.1207],\n",
      "        [1.1492],\n",
      "        [1.1111],\n",
      "        [1.1328],\n",
      "        [1.1130],\n",
      "        [1.1544],\n",
      "        [1.0899],\n",
      "        [1.1456],\n",
      "        [1.1292],\n",
      "        [1.1314],\n",
      "        [1.1510],\n",
      "        [1.1064],\n",
      "        [1.1560]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1224],\n",
      "        [1.1563],\n",
      "        [1.1443],\n",
      "        [1.1390],\n",
      "        [1.1539],\n",
      "        [1.1410],\n",
      "        [1.1403],\n",
      "        [1.1620],\n",
      "        [1.0907],\n",
      "        [1.1097],\n",
      "        [1.0972],\n",
      "        [1.1367],\n",
      "        [1.1402],\n",
      "        [1.1100],\n",
      "        [1.1197],\n",
      "        [1.1446],\n",
      "        [1.1055],\n",
      "        [1.1274],\n",
      "        [1.1274],\n",
      "        [1.1183],\n",
      "        [1.1407],\n",
      "        [1.1186],\n",
      "        [1.1259],\n",
      "        [1.1130],\n",
      "        [1.1041],\n",
      "        [1.1332],\n",
      "        [1.1450],\n",
      "        [1.1454],\n",
      "        [1.1114],\n",
      "        [1.1021],\n",
      "        [1.1193],\n",
      "        [1.1363],\n",
      "        [1.1092],\n",
      "        [1.0671],\n",
      "        [1.1609],\n",
      "        [1.1453],\n",
      "        [1.1123],\n",
      "        [1.1489],\n",
      "        [1.1266],\n",
      "        [1.1488],\n",
      "        [1.0629],\n",
      "        [1.1300],\n",
      "        [1.1430],\n",
      "        [1.1314],\n",
      "        [1.1018],\n",
      "        [1.1008],\n",
      "        [1.1580],\n",
      "        [1.1350],\n",
      "        [1.1356],\n",
      "        [1.1218],\n",
      "        [1.1340],\n",
      "        [1.1623],\n",
      "        [1.1347],\n",
      "        [1.1279],\n",
      "        [1.1572],\n",
      "        [1.1603],\n",
      "        [1.1332],\n",
      "        [1.1079],\n",
      "        [1.1246],\n",
      "        [1.1263],\n",
      "        [1.1377],\n",
      "        [1.0620],\n",
      "        [1.1139],\n",
      "        [1.1051],\n",
      "        [1.1003],\n",
      "        [1.1279],\n",
      "        [1.1329],\n",
      "        [1.1575],\n",
      "        [1.1485],\n",
      "        [1.1256],\n",
      "        [1.1417],\n",
      "        [1.1554],\n",
      "        [1.0733],\n",
      "        [1.1231],\n",
      "        [1.1115],\n",
      "        [1.0492],\n",
      "        [1.1456],\n",
      "        [1.1411],\n",
      "        [1.1009],\n",
      "        [1.1380],\n",
      "        [1.1169],\n",
      "        [1.0922],\n",
      "        [1.1041],\n",
      "        [1.0977],\n",
      "        [1.1364],\n",
      "        [1.1582],\n",
      "        [1.0904],\n",
      "        [1.1604],\n",
      "        [1.1315],\n",
      "        [1.1213],\n",
      "        [1.1419],\n",
      "        [1.1263],\n",
      "        [1.1446],\n",
      "        [1.1432],\n",
      "        [1.1489],\n",
      "        [0.4775],\n",
      "        [1.1247],\n",
      "        [1.1163],\n",
      "        [1.1002],\n",
      "        [1.1428],\n",
      "        [1.1395],\n",
      "        [1.1234],\n",
      "        [1.1249],\n",
      "        [1.1256],\n",
      "        [1.0962],\n",
      "        [1.1287],\n",
      "        [1.1074],\n",
      "        [1.1025],\n",
      "        [1.1049],\n",
      "        [1.1211],\n",
      "        [1.1455],\n",
      "        [1.0449],\n",
      "        [1.1308],\n",
      "        [1.1595],\n",
      "        [1.1303],\n",
      "        [1.1480],\n",
      "        [1.1546],\n",
      "        [1.1433],\n",
      "        [1.1332],\n",
      "        [1.1309],\n",
      "        [1.1632],\n",
      "        [1.1440],\n",
      "        [1.1532],\n",
      "        [1.1398],\n",
      "        [1.1598],\n",
      "        [1.1310],\n",
      "        [1.1334],\n",
      "        [1.1411]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1361],\n",
      "        [1.1315],\n",
      "        [1.0730],\n",
      "        [1.1151],\n",
      "        [1.1330],\n",
      "        [1.1405],\n",
      "        [1.1220],\n",
      "        [1.1512],\n",
      "        [1.1525],\n",
      "        [1.1095],\n",
      "        [1.0841],\n",
      "        [1.1313],\n",
      "        [1.1276],\n",
      "        [1.1164],\n",
      "        [1.1179],\n",
      "        [1.0928],\n",
      "        [1.1294],\n",
      "        [1.0965],\n",
      "        [1.1222],\n",
      "        [1.1391],\n",
      "        [1.0966],\n",
      "        [1.1296],\n",
      "        [1.1362],\n",
      "        [1.1118],\n",
      "        [1.1295],\n",
      "        [1.1138],\n",
      "        [1.1067],\n",
      "        [1.1033],\n",
      "        [1.1382],\n",
      "        [1.1287],\n",
      "        [1.1507],\n",
      "        [1.1307],\n",
      "        [1.1249],\n",
      "        [1.1261],\n",
      "        [1.1247],\n",
      "        [1.1459],\n",
      "        [1.1209],\n",
      "        [1.1470],\n",
      "        [1.1100],\n",
      "        [1.1515],\n",
      "        [1.1331],\n",
      "        [1.1554],\n",
      "        [1.1556],\n",
      "        [1.0698],\n",
      "        [1.1257],\n",
      "        [1.1408],\n",
      "        [1.1394],\n",
      "        [1.1099],\n",
      "        [1.1142],\n",
      "        [1.1468],\n",
      "        [1.1133],\n",
      "        [1.0635],\n",
      "        [1.1175],\n",
      "        [1.1288],\n",
      "        [1.0962],\n",
      "        [1.1408],\n",
      "        [1.1243],\n",
      "        [1.1327],\n",
      "        [1.1251],\n",
      "        [1.1177],\n",
      "        [1.1445],\n",
      "        [1.1323],\n",
      "        [1.1353],\n",
      "        [1.1415],\n",
      "        [1.0843],\n",
      "        [1.1512],\n",
      "        [1.1362],\n",
      "        [1.1517],\n",
      "        [1.1070],\n",
      "        [1.0780],\n",
      "        [1.1205],\n",
      "        [1.1061],\n",
      "        [1.1255],\n",
      "        [1.1271],\n",
      "        [1.0890],\n",
      "        [1.1376],\n",
      "        [1.1288],\n",
      "        [1.1009],\n",
      "        [1.1234],\n",
      "        [1.1364],\n",
      "        [1.1010],\n",
      "        [1.1447],\n",
      "        [1.1115],\n",
      "        [1.1020],\n",
      "        [1.1324],\n",
      "        [1.1314],\n",
      "        [1.1127],\n",
      "        [1.0928],\n",
      "        [1.0965],\n",
      "        [1.1137],\n",
      "        [1.0945],\n",
      "        [1.1392],\n",
      "        [1.1555],\n",
      "        [1.1520],\n",
      "        [1.1553],\n",
      "        [1.1198],\n",
      "        [1.1174],\n",
      "        [1.1113],\n",
      "        [1.1465],\n",
      "        [1.1508],\n",
      "        [1.1427],\n",
      "        [1.1351],\n",
      "        [1.1445],\n",
      "        [1.1551],\n",
      "        [1.1161],\n",
      "        [1.1331],\n",
      "        [1.1477],\n",
      "        [1.1261],\n",
      "        [1.1206],\n",
      "        [1.1107],\n",
      "        [1.1375],\n",
      "        [1.1379],\n",
      "        [1.1024],\n",
      "        [1.1207],\n",
      "        [1.1310],\n",
      "        [1.1240],\n",
      "        [1.1552],\n",
      "        [1.1134],\n",
      "        [1.1497],\n",
      "        [1.1311],\n",
      "        [1.1051],\n",
      "        [1.1354],\n",
      "        [1.1382],\n",
      "        [1.0475],\n",
      "        [1.1296],\n",
      "        [1.1530],\n",
      "        [1.1435],\n",
      "        [1.1458]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0953],\n",
      "        [1.1372],\n",
      "        [1.1231],\n",
      "        [1.1202],\n",
      "        [1.0786],\n",
      "        [1.1362],\n",
      "        [1.1039],\n",
      "        [1.1316],\n",
      "        [1.1306],\n",
      "        [1.1048],\n",
      "        [1.0851],\n",
      "        [1.0819],\n",
      "        [1.1220],\n",
      "        [1.1477],\n",
      "        [1.0925],\n",
      "        [1.0763],\n",
      "        [1.1279],\n",
      "        [1.1220],\n",
      "        [1.1416],\n",
      "        [1.1132],\n",
      "        [1.0997],\n",
      "        [1.0968],\n",
      "        [1.1154],\n",
      "        [1.1183],\n",
      "        [1.0893],\n",
      "        [1.1409],\n",
      "        [1.1470],\n",
      "        [1.1072],\n",
      "        [1.1232],\n",
      "        [1.1379],\n",
      "        [1.1045],\n",
      "        [1.1187],\n",
      "        [1.1134],\n",
      "        [1.1277],\n",
      "        [1.1386],\n",
      "        [1.0116],\n",
      "        [1.1264],\n",
      "        [1.1163],\n",
      "        [1.1233],\n",
      "        [1.1389],\n",
      "        [1.1093],\n",
      "        [1.1097],\n",
      "        [1.1450],\n",
      "        [1.0512],\n",
      "        [1.1198],\n",
      "        [1.1314],\n",
      "        [1.1050],\n",
      "        [1.0918],\n",
      "        [1.1299],\n",
      "        [1.1368],\n",
      "        [1.1451],\n",
      "        [1.1317],\n",
      "        [1.1084],\n",
      "        [1.0918],\n",
      "        [1.1493],\n",
      "        [1.1236],\n",
      "        [1.1315],\n",
      "        [1.0733],\n",
      "        [1.1042],\n",
      "        [1.1066],\n",
      "        [1.1162],\n",
      "        [1.1277],\n",
      "        [1.1250],\n",
      "        [1.1404],\n",
      "        [1.1434],\n",
      "        [1.1325],\n",
      "        [1.0849],\n",
      "        [1.1355],\n",
      "        [1.1216],\n",
      "        [1.0891],\n",
      "        [1.1492],\n",
      "        [1.1094],\n",
      "        [1.1489],\n",
      "        [1.0713],\n",
      "        [1.1357],\n",
      "        [1.1071],\n",
      "        [1.0739],\n",
      "        [1.0925],\n",
      "        [1.1215],\n",
      "        [1.1228],\n",
      "        [1.1443],\n",
      "        [1.1200],\n",
      "        [1.1319],\n",
      "        [1.1142],\n",
      "        [1.1320],\n",
      "        [1.0979],\n",
      "        [1.1028],\n",
      "        [1.1400],\n",
      "        [1.1424],\n",
      "        [1.1375],\n",
      "        [1.1084],\n",
      "        [1.0701],\n",
      "        [1.1450],\n",
      "        [1.1403],\n",
      "        [1.1091],\n",
      "        [1.1201],\n",
      "        [1.1418],\n",
      "        [1.1038],\n",
      "        [1.1488],\n",
      "        [1.1114],\n",
      "        [1.0951],\n",
      "        [1.1332],\n",
      "        [1.1309],\n",
      "        [1.1066],\n",
      "        [1.0822],\n",
      "        [1.0823],\n",
      "        [1.0983],\n",
      "        [1.0989],\n",
      "        [1.1245],\n",
      "        [1.1491],\n",
      "        [1.1060],\n",
      "        [1.1343],\n",
      "        [1.1428],\n",
      "        [1.1302],\n",
      "        [1.1245],\n",
      "        [1.1435],\n",
      "        [1.1133],\n",
      "        [1.1502],\n",
      "        [1.1348],\n",
      "        [1.1149],\n",
      "        [1.1182],\n",
      "        [1.0951],\n",
      "        [1.1062],\n",
      "        [1.1337],\n",
      "        [1.1385],\n",
      "        [1.0945],\n",
      "        [1.1164],\n",
      "        [1.0896]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0882],\n",
      "        [1.1102],\n",
      "        [1.1391],\n",
      "        [1.0894],\n",
      "        [1.1022],\n",
      "        [1.0912],\n",
      "        [1.1234],\n",
      "        [1.0829],\n",
      "        [1.1318],\n",
      "        [1.1207],\n",
      "        [1.1134],\n",
      "        [1.0934],\n",
      "        [1.1064],\n",
      "        [1.0953],\n",
      "        [1.1257],\n",
      "        [1.1289],\n",
      "        [0.6302],\n",
      "        [1.1048],\n",
      "        [1.1279],\n",
      "        [1.0510],\n",
      "        [1.1215],\n",
      "        [1.1234],\n",
      "        [1.0665],\n",
      "        [1.1134],\n",
      "        [1.1245],\n",
      "        [1.1425],\n",
      "        [1.1175],\n",
      "        [1.1412],\n",
      "        [1.0780],\n",
      "        [1.1043],\n",
      "        [1.1060],\n",
      "        [1.1149],\n",
      "        [1.0934],\n",
      "        [1.1115],\n",
      "        [1.1194],\n",
      "        [1.0891],\n",
      "        [1.1325],\n",
      "        [1.0757],\n",
      "        [1.1301],\n",
      "        [1.1108],\n",
      "        [1.0607],\n",
      "        [1.1286],\n",
      "        [1.1413],\n",
      "        [1.1177],\n",
      "        [1.1009],\n",
      "        [1.1284],\n",
      "        [1.1402],\n",
      "        [1.0968],\n",
      "        [1.1243],\n",
      "        [1.0980],\n",
      "        [1.0978],\n",
      "        [1.0780],\n",
      "        [1.1332],\n",
      "        [1.1195],\n",
      "        [1.1033],\n",
      "        [1.1008],\n",
      "        [1.1280],\n",
      "        [1.1065],\n",
      "        [1.0899],\n",
      "        [1.0900],\n",
      "        [1.1191],\n",
      "        [1.0805],\n",
      "        [1.1108],\n",
      "        [1.0973],\n",
      "        [1.1170],\n",
      "        [1.0717],\n",
      "        [1.0853],\n",
      "        [1.1337],\n",
      "        [1.1311],\n",
      "        [1.1182],\n",
      "        [1.1147],\n",
      "        [1.1421],\n",
      "        [1.1406],\n",
      "        [1.0707],\n",
      "        [1.0584],\n",
      "        [1.1326],\n",
      "        [1.1256],\n",
      "        [1.1408],\n",
      "        [1.1251],\n",
      "        [1.0796],\n",
      "        [1.1305],\n",
      "        [1.1289],\n",
      "        [1.1240],\n",
      "        [1.1039],\n",
      "        [1.1224],\n",
      "        [1.0837],\n",
      "        [1.1127],\n",
      "        [1.1277],\n",
      "        [1.1303],\n",
      "        [1.0968],\n",
      "        [1.1182],\n",
      "        [1.1426],\n",
      "        [1.1429],\n",
      "        [1.1120],\n",
      "        [1.1199],\n",
      "        [1.1377],\n",
      "        [1.1201],\n",
      "        [1.1105],\n",
      "        [1.1246],\n",
      "        [1.0812],\n",
      "        [1.0978],\n",
      "        [1.0816],\n",
      "        [1.1306],\n",
      "        [1.1294],\n",
      "        [1.1192],\n",
      "        [1.1132],\n",
      "        [1.1161],\n",
      "        [1.0999],\n",
      "        [1.1424],\n",
      "        [1.0695],\n",
      "        [1.1307],\n",
      "        [1.0797],\n",
      "        [1.1087],\n",
      "        [1.0817],\n",
      "        [1.1016],\n",
      "        [1.1022],\n",
      "        [1.0942],\n",
      "        [1.1395],\n",
      "        [1.1342],\n",
      "        [1.1441],\n",
      "        [1.1067],\n",
      "        [1.0848],\n",
      "        [1.1363],\n",
      "        [1.1113],\n",
      "        [1.1144],\n",
      "        [1.0836],\n",
      "        [1.1410],\n",
      "        [1.0952]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1039],\n",
      "        [1.1266],\n",
      "        [1.0987],\n",
      "        [1.1124]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  30 | lr 0.00100 train_loss 2.12381 | val_loss 2.28982 | val_rmse 1.51322\n",
      "tensor([[1.1096],\n",
      "        [1.1287],\n",
      "        [1.0824],\n",
      "        [1.1294],\n",
      "        [1.0570],\n",
      "        [1.0669],\n",
      "        [1.0744],\n",
      "        [1.1129],\n",
      "        [1.1309],\n",
      "        [1.1022],\n",
      "        [1.0831],\n",
      "        [1.0977],\n",
      "        [1.0900],\n",
      "        [1.1219],\n",
      "        [1.0730],\n",
      "        [1.1078],\n",
      "        [1.0927],\n",
      "        [1.1295],\n",
      "        [1.0714],\n",
      "        [1.1248],\n",
      "        [1.0929],\n",
      "        [1.1033],\n",
      "        [1.1183],\n",
      "        [1.0925],\n",
      "        [1.0833],\n",
      "        [1.0756],\n",
      "        [1.0911],\n",
      "        [1.1300],\n",
      "        [1.0796],\n",
      "        [1.0773],\n",
      "        [1.1206],\n",
      "        [1.1124],\n",
      "        [1.1019],\n",
      "        [1.0996],\n",
      "        [1.1073],\n",
      "        [1.0874],\n",
      "        [1.0991],\n",
      "        [1.0699],\n",
      "        [1.1177],\n",
      "        [1.1037],\n",
      "        [1.1093],\n",
      "        [1.0682],\n",
      "        [1.0871],\n",
      "        [1.1203],\n",
      "        [1.1246],\n",
      "        [1.0562],\n",
      "        [1.1013],\n",
      "        [1.1278],\n",
      "        [1.1297],\n",
      "        [1.0846],\n",
      "        [1.1001],\n",
      "        [1.1289],\n",
      "        [1.0839],\n",
      "        [1.0952],\n",
      "        [1.1064],\n",
      "        [1.1233],\n",
      "        [1.0678],\n",
      "        [1.1157],\n",
      "        [1.1221],\n",
      "        [1.1167],\n",
      "        [1.0912],\n",
      "        [1.1222],\n",
      "        [1.0467],\n",
      "        [1.0511],\n",
      "        [1.1105],\n",
      "        [1.1133],\n",
      "        [1.1323],\n",
      "        [1.0525],\n",
      "        [1.0875],\n",
      "        [1.1223],\n",
      "        [1.1205],\n",
      "        [1.1021],\n",
      "        [1.1136],\n",
      "        [1.0852],\n",
      "        [1.0953],\n",
      "        [1.1051],\n",
      "        [1.0737],\n",
      "        [1.0952],\n",
      "        [1.0491],\n",
      "        [1.0927],\n",
      "        [1.1259],\n",
      "        [1.1003],\n",
      "        [1.0920],\n",
      "        [1.0570],\n",
      "        [1.0449],\n",
      "        [1.1040],\n",
      "        [1.1057],\n",
      "        [1.1000],\n",
      "        [1.1000],\n",
      "        [1.0844],\n",
      "        [1.1149],\n",
      "        [1.0466],\n",
      "        [1.0739],\n",
      "        [1.1188],\n",
      "        [1.0950],\n",
      "        [1.0610],\n",
      "        [1.1049],\n",
      "        [1.0947],\n",
      "        [1.1016],\n",
      "        [1.1207],\n",
      "        [1.1267],\n",
      "        [1.1008],\n",
      "        [1.0800],\n",
      "        [1.0891],\n",
      "        [1.0883],\n",
      "        [1.1229],\n",
      "        [1.1025],\n",
      "        [1.1187],\n",
      "        [1.1209],\n",
      "        [1.1061],\n",
      "        [1.1215],\n",
      "        [1.1303],\n",
      "        [1.0952],\n",
      "        [1.1128],\n",
      "        [1.1080],\n",
      "        [1.1055],\n",
      "        [1.1266],\n",
      "        [1.1249],\n",
      "        [1.0690],\n",
      "        [1.0820],\n",
      "        [1.0955],\n",
      "        [1.1202],\n",
      "        [1.0795],\n",
      "        [1.0701],\n",
      "        [1.1125],\n",
      "        [1.1029],\n",
      "        [1.0890],\n",
      "        [1.1201]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1026],\n",
      "        [1.0955],\n",
      "        [1.0671],\n",
      "        [1.1033],\n",
      "        [1.0945],\n",
      "        [1.1048],\n",
      "        [1.0883],\n",
      "        [1.1034],\n",
      "        [1.0909],\n",
      "        [1.0799],\n",
      "        [1.0856],\n",
      "        [1.1131],\n",
      "        [1.0536],\n",
      "        [1.0629],\n",
      "        [1.0710],\n",
      "        [1.1069],\n",
      "        [1.0751],\n",
      "        [1.0965],\n",
      "        [1.0884],\n",
      "        [1.1099],\n",
      "        [1.0903],\n",
      "        [1.1000],\n",
      "        [1.0860],\n",
      "        [1.1055],\n",
      "        [1.0894],\n",
      "        [1.0980],\n",
      "        [1.0952],\n",
      "        [1.1134],\n",
      "        [1.1039],\n",
      "        [1.0705],\n",
      "        [1.1151],\n",
      "        [1.1010],\n",
      "        [1.0853],\n",
      "        [1.0808],\n",
      "        [1.1109],\n",
      "        [1.0571],\n",
      "        [1.1082],\n",
      "        [1.0883],\n",
      "        [1.0393],\n",
      "        [1.0850],\n",
      "        [1.0996],\n",
      "        [1.1014],\n",
      "        [1.1046],\n",
      "        [1.1186],\n",
      "        [1.1091],\n",
      "        [1.0836],\n",
      "        [1.0836],\n",
      "        [1.0831],\n",
      "        [1.0836],\n",
      "        [1.0968],\n",
      "        [1.0991],\n",
      "        [1.0576],\n",
      "        [1.1138],\n",
      "        [1.0833],\n",
      "        [1.0937],\n",
      "        [1.1008],\n",
      "        [1.1141],\n",
      "        [1.1003],\n",
      "        [1.1007],\n",
      "        [1.0850],\n",
      "        [1.0543],\n",
      "        [1.1195],\n",
      "        [1.0801],\n",
      "        [1.1057],\n",
      "        [1.1224],\n",
      "        [1.1013],\n",
      "        [1.0856],\n",
      "        [1.0992],\n",
      "        [1.1093],\n",
      "        [1.1143],\n",
      "        [1.0799],\n",
      "        [1.1159],\n",
      "        [1.1091],\n",
      "        [1.0865],\n",
      "        [1.0877],\n",
      "        [1.1241],\n",
      "        [1.0931],\n",
      "        [1.1188],\n",
      "        [1.0792],\n",
      "        [1.0939],\n",
      "        [1.0800],\n",
      "        [1.0892],\n",
      "        [1.0892],\n",
      "        [1.0745],\n",
      "        [1.0708],\n",
      "        [1.0621],\n",
      "        [1.0211],\n",
      "        [1.0878],\n",
      "        [1.0853],\n",
      "        [1.1200],\n",
      "        [1.0991],\n",
      "        [1.0852],\n",
      "        [1.0947],\n",
      "        [1.0940],\n",
      "        [1.1059],\n",
      "        [1.0730],\n",
      "        [1.0943],\n",
      "        [1.0695],\n",
      "        [1.0874],\n",
      "        [1.0939],\n",
      "        [1.0899],\n",
      "        [1.1097],\n",
      "        [1.1134],\n",
      "        [1.0656],\n",
      "        [1.0835],\n",
      "        [1.0817],\n",
      "        [1.1050],\n",
      "        [1.1206],\n",
      "        [1.0771],\n",
      "        [1.1074],\n",
      "        [1.1008],\n",
      "        [1.0952],\n",
      "        [1.1051],\n",
      "        [1.1136],\n",
      "        [1.0691],\n",
      "        [1.1084],\n",
      "        [1.0658],\n",
      "        [1.0895],\n",
      "        [1.1214],\n",
      "        [1.0976],\n",
      "        [1.1077],\n",
      "        [1.1064],\n",
      "        [1.1124],\n",
      "        [1.0966],\n",
      "        [1.1133],\n",
      "        [1.0723],\n",
      "        [1.0620],\n",
      "        [1.1077]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0970],\n",
      "        [1.0852],\n",
      "        [1.0903],\n",
      "        [1.0680],\n",
      "        [1.0878],\n",
      "        [1.0627],\n",
      "        [1.0542],\n",
      "        [1.0940],\n",
      "        [1.1080],\n",
      "        [1.1047],\n",
      "        [1.0750],\n",
      "        [1.1023],\n",
      "        [1.0773],\n",
      "        [1.0657],\n",
      "        [1.0724],\n",
      "        [1.0803],\n",
      "        [1.1020],\n",
      "        [1.0698],\n",
      "        [1.1136],\n",
      "        [1.0614],\n",
      "        [1.0994],\n",
      "        [1.1079],\n",
      "        [1.1069],\n",
      "        [1.0821],\n",
      "        [1.0966],\n",
      "        [1.0329],\n",
      "        [1.0966],\n",
      "        [1.0923],\n",
      "        [1.1090],\n",
      "        [1.1136],\n",
      "        [1.0880],\n",
      "        [1.1000],\n",
      "        [1.0945],\n",
      "        [1.0992],\n",
      "        [1.1123],\n",
      "        [1.0720],\n",
      "        [1.0525],\n",
      "        [1.0780],\n",
      "        [1.0687],\n",
      "        [1.0935],\n",
      "        [1.0762],\n",
      "        [1.0757],\n",
      "        [1.1076],\n",
      "        [1.0960],\n",
      "        [1.0699],\n",
      "        [1.0938],\n",
      "        [1.0395],\n",
      "        [1.1041],\n",
      "        [1.1057],\n",
      "        [1.1081],\n",
      "        [1.0958],\n",
      "        [1.0505],\n",
      "        [1.1048],\n",
      "        [1.0729],\n",
      "        [1.0988],\n",
      "        [1.1094],\n",
      "        [1.0901],\n",
      "        [1.0962],\n",
      "        [1.0683],\n",
      "        [1.0927],\n",
      "        [1.1033],\n",
      "        [1.0535],\n",
      "        [1.1143],\n",
      "        [1.0875],\n",
      "        [1.0840],\n",
      "        [1.0761],\n",
      "        [1.1042],\n",
      "        [1.0992],\n",
      "        [1.0781],\n",
      "        [1.1057],\n",
      "        [1.0807],\n",
      "        [1.1084],\n",
      "        [1.0832],\n",
      "        [1.0738],\n",
      "        [1.0861],\n",
      "        [1.0784],\n",
      "        [1.0892],\n",
      "        [1.0682],\n",
      "        [1.0956],\n",
      "        [1.0935],\n",
      "        [1.1086],\n",
      "        [1.1112],\n",
      "        [1.0913],\n",
      "        [1.0985],\n",
      "        [1.1015],\n",
      "        [1.0806],\n",
      "        [1.1014],\n",
      "        [1.0838],\n",
      "        [1.1114],\n",
      "        [1.0944],\n",
      "        [1.1124],\n",
      "        [1.1037],\n",
      "        [1.0876],\n",
      "        [1.0982],\n",
      "        [1.0874],\n",
      "        [1.0971],\n",
      "        [1.0745],\n",
      "        [1.0955],\n",
      "        [1.0932],\n",
      "        [1.0535],\n",
      "        [1.0823],\n",
      "        [1.0630],\n",
      "        [1.0694],\n",
      "        [1.0953],\n",
      "        [1.1057],\n",
      "        [1.0994],\n",
      "        [1.1058],\n",
      "        [1.1028],\n",
      "        [1.0932],\n",
      "        [1.1078],\n",
      "        [1.0891],\n",
      "        [1.0901],\n",
      "        [1.0708],\n",
      "        [1.0595],\n",
      "        [1.1108],\n",
      "        [1.0983],\n",
      "        [1.1030],\n",
      "        [1.0706],\n",
      "        [1.0765],\n",
      "        [1.1087],\n",
      "        [1.0645],\n",
      "        [1.0846],\n",
      "        [1.0928],\n",
      "        [1.0985],\n",
      "        [1.1138],\n",
      "        [1.1162],\n",
      "        [1.1027],\n",
      "        [1.1061]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0678],\n",
      "        [1.0623],\n",
      "        [1.0907],\n",
      "        [1.0878],\n",
      "        [1.1094],\n",
      "        [1.0357],\n",
      "        [1.0963],\n",
      "        [1.0868],\n",
      "        [1.0767],\n",
      "        [1.0832],\n",
      "        [1.0831],\n",
      "        [1.0776],\n",
      "        [1.1053],\n",
      "        [1.0743],\n",
      "        [1.0981],\n",
      "        [1.0834],\n",
      "        [1.0385],\n",
      "        [1.0718],\n",
      "        [1.0911],\n",
      "        [1.0536],\n",
      "        [1.0321],\n",
      "        [1.0654],\n",
      "        [1.0780],\n",
      "        [1.0855],\n",
      "        [1.0501],\n",
      "        [1.0803],\n",
      "        [1.0936],\n",
      "        [1.0792],\n",
      "        [1.0425],\n",
      "        [1.0530],\n",
      "        [1.0799],\n",
      "        [1.0927],\n",
      "        [1.0642],\n",
      "        [1.0605],\n",
      "        [1.0547],\n",
      "        [1.0481],\n",
      "        [1.0907],\n",
      "        [1.0624],\n",
      "        [1.0627],\n",
      "        [1.0771],\n",
      "        [1.0470],\n",
      "        [1.0317],\n",
      "        [1.0666],\n",
      "        [1.0858],\n",
      "        [1.0662],\n",
      "        [1.0469],\n",
      "        [1.0940],\n",
      "        [1.0514],\n",
      "        [1.0744],\n",
      "        [1.0664],\n",
      "        [1.0815],\n",
      "        [1.0989],\n",
      "        [1.0915],\n",
      "        [1.1042],\n",
      "        [1.0635],\n",
      "        [1.0550],\n",
      "        [1.0691],\n",
      "        [1.1046],\n",
      "        [1.0941],\n",
      "        [1.0997],\n",
      "        [1.0887],\n",
      "        [1.0344],\n",
      "        [1.0930],\n",
      "        [1.0675],\n",
      "        [1.1077],\n",
      "        [1.0806],\n",
      "        [1.1094],\n",
      "        [1.0977],\n",
      "        [1.0625],\n",
      "        [1.0362],\n",
      "        [1.0499],\n",
      "        [1.0789],\n",
      "        [1.0966],\n",
      "        [1.0641],\n",
      "        [1.0492],\n",
      "        [1.1061],\n",
      "        [1.0236],\n",
      "        [1.0894],\n",
      "        [1.0367],\n",
      "        [1.1033],\n",
      "        [1.0619],\n",
      "        [1.0701],\n",
      "        [1.0665],\n",
      "        [1.0682],\n",
      "        [1.0841],\n",
      "        [1.0336],\n",
      "        [1.0671],\n",
      "        [1.0771],\n",
      "        [1.1018],\n",
      "        [1.0973],\n",
      "        [1.0782],\n",
      "        [1.1024],\n",
      "        [1.0704],\n",
      "        [1.0373],\n",
      "        [1.0757],\n",
      "        [1.0633],\n",
      "        [1.1033],\n",
      "        [1.0613],\n",
      "        [1.0433],\n",
      "        [1.0783],\n",
      "        [1.1079],\n",
      "        [1.0585],\n",
      "        [1.0826],\n",
      "        [1.1058],\n",
      "        [1.0856],\n",
      "        [1.0590],\n",
      "        [1.0705],\n",
      "        [1.0310],\n",
      "        [1.0994],\n",
      "        [1.1010],\n",
      "        [1.1030],\n",
      "        [1.0765],\n",
      "        [1.0221],\n",
      "        [1.1045],\n",
      "        [1.0767],\n",
      "        [1.0981],\n",
      "        [1.0738],\n",
      "        [1.1032],\n",
      "        [1.1066],\n",
      "        [1.0708],\n",
      "        [1.0694],\n",
      "        [1.0927],\n",
      "        [1.1069],\n",
      "        [1.0284],\n",
      "        [1.0962],\n",
      "        [1.1077],\n",
      "        [1.0953],\n",
      "        [1.0424]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1024],\n",
      "        [1.1067],\n",
      "        [1.0445],\n",
      "        [1.0953],\n",
      "        [1.0823],\n",
      "        [1.0740],\n",
      "        [1.0517],\n",
      "        [1.0793],\n",
      "        [1.0552],\n",
      "        [1.0928],\n",
      "        [1.0665],\n",
      "        [1.0993],\n",
      "        [1.0675],\n",
      "        [1.0778],\n",
      "        [1.0774],\n",
      "        [1.0956],\n",
      "        [1.0848],\n",
      "        [1.0686],\n",
      "        [1.0850],\n",
      "        [1.0659],\n",
      "        [1.0996],\n",
      "        [1.0735],\n",
      "        [1.0972],\n",
      "        [1.1063],\n",
      "        [1.0716],\n",
      "        [1.0976],\n",
      "        [1.0552],\n",
      "        [1.0909],\n",
      "        [1.0456],\n",
      "        [1.0933],\n",
      "        [1.0877],\n",
      "        [1.0815],\n",
      "        [1.0606],\n",
      "        [1.0682],\n",
      "        [1.0885],\n",
      "        [1.0890],\n",
      "        [1.0906],\n",
      "        [1.0818],\n",
      "        [1.0647],\n",
      "        [1.0485],\n",
      "        [1.0917],\n",
      "        [1.0921],\n",
      "        [1.0904],\n",
      "        [1.0801],\n",
      "        [1.0725],\n",
      "        [1.0852],\n",
      "        [1.0906],\n",
      "        [1.0856],\n",
      "        [1.0885],\n",
      "        [1.0609],\n",
      "        [1.0822],\n",
      "        [1.0864],\n",
      "        [1.0514],\n",
      "        [1.0801],\n",
      "        [1.0830],\n",
      "        [1.0722],\n",
      "        [1.1005],\n",
      "        [1.0772],\n",
      "        [1.0738],\n",
      "        [1.0629],\n",
      "        [1.0839],\n",
      "        [1.0672],\n",
      "        [1.0565],\n",
      "        [1.0674],\n",
      "        [1.0629],\n",
      "        [1.0956],\n",
      "        [1.0592],\n",
      "        [1.0960],\n",
      "        [1.0842],\n",
      "        [1.0776],\n",
      "        [1.0788],\n",
      "        [1.0617],\n",
      "        [1.0369],\n",
      "        [1.0906],\n",
      "        [1.0581],\n",
      "        [1.0748],\n",
      "        [1.0725],\n",
      "        [1.0688],\n",
      "        [1.0807],\n",
      "        [1.0859],\n",
      "        [1.0829],\n",
      "        [1.0745],\n",
      "        [1.0917],\n",
      "        [1.0978],\n",
      "        [1.0270],\n",
      "        [1.0723],\n",
      "        [1.0334],\n",
      "        [1.0763],\n",
      "        [1.0986],\n",
      "        [1.0662],\n",
      "        [1.0960],\n",
      "        [1.0614],\n",
      "        [1.0568],\n",
      "        [1.0332],\n",
      "        [1.1012],\n",
      "        [1.1027],\n",
      "        [1.0640],\n",
      "        [1.0609],\n",
      "        [1.0921],\n",
      "        [1.0852],\n",
      "        [1.0384],\n",
      "        [1.0840],\n",
      "        [1.0666],\n",
      "        [1.0925],\n",
      "        [1.0847],\n",
      "        [1.0820],\n",
      "        [1.0684],\n",
      "        [1.0411],\n",
      "        [1.0630],\n",
      "        [1.0747],\n",
      "        [1.0883],\n",
      "        [1.0821],\n",
      "        [1.0567],\n",
      "        [1.0715],\n",
      "        [1.0854],\n",
      "        [1.0881],\n",
      "        [1.0744],\n",
      "        [1.0905],\n",
      "        [1.0805],\n",
      "        [1.0941],\n",
      "        [1.0830],\n",
      "        [1.0564],\n",
      "        [1.0570],\n",
      "        [1.0832],\n",
      "        [1.0287],\n",
      "        [1.1031],\n",
      "        [1.0986],\n",
      "        [1.0937]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0619],\n",
      "        [1.0976],\n",
      "        [1.0732],\n",
      "        [1.0673],\n",
      "        [1.0754],\n",
      "        [1.0346],\n",
      "        [1.0874],\n",
      "        [1.0945],\n",
      "        [1.0367],\n",
      "        [1.0263],\n",
      "        [1.0897],\n",
      "        [1.0487],\n",
      "        [1.0910],\n",
      "        [1.0608],\n",
      "        [1.0526],\n",
      "        [1.0639],\n",
      "        [1.0710],\n",
      "        [1.1015],\n",
      "        [1.0987],\n",
      "        [1.0560],\n",
      "        [1.0841],\n",
      "        [1.0866],\n",
      "        [1.0652],\n",
      "        [1.0724],\n",
      "        [1.0806],\n",
      "        [1.0311],\n",
      "        [1.0636],\n",
      "        [1.0736],\n",
      "        [1.0719],\n",
      "        [1.0940],\n",
      "        [1.0939],\n",
      "        [1.0815],\n",
      "        [1.0304],\n",
      "        [1.0458],\n",
      "        [1.0414],\n",
      "        [1.0865],\n",
      "        [1.0498],\n",
      "        [1.0630],\n",
      "        [1.0252],\n",
      "        [1.0823],\n",
      "        [1.0736],\n",
      "        [1.0745],\n",
      "        [1.0817],\n",
      "        [1.0623],\n",
      "        [1.0873],\n",
      "        [1.0967],\n",
      "        [1.0347],\n",
      "        [1.0869],\n",
      "        [1.0561],\n",
      "        [1.0653],\n",
      "        [1.0438],\n",
      "        [1.0863],\n",
      "        [1.0858],\n",
      "        [1.0582],\n",
      "        [1.0905],\n",
      "        [1.0757],\n",
      "        [1.0834],\n",
      "        [1.0726],\n",
      "        [1.0780],\n",
      "        [1.0889],\n",
      "        [1.0886],\n",
      "        [1.0598],\n",
      "        [1.0238],\n",
      "        [1.0968],\n",
      "        [1.0537],\n",
      "        [1.0796],\n",
      "        [1.0870],\n",
      "        [1.0904],\n",
      "        [1.0992],\n",
      "        [1.0912],\n",
      "        [1.0757],\n",
      "        [1.0654],\n",
      "        [1.0908],\n",
      "        [1.0887],\n",
      "        [1.0585],\n",
      "        [1.0537],\n",
      "        [1.0312],\n",
      "        [1.0242],\n",
      "        [1.0944],\n",
      "        [1.0610],\n",
      "        [1.0714],\n",
      "        [1.0870],\n",
      "        [1.0514],\n",
      "        [1.0301],\n",
      "        [1.1019],\n",
      "        [1.0821],\n",
      "        [1.0209],\n",
      "        [1.0485],\n",
      "        [1.0764],\n",
      "        [1.0347],\n",
      "        [1.0191],\n",
      "        [1.0967],\n",
      "        [1.0336],\n",
      "        [1.0484],\n",
      "        [1.0825],\n",
      "        [1.0218],\n",
      "        [1.0855],\n",
      "        [1.0721],\n",
      "        [1.0768],\n",
      "        [1.0644],\n",
      "        [1.0499],\n",
      "        [1.0694],\n",
      "        [1.0658],\n",
      "        [1.0995],\n",
      "        [1.0696],\n",
      "        [1.0835],\n",
      "        [1.0713],\n",
      "        [1.0569],\n",
      "        [1.0788],\n",
      "        [1.0837],\n",
      "        [1.0917],\n",
      "        [1.0675],\n",
      "        [1.0677],\n",
      "        [1.0666],\n",
      "        [1.0705],\n",
      "        [1.0577],\n",
      "        [1.0505],\n",
      "        [1.0960],\n",
      "        [1.0754],\n",
      "        [1.0771],\n",
      "        [1.0763],\n",
      "        [1.0629],\n",
      "        [1.0467],\n",
      "        [1.0776],\n",
      "        [1.0143],\n",
      "        [1.0324],\n",
      "        [1.0670],\n",
      "        [1.0749]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0168],\n",
      "        [1.0731],\n",
      "        [1.0587],\n",
      "        [1.0846],\n",
      "        [1.0771],\n",
      "        [1.0806],\n",
      "        [1.0601],\n",
      "        [1.0499],\n",
      "        [1.0746],\n",
      "        [1.0917],\n",
      "        [1.0811],\n",
      "        [1.0601],\n",
      "        [1.0025],\n",
      "        [1.0395],\n",
      "        [1.0696],\n",
      "        [1.0769],\n",
      "        [1.0948],\n",
      "        [1.0349],\n",
      "        [1.0758],\n",
      "        [1.0507],\n",
      "        [1.0625],\n",
      "        [1.0900],\n",
      "        [1.0747],\n",
      "        [1.0516],\n",
      "        [1.0656],\n",
      "        [1.0898],\n",
      "        [1.0588],\n",
      "        [1.0583],\n",
      "        [1.0851],\n",
      "        [1.0843],\n",
      "        [1.0951],\n",
      "        [1.0553],\n",
      "        [1.0936],\n",
      "        [1.0870],\n",
      "        [1.0653],\n",
      "        [1.0759],\n",
      "        [1.0492],\n",
      "        [1.0753],\n",
      "        [1.0358],\n",
      "        [1.0786],\n",
      "        [1.0932],\n",
      "        [1.0778],\n",
      "        [1.0835],\n",
      "        [1.0899],\n",
      "        [1.0508],\n",
      "        [1.0649],\n",
      "        [1.0832],\n",
      "        [1.0266],\n",
      "        [1.0860],\n",
      "        [1.0695],\n",
      "        [1.0656],\n",
      "        [1.0838],\n",
      "        [1.0781],\n",
      "        [1.0798],\n",
      "        [1.0836],\n",
      "        [1.0845],\n",
      "        [1.0338],\n",
      "        [1.0556],\n",
      "        [1.0375],\n",
      "        [1.0774],\n",
      "        [1.0885],\n",
      "        [1.0732],\n",
      "        [1.0688],\n",
      "        [1.0608],\n",
      "        [1.0554],\n",
      "        [1.0569],\n",
      "        [1.0660],\n",
      "        [1.0119],\n",
      "        [1.0801],\n",
      "        [1.0418],\n",
      "        [1.0784],\n",
      "        [1.0868],\n",
      "        [1.0620],\n",
      "        [1.0429],\n",
      "        [1.0666],\n",
      "        [1.0805],\n",
      "        [1.0573],\n",
      "        [1.0788],\n",
      "        [1.0651],\n",
      "        [1.0768],\n",
      "        [1.0656],\n",
      "        [1.0601],\n",
      "        [1.0669],\n",
      "        [1.0479],\n",
      "        [1.0289],\n",
      "        [1.0662],\n",
      "        [1.0750],\n",
      "        [1.0763],\n",
      "        [1.0787],\n",
      "        [1.0666],\n",
      "        [1.0489],\n",
      "        [1.0336],\n",
      "        [1.0901],\n",
      "        [1.0998],\n",
      "        [1.0613],\n",
      "        [1.0863],\n",
      "        [1.0551],\n",
      "        [1.0594],\n",
      "        [1.0850],\n",
      "        [1.0552],\n",
      "        [1.0727],\n",
      "        [1.0536],\n",
      "        [1.0842],\n",
      "        [1.0784],\n",
      "        [1.0286],\n",
      "        [1.0942],\n",
      "        [1.0170],\n",
      "        [1.0453],\n",
      "        [1.0676],\n",
      "        [1.0926],\n",
      "        [1.0878],\n",
      "        [1.0712],\n",
      "        [1.0682],\n",
      "        [1.0242],\n",
      "        [1.0871],\n",
      "        [1.0743],\n",
      "        [1.0525],\n",
      "        [1.0787],\n",
      "        [1.0424],\n",
      "        [1.0571],\n",
      "        [1.0739],\n",
      "        [1.0763],\n",
      "        [1.0553],\n",
      "        [1.0809],\n",
      "        [1.0702],\n",
      "        [1.0514],\n",
      "        [1.0627],\n",
      "        [1.0834]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0597],\n",
      "        [1.0634],\n",
      "        [1.0784],\n",
      "        [1.0726]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  31 | lr 0.00100 train_loss 2.12117 | val_loss 2.30225 | val_rmse 1.51732\n",
      "tensor([[0.9997],\n",
      "        [1.0097],\n",
      "        [1.0540],\n",
      "        [1.0530],\n",
      "        [0.9995],\n",
      "        [1.0620],\n",
      "        [1.0549],\n",
      "        [1.0390],\n",
      "        [1.0116],\n",
      "        [1.0648],\n",
      "        [1.0661],\n",
      "        [1.0847],\n",
      "        [1.0422],\n",
      "        [1.0532],\n",
      "        [1.0701],\n",
      "        [1.0142],\n",
      "        [1.0563],\n",
      "        [1.0606],\n",
      "        [1.0653],\n",
      "        [1.0129],\n",
      "        [1.0845],\n",
      "        [1.0479],\n",
      "        [1.0698],\n",
      "        [1.0610],\n",
      "        [1.0449],\n",
      "        [1.0850],\n",
      "        [1.0694],\n",
      "        [1.0600],\n",
      "        [1.0628],\n",
      "        [1.0259],\n",
      "        [1.0833],\n",
      "        [1.0708],\n",
      "        [1.0673],\n",
      "        [1.0714],\n",
      "        [1.0336],\n",
      "        [1.0493],\n",
      "        [1.0671],\n",
      "        [1.0540],\n",
      "        [1.0550],\n",
      "        [1.0684],\n",
      "        [1.0354],\n",
      "        [1.0363],\n",
      "        [1.0310],\n",
      "        [1.0690],\n",
      "        [1.0769],\n",
      "        [1.0813],\n",
      "        [1.0794],\n",
      "        [1.0762],\n",
      "        [1.0630],\n",
      "        [1.0511],\n",
      "        [1.0349],\n",
      "        [1.0364],\n",
      "        [1.0874],\n",
      "        [1.0498],\n",
      "        [1.0587],\n",
      "        [1.0726],\n",
      "        [1.0716],\n",
      "        [1.0560],\n",
      "        [1.0399],\n",
      "        [1.0436],\n",
      "        [1.0633],\n",
      "        [1.0708],\n",
      "        [1.0910],\n",
      "        [1.0757],\n",
      "        [1.0796],\n",
      "        [1.0715],\n",
      "        [1.0291],\n",
      "        [1.0692],\n",
      "        [1.0194],\n",
      "        [1.0665],\n",
      "        [1.0719],\n",
      "        [1.0708],\n",
      "        [1.0716],\n",
      "        [1.0453],\n",
      "        [1.0401],\n",
      "        [1.0777],\n",
      "        [1.0462],\n",
      "        [1.0712],\n",
      "        [1.0638],\n",
      "        [1.0408],\n",
      "        [1.0660],\n",
      "        [1.0146],\n",
      "        [1.0334],\n",
      "        [1.0611],\n",
      "        [1.0469],\n",
      "        [1.0431],\n",
      "        [1.0357],\n",
      "        [1.0509],\n",
      "        [1.0792],\n",
      "        [1.0164],\n",
      "        [1.0730],\n",
      "        [1.0713],\n",
      "        [1.0726],\n",
      "        [1.0507],\n",
      "        [1.0773],\n",
      "        [1.0836],\n",
      "        [1.0229],\n",
      "        [1.0644],\n",
      "        [1.0722],\n",
      "        [1.0528],\n",
      "        [1.0225],\n",
      "        [1.0800],\n",
      "        [1.0829],\n",
      "        [1.0744],\n",
      "        [1.0648],\n",
      "        [1.0733],\n",
      "        [1.0221],\n",
      "        [1.0781],\n",
      "        [1.0853],\n",
      "        [1.0788],\n",
      "        [1.0546],\n",
      "        [1.0887],\n",
      "        [1.0752],\n",
      "        [1.0644],\n",
      "        [1.0777],\n",
      "        [1.0525],\n",
      "        [1.0495],\n",
      "        [1.0686],\n",
      "        [1.0628],\n",
      "        [1.0305],\n",
      "        [1.0603],\n",
      "        [1.0349],\n",
      "        [1.0479],\n",
      "        [1.0686],\n",
      "        [1.0419],\n",
      "        [1.0016],\n",
      "        [1.0500],\n",
      "        [1.0431]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0243],\n",
      "        [0.9945],\n",
      "        [1.0638],\n",
      "        [1.0527],\n",
      "        [1.0817],\n",
      "        [1.0646],\n",
      "        [1.0706],\n",
      "        [1.0662],\n",
      "        [1.0794],\n",
      "        [1.0435],\n",
      "        [1.0602],\n",
      "        [1.0533],\n",
      "        [1.0727],\n",
      "        [1.0684],\n",
      "        [1.0538],\n",
      "        [1.0683],\n",
      "        [0.9861],\n",
      "        [1.0364],\n",
      "        [1.0654],\n",
      "        [1.0722],\n",
      "        [1.0663],\n",
      "        [1.0369],\n",
      "        [1.0552],\n",
      "        [1.0640],\n",
      "        [1.0412],\n",
      "        [1.0545],\n",
      "        [1.0734],\n",
      "        [1.0400],\n",
      "        [1.0582],\n",
      "        [1.0513],\n",
      "        [1.0725],\n",
      "        [1.0463],\n",
      "        [1.0443],\n",
      "        [1.0445],\n",
      "        [1.0280],\n",
      "        [1.0667],\n",
      "        [1.0050],\n",
      "        [1.0757],\n",
      "        [1.0572],\n",
      "        [1.0479],\n",
      "        [1.0478],\n",
      "        [1.0707],\n",
      "        [1.0438],\n",
      "        [1.0322],\n",
      "        [1.0681],\n",
      "        [1.0636],\n",
      "        [1.0586],\n",
      "        [1.0561],\n",
      "        [0.9923],\n",
      "        [1.0785],\n",
      "        [1.0525],\n",
      "        [1.0581],\n",
      "        [1.0841],\n",
      "        [1.0748],\n",
      "        [1.0164],\n",
      "        [1.0753],\n",
      "        [1.0067],\n",
      "        [1.0657],\n",
      "        [1.0404],\n",
      "        [1.0166],\n",
      "        [1.0478],\n",
      "        [0.9969],\n",
      "        [1.0829],\n",
      "        [1.0312],\n",
      "        [1.0641],\n",
      "        [1.0646],\n",
      "        [1.0258],\n",
      "        [1.0626],\n",
      "        [1.0664],\n",
      "        [1.0558],\n",
      "        [1.0656],\n",
      "        [1.0777],\n",
      "        [1.0835],\n",
      "        [1.0559],\n",
      "        [1.0578],\n",
      "        [1.0766],\n",
      "        [0.9983],\n",
      "        [1.0509],\n",
      "        [1.0697],\n",
      "        [1.0606],\n",
      "        [1.0576],\n",
      "        [1.0465],\n",
      "        [1.0405],\n",
      "        [1.0311],\n",
      "        [1.0624],\n",
      "        [1.0413],\n",
      "        [1.0558],\n",
      "        [1.0754],\n",
      "        [1.0333],\n",
      "        [1.0668],\n",
      "        [1.0748],\n",
      "        [1.0152],\n",
      "        [1.0513],\n",
      "        [1.0484],\n",
      "        [1.0147],\n",
      "        [1.0595],\n",
      "        [1.0691],\n",
      "        [1.0760],\n",
      "        [1.0677],\n",
      "        [1.0420],\n",
      "        [1.0278],\n",
      "        [1.0564],\n",
      "        [1.0829],\n",
      "        [1.0781],\n",
      "        [1.0700],\n",
      "        [1.0457],\n",
      "        [1.0291],\n",
      "        [1.0652],\n",
      "        [1.0710],\n",
      "        [1.0789],\n",
      "        [1.7570],\n",
      "        [1.0119],\n",
      "        [1.0525],\n",
      "        [1.0581],\n",
      "        [1.0452],\n",
      "        [1.0831],\n",
      "        [1.0525],\n",
      "        [1.0697],\n",
      "        [1.0683],\n",
      "        [1.0655],\n",
      "        [1.0280],\n",
      "        [1.0218],\n",
      "        [1.0586],\n",
      "        [1.0522],\n",
      "        [1.0281],\n",
      "        [1.0770],\n",
      "        [1.0615],\n",
      "        [1.0182]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0543],\n",
      "        [1.0703],\n",
      "        [1.0380],\n",
      "        [1.0640],\n",
      "        [1.0318],\n",
      "        [1.0589],\n",
      "        [1.0533],\n",
      "        [0.9854],\n",
      "        [1.0737],\n",
      "        [1.0381],\n",
      "        [1.0633],\n",
      "        [1.0738],\n",
      "        [1.0785],\n",
      "        [1.0585],\n",
      "        [1.0541],\n",
      "        [1.0481],\n",
      "        [1.0555],\n",
      "        [1.0707],\n",
      "        [1.0509],\n",
      "        [1.0714],\n",
      "        [1.0248],\n",
      "        [1.0676],\n",
      "        [1.0272],\n",
      "        [1.0665],\n",
      "        [1.0626],\n",
      "        [1.0635],\n",
      "        [1.0203],\n",
      "        [1.0620],\n",
      "        [1.0205],\n",
      "        [1.0726],\n",
      "        [1.0153],\n",
      "        [1.0558],\n",
      "        [1.0639],\n",
      "        [1.0556],\n",
      "        [1.0763],\n",
      "        [1.0249],\n",
      "        [1.0562],\n",
      "        [1.0080],\n",
      "        [1.0669],\n",
      "        [1.0714],\n",
      "        [1.0842],\n",
      "        [1.0639],\n",
      "        [1.0541],\n",
      "        [0.9950],\n",
      "        [1.0772],\n",
      "        [1.0653],\n",
      "        [1.0046],\n",
      "        [1.0095],\n",
      "        [1.0421],\n",
      "        [1.0574],\n",
      "        [1.0701],\n",
      "        [1.0218],\n",
      "        [1.0519],\n",
      "        [1.0405],\n",
      "        [1.0583],\n",
      "        [1.0510],\n",
      "        [1.0753],\n",
      "        [1.0727],\n",
      "        [1.0467],\n",
      "        [1.0496],\n",
      "        [1.0373],\n",
      "        [1.0676],\n",
      "        [1.0744],\n",
      "        [1.0659],\n",
      "        [1.0701],\n",
      "        [1.0636],\n",
      "        [1.0553],\n",
      "        [1.0244],\n",
      "        [1.0541],\n",
      "        [1.0697],\n",
      "        [1.0779],\n",
      "        [1.0084],\n",
      "        [1.0825],\n",
      "        [1.0430],\n",
      "        [1.0474],\n",
      "        [1.0811],\n",
      "        [1.0335],\n",
      "        [1.0735],\n",
      "        [1.0461],\n",
      "        [1.0649],\n",
      "        [1.0495],\n",
      "        [1.0660],\n",
      "        [1.0699],\n",
      "        [1.0435],\n",
      "        [1.0583],\n",
      "        [1.0672],\n",
      "        [1.0641],\n",
      "        [1.0402],\n",
      "        [1.0760],\n",
      "        [1.0414],\n",
      "        [1.0295],\n",
      "        [1.0409],\n",
      "        [1.0505],\n",
      "        [1.0100],\n",
      "        [1.0751],\n",
      "        [1.0463],\n",
      "        [1.0271],\n",
      "        [1.0714],\n",
      "        [1.0544],\n",
      "        [1.0770],\n",
      "        [1.0445],\n",
      "        [1.0306],\n",
      "        [1.0188],\n",
      "        [1.0417],\n",
      "        [1.0600],\n",
      "        [1.0460],\n",
      "        [1.0080],\n",
      "        [1.0683],\n",
      "        [1.0601],\n",
      "        [1.0549],\n",
      "        [1.0567],\n",
      "        [1.0517],\n",
      "        [1.0618],\n",
      "        [1.0482],\n",
      "        [1.0459],\n",
      "        [1.0471],\n",
      "        [1.0363],\n",
      "        [1.0288],\n",
      "        [1.0793],\n",
      "        [1.0738],\n",
      "        [1.0517],\n",
      "        [1.0655],\n",
      "        [1.0458],\n",
      "        [1.0315],\n",
      "        [1.0781],\n",
      "        [1.0238],\n",
      "        [1.0787],\n",
      "        [1.0460]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0566],\n",
      "        [1.0168],\n",
      "        [1.0124],\n",
      "        [1.0402],\n",
      "        [1.0461],\n",
      "        [1.0532],\n",
      "        [1.0718],\n",
      "        [1.0781],\n",
      "        [1.0259],\n",
      "        [1.0187],\n",
      "        [1.0614],\n",
      "        [1.0682],\n",
      "        [1.0659],\n",
      "        [1.0169],\n",
      "        [1.0521],\n",
      "        [1.0630],\n",
      "        [1.0417],\n",
      "        [1.0523],\n",
      "        [1.0488],\n",
      "        [1.0595],\n",
      "        [1.0390],\n",
      "        [1.0615],\n",
      "        [1.0477],\n",
      "        [1.0626],\n",
      "        [1.0670],\n",
      "        [1.0456],\n",
      "        [1.0227],\n",
      "        [1.0382],\n",
      "        [1.0605],\n",
      "        [1.0717],\n",
      "        [1.0167],\n",
      "        [1.0223],\n",
      "        [1.0376],\n",
      "        [1.0708],\n",
      "        [1.0465],\n",
      "        [1.0119],\n",
      "        [1.0590],\n",
      "        [1.0088],\n",
      "        [1.0598],\n",
      "        [1.0624],\n",
      "        [1.0745],\n",
      "        [1.0251],\n",
      "        [1.0429],\n",
      "        [1.0612],\n",
      "        [1.0647],\n",
      "        [0.9770],\n",
      "        [1.0515],\n",
      "        [1.0683],\n",
      "        [1.0578],\n",
      "        [1.0588],\n",
      "        [1.0680],\n",
      "        [1.0499],\n",
      "        [1.0630],\n",
      "        [1.0701],\n",
      "        [1.0473],\n",
      "        [1.0740],\n",
      "        [1.0736],\n",
      "        [1.0697],\n",
      "        [1.0770],\n",
      "        [1.0570],\n",
      "        [0.9860],\n",
      "        [1.0620],\n",
      "        [1.0468],\n",
      "        [1.0187],\n",
      "        [1.0543],\n",
      "        [1.0575],\n",
      "        [1.0527],\n",
      "        [1.0679],\n",
      "        [1.0413],\n",
      "        [1.0617],\n",
      "        [1.0778],\n",
      "        [1.0574],\n",
      "        [1.0681],\n",
      "        [1.0175],\n",
      "        [1.0733],\n",
      "        [1.0326],\n",
      "        [1.0268],\n",
      "        [1.0435],\n",
      "        [1.0428],\n",
      "        [1.0670],\n",
      "        [1.0554],\n",
      "        [1.0749],\n",
      "        [1.0737],\n",
      "        [1.0749],\n",
      "        [1.0231],\n",
      "        [1.0627],\n",
      "        [1.0005],\n",
      "        [1.0541],\n",
      "        [1.0463],\n",
      "        [1.0077],\n",
      "        [1.0648],\n",
      "        [1.0710],\n",
      "        [1.0511],\n",
      "        [1.0056],\n",
      "        [1.0745],\n",
      "        [1.0283],\n",
      "        [1.0442],\n",
      "        [1.0275],\n",
      "        [1.0438],\n",
      "        [1.0484],\n",
      "        [1.0557],\n",
      "        [1.0587],\n",
      "        [1.0202],\n",
      "        [1.0373],\n",
      "        [1.0425],\n",
      "        [1.0537],\n",
      "        [1.0548],\n",
      "        [1.0330],\n",
      "        [1.0583],\n",
      "        [1.0749],\n",
      "        [1.0771],\n",
      "        [1.0599],\n",
      "        [1.0674],\n",
      "        [1.0251],\n",
      "        [1.0408],\n",
      "        [1.0609],\n",
      "        [1.0513],\n",
      "        [1.0642],\n",
      "        [1.0131],\n",
      "        [1.0388],\n",
      "        [1.0539],\n",
      "        [1.0759],\n",
      "        [1.0572],\n",
      "        [1.0382],\n",
      "        [1.0573],\n",
      "        [1.0626],\n",
      "        [1.0382],\n",
      "        [1.0579]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0449],\n",
      "        [1.0435],\n",
      "        [1.0296],\n",
      "        [1.0354],\n",
      "        [1.0074],\n",
      "        [1.0497],\n",
      "        [1.0199],\n",
      "        [1.0725],\n",
      "        [1.0340],\n",
      "        [1.0242],\n",
      "        [1.0016],\n",
      "        [1.0539],\n",
      "        [1.0529],\n",
      "        [1.0403],\n",
      "        [1.0674],\n",
      "        [1.0481],\n",
      "        [1.0500],\n",
      "        [1.0160],\n",
      "        [1.0376],\n",
      "        [1.0533],\n",
      "        [1.0485],\n",
      "        [1.0221],\n",
      "        [1.0506],\n",
      "        [1.0075],\n",
      "        [1.0733],\n",
      "        [1.0454],\n",
      "        [1.0489],\n",
      "        [1.0319],\n",
      "        [1.0587],\n",
      "        [1.0439],\n",
      "        [0.9898],\n",
      "        [1.0505],\n",
      "        [1.0514],\n",
      "        [1.0431],\n",
      "        [1.0500],\n",
      "        [1.0521],\n",
      "        [1.0371],\n",
      "        [1.0258],\n",
      "        [1.0368],\n",
      "        [1.0682],\n",
      "        [1.0187],\n",
      "        [1.0590],\n",
      "        [1.0669],\n",
      "        [1.0595],\n",
      "        [1.0297],\n",
      "        [1.0354],\n",
      "        [1.0389],\n",
      "        [1.0589],\n",
      "        [1.0494],\n",
      "        [1.0471],\n",
      "        [1.0154],\n",
      "        [1.0755],\n",
      "        [0.9772],\n",
      "        [1.0588],\n",
      "        [0.9836],\n",
      "        [1.0344],\n",
      "        [1.0719],\n",
      "        [1.0368],\n",
      "        [1.0112],\n",
      "        [1.0406],\n",
      "        [1.0756],\n",
      "        [1.0764],\n",
      "        [1.0662],\n",
      "        [1.0538],\n",
      "        [1.0306],\n",
      "        [1.0419],\n",
      "        [1.0570],\n",
      "        [1.0292],\n",
      "        [1.0373],\n",
      "        [1.0344],\n",
      "        [1.0514],\n",
      "        [1.0449],\n",
      "        [1.0481],\n",
      "        [1.0639],\n",
      "        [1.0556],\n",
      "        [1.0072],\n",
      "        [1.0569],\n",
      "        [1.0617],\n",
      "        [1.0447],\n",
      "        [1.0739],\n",
      "        [1.0191],\n",
      "        [1.0283],\n",
      "        [1.0374],\n",
      "        [1.0469],\n",
      "        [1.0719],\n",
      "        [1.0259],\n",
      "        [1.0401],\n",
      "        [1.0725],\n",
      "        [1.0591],\n",
      "        [1.0208],\n",
      "        [1.0183],\n",
      "        [1.0136],\n",
      "        [1.0455],\n",
      "        [1.0253],\n",
      "        [1.0754],\n",
      "        [1.0640],\n",
      "        [1.0678],\n",
      "        [1.0407],\n",
      "        [1.0088],\n",
      "        [1.0538],\n",
      "        [1.0747],\n",
      "        [1.0747],\n",
      "        [1.0443],\n",
      "        [1.0221],\n",
      "        [1.0243],\n",
      "        [1.0633],\n",
      "        [1.0462],\n",
      "        [1.0807],\n",
      "        [0.9932],\n",
      "        [0.9863],\n",
      "        [1.0629],\n",
      "        [1.0629],\n",
      "        [1.0528],\n",
      "        [1.0577],\n",
      "        [0.2301],\n",
      "        [1.0637],\n",
      "        [1.0479],\n",
      "        [1.0751],\n",
      "        [1.0581],\n",
      "        [1.0569],\n",
      "        [1.0374],\n",
      "        [1.0190],\n",
      "        [1.0057],\n",
      "        [1.0390],\n",
      "        [1.0165],\n",
      "        [1.0462],\n",
      "        [1.0392],\n",
      "        [0.9900]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0361],\n",
      "        [1.0323],\n",
      "        [1.0450],\n",
      "        [1.0060],\n",
      "        [1.0714],\n",
      "        [1.0645],\n",
      "        [1.0091],\n",
      "        [1.0483],\n",
      "        [1.0293],\n",
      "        [1.0645],\n",
      "        [1.0403],\n",
      "        [1.0346],\n",
      "        [1.0518],\n",
      "        [1.0354],\n",
      "        [1.0609],\n",
      "        [1.0507],\n",
      "        [1.0620],\n",
      "        [1.0768],\n",
      "        [1.0704],\n",
      "        [1.0183],\n",
      "        [1.0279],\n",
      "        [1.0091],\n",
      "        [1.0534],\n",
      "        [1.0317],\n",
      "        [1.0333],\n",
      "        [1.0484],\n",
      "        [1.0288],\n",
      "        [1.0522],\n",
      "        [1.0492],\n",
      "        [1.0522],\n",
      "        [1.0650],\n",
      "        [1.0628],\n",
      "        [1.0514],\n",
      "        [1.0714],\n",
      "        [1.0748],\n",
      "        [1.0110],\n",
      "        [1.0520],\n",
      "        [1.0392],\n",
      "        [1.0673],\n",
      "        [1.0282],\n",
      "        [1.0609],\n",
      "        [1.0565],\n",
      "        [1.0752],\n",
      "        [1.0139],\n",
      "        [1.0342],\n",
      "        [1.0775],\n",
      "        [1.0470],\n",
      "        [1.0599],\n",
      "        [1.0594],\n",
      "        [1.0541],\n",
      "        [1.0402],\n",
      "        [1.0462],\n",
      "        [1.0372],\n",
      "        [1.0660],\n",
      "        [1.0431],\n",
      "        [1.0588],\n",
      "        [1.0127],\n",
      "        [1.0599],\n",
      "        [1.0217],\n",
      "        [1.0653],\n",
      "        [1.0575],\n",
      "        [1.0390],\n",
      "        [1.0654],\n",
      "        [1.0590],\n",
      "        [1.0535],\n",
      "        [1.0646],\n",
      "        [1.0649],\n",
      "        [1.0675],\n",
      "        [1.0561],\n",
      "        [1.0393],\n",
      "        [1.0344],\n",
      "        [1.0467],\n",
      "        [1.0433],\n",
      "        [1.0666],\n",
      "        [1.0471],\n",
      "        [1.0135],\n",
      "        [1.0356],\n",
      "        [1.0574],\n",
      "        [1.0703],\n",
      "        [1.0446],\n",
      "        [1.0644],\n",
      "        [1.0380],\n",
      "        [1.0345],\n",
      "        [1.0730],\n",
      "        [1.0472],\n",
      "        [1.0441],\n",
      "        [1.0559],\n",
      "        [1.0590],\n",
      "        [0.9924],\n",
      "        [1.0579],\n",
      "        [1.0540],\n",
      "        [1.0521],\n",
      "        [1.0344],\n",
      "        [1.0732],\n",
      "        [1.0506],\n",
      "        [1.0363],\n",
      "        [1.0375],\n",
      "        [1.0510],\n",
      "        [1.0392],\n",
      "        [1.0508],\n",
      "        [1.0546],\n",
      "        [1.0227],\n",
      "        [1.0582],\n",
      "        [1.0642],\n",
      "        [1.0232],\n",
      "        [1.0425],\n",
      "        [1.0536],\n",
      "        [1.0558],\n",
      "        [1.0787],\n",
      "        [1.0456],\n",
      "        [1.0368],\n",
      "        [1.0283],\n",
      "        [1.0338],\n",
      "        [1.0722],\n",
      "        [1.0340],\n",
      "        [1.0492],\n",
      "        [1.0683],\n",
      "        [1.0571],\n",
      "        [1.0688],\n",
      "        [1.0272],\n",
      "        [1.0399],\n",
      "        [1.0788],\n",
      "        [1.0751],\n",
      "        [1.0560],\n",
      "        [1.0561],\n",
      "        [1.0362],\n",
      "        [1.0356],\n",
      "        [1.0414]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0294],\n",
      "        [1.0445],\n",
      "        [1.0727],\n",
      "        [1.0311],\n",
      "        [1.0622],\n",
      "        [1.0503],\n",
      "        [0.9916],\n",
      "        [1.0462],\n",
      "        [1.0425],\n",
      "        [1.0509],\n",
      "        [1.0481],\n",
      "        [1.0653],\n",
      "        [1.0488],\n",
      "        [1.0593],\n",
      "        [1.0643],\n",
      "        [1.0605],\n",
      "        [1.0261],\n",
      "        [1.0653],\n",
      "        [1.0411],\n",
      "        [1.0566],\n",
      "        [1.0364],\n",
      "        [1.0341],\n",
      "        [1.0408],\n",
      "        [1.0577],\n",
      "        [1.0357],\n",
      "        [1.0647],\n",
      "        [1.0706],\n",
      "        [1.0614],\n",
      "        [1.0498],\n",
      "        [1.0374],\n",
      "        [1.0688],\n",
      "        [1.0141],\n",
      "        [0.9980],\n",
      "        [1.0678],\n",
      "        [1.0495],\n",
      "        [1.0705],\n",
      "        [1.0127],\n",
      "        [1.0333],\n",
      "        [1.0634],\n",
      "        [1.0429],\n",
      "        [1.0543],\n",
      "        [1.0384],\n",
      "        [1.0464],\n",
      "        [1.0372],\n",
      "        [1.0202],\n",
      "        [1.0310],\n",
      "        [1.0700],\n",
      "        [1.0351],\n",
      "        [1.0394],\n",
      "        [1.0499],\n",
      "        [1.0492],\n",
      "        [1.0089],\n",
      "        [1.0606],\n",
      "        [1.0435],\n",
      "        [1.0420],\n",
      "        [1.0364],\n",
      "        [1.0357],\n",
      "        [1.0240],\n",
      "        [1.0235],\n",
      "        [1.0536],\n",
      "        [1.0715],\n",
      "        [1.0441],\n",
      "        [1.0344],\n",
      "        [1.0435],\n",
      "        [1.0163],\n",
      "        [1.0705],\n",
      "        [1.0644],\n",
      "        [1.0406],\n",
      "        [1.0677],\n",
      "        [1.0671],\n",
      "        [1.0523],\n",
      "        [1.0372],\n",
      "        [1.0094],\n",
      "        [1.0615],\n",
      "        [1.0338],\n",
      "        [1.0555],\n",
      "        [1.0711],\n",
      "        [1.0522],\n",
      "        [1.0150],\n",
      "        [1.0201],\n",
      "        [1.0434],\n",
      "        [1.0400],\n",
      "        [1.0344],\n",
      "        [1.0627],\n",
      "        [1.0423],\n",
      "        [0.9825],\n",
      "        [1.0547],\n",
      "        [1.0567],\n",
      "        [1.0520],\n",
      "        [1.0413],\n",
      "        [1.0545],\n",
      "        [1.0462],\n",
      "        [1.0204],\n",
      "        [1.0338],\n",
      "        [1.0534],\n",
      "        [1.0284],\n",
      "        [1.0478],\n",
      "        [1.0585],\n",
      "        [1.0534],\n",
      "        [1.0503],\n",
      "        [1.0582],\n",
      "        [0.9845],\n",
      "        [1.0779],\n",
      "        [1.0235],\n",
      "        [1.0646],\n",
      "        [1.0735],\n",
      "        [1.0303],\n",
      "        [1.0554],\n",
      "        [1.0670],\n",
      "        [1.0544],\n",
      "        [1.0171],\n",
      "        [1.0539],\n",
      "        [1.0557],\n",
      "        [1.0150],\n",
      "        [1.0735],\n",
      "        [0.9962],\n",
      "        [1.0532],\n",
      "        [1.0561],\n",
      "        [1.0682],\n",
      "        [1.0482],\n",
      "        [1.0145],\n",
      "        [1.0644],\n",
      "        [0.9763],\n",
      "        [1.0729],\n",
      "        [1.0579],\n",
      "        [1.0567],\n",
      "        [1.0045],\n",
      "        [1.0123]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0542],\n",
      "        [1.0153],\n",
      "        [1.0531],\n",
      "        [1.0636]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  32 | lr 0.00100 train_loss 2.13008 | val_loss 2.30566 | val_rmse 1.51844\n",
      "tensor([[1.0713],\n",
      "        [1.0682],\n",
      "        [1.0105],\n",
      "        [1.0482],\n",
      "        [1.0247],\n",
      "        [1.0140],\n",
      "        [1.0693],\n",
      "        [1.0452],\n",
      "        [0.9997],\n",
      "        [1.0351],\n",
      "        [0.9686],\n",
      "        [1.0593],\n",
      "        [1.0444],\n",
      "        [1.0477],\n",
      "        [1.0241],\n",
      "        [1.0520],\n",
      "        [1.0384],\n",
      "        [1.0550],\n",
      "        [1.0265],\n",
      "        [1.0545],\n",
      "        [1.0503],\n",
      "        [1.0327],\n",
      "        [1.0383],\n",
      "        [1.0623],\n",
      "        [1.0574],\n",
      "        [1.0286],\n",
      "        [1.0544],\n",
      "        [1.0680],\n",
      "        [0.9878],\n",
      "        [1.0490],\n",
      "        [1.0484],\n",
      "        [1.0152],\n",
      "        [1.0412],\n",
      "        [1.0670],\n",
      "        [1.0760],\n",
      "        [1.0624],\n",
      "        [1.0676],\n",
      "        [1.0436],\n",
      "        [1.0769],\n",
      "        [1.0501],\n",
      "        [1.0771],\n",
      "        [1.0681],\n",
      "        [1.0405],\n",
      "        [1.0721],\n",
      "        [1.0491],\n",
      "        [1.0459],\n",
      "        [1.0749],\n",
      "        [1.0678],\n",
      "        [1.0535],\n",
      "        [1.0303],\n",
      "        [1.0386],\n",
      "        [1.0644],\n",
      "        [1.0766],\n",
      "        [1.0774],\n",
      "        [1.0735],\n",
      "        [1.0735],\n",
      "        [1.0585],\n",
      "        [1.0572],\n",
      "        [1.0365],\n",
      "        [1.0695],\n",
      "        [1.0728],\n",
      "        [1.0563],\n",
      "        [1.0745],\n",
      "        [1.0542],\n",
      "        [1.0803],\n",
      "        [1.0619],\n",
      "        [1.0593],\n",
      "        [1.0750],\n",
      "        [1.0768],\n",
      "        [1.0578],\n",
      "        [1.0643],\n",
      "        [1.0345],\n",
      "        [1.0617],\n",
      "        [1.0722],\n",
      "        [1.0545],\n",
      "        [1.0631],\n",
      "        [1.0544],\n",
      "        [1.0559],\n",
      "        [1.0631],\n",
      "        [1.0733],\n",
      "        [1.0766],\n",
      "        [1.0676],\n",
      "        [1.0181],\n",
      "        [1.0468],\n",
      "        [1.0791],\n",
      "        [1.0604],\n",
      "        [1.0576],\n",
      "        [1.0700],\n",
      "        [1.0379],\n",
      "        [1.0584],\n",
      "        [1.0520],\n",
      "        [1.0618],\n",
      "        [1.0731],\n",
      "        [1.0762],\n",
      "        [1.0223],\n",
      "        [1.0715],\n",
      "        [1.0585],\n",
      "        [1.0723],\n",
      "        [1.0287],\n",
      "        [1.0064],\n",
      "        [1.0288],\n",
      "        [1.0548],\n",
      "        [1.0436],\n",
      "        [1.0499],\n",
      "        [1.0730],\n",
      "        [1.0754],\n",
      "        [1.0587],\n",
      "        [1.0436],\n",
      "        [1.0517],\n",
      "        [1.0584],\n",
      "        [1.0298],\n",
      "        [1.0430],\n",
      "        [1.0220],\n",
      "        [1.0330],\n",
      "        [1.0629],\n",
      "        [1.0663],\n",
      "        [1.0569],\n",
      "        [0.9912],\n",
      "        [1.0215],\n",
      "        [1.0422],\n",
      "        [1.0665],\n",
      "        [1.0234],\n",
      "        [1.0344],\n",
      "        [1.0502],\n",
      "        [1.0265],\n",
      "        [1.0517],\n",
      "        [1.0541],\n",
      "        [1.0537]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0359],\n",
      "        [1.0818],\n",
      "        [1.0356],\n",
      "        [1.0730],\n",
      "        [1.0679],\n",
      "        [1.0634],\n",
      "        [1.0743],\n",
      "        [1.0421],\n",
      "        [1.0757],\n",
      "        [0.9893],\n",
      "        [1.0738],\n",
      "        [1.0593],\n",
      "        [1.0742],\n",
      "        [1.0289],\n",
      "        [1.0691],\n",
      "        [1.0267],\n",
      "        [1.0163],\n",
      "        [1.0463],\n",
      "        [1.0791],\n",
      "        [1.0533],\n",
      "        [1.0306],\n",
      "        [1.0839],\n",
      "        [1.0721],\n",
      "        [1.0480],\n",
      "        [1.0576],\n",
      "        [1.0684],\n",
      "        [1.0620],\n",
      "        [1.0407],\n",
      "        [1.0812],\n",
      "        [1.0705],\n",
      "        [1.0562],\n",
      "        [1.0817],\n",
      "        [1.0759],\n",
      "        [1.0615],\n",
      "        [1.0391],\n",
      "        [1.0710],\n",
      "        [1.0536],\n",
      "        [1.0708],\n",
      "        [1.0685],\n",
      "        [0.9889],\n",
      "        [1.0586],\n",
      "        [1.0815],\n",
      "        [1.0792],\n",
      "        [1.0649],\n",
      "        [1.0265],\n",
      "        [1.0470],\n",
      "        [1.0706],\n",
      "        [1.0469],\n",
      "        [1.0205],\n",
      "        [1.0335],\n",
      "        [0.9999],\n",
      "        [1.0277],\n",
      "        [1.0457],\n",
      "        [1.0419],\n",
      "        [1.0638],\n",
      "        [1.0612],\n",
      "        [1.0350],\n",
      "        [1.0683],\n",
      "        [1.0736],\n",
      "        [1.0307],\n",
      "        [1.0825],\n",
      "        [1.0700],\n",
      "        [1.0759],\n",
      "        [1.0594],\n",
      "        [0.9872],\n",
      "        [1.0722],\n",
      "        [1.0172],\n",
      "        [1.0189],\n",
      "        [1.0806],\n",
      "        [1.0471],\n",
      "        [1.0580],\n",
      "        [1.0531],\n",
      "        [1.0694],\n",
      "        [1.0462],\n",
      "        [1.0530],\n",
      "        [1.0457],\n",
      "        [1.0500],\n",
      "        [1.0330],\n",
      "        [1.0714],\n",
      "        [1.0334],\n",
      "        [1.0566],\n",
      "        [1.0631],\n",
      "        [1.0372],\n",
      "        [1.0507],\n",
      "        [1.0686],\n",
      "        [1.0550],\n",
      "        [1.0718],\n",
      "        [1.0680],\n",
      "        [1.0224],\n",
      "        [1.0687],\n",
      "        [1.0721],\n",
      "        [1.0439],\n",
      "        [1.0614],\n",
      "        [1.0314],\n",
      "        [1.0633],\n",
      "        [1.0550],\n",
      "        [1.0799],\n",
      "        [1.0472],\n",
      "        [1.0591],\n",
      "        [1.0447],\n",
      "        [1.0746],\n",
      "        [1.0664],\n",
      "        [1.0703],\n",
      "        [1.0622],\n",
      "        [1.0473],\n",
      "        [1.0743],\n",
      "        [1.0348],\n",
      "        [1.0555],\n",
      "        [1.0415],\n",
      "        [1.0399],\n",
      "        [1.0353],\n",
      "        [1.0343],\n",
      "        [1.0535],\n",
      "        [1.0697],\n",
      "        [1.0227],\n",
      "        [1.0673],\n",
      "        [1.0455],\n",
      "        [1.0634],\n",
      "        [1.0285],\n",
      "        [1.0467],\n",
      "        [1.0670],\n",
      "        [1.0778],\n",
      "        [1.0691],\n",
      "        [1.0618],\n",
      "        [1.0742],\n",
      "        [1.0668],\n",
      "        [1.0344],\n",
      "        [1.0414]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0785],\n",
      "        [1.0677],\n",
      "        [0.9943],\n",
      "        [1.0582],\n",
      "        [1.0659],\n",
      "        [1.0430],\n",
      "        [1.0639],\n",
      "        [1.0730],\n",
      "        [1.0674],\n",
      "        [1.0752],\n",
      "        [1.0421],\n",
      "        [1.0222],\n",
      "        [1.0579],\n",
      "        [1.0864],\n",
      "        [1.0204],\n",
      "        [1.0604],\n",
      "        [1.0429],\n",
      "        [1.0631],\n",
      "        [1.0823],\n",
      "        [1.0417],\n",
      "        [1.0634],\n",
      "        [1.0765],\n",
      "        [1.0149],\n",
      "        [1.0509],\n",
      "        [1.0564],\n",
      "        [1.0710],\n",
      "        [1.0524],\n",
      "        [1.0435],\n",
      "        [1.0652],\n",
      "        [1.0496],\n",
      "        [1.0795],\n",
      "        [1.0237],\n",
      "        [1.0863],\n",
      "        [1.0623],\n",
      "        [1.0516],\n",
      "        [1.0766],\n",
      "        [1.0385],\n",
      "        [1.0727],\n",
      "        [1.0769],\n",
      "        [1.0439],\n",
      "        [1.0494],\n",
      "        [1.0130],\n",
      "        [1.0441],\n",
      "        [1.0487],\n",
      "        [1.0672],\n",
      "        [1.0318],\n",
      "        [1.0607],\n",
      "        [1.0597],\n",
      "        [1.0023],\n",
      "        [1.0811],\n",
      "        [1.0739],\n",
      "        [1.0557],\n",
      "        [1.0806],\n",
      "        [1.0541],\n",
      "        [1.0819],\n",
      "        [1.0820],\n",
      "        [1.0645],\n",
      "        [1.0540],\n",
      "        [1.0707],\n",
      "        [1.0667],\n",
      "        [1.0622],\n",
      "        [1.0126],\n",
      "        [1.0616],\n",
      "        [0.9943],\n",
      "        [1.0779],\n",
      "        [1.0833],\n",
      "        [1.0444],\n",
      "        [1.0421],\n",
      "        [1.0618],\n",
      "        [1.0344],\n",
      "        [1.0822],\n",
      "        [1.0865],\n",
      "        [1.0783],\n",
      "        [1.0668],\n",
      "        [1.0324],\n",
      "        [1.0828],\n",
      "        [1.0653],\n",
      "        [1.0638],\n",
      "        [1.0473],\n",
      "        [1.0558],\n",
      "        [1.0493],\n",
      "        [1.0694],\n",
      "        [1.0623],\n",
      "        [1.0607],\n",
      "        [1.0602],\n",
      "        [1.0752],\n",
      "        [1.0187],\n",
      "        [1.0216],\n",
      "        [1.0854],\n",
      "        [1.0573],\n",
      "        [1.0528],\n",
      "        [1.0636],\n",
      "        [1.0705],\n",
      "        [1.0430],\n",
      "        [1.0775],\n",
      "        [1.0779],\n",
      "        [1.0712],\n",
      "        [1.0534],\n",
      "        [1.0676],\n",
      "        [1.0710],\n",
      "        [1.0648],\n",
      "        [1.0891],\n",
      "        [1.0480],\n",
      "        [1.0732],\n",
      "        [1.0558],\n",
      "        [1.0435],\n",
      "        [1.0831],\n",
      "        [1.0456],\n",
      "        [1.0759],\n",
      "        [1.0316],\n",
      "        [1.0554],\n",
      "        [1.0053],\n",
      "        [1.0589],\n",
      "        [1.0571],\n",
      "        [1.0589],\n",
      "        [1.0873],\n",
      "        [1.0339],\n",
      "        [1.0651],\n",
      "        [1.0638],\n",
      "        [1.0639],\n",
      "        [1.0762],\n",
      "        [1.0638],\n",
      "        [1.0209],\n",
      "        [1.0830],\n",
      "        [1.0197],\n",
      "        [1.0573],\n",
      "        [1.0792],\n",
      "        [1.0866]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0538],\n",
      "        [1.0778],\n",
      "        [1.0829],\n",
      "        [1.0812],\n",
      "        [1.0506],\n",
      "        [1.0872],\n",
      "        [1.0150],\n",
      "        [1.0570],\n",
      "        [1.0473],\n",
      "        [1.0475],\n",
      "        [1.0619],\n",
      "        [1.0742],\n",
      "        [1.0530],\n",
      "        [1.0585],\n",
      "        [1.0180],\n",
      "        [1.0753],\n",
      "        [1.0887],\n",
      "        [1.0599],\n",
      "        [1.0759],\n",
      "        [1.0567],\n",
      "        [1.0788],\n",
      "        [1.0707],\n",
      "        [1.0612],\n",
      "        [1.0637],\n",
      "        [1.0852],\n",
      "        [1.0910],\n",
      "        [1.0234],\n",
      "        [1.0422],\n",
      "        [1.0762],\n",
      "        [1.0823],\n",
      "        [0.0290],\n",
      "        [1.0855],\n",
      "        [1.0387],\n",
      "        [1.0883],\n",
      "        [1.0524],\n",
      "        [1.0686],\n",
      "        [1.0511],\n",
      "        [1.0696],\n",
      "        [1.0571],\n",
      "        [1.0644],\n",
      "        [1.0674],\n",
      "        [1.0611],\n",
      "        [1.0720],\n",
      "        [1.0074],\n",
      "        [1.0707],\n",
      "        [1.0798],\n",
      "        [1.0652],\n",
      "        [1.0497],\n",
      "        [1.0263],\n",
      "        [1.1961],\n",
      "        [1.0543],\n",
      "        [1.0718],\n",
      "        [1.0563],\n",
      "        [1.0291],\n",
      "        [1.0736],\n",
      "        [1.0536],\n",
      "        [1.0713],\n",
      "        [1.0783],\n",
      "        [1.0593],\n",
      "        [1.0854],\n",
      "        [1.0731],\n",
      "        [1.0758],\n",
      "        [1.0476],\n",
      "        [1.0491],\n",
      "        [1.0478],\n",
      "        [1.0543],\n",
      "        [1.0333],\n",
      "        [1.0237],\n",
      "        [1.0577],\n",
      "        [1.0761],\n",
      "        [1.0686],\n",
      "        [1.0824],\n",
      "        [1.0504],\n",
      "        [1.0893],\n",
      "        [1.0563],\n",
      "        [1.0252],\n",
      "        [1.0695],\n",
      "        [1.0810],\n",
      "        [1.0570],\n",
      "        [1.0106],\n",
      "        [1.0396],\n",
      "        [1.0487],\n",
      "        [1.0744],\n",
      "        [1.0567],\n",
      "        [1.0876],\n",
      "        [1.0784],\n",
      "        [0.9981],\n",
      "        [1.0483],\n",
      "        [1.0626],\n",
      "        [1.0411],\n",
      "        [1.0451],\n",
      "        [1.0802],\n",
      "        [1.0543],\n",
      "        [1.0756],\n",
      "        [1.0366],\n",
      "        [1.0765],\n",
      "        [1.0827],\n",
      "        [1.0749],\n",
      "        [1.0735],\n",
      "        [1.0769],\n",
      "        [1.0251],\n",
      "        [1.0550],\n",
      "        [1.0296],\n",
      "        [1.0325],\n",
      "        [1.0470],\n",
      "        [1.0738],\n",
      "        [1.0722],\n",
      "        [1.0846],\n",
      "        [1.0765],\n",
      "        [1.0692],\n",
      "        [1.0137],\n",
      "        [1.0729],\n",
      "        [1.0545],\n",
      "        [1.0349],\n",
      "        [1.0578],\n",
      "        [1.0682],\n",
      "        [1.0806],\n",
      "        [1.0772],\n",
      "        [1.0542],\n",
      "        [1.0418],\n",
      "        [1.0848],\n",
      "        [1.0883],\n",
      "        [1.0810],\n",
      "        [1.0630],\n",
      "        [1.0877],\n",
      "        [1.0501],\n",
      "        [0.9954],\n",
      "        [1.0350]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0861],\n",
      "        [1.0906],\n",
      "        [1.0404],\n",
      "        [1.0670],\n",
      "        [1.0671],\n",
      "        [1.0688],\n",
      "        [1.0946],\n",
      "        [1.0705],\n",
      "        [1.0820],\n",
      "        [1.0531],\n",
      "        [1.0709],\n",
      "        [1.0886],\n",
      "        [1.0961],\n",
      "        [1.0756],\n",
      "        [1.0473],\n",
      "        [1.0722],\n",
      "        [1.0824],\n",
      "        [1.0808],\n",
      "        [1.0648],\n",
      "        [1.0322],\n",
      "        [1.0811],\n",
      "        [1.0715],\n",
      "        [1.0678],\n",
      "        [1.0917],\n",
      "        [1.0789],\n",
      "        [1.0795],\n",
      "        [1.0814],\n",
      "        [1.0824],\n",
      "        [1.0672],\n",
      "        [1.0133],\n",
      "        [1.0769],\n",
      "        [1.0899],\n",
      "        [1.0363],\n",
      "        [1.0586],\n",
      "        [1.0520],\n",
      "        [1.0138],\n",
      "        [1.0934],\n",
      "        [1.0765],\n",
      "        [1.0905],\n",
      "        [1.0705],\n",
      "        [1.0941],\n",
      "        [1.0685],\n",
      "        [1.0684],\n",
      "        [1.0647],\n",
      "        [1.0236],\n",
      "        [1.0550],\n",
      "        [1.0624],\n",
      "        [1.0870],\n",
      "        [1.0675],\n",
      "        [1.0581],\n",
      "        [1.0003],\n",
      "        [1.0824],\n",
      "        [1.0963],\n",
      "        [1.0903],\n",
      "        [1.0777],\n",
      "        [1.0405],\n",
      "        [1.0742],\n",
      "        [1.0711],\n",
      "        [1.0562],\n",
      "        [1.0863],\n",
      "        [1.0644],\n",
      "        [1.0826],\n",
      "        [1.0791],\n",
      "        [1.0357],\n",
      "        [1.0829],\n",
      "        [1.0807],\n",
      "        [1.0667],\n",
      "        [1.0638],\n",
      "        [1.0949],\n",
      "        [1.0668],\n",
      "        [1.0610],\n",
      "        [1.0671],\n",
      "        [1.0653],\n",
      "        [1.0743],\n",
      "        [1.0947],\n",
      "        [1.0485],\n",
      "        [1.0773],\n",
      "        [0.9823],\n",
      "        [1.0830],\n",
      "        [1.0866],\n",
      "        [1.0700],\n",
      "        [1.0668],\n",
      "        [1.0469],\n",
      "        [1.0741],\n",
      "        [1.0625],\n",
      "        [1.0854],\n",
      "        [1.0674],\n",
      "        [1.0828],\n",
      "        [1.0786],\n",
      "        [1.0974],\n",
      "        [1.0606],\n",
      "        [1.0768],\n",
      "        [1.0690],\n",
      "        [1.0793],\n",
      "        [1.0606],\n",
      "        [1.0466],\n",
      "        [1.0471],\n",
      "        [1.0816],\n",
      "        [1.0483],\n",
      "        [1.0923],\n",
      "        [1.0381],\n",
      "        [1.0916],\n",
      "        [1.0558],\n",
      "        [1.0801],\n",
      "        [1.0897],\n",
      "        [1.0778],\n",
      "        [1.0851],\n",
      "        [1.0842],\n",
      "        [1.0816],\n",
      "        [1.0477],\n",
      "        [0.9972],\n",
      "        [1.0747],\n",
      "        [1.0584],\n",
      "        [1.0459],\n",
      "        [1.0211],\n",
      "        [1.0821],\n",
      "        [1.0810],\n",
      "        [1.0553],\n",
      "        [1.0510],\n",
      "        [1.0421],\n",
      "        [1.0869],\n",
      "        [1.0744],\n",
      "        [1.0513],\n",
      "        [1.0880],\n",
      "        [1.0924],\n",
      "        [0.7362],\n",
      "        [1.0781],\n",
      "        [1.0513]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0743],\n",
      "        [1.0454],\n",
      "        [1.0675],\n",
      "        [1.0720],\n",
      "        [1.0492],\n",
      "        [1.0598],\n",
      "        [1.0901],\n",
      "        [1.0842],\n",
      "        [1.0753],\n",
      "        [1.0999],\n",
      "        [1.0851],\n",
      "        [1.0513],\n",
      "        [1.0618],\n",
      "        [1.0890],\n",
      "        [1.0881],\n",
      "        [1.0527],\n",
      "        [1.0517],\n",
      "        [1.0622],\n",
      "        [1.0769],\n",
      "        [1.0547],\n",
      "        [1.0309],\n",
      "        [1.0802],\n",
      "        [1.0955],\n",
      "        [1.0314],\n",
      "        [1.0462],\n",
      "        [1.0957],\n",
      "        [1.0332],\n",
      "        [1.0699],\n",
      "        [1.0834],\n",
      "        [1.0585],\n",
      "        [1.0847],\n",
      "        [1.0873],\n",
      "        [1.0597],\n",
      "        [1.0976],\n",
      "        [1.0969],\n",
      "        [1.0868],\n",
      "        [1.0414],\n",
      "        [1.0829],\n",
      "        [1.0827],\n",
      "        [1.0717],\n",
      "        [1.0667],\n",
      "        [1.0884],\n",
      "        [1.0678],\n",
      "        [1.0785],\n",
      "        [1.0937],\n",
      "        [1.0490],\n",
      "        [1.0524],\n",
      "        [1.0650],\n",
      "        [1.0713],\n",
      "        [1.0649],\n",
      "        [1.0835],\n",
      "        [1.0877],\n",
      "        [1.0696],\n",
      "        [1.0969],\n",
      "        [1.0899],\n",
      "        [1.0209],\n",
      "        [1.0719],\n",
      "        [1.0660],\n",
      "        [1.0956],\n",
      "        [1.0713],\n",
      "        [1.0943],\n",
      "        [1.0578],\n",
      "        [1.0749],\n",
      "        [1.0865],\n",
      "        [1.0938],\n",
      "        [1.0493],\n",
      "        [1.0958],\n",
      "        [1.1017],\n",
      "        [1.0503],\n",
      "        [1.0835],\n",
      "        [1.0638],\n",
      "        [1.0825],\n",
      "        [1.0823],\n",
      "        [1.0743],\n",
      "        [1.0587],\n",
      "        [1.0866],\n",
      "        [1.0936],\n",
      "        [1.0295],\n",
      "        [1.0589],\n",
      "        [1.0817],\n",
      "        [1.0919],\n",
      "        [1.0944],\n",
      "        [1.0565],\n",
      "        [1.0784],\n",
      "        [1.0980],\n",
      "        [1.0910],\n",
      "        [1.0731],\n",
      "        [1.0621],\n",
      "        [1.0839],\n",
      "        [1.0550],\n",
      "        [1.0771],\n",
      "        [1.0792],\n",
      "        [1.0371],\n",
      "        [1.0349],\n",
      "        [1.0475],\n",
      "        [1.0375],\n",
      "        [1.0538],\n",
      "        [1.0769],\n",
      "        [1.0651],\n",
      "        [1.0943],\n",
      "        [1.0863],\n",
      "        [1.0520],\n",
      "        [1.0666],\n",
      "        [1.0811],\n",
      "        [1.0875],\n",
      "        [1.0761],\n",
      "        [1.0352],\n",
      "        [1.0684],\n",
      "        [1.0797],\n",
      "        [1.0929],\n",
      "        [1.0820],\n",
      "        [1.0619],\n",
      "        [1.0969],\n",
      "        [1.0416],\n",
      "        [1.0727],\n",
      "        [1.0814],\n",
      "        [1.0721],\n",
      "        [1.0477],\n",
      "        [1.0746],\n",
      "        [1.0543],\n",
      "        [1.0460],\n",
      "        [1.0602],\n",
      "        [1.0850],\n",
      "        [1.0949],\n",
      "        [1.0668],\n",
      "        [0.9867],\n",
      "        [1.0478],\n",
      "        [1.0431]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0722],\n",
      "        [1.0473],\n",
      "        [1.0208],\n",
      "        [1.0851],\n",
      "        [1.0862],\n",
      "        [1.0808],\n",
      "        [1.0522],\n",
      "        [1.1001],\n",
      "        [1.0813],\n",
      "        [1.0757],\n",
      "        [1.0862],\n",
      "        [1.0536],\n",
      "        [1.0566],\n",
      "        [1.0919],\n",
      "        [1.0647],\n",
      "        [1.0755],\n",
      "        [1.0763],\n",
      "        [1.0577],\n",
      "        [1.0490],\n",
      "        [1.0871],\n",
      "        [1.1027],\n",
      "        [1.1052],\n",
      "        [1.0965],\n",
      "        [1.0230],\n",
      "        [1.0935],\n",
      "        [1.0981],\n",
      "        [1.0759],\n",
      "        [1.0935],\n",
      "        [1.0723],\n",
      "        [1.0528],\n",
      "        [1.0857],\n",
      "        [1.0693],\n",
      "        [1.0249],\n",
      "        [1.1033],\n",
      "        [1.0890],\n",
      "        [1.0999],\n",
      "        [1.0909],\n",
      "        [1.0655],\n",
      "        [1.0905],\n",
      "        [1.0226],\n",
      "        [1.0803],\n",
      "        [1.0904],\n",
      "        [1.0830],\n",
      "        [1.0811],\n",
      "        [1.0799],\n",
      "        [1.0985],\n",
      "        [1.0574],\n",
      "        [1.0857],\n",
      "        [1.0833],\n",
      "        [1.0543],\n",
      "        [1.0871],\n",
      "        [1.0986],\n",
      "        [0.0966],\n",
      "        [1.0723],\n",
      "        [1.0959],\n",
      "        [1.0566],\n",
      "        [1.0827],\n",
      "        [1.0835],\n",
      "        [1.0789],\n",
      "        [1.0494],\n",
      "        [1.0768],\n",
      "        [1.0627],\n",
      "        [1.0925],\n",
      "        [1.0701],\n",
      "        [1.0438],\n",
      "        [1.0900],\n",
      "        [1.0454],\n",
      "        [1.0506],\n",
      "        [1.0796],\n",
      "        [1.0882],\n",
      "        [1.0557],\n",
      "        [1.0794],\n",
      "        [1.1007],\n",
      "        [1.0436],\n",
      "        [1.0657],\n",
      "        [1.0640],\n",
      "        [1.0673],\n",
      "        [1.0183],\n",
      "        [1.0660],\n",
      "        [1.0660],\n",
      "        [1.0923],\n",
      "        [1.0686],\n",
      "        [1.0513],\n",
      "        [1.0699],\n",
      "        [1.0947],\n",
      "        [1.0664],\n",
      "        [1.0784],\n",
      "        [1.0673],\n",
      "        [1.0428],\n",
      "        [1.0599],\n",
      "        [1.0642],\n",
      "        [1.0744],\n",
      "        [1.0610],\n",
      "        [1.0460],\n",
      "        [1.0259],\n",
      "        [1.0947],\n",
      "        [1.0785],\n",
      "        [1.0983],\n",
      "        [1.0693],\n",
      "        [1.1042],\n",
      "        [1.1029],\n",
      "        [1.0754],\n",
      "        [1.0575],\n",
      "        [1.0738],\n",
      "        [1.0829],\n",
      "        [1.0644],\n",
      "        [1.0915],\n",
      "        [1.0515],\n",
      "        [1.0285],\n",
      "        [1.0670],\n",
      "        [1.0903],\n",
      "        [1.0618],\n",
      "        [1.0805],\n",
      "        [1.0932],\n",
      "        [1.0831],\n",
      "        [1.0017],\n",
      "        [1.0938],\n",
      "        [1.0957],\n",
      "        [1.0983],\n",
      "        [1.0486],\n",
      "        [1.0900],\n",
      "        [1.0955],\n",
      "        [1.0757],\n",
      "        [1.0631],\n",
      "        [1.0929],\n",
      "        [1.0811],\n",
      "        [1.0874],\n",
      "        [1.0750]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0752],\n",
      "        [1.0950],\n",
      "        [1.0886],\n",
      "        [1.0786]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  33 | lr 0.00100 train_loss 2.12507 | val_loss 2.29498 | val_rmse 1.51492\n",
      "tensor([[1.0593],\n",
      "        [1.0941],\n",
      "        [1.0817],\n",
      "        [1.1105],\n",
      "        [1.1015],\n",
      "        [1.0628],\n",
      "        [1.0699],\n",
      "        [1.0586],\n",
      "        [1.0823],\n",
      "        [1.0866],\n",
      "        [1.1047],\n",
      "        [1.0159],\n",
      "        [1.0129],\n",
      "        [1.0965],\n",
      "        [1.0539],\n",
      "        [1.0848],\n",
      "        [1.0971],\n",
      "        [1.0403],\n",
      "        [1.1096],\n",
      "        [1.0759],\n",
      "        [1.1059],\n",
      "        [1.0883],\n",
      "        [1.0942],\n",
      "        [1.1058],\n",
      "        [1.0715],\n",
      "        [1.0993],\n",
      "        [1.1047],\n",
      "        [1.0956],\n",
      "        [1.0833],\n",
      "        [1.0933],\n",
      "        [1.0961],\n",
      "        [1.0273],\n",
      "        [1.0911],\n",
      "        [1.0596],\n",
      "        [1.0772],\n",
      "        [1.0827],\n",
      "        [1.0461],\n",
      "        [1.0841],\n",
      "        [1.1095],\n",
      "        [1.0974],\n",
      "        [1.1025],\n",
      "        [1.1093],\n",
      "        [1.0753],\n",
      "        [1.0638],\n",
      "        [1.0751],\n",
      "        [1.0641],\n",
      "        [1.0589],\n",
      "        [1.0860],\n",
      "        [1.0892],\n",
      "        [1.0772],\n",
      "        [1.0635],\n",
      "        [1.0705],\n",
      "        [1.0989],\n",
      "        [1.0647],\n",
      "        [1.0634],\n",
      "        [1.0726],\n",
      "        [1.0733],\n",
      "        [1.0808],\n",
      "        [1.1019],\n",
      "        [1.0698],\n",
      "        [1.0734],\n",
      "        [1.1084],\n",
      "        [1.1098],\n",
      "        [1.1104],\n",
      "        [1.1068],\n",
      "        [1.0610],\n",
      "        [1.0958],\n",
      "        [1.0945],\n",
      "        [1.0721],\n",
      "        [1.0904],\n",
      "        [1.1130],\n",
      "        [1.0488],\n",
      "        [1.0523],\n",
      "        [1.0709],\n",
      "        [1.1078],\n",
      "        [1.0979],\n",
      "        [1.1105],\n",
      "        [1.0825],\n",
      "        [1.0969],\n",
      "        [1.0816],\n",
      "        [1.0334],\n",
      "        [1.0836],\n",
      "        [1.0647],\n",
      "        [1.0992],\n",
      "        [1.0974],\n",
      "        [1.0292],\n",
      "        [1.0727],\n",
      "        [1.1091],\n",
      "        [1.0818],\n",
      "        [1.0815],\n",
      "        [1.0188],\n",
      "        [1.0841],\n",
      "        [1.0987],\n",
      "        [1.0666],\n",
      "        [1.0800],\n",
      "        [0.0028],\n",
      "        [1.0937],\n",
      "        [1.0954],\n",
      "        [1.1043],\n",
      "        [1.1033],\n",
      "        [1.0394],\n",
      "        [1.0945],\n",
      "        [1.0891],\n",
      "        [1.0603],\n",
      "        [1.1057],\n",
      "        [1.1080],\n",
      "        [1.1078],\n",
      "        [1.0938],\n",
      "        [1.0842],\n",
      "        [1.0853],\n",
      "        [1.1105],\n",
      "        [1.0808],\n",
      "        [1.0707],\n",
      "        [1.0572],\n",
      "        [1.0883],\n",
      "        [1.0903],\n",
      "        [1.0707],\n",
      "        [1.1053],\n",
      "        [1.1101],\n",
      "        [1.0354],\n",
      "        [1.0730],\n",
      "        [1.0634],\n",
      "        [1.0771],\n",
      "        [1.0893],\n",
      "        [1.0530],\n",
      "        [1.0906],\n",
      "        [1.0527],\n",
      "        [1.0074]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1050],\n",
      "        [1.1090],\n",
      "        [1.0926],\n",
      "        [1.0883],\n",
      "        [1.0996],\n",
      "        [1.1079],\n",
      "        [1.1030],\n",
      "        [1.0313],\n",
      "        [1.0750],\n",
      "        [1.0683],\n",
      "        [1.0808],\n",
      "        [1.0901],\n",
      "        [1.0661],\n",
      "        [1.0958],\n",
      "        [1.0557],\n",
      "        [1.0920],\n",
      "        [1.1033],\n",
      "        [1.1110],\n",
      "        [1.1045],\n",
      "        [1.0763],\n",
      "        [1.0941],\n",
      "        [1.0669],\n",
      "        [1.0903],\n",
      "        [1.0903],\n",
      "        [1.0634],\n",
      "        [1.0450],\n",
      "        [1.1047],\n",
      "        [1.0865],\n",
      "        [1.0761],\n",
      "        [1.0884],\n",
      "        [1.0686],\n",
      "        [1.0951],\n",
      "        [1.0882],\n",
      "        [1.0785],\n",
      "        [1.0915],\n",
      "        [1.1132],\n",
      "        [1.0989],\n",
      "        [1.0816],\n",
      "        [1.0300],\n",
      "        [1.0769],\n",
      "        [1.0829],\n",
      "        [1.0734],\n",
      "        [1.0771],\n",
      "        [1.0293],\n",
      "        [1.0767],\n",
      "        [1.0692],\n",
      "        [1.0908],\n",
      "        [1.0911],\n",
      "        [1.0717],\n",
      "        [1.0349],\n",
      "        [1.0577],\n",
      "        [1.0368],\n",
      "        [1.1036],\n",
      "        [1.1093],\n",
      "        [1.1105],\n",
      "        [1.1006],\n",
      "        [1.0496],\n",
      "        [1.0163],\n",
      "        [1.0894],\n",
      "        [1.0916],\n",
      "        [1.0656],\n",
      "        [1.0089],\n",
      "        [1.0722],\n",
      "        [1.0911],\n",
      "        [1.0692],\n",
      "        [1.0767],\n",
      "        [1.0522],\n",
      "        [1.0855],\n",
      "        [1.0876],\n",
      "        [1.1080],\n",
      "        [1.1040],\n",
      "        [1.0765],\n",
      "        [1.0626],\n",
      "        [1.0963],\n",
      "        [1.0830],\n",
      "        [1.0939],\n",
      "        [1.0847],\n",
      "        [1.0947],\n",
      "        [1.0909],\n",
      "        [1.0408],\n",
      "        [1.0625],\n",
      "        [1.0988],\n",
      "        [1.0808],\n",
      "        [1.0793],\n",
      "        [1.0805],\n",
      "        [1.0768],\n",
      "        [1.0966],\n",
      "        [1.0889],\n",
      "        [1.0819],\n",
      "        [1.0759],\n",
      "        [1.1035],\n",
      "        [1.0404],\n",
      "        [1.1080],\n",
      "        [1.0920],\n",
      "        [1.0772],\n",
      "        [1.0648],\n",
      "        [1.0944],\n",
      "        [1.0962],\n",
      "        [1.0921],\n",
      "        [1.0816],\n",
      "        [1.1110],\n",
      "        [1.0679],\n",
      "        [1.0895],\n",
      "        [1.0856],\n",
      "        [1.0647],\n",
      "        [1.0198],\n",
      "        [1.0915],\n",
      "        [1.0678],\n",
      "        [1.1014],\n",
      "        [1.0972],\n",
      "        [1.1023],\n",
      "        [1.0645],\n",
      "        [1.0870],\n",
      "        [1.0831],\n",
      "        [1.0696],\n",
      "        [1.0899],\n",
      "        [1.0593],\n",
      "        [1.0859],\n",
      "        [1.0537],\n",
      "        [1.1013],\n",
      "        [1.0693],\n",
      "        [1.0844],\n",
      "        [1.1043],\n",
      "        [1.0892],\n",
      "        [1.1055],\n",
      "        [1.0821],\n",
      "        [1.1100],\n",
      "        [1.0929]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0608],\n",
      "        [1.1103],\n",
      "        [1.0853],\n",
      "        [1.0778],\n",
      "        [1.0477],\n",
      "        [1.1054],\n",
      "        [1.0888],\n",
      "        [1.0665],\n",
      "        [1.0777],\n",
      "        [1.1002],\n",
      "        [1.0925],\n",
      "        [1.1033],\n",
      "        [1.1080],\n",
      "        [1.1039],\n",
      "        [1.0795],\n",
      "        [1.1118],\n",
      "        [1.0848],\n",
      "        [1.0733],\n",
      "        [1.0722],\n",
      "        [1.1092],\n",
      "        [1.1109],\n",
      "        [1.1112],\n",
      "        [1.0899],\n",
      "        [1.0914],\n",
      "        [1.1062],\n",
      "        [1.0824],\n",
      "        [1.0802],\n",
      "        [1.1002],\n",
      "        [1.0833],\n",
      "        [1.0542],\n",
      "        [1.1011],\n",
      "        [1.1114],\n",
      "        [1.0460],\n",
      "        [1.1034],\n",
      "        [1.1099],\n",
      "        [1.0889],\n",
      "        [1.0245],\n",
      "        [1.0843],\n",
      "        [1.0901],\n",
      "        [1.0861],\n",
      "        [1.0504],\n",
      "        [1.0565],\n",
      "        [1.0876],\n",
      "        [1.0893],\n",
      "        [1.0669],\n",
      "        [1.0828],\n",
      "        [1.1011],\n",
      "        [1.0947],\n",
      "        [1.0902],\n",
      "        [1.0955],\n",
      "        [1.0744],\n",
      "        [1.0399],\n",
      "        [1.0894],\n",
      "        [1.0971],\n",
      "        [1.0975],\n",
      "        [1.0863],\n",
      "        [1.1072],\n",
      "        [1.1038],\n",
      "        [1.0709],\n",
      "        [1.0632],\n",
      "        [1.0980],\n",
      "        [1.0834],\n",
      "        [1.0642],\n",
      "        [1.0772],\n",
      "        [1.1089],\n",
      "        [1.0966],\n",
      "        [1.1022],\n",
      "        [1.1090],\n",
      "        [1.1037],\n",
      "        [1.0411],\n",
      "        [1.0771],\n",
      "        [1.1117],\n",
      "        [1.1120],\n",
      "        [1.0731],\n",
      "        [1.0925],\n",
      "        [1.0993],\n",
      "        [1.0913],\n",
      "        [1.0778],\n",
      "        [1.0671],\n",
      "        [1.1014],\n",
      "        [1.0964],\n",
      "        [1.0501],\n",
      "        [1.0656],\n",
      "        [1.1060],\n",
      "        [1.0952],\n",
      "        [1.0583],\n",
      "        [1.1110],\n",
      "        [1.1011],\n",
      "        [1.0076],\n",
      "        [1.0716],\n",
      "        [1.0922],\n",
      "        [1.0670],\n",
      "        [1.0743],\n",
      "        [1.1090],\n",
      "        [1.0727],\n",
      "        [1.0947],\n",
      "        [1.0644],\n",
      "        [1.0485],\n",
      "        [1.1139],\n",
      "        [1.0931],\n",
      "        [1.0527],\n",
      "        [1.0876],\n",
      "        [1.0787],\n",
      "        [1.0860],\n",
      "        [1.0585],\n",
      "        [1.1086],\n",
      "        [1.1057],\n",
      "        [1.0138],\n",
      "        [1.0946],\n",
      "        [1.1029],\n",
      "        [1.0791],\n",
      "        [1.1065],\n",
      "        [1.0977],\n",
      "        [1.1031],\n",
      "        [1.0953],\n",
      "        [1.0567],\n",
      "        [1.0588],\n",
      "        [1.0822],\n",
      "        [1.1100],\n",
      "        [1.0998],\n",
      "        [1.0463],\n",
      "        [1.1023],\n",
      "        [1.1010],\n",
      "        [1.1121],\n",
      "        [1.0751],\n",
      "        [1.0464],\n",
      "        [1.0611],\n",
      "        [1.0750]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0491],\n",
      "        [1.1050],\n",
      "        [1.1067],\n",
      "        [1.0619],\n",
      "        [1.1118],\n",
      "        [1.0737],\n",
      "        [1.1151],\n",
      "        [1.1102],\n",
      "        [1.1136],\n",
      "        [1.0892],\n",
      "        [1.0813],\n",
      "        [1.0656],\n",
      "        [1.0855],\n",
      "        [1.0969],\n",
      "        [1.0729],\n",
      "        [1.0582],\n",
      "        [1.0763],\n",
      "        [1.0973],\n",
      "        [1.1064],\n",
      "        [1.0917],\n",
      "        [1.1088],\n",
      "        [1.0683],\n",
      "        [1.0592],\n",
      "        [1.1025],\n",
      "        [1.0749],\n",
      "        [1.0970],\n",
      "        [1.0980],\n",
      "        [1.1007],\n",
      "        [1.0281],\n",
      "        [1.0477],\n",
      "        [1.0627],\n",
      "        [1.0603],\n",
      "        [1.1073],\n",
      "        [0.9979],\n",
      "        [1.0964],\n",
      "        [1.1117],\n",
      "        [1.0948],\n",
      "        [1.1061],\n",
      "        [1.1048],\n",
      "        [1.0669],\n",
      "        [1.0331],\n",
      "        [1.0756],\n",
      "        [1.0819],\n",
      "        [1.0834],\n",
      "        [0.7798],\n",
      "        [1.0804],\n",
      "        [1.0813],\n",
      "        [1.0246],\n",
      "        [1.0768],\n",
      "        [1.1065],\n",
      "        [1.1117],\n",
      "        [1.1075],\n",
      "        [1.0754],\n",
      "        [1.0652],\n",
      "        [1.0606],\n",
      "        [1.0753],\n",
      "        [1.1103],\n",
      "        [1.0845],\n",
      "        [1.1007],\n",
      "        [1.0913],\n",
      "        [1.0744],\n",
      "        [1.0926],\n",
      "        [1.0727],\n",
      "        [1.1040],\n",
      "        [1.1047],\n",
      "        [1.1027],\n",
      "        [1.0433],\n",
      "        [1.0664],\n",
      "        [1.1071],\n",
      "        [1.0598],\n",
      "        [1.0946],\n",
      "        [1.0668],\n",
      "        [1.0957],\n",
      "        [1.0980],\n",
      "        [1.0616],\n",
      "        [1.0847],\n",
      "        [1.0540],\n",
      "        [1.0849],\n",
      "        [1.0711],\n",
      "        [1.0904],\n",
      "        [1.0998],\n",
      "        [1.1074],\n",
      "        [1.0641],\n",
      "        [1.1078],\n",
      "        [1.0742],\n",
      "        [1.0675],\n",
      "        [1.0344],\n",
      "        [1.0944],\n",
      "        [1.0878],\n",
      "        [1.0856],\n",
      "        [1.0689],\n",
      "        [1.0689],\n",
      "        [1.0269],\n",
      "        [1.1118],\n",
      "        [1.0763],\n",
      "        [1.0879],\n",
      "        [1.0892],\n",
      "        [1.0497],\n",
      "        [1.0593],\n",
      "        [1.0498],\n",
      "        [1.0834],\n",
      "        [1.0903],\n",
      "        [1.1005],\n",
      "        [1.1003],\n",
      "        [1.1073],\n",
      "        [1.0876],\n",
      "        [1.0586],\n",
      "        [1.0674],\n",
      "        [1.0231],\n",
      "        [1.0885],\n",
      "        [1.0781],\n",
      "        [1.1002],\n",
      "        [1.0252],\n",
      "        [1.0674],\n",
      "        [1.0597],\n",
      "        [1.0983],\n",
      "        [1.0815],\n",
      "        [1.0874],\n",
      "        [1.0799],\n",
      "        [1.1032],\n",
      "        [1.0636],\n",
      "        [1.1076],\n",
      "        [1.0756],\n",
      "        [1.1052],\n",
      "        [1.0577],\n",
      "        [1.0594],\n",
      "        [1.1041],\n",
      "        [1.0736]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1120],\n",
      "        [1.0999],\n",
      "        [1.1067],\n",
      "        [1.0805],\n",
      "        [1.1046],\n",
      "        [1.0817],\n",
      "        [1.1104],\n",
      "        [1.0993],\n",
      "        [1.0470],\n",
      "        [1.0485],\n",
      "        [1.0934],\n",
      "        [1.0780],\n",
      "        [1.0410],\n",
      "        [1.0375],\n",
      "        [1.0739],\n",
      "        [1.0853],\n",
      "        [1.0994],\n",
      "        [1.1041],\n",
      "        [1.1089],\n",
      "        [1.0730],\n",
      "        [1.1108],\n",
      "        [1.0900],\n",
      "        [1.0929],\n",
      "        [1.0816],\n",
      "        [1.0659],\n",
      "        [1.0719],\n",
      "        [1.0858],\n",
      "        [1.0548],\n",
      "        [1.0771],\n",
      "        [1.0852],\n",
      "        [1.0893],\n",
      "        [1.0104],\n",
      "        [1.0683],\n",
      "        [1.0768],\n",
      "        [1.0870],\n",
      "        [1.0767],\n",
      "        [1.0970],\n",
      "        [1.0973],\n",
      "        [1.1114],\n",
      "        [1.0850],\n",
      "        [1.0981],\n",
      "        [1.0415],\n",
      "        [1.0530],\n",
      "        [1.1120],\n",
      "        [1.0807],\n",
      "        [1.0699],\n",
      "        [1.1039],\n",
      "        [1.0967],\n",
      "        [1.0887],\n",
      "        [1.1085],\n",
      "        [1.0561],\n",
      "        [1.0590],\n",
      "        [1.0879],\n",
      "        [1.0981],\n",
      "        [1.1020],\n",
      "        [1.1005],\n",
      "        [1.0808],\n",
      "        [1.0538],\n",
      "        [1.1019],\n",
      "        [1.0762],\n",
      "        [1.0853],\n",
      "        [1.0593],\n",
      "        [1.0760],\n",
      "        [1.0646],\n",
      "        [1.0511],\n",
      "        [1.0177],\n",
      "        [1.0991],\n",
      "        [1.0614],\n",
      "        [1.0839],\n",
      "        [1.0929],\n",
      "        [1.0783],\n",
      "        [1.0672],\n",
      "        [1.0570],\n",
      "        [1.0752],\n",
      "        [1.0425],\n",
      "        [1.0901],\n",
      "        [1.0902],\n",
      "        [1.0624],\n",
      "        [1.0953],\n",
      "        [1.0932],\n",
      "        [1.1062],\n",
      "        [1.0973],\n",
      "        [1.0954],\n",
      "        [1.0096],\n",
      "        [1.0864],\n",
      "        [1.0502],\n",
      "        [1.0903],\n",
      "        [1.0723],\n",
      "        [1.0753],\n",
      "        [1.0599],\n",
      "        [1.1086],\n",
      "        [1.0823],\n",
      "        [1.0670],\n",
      "        [1.0786],\n",
      "        [1.0759],\n",
      "        [1.0677],\n",
      "        [1.0986],\n",
      "        [1.0794],\n",
      "        [1.0958],\n",
      "        [1.0656],\n",
      "        [1.0904],\n",
      "        [1.1147],\n",
      "        [1.0643],\n",
      "        [1.0906],\n",
      "        [1.0852],\n",
      "        [1.0861],\n",
      "        [1.0765],\n",
      "        [1.0830],\n",
      "        [1.0983],\n",
      "        [1.0455],\n",
      "        [1.0985],\n",
      "        [1.0952],\n",
      "        [1.1084],\n",
      "        [1.0702],\n",
      "        [1.0356],\n",
      "        [1.0923],\n",
      "        [1.0981],\n",
      "        [1.0911],\n",
      "        [1.0918],\n",
      "        [1.0568],\n",
      "        [1.0745],\n",
      "        [1.0999],\n",
      "        [1.0893],\n",
      "        [1.0559],\n",
      "        [1.1043],\n",
      "        [1.1120],\n",
      "        [1.0766],\n",
      "        [1.0926]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0854],\n",
      "        [1.1020],\n",
      "        [1.0723],\n",
      "        [1.0891],\n",
      "        [1.0729],\n",
      "        [1.0443],\n",
      "        [1.0829],\n",
      "        [1.0760],\n",
      "        [1.1132],\n",
      "        [1.0806],\n",
      "        [1.0676],\n",
      "        [1.0934],\n",
      "        [1.0862],\n",
      "        [1.0380],\n",
      "        [1.0562],\n",
      "        [1.0979],\n",
      "        [1.0552],\n",
      "        [1.0858],\n",
      "        [1.0972],\n",
      "        [1.1037],\n",
      "        [1.0801],\n",
      "        [1.0941],\n",
      "        [1.1013],\n",
      "        [1.0985],\n",
      "        [1.0497],\n",
      "        [1.0904],\n",
      "        [1.0836],\n",
      "        [1.1042],\n",
      "        [1.0952],\n",
      "        [1.0495],\n",
      "        [1.0953],\n",
      "        [1.0862],\n",
      "        [1.0674],\n",
      "        [1.0554],\n",
      "        [1.1055],\n",
      "        [1.0677],\n",
      "        [1.0988],\n",
      "        [1.0640],\n",
      "        [1.0923],\n",
      "        [1.0758],\n",
      "        [1.0978],\n",
      "        [1.1004],\n",
      "        [1.0942],\n",
      "        [1.0991],\n",
      "        [1.0652],\n",
      "        [1.0731],\n",
      "        [1.0729],\n",
      "        [1.0796],\n",
      "        [1.0735],\n",
      "        [1.0609],\n",
      "        [1.0622],\n",
      "        [1.0971],\n",
      "        [1.0845],\n",
      "        [1.0529],\n",
      "        [1.0749],\n",
      "        [1.0800],\n",
      "        [1.0954],\n",
      "        [1.0754],\n",
      "        [1.0967],\n",
      "        [1.0681],\n",
      "        [1.1024],\n",
      "        [1.1017],\n",
      "        [1.0535],\n",
      "        [1.0902],\n",
      "        [1.0477],\n",
      "        [1.0896],\n",
      "        [1.1018],\n",
      "        [1.0742],\n",
      "        [1.0936],\n",
      "        [1.0600],\n",
      "        [1.0586],\n",
      "        [1.0714],\n",
      "        [1.0921],\n",
      "        [1.0636],\n",
      "        [1.0840],\n",
      "        [1.0785],\n",
      "        [1.0847],\n",
      "        [1.0984],\n",
      "        [1.0835],\n",
      "        [1.1011],\n",
      "        [1.0911],\n",
      "        [1.0319],\n",
      "        [1.0645],\n",
      "        [1.0708],\n",
      "        [1.0999],\n",
      "        [1.0731],\n",
      "        [1.0725],\n",
      "        [1.1012],\n",
      "        [1.0813],\n",
      "        [1.0473],\n",
      "        [1.1124],\n",
      "        [1.0852],\n",
      "        [1.0619],\n",
      "        [1.0639],\n",
      "        [1.0782],\n",
      "        [1.1049],\n",
      "        [1.1059],\n",
      "        [1.0829],\n",
      "        [1.0593],\n",
      "        [1.0376],\n",
      "        [1.0991],\n",
      "        [1.0761],\n",
      "        [1.0931],\n",
      "        [1.1121],\n",
      "        [1.0743],\n",
      "        [1.1068],\n",
      "        [1.0609],\n",
      "        [1.0438],\n",
      "        [1.0863],\n",
      "        [1.0680],\n",
      "        [1.1017],\n",
      "        [1.1159],\n",
      "        [1.0702],\n",
      "        [1.0989],\n",
      "        [1.0876],\n",
      "        [1.0950],\n",
      "        [1.0751],\n",
      "        [1.0873],\n",
      "        [1.0622],\n",
      "        [1.0993],\n",
      "        [1.0788],\n",
      "        [1.0682],\n",
      "        [1.0954],\n",
      "        [1.0714],\n",
      "        [1.1034],\n",
      "        [1.1026],\n",
      "        [1.0619],\n",
      "        [1.0720]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1093],\n",
      "        [1.0955],\n",
      "        [1.0583],\n",
      "        [1.0385],\n",
      "        [1.0800],\n",
      "        [1.0861],\n",
      "        [1.0372],\n",
      "        [1.0988],\n",
      "        [1.0935],\n",
      "        [1.0687],\n",
      "        [1.0913],\n",
      "        [1.0847],\n",
      "        [1.0810],\n",
      "        [1.1110],\n",
      "        [1.0845],\n",
      "        [1.1018],\n",
      "        [1.0852],\n",
      "        [1.0957],\n",
      "        [1.0643],\n",
      "        [1.0950],\n",
      "        [1.0668],\n",
      "        [1.0612],\n",
      "        [1.0701],\n",
      "        [1.1089],\n",
      "        [1.1079],\n",
      "        [1.0977],\n",
      "        [1.0839],\n",
      "        [1.0950],\n",
      "        [1.0873],\n",
      "        [1.0691],\n",
      "        [1.0940],\n",
      "        [1.1107],\n",
      "        [1.0921],\n",
      "        [1.0820],\n",
      "        [1.0962],\n",
      "        [1.0729],\n",
      "        [1.0760],\n",
      "        [1.0626],\n",
      "        [1.0568],\n",
      "        [1.1057],\n",
      "        [1.0531],\n",
      "        [1.0852],\n",
      "        [1.1005],\n",
      "        [1.0663],\n",
      "        [1.0562],\n",
      "        [1.0941],\n",
      "        [1.0640],\n",
      "        [1.0865],\n",
      "        [1.1080],\n",
      "        [1.0800],\n",
      "        [1.0926],\n",
      "        [1.1093],\n",
      "        [1.0939],\n",
      "        [1.0916],\n",
      "        [1.0351],\n",
      "        [1.0774],\n",
      "        [1.1065],\n",
      "        [1.0764],\n",
      "        [1.0600],\n",
      "        [1.0755],\n",
      "        [1.0540],\n",
      "        [1.0700],\n",
      "        [1.0733],\n",
      "        [1.0858],\n",
      "        [1.0980],\n",
      "        [1.1036],\n",
      "        [1.0479],\n",
      "        [1.0590],\n",
      "        [1.0351],\n",
      "        [1.0888],\n",
      "        [1.0958],\n",
      "        [1.0366],\n",
      "        [1.1061],\n",
      "        [1.1013],\n",
      "        [1.0914],\n",
      "        [1.0914],\n",
      "        [1.0784],\n",
      "        [1.0827],\n",
      "        [1.1115],\n",
      "        [1.0647],\n",
      "        [1.0657],\n",
      "        [1.0806],\n",
      "        [1.0768],\n",
      "        [1.0944],\n",
      "        [1.1054],\n",
      "        [1.0787],\n",
      "        [1.0706],\n",
      "        [1.0926],\n",
      "        [1.0671],\n",
      "        [1.0605],\n",
      "        [1.0839],\n",
      "        [1.1035],\n",
      "        [1.0993],\n",
      "        [1.0960],\n",
      "        [1.1081],\n",
      "        [1.1140],\n",
      "        [1.1079],\n",
      "        [1.0790],\n",
      "        [1.0697],\n",
      "        [1.0940],\n",
      "        [1.0614],\n",
      "        [1.0497],\n",
      "        [1.1124],\n",
      "        [1.1113],\n",
      "        [1.0831],\n",
      "        [1.0355],\n",
      "        [1.0667],\n",
      "        [1.1002],\n",
      "        [0.2535],\n",
      "        [1.0738],\n",
      "        [1.0978],\n",
      "        [1.0993],\n",
      "        [1.0572],\n",
      "        [1.0705],\n",
      "        [1.0759],\n",
      "        [1.1102],\n",
      "        [1.0725],\n",
      "        [1.0964],\n",
      "        [1.1034],\n",
      "        [1.0605],\n",
      "        [1.0776],\n",
      "        [1.0883],\n",
      "        [1.0789],\n",
      "        [1.0699],\n",
      "        [1.0671],\n",
      "        [1.0487],\n",
      "        [1.0934],\n",
      "        [1.0610]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0450],\n",
      "        [1.0651],\n",
      "        [1.1092],\n",
      "        [1.0952]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  34 | lr 0.00010 train_loss 2.12151 | val_loss 2.29410 | val_rmse 1.51463\n",
      "tensor([[1.0756],\n",
      "        [1.1093],\n",
      "        [1.1030],\n",
      "        [1.0744],\n",
      "        [1.0969],\n",
      "        [1.0814],\n",
      "        [1.0376],\n",
      "        [1.0660],\n",
      "        [1.1116],\n",
      "        [1.0613],\n",
      "        [1.0673],\n",
      "        [1.0612],\n",
      "        [1.0938],\n",
      "        [1.0888],\n",
      "        [1.0848],\n",
      "        [1.0962],\n",
      "        [1.1027],\n",
      "        [1.0579],\n",
      "        [1.0975],\n",
      "        [1.0841],\n",
      "        [1.0969],\n",
      "        [1.1131],\n",
      "        [1.0602],\n",
      "        [1.0898],\n",
      "        [1.1126],\n",
      "        [1.0808],\n",
      "        [1.0565],\n",
      "        [1.0985],\n",
      "        [1.0900],\n",
      "        [1.0989],\n",
      "        [1.1049],\n",
      "        [1.1106],\n",
      "        [1.1062],\n",
      "        [1.0648],\n",
      "        [1.1089],\n",
      "        [1.0937],\n",
      "        [1.0906],\n",
      "        [1.1093],\n",
      "        [1.0881],\n",
      "        [1.1093],\n",
      "        [1.1141],\n",
      "        [1.0824],\n",
      "        [1.1113],\n",
      "        [1.0924],\n",
      "        [1.0965],\n",
      "        [1.1071],\n",
      "        [1.0868],\n",
      "        [1.1073],\n",
      "        [1.0886],\n",
      "        [1.0883],\n",
      "        [1.0409],\n",
      "        [1.0584],\n",
      "        [1.0893],\n",
      "        [1.1102],\n",
      "        [1.0846],\n",
      "        [1.1091],\n",
      "        [1.0818],\n",
      "        [1.0194],\n",
      "        [1.0819],\n",
      "        [1.0882],\n",
      "        [1.1019],\n",
      "        [1.0778],\n",
      "        [1.0697],\n",
      "        [1.0906],\n",
      "        [1.1051],\n",
      "        [1.0816],\n",
      "        [1.0777],\n",
      "        [1.0901],\n",
      "        [1.0876],\n",
      "        [1.0828],\n",
      "        [1.0769],\n",
      "        [1.0829],\n",
      "        [1.0414],\n",
      "        [1.1088],\n",
      "        [1.0827],\n",
      "        [1.0649],\n",
      "        [1.0689],\n",
      "        [1.0761],\n",
      "        [1.0692],\n",
      "        [1.1070],\n",
      "        [1.1094],\n",
      "        [1.1043],\n",
      "        [1.0901],\n",
      "        [1.0828],\n",
      "        [1.1141],\n",
      "        [1.1001],\n",
      "        [1.0556],\n",
      "        [1.1068],\n",
      "        [1.0567],\n",
      "        [1.0977],\n",
      "        [1.0776],\n",
      "        [1.1007],\n",
      "        [1.1137],\n",
      "        [1.0728],\n",
      "        [1.0889],\n",
      "        [1.0804],\n",
      "        [1.0643],\n",
      "        [1.0557],\n",
      "        [1.1024],\n",
      "        [1.0739],\n",
      "        [1.1144],\n",
      "        [1.1019],\n",
      "        [1.1037],\n",
      "        [1.0911],\n",
      "        [1.0851],\n",
      "        [1.1116],\n",
      "        [1.1073],\n",
      "        [1.0511],\n",
      "        [1.1064],\n",
      "        [1.1039],\n",
      "        [1.1133],\n",
      "        [1.0969],\n",
      "        [1.1003],\n",
      "        [1.1097],\n",
      "        [1.0833],\n",
      "        [1.0704],\n",
      "        [1.0717],\n",
      "        [1.0460],\n",
      "        [1.1067],\n",
      "        [1.0723],\n",
      "        [1.0793],\n",
      "        [1.0471],\n",
      "        [1.1161],\n",
      "        [1.0866],\n",
      "        [1.1136],\n",
      "        [1.1074],\n",
      "        [1.1035],\n",
      "        [1.1011]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0762],\n",
      "        [1.0423],\n",
      "        [1.1001],\n",
      "        [1.1115],\n",
      "        [1.0732],\n",
      "        [1.1043],\n",
      "        [1.1124],\n",
      "        [1.0653],\n",
      "        [1.0812],\n",
      "        [1.0919],\n",
      "        [1.0548],\n",
      "        [1.0963],\n",
      "        [1.0535],\n",
      "        [1.0909],\n",
      "        [1.0949],\n",
      "        [1.0973],\n",
      "        [1.0986],\n",
      "        [1.1070],\n",
      "        [1.0529],\n",
      "        [1.0786],\n",
      "        [1.0991],\n",
      "        [1.0948],\n",
      "        [1.0991],\n",
      "        [1.0893],\n",
      "        [1.0934],\n",
      "        [1.0950],\n",
      "        [1.1007],\n",
      "        [1.0736],\n",
      "        [1.0910],\n",
      "        [1.0867],\n",
      "        [1.0696],\n",
      "        [1.0935],\n",
      "        [1.0900],\n",
      "        [1.0880],\n",
      "        [1.0696],\n",
      "        [1.0847],\n",
      "        [1.1078],\n",
      "        [1.0817],\n",
      "        [1.0922],\n",
      "        [1.0416],\n",
      "        [1.0892],\n",
      "        [1.0576],\n",
      "        [1.1108],\n",
      "        [1.0720],\n",
      "        [1.1041],\n",
      "        [1.0541],\n",
      "        [1.0734],\n",
      "        [1.0990],\n",
      "        [1.0687],\n",
      "        [1.0921],\n",
      "        [1.0692],\n",
      "        [1.0667],\n",
      "        [1.0606],\n",
      "        [1.0990],\n",
      "        [1.0669],\n",
      "        [1.0903],\n",
      "        [1.1144],\n",
      "        [1.0603],\n",
      "        [1.0865],\n",
      "        [1.0948],\n",
      "        [1.0438],\n",
      "        [1.0806],\n",
      "        [1.0177],\n",
      "        [1.0573],\n",
      "        [1.0888],\n",
      "        [1.0370],\n",
      "        [1.0633],\n",
      "        [1.0546],\n",
      "        [1.1056],\n",
      "        [1.0931],\n",
      "        [1.0958],\n",
      "        [1.0223],\n",
      "        [1.1127],\n",
      "        [1.0716],\n",
      "        [1.0939],\n",
      "        [1.0533],\n",
      "        [1.0721],\n",
      "        [1.0883],\n",
      "        [1.0786],\n",
      "        [1.0698],\n",
      "        [1.0817],\n",
      "        [1.0920],\n",
      "        [1.0951],\n",
      "        [1.0559],\n",
      "        [1.0554],\n",
      "        [1.0921],\n",
      "        [1.0998],\n",
      "        [1.1002],\n",
      "        [1.0966],\n",
      "        [1.0734],\n",
      "        [1.0445],\n",
      "        [1.0760],\n",
      "        [1.0896],\n",
      "        [1.1102],\n",
      "        [1.0897],\n",
      "        [1.1072],\n",
      "        [1.0708],\n",
      "        [1.0573],\n",
      "        [1.0510],\n",
      "        [1.0844],\n",
      "        [1.0983],\n",
      "        [1.0748],\n",
      "        [1.1013],\n",
      "        [1.0705],\n",
      "        [1.0799],\n",
      "        [1.0726],\n",
      "        [1.0418],\n",
      "        [1.0841],\n",
      "        [1.1083],\n",
      "        [1.0955],\n",
      "        [1.0755],\n",
      "        [1.0918],\n",
      "        [1.0979],\n",
      "        [1.0478],\n",
      "        [1.0914],\n",
      "        [1.1122],\n",
      "        [1.0192],\n",
      "        [1.0632],\n",
      "        [1.1049],\n",
      "        [1.0934],\n",
      "        [1.0860],\n",
      "        [1.0616],\n",
      "        [1.0546],\n",
      "        [1.0959],\n",
      "        [0.9950],\n",
      "        [1.0655],\n",
      "        [1.0586],\n",
      "        [1.0845]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1039],\n",
      "        [1.1018],\n",
      "        [1.0489],\n",
      "        [1.1130],\n",
      "        [1.0586],\n",
      "        [1.0633],\n",
      "        [1.0750],\n",
      "        [1.0705],\n",
      "        [1.1004],\n",
      "        [1.0945],\n",
      "        [1.0932],\n",
      "        [1.1078],\n",
      "        [1.0959],\n",
      "        [1.1080],\n",
      "        [1.0788],\n",
      "        [1.0876],\n",
      "        [1.0867],\n",
      "        [1.0930],\n",
      "        [1.0970],\n",
      "        [1.0265],\n",
      "        [1.0269],\n",
      "        [1.0759],\n",
      "        [1.0605],\n",
      "        [1.1001],\n",
      "        [1.0506],\n",
      "        [1.1137],\n",
      "        [1.0871],\n",
      "        [1.1118],\n",
      "        [1.0810],\n",
      "        [1.1169],\n",
      "        [1.0831],\n",
      "        [1.0575],\n",
      "        [1.1146],\n",
      "        [1.0616],\n",
      "        [1.1051],\n",
      "        [1.0753],\n",
      "        [1.0814],\n",
      "        [1.0838],\n",
      "        [1.0807],\n",
      "        [1.1121],\n",
      "        [1.0794],\n",
      "        [1.0684],\n",
      "        [1.0633],\n",
      "        [1.1114],\n",
      "        [1.0752],\n",
      "        [1.1141],\n",
      "        [1.0932],\n",
      "        [1.0343],\n",
      "        [1.1147],\n",
      "        [1.0325],\n",
      "        [1.0904],\n",
      "        [1.1067],\n",
      "        [1.1143],\n",
      "        [1.0966],\n",
      "        [1.0982],\n",
      "        [1.0758],\n",
      "        [1.1087],\n",
      "        [1.0423],\n",
      "        [1.1141],\n",
      "        [1.0520],\n",
      "        [1.1104],\n",
      "        [1.0894],\n",
      "        [1.0893],\n",
      "        [1.1016],\n",
      "        [1.0887],\n",
      "        [1.0839],\n",
      "        [1.0913],\n",
      "        [1.0577],\n",
      "        [1.1015],\n",
      "        [1.1138],\n",
      "        [1.0963],\n",
      "        [1.0897],\n",
      "        [1.1112],\n",
      "        [1.1032],\n",
      "        [1.1034],\n",
      "        [1.0677],\n",
      "        [1.1050],\n",
      "        [1.0915],\n",
      "        [1.0860],\n",
      "        [1.1128],\n",
      "        [1.0539],\n",
      "        [1.0458],\n",
      "        [1.1078],\n",
      "        [1.0706],\n",
      "        [1.0852],\n",
      "        [1.0658],\n",
      "        [1.0886],\n",
      "        [1.0985],\n",
      "        [1.0922],\n",
      "        [1.1058],\n",
      "        [1.0906],\n",
      "        [1.1032],\n",
      "        [1.0765],\n",
      "        [1.0771],\n",
      "        [1.0765],\n",
      "        [1.1052],\n",
      "        [1.0830],\n",
      "        [1.0883],\n",
      "        [1.0821],\n",
      "        [1.0731],\n",
      "        [1.0899],\n",
      "        [1.0791],\n",
      "        [1.0673],\n",
      "        [1.0485],\n",
      "        [1.0805],\n",
      "        [1.1014],\n",
      "        [1.0972],\n",
      "        [1.0823],\n",
      "        [1.0610],\n",
      "        [1.0982],\n",
      "        [1.0960],\n",
      "        [1.0785],\n",
      "        [1.0910],\n",
      "        [1.0744],\n",
      "        [1.0561],\n",
      "        [1.0370],\n",
      "        [1.1108],\n",
      "        [1.0503],\n",
      "        [1.0662],\n",
      "        [1.1043],\n",
      "        [1.0823],\n",
      "        [1.1085],\n",
      "        [1.0619],\n",
      "        [1.0866],\n",
      "        [1.0875],\n",
      "        [1.0761],\n",
      "        [1.1079],\n",
      "        [1.0840]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1143],\n",
      "        [1.0527],\n",
      "        [1.0554],\n",
      "        [1.0486],\n",
      "        [1.0605],\n",
      "        [1.1034],\n",
      "        [1.0604],\n",
      "        [1.0969],\n",
      "        [1.0817],\n",
      "        [1.0265],\n",
      "        [1.0903],\n",
      "        [1.0695],\n",
      "        [1.0864],\n",
      "        [1.0931],\n",
      "        [1.0776],\n",
      "        [1.0784],\n",
      "        [1.1104],\n",
      "        [1.0725],\n",
      "        [1.1094],\n",
      "        [1.0568],\n",
      "        [1.1101],\n",
      "        [1.0705],\n",
      "        [1.0818],\n",
      "        [1.0926],\n",
      "        [1.0981],\n",
      "        [1.1111],\n",
      "        [1.0891],\n",
      "        [1.0813],\n",
      "        [1.0906],\n",
      "        [1.0496],\n",
      "        [1.1004],\n",
      "        [1.0244],\n",
      "        [1.0807],\n",
      "        [1.0964],\n",
      "        [1.0621],\n",
      "        [1.0479],\n",
      "        [1.0999],\n",
      "        [1.0844],\n",
      "        [1.0239],\n",
      "        [1.0944],\n",
      "        [1.0951],\n",
      "        [1.0556],\n",
      "        [1.0508],\n",
      "        [1.0601],\n",
      "        [1.1025],\n",
      "        [1.0554],\n",
      "        [1.0589],\n",
      "        [1.0453],\n",
      "        [1.0233],\n",
      "        [1.0889],\n",
      "        [1.0324],\n",
      "        [1.0878],\n",
      "        [1.0985],\n",
      "        [1.1011],\n",
      "        [1.1034],\n",
      "        [1.0741],\n",
      "        [1.0871],\n",
      "        [1.0716],\n",
      "        [1.1017],\n",
      "        [1.0991],\n",
      "        [1.0649],\n",
      "        [1.0916],\n",
      "        [1.1011],\n",
      "        [1.0991],\n",
      "        [1.0597],\n",
      "        [1.0813],\n",
      "        [1.1051],\n",
      "        [1.0995],\n",
      "        [1.0843],\n",
      "        [1.0645],\n",
      "        [1.1034],\n",
      "        [1.0739],\n",
      "        [1.0964],\n",
      "        [1.0418],\n",
      "        [1.1057],\n",
      "        [1.1037],\n",
      "        [1.1008],\n",
      "        [1.1182],\n",
      "        [1.1149],\n",
      "        [1.0705],\n",
      "        [1.0875],\n",
      "        [1.0768],\n",
      "        [1.0900],\n",
      "        [1.0443],\n",
      "        [1.0634],\n",
      "        [1.1077],\n",
      "        [1.0628],\n",
      "        [1.1041],\n",
      "        [1.0937],\n",
      "        [1.0992],\n",
      "        [1.0846],\n",
      "        [1.0872],\n",
      "        [1.0377],\n",
      "        [1.0448],\n",
      "        [1.1123],\n",
      "        [1.0522],\n",
      "        [1.0950],\n",
      "        [1.0853],\n",
      "        [1.0899],\n",
      "        [1.0465],\n",
      "        [1.0457],\n",
      "        [1.0866],\n",
      "        [1.0713],\n",
      "        [1.0020],\n",
      "        [1.0932],\n",
      "        [1.0631],\n",
      "        [1.0668],\n",
      "        [1.0871],\n",
      "        [1.0694],\n",
      "        [1.0882],\n",
      "        [1.1085],\n",
      "        [1.1074],\n",
      "        [1.0659],\n",
      "        [1.0534],\n",
      "        [1.1100],\n",
      "        [1.0719],\n",
      "        [1.0927],\n",
      "        [1.0814],\n",
      "        [1.0641],\n",
      "        [1.0886],\n",
      "        [1.0781],\n",
      "        [1.0563],\n",
      "        [1.1078],\n",
      "        [1.0781],\n",
      "        [1.0472],\n",
      "        [1.0754],\n",
      "        [1.0694],\n",
      "        [1.0616]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1008],\n",
      "        [1.1114],\n",
      "        [1.1015],\n",
      "        [1.0743],\n",
      "        [1.1003],\n",
      "        [1.0910],\n",
      "        [1.1010],\n",
      "        [1.1038],\n",
      "        [1.0861],\n",
      "        [1.0942],\n",
      "        [1.1058],\n",
      "        [1.0105],\n",
      "        [1.1038],\n",
      "        [1.0592],\n",
      "        [1.0779],\n",
      "        [1.0726],\n",
      "        [1.0732],\n",
      "        [1.1068],\n",
      "        [1.0409],\n",
      "        [1.0759],\n",
      "        [1.0972],\n",
      "        [1.0980],\n",
      "        [1.1062],\n",
      "        [1.0885],\n",
      "        [1.0863],\n",
      "        [1.1058],\n",
      "        [1.1044],\n",
      "        [1.1020],\n",
      "        [1.0802],\n",
      "        [1.0963],\n",
      "        [1.1174],\n",
      "        [1.0819],\n",
      "        [1.0907],\n",
      "        [1.1101],\n",
      "        [1.1035],\n",
      "        [1.0669],\n",
      "        [1.0948],\n",
      "        [1.1101],\n",
      "        [1.1084],\n",
      "        [1.0537],\n",
      "        [1.1113],\n",
      "        [1.1094],\n",
      "        [1.0942],\n",
      "        [1.0989],\n",
      "        [1.0969],\n",
      "        [1.0700],\n",
      "        [1.1081],\n",
      "        [1.1113],\n",
      "        [1.1054],\n",
      "        [1.1117],\n",
      "        [1.1155],\n",
      "        [1.0631],\n",
      "        [1.0713],\n",
      "        [1.0868],\n",
      "        [1.1134],\n",
      "        [1.0842],\n",
      "        [1.0845],\n",
      "        [1.0551],\n",
      "        [1.1014],\n",
      "        [1.0849],\n",
      "        [1.0785],\n",
      "        [1.1021],\n",
      "        [1.0478],\n",
      "        [1.0965],\n",
      "        [1.0975],\n",
      "        [1.0703],\n",
      "        [1.0622],\n",
      "        [1.1053],\n",
      "        [1.0831],\n",
      "        [1.0769],\n",
      "        [1.0977],\n",
      "        [1.1013],\n",
      "        [1.0804],\n",
      "        [1.1076],\n",
      "        [1.0827],\n",
      "        [1.0783],\n",
      "        [1.0743],\n",
      "        [1.0776],\n",
      "        [1.0964],\n",
      "        [1.1151],\n",
      "        [1.0928],\n",
      "        [1.0881],\n",
      "        [1.0935],\n",
      "        [1.0610],\n",
      "        [1.0901],\n",
      "        [1.1002],\n",
      "        [1.1059],\n",
      "        [1.0546],\n",
      "        [1.1077],\n",
      "        [1.1121],\n",
      "        [1.1103],\n",
      "        [1.0700],\n",
      "        [1.0964],\n",
      "        [1.1136],\n",
      "        [1.0850],\n",
      "        [1.0937],\n",
      "        [1.0877],\n",
      "        [1.0520],\n",
      "        [1.0855],\n",
      "        [1.1089],\n",
      "        [1.0717],\n",
      "        [1.0973],\n",
      "        [1.0504],\n",
      "        [1.0909],\n",
      "        [1.0735],\n",
      "        [1.1048],\n",
      "        [1.0955],\n",
      "        [1.0770],\n",
      "        [1.0760],\n",
      "        [1.0864],\n",
      "        [1.0789],\n",
      "        [1.1027],\n",
      "        [1.0198],\n",
      "        [1.0853],\n",
      "        [1.0761],\n",
      "        [1.1151],\n",
      "        [1.0768],\n",
      "        [1.0781],\n",
      "        [1.1120],\n",
      "        [1.0832],\n",
      "        [1.0916],\n",
      "        [1.1085],\n",
      "        [1.1073],\n",
      "        [1.0925],\n",
      "        [1.0769],\n",
      "        [1.1056],\n",
      "        [1.1025],\n",
      "        [1.0774]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0800],\n",
      "        [1.0941],\n",
      "        [1.0916],\n",
      "        [1.1008],\n",
      "        [1.0908],\n",
      "        [1.1155],\n",
      "        [1.0927],\n",
      "        [1.0967],\n",
      "        [1.0914],\n",
      "        [1.0896],\n",
      "        [1.0891],\n",
      "        [1.0802],\n",
      "        [1.0897],\n",
      "        [1.0590],\n",
      "        [1.0579],\n",
      "        [1.1115],\n",
      "        [1.0540],\n",
      "        [1.0604],\n",
      "        [1.1113],\n",
      "        [1.0422],\n",
      "        [1.1036],\n",
      "        [1.0733],\n",
      "        [1.1088],\n",
      "        [1.0866],\n",
      "        [1.1073],\n",
      "        [1.0807],\n",
      "        [1.0833],\n",
      "        [1.0701],\n",
      "        [1.1078],\n",
      "        [1.0743],\n",
      "        [1.0920],\n",
      "        [1.0925],\n",
      "        [1.0904],\n",
      "        [1.1031],\n",
      "        [1.0713],\n",
      "        [1.0831],\n",
      "        [1.1011],\n",
      "        [1.1009],\n",
      "        [1.1147],\n",
      "        [1.1101],\n",
      "        [1.0383],\n",
      "        [1.0399],\n",
      "        [1.1119],\n",
      "        [1.0598],\n",
      "        [1.0798],\n",
      "        [1.1015],\n",
      "        [1.0906],\n",
      "        [1.0963],\n",
      "        [1.0917],\n",
      "        [1.0937],\n",
      "        [1.0907],\n",
      "        [1.0711],\n",
      "        [1.0729],\n",
      "        [1.1017],\n",
      "        [1.0911],\n",
      "        [1.1055],\n",
      "        [1.0773],\n",
      "        [1.1093],\n",
      "        [1.0296],\n",
      "        [1.0740],\n",
      "        [1.0875],\n",
      "        [1.0893],\n",
      "        [1.1027],\n",
      "        [1.0842],\n",
      "        [1.0991],\n",
      "        [1.1078],\n",
      "        [1.1103],\n",
      "        [1.1129],\n",
      "        [1.0920],\n",
      "        [1.1070],\n",
      "        [1.0849],\n",
      "        [1.0798],\n",
      "        [1.0156],\n",
      "        [1.0905],\n",
      "        [1.0482],\n",
      "        [1.0278],\n",
      "        [1.0991],\n",
      "        [1.0997],\n",
      "        [1.0873],\n",
      "        [1.1131],\n",
      "        [1.0630],\n",
      "        [1.1113],\n",
      "        [1.0561],\n",
      "        [1.1095],\n",
      "        [0.1539],\n",
      "        [1.0531],\n",
      "        [1.0659],\n",
      "        [1.0484],\n",
      "        [1.0911],\n",
      "        [1.0976],\n",
      "        [1.0958],\n",
      "        [1.0874],\n",
      "        [1.1077],\n",
      "        [1.0731],\n",
      "        [1.0942],\n",
      "        [1.0858],\n",
      "        [1.0693],\n",
      "        [1.0973],\n",
      "        [1.0749],\n",
      "        [1.0949],\n",
      "        [1.1107],\n",
      "        [1.0303],\n",
      "        [1.0408],\n",
      "        [1.0633],\n",
      "        [1.1149],\n",
      "        [1.1006],\n",
      "        [1.1115],\n",
      "        [1.1116],\n",
      "        [1.1044],\n",
      "        [1.1008],\n",
      "        [1.0610],\n",
      "        [1.1004],\n",
      "        [1.0735],\n",
      "        [1.0554],\n",
      "        [1.1099],\n",
      "        [1.0973],\n",
      "        [1.0657],\n",
      "        [1.0978],\n",
      "        [1.1107],\n",
      "        [1.0893],\n",
      "        [1.0672],\n",
      "        [1.0762],\n",
      "        [1.0867],\n",
      "        [1.1154],\n",
      "        [1.0877],\n",
      "        [1.0956],\n",
      "        [1.0991],\n",
      "        [1.0570]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0672],\n",
      "        [1.0496],\n",
      "        [1.0833],\n",
      "        [1.0869],\n",
      "        [1.0405],\n",
      "        [1.0692],\n",
      "        [1.0862],\n",
      "        [1.0547],\n",
      "        [1.0975],\n",
      "        [1.0857],\n",
      "        [1.0834],\n",
      "        [1.0520],\n",
      "        [1.0897],\n",
      "        [1.0956],\n",
      "        [1.1015],\n",
      "        [1.0687],\n",
      "        [1.0862],\n",
      "        [1.1135],\n",
      "        [1.0708],\n",
      "        [1.1041],\n",
      "        [1.0944],\n",
      "        [1.0603],\n",
      "        [1.1011],\n",
      "        [1.0904],\n",
      "        [1.0619],\n",
      "        [1.0812],\n",
      "        [1.0532],\n",
      "        [1.0919],\n",
      "        [1.0789],\n",
      "        [1.0864],\n",
      "        [1.0511],\n",
      "        [1.0865],\n",
      "        [1.0929],\n",
      "        [1.0652],\n",
      "        [1.1006],\n",
      "        [1.1066],\n",
      "        [1.0777],\n",
      "        [1.0741],\n",
      "        [1.0791],\n",
      "        [1.0787],\n",
      "        [1.1065],\n",
      "        [1.1001],\n",
      "        [1.0998],\n",
      "        [1.0903],\n",
      "        [1.0712],\n",
      "        [1.1006],\n",
      "        [1.0615],\n",
      "        [1.0756],\n",
      "        [1.0737],\n",
      "        [1.0589],\n",
      "        [1.0793],\n",
      "        [1.0592],\n",
      "        [1.0605],\n",
      "        [1.1060],\n",
      "        [1.0433],\n",
      "        [1.0652],\n",
      "        [1.0942],\n",
      "        [1.0765],\n",
      "        [1.0766],\n",
      "        [1.0934],\n",
      "        [1.0568],\n",
      "        [1.1141],\n",
      "        [1.0803],\n",
      "        [1.1070],\n",
      "        [1.1095],\n",
      "        [1.0890],\n",
      "        [1.0645],\n",
      "        [1.0847],\n",
      "        [1.0822],\n",
      "        [1.1113],\n",
      "        [1.0878],\n",
      "        [1.1045],\n",
      "        [1.0649],\n",
      "        [1.0809],\n",
      "        [1.0705],\n",
      "        [1.1170],\n",
      "        [1.1182],\n",
      "        [1.1120],\n",
      "        [1.0744],\n",
      "        [1.0808],\n",
      "        [1.1013],\n",
      "        [1.0861],\n",
      "        [1.0849],\n",
      "        [1.1027],\n",
      "        [1.0934],\n",
      "        [1.0831],\n",
      "        [1.0916],\n",
      "        [1.0945],\n",
      "        [1.0904],\n",
      "        [1.0927],\n",
      "        [1.0962],\n",
      "        [1.1112],\n",
      "        [1.1112],\n",
      "        [1.0884],\n",
      "        [1.0695],\n",
      "        [1.0868],\n",
      "        [1.0886],\n",
      "        [1.0919],\n",
      "        [1.0768],\n",
      "        [1.0976],\n",
      "        [1.1093],\n",
      "        [1.0790],\n",
      "        [1.0961],\n",
      "        [1.0624],\n",
      "        [1.1049],\n",
      "        [1.0926],\n",
      "        [1.0983],\n",
      "        [1.1012],\n",
      "        [1.1044],\n",
      "        [1.0869],\n",
      "        [1.0827],\n",
      "        [1.1013],\n",
      "        [1.0962],\n",
      "        [1.0529],\n",
      "        [1.1025],\n",
      "        [1.1104],\n",
      "        [1.0756],\n",
      "        [1.0972],\n",
      "        [1.0954],\n",
      "        [1.0834],\n",
      "        [1.0670],\n",
      "        [1.0864],\n",
      "        [1.1044],\n",
      "        [1.0656],\n",
      "        [1.0686],\n",
      "        [1.0748],\n",
      "        [1.0578],\n",
      "        [1.0542]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0779],\n",
      "        [1.1034],\n",
      "        [1.0214],\n",
      "        [1.0954]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  35 | lr 0.00010 train_loss 2.12368 | val_loss 2.29338 | val_rmse 1.51439\n",
      "tensor([[1.0816],\n",
      "        [1.0918],\n",
      "        [1.0294],\n",
      "        [1.0976],\n",
      "        [1.1026],\n",
      "        [1.0884],\n",
      "        [1.0720],\n",
      "        [1.0773],\n",
      "        [1.0893],\n",
      "        [1.0875],\n",
      "        [1.0876],\n",
      "        [1.1109],\n",
      "        [1.0652],\n",
      "        [1.0979],\n",
      "        [1.0999],\n",
      "        [1.0742],\n",
      "        [1.0750],\n",
      "        [1.1110],\n",
      "        [1.1042],\n",
      "        [1.0565],\n",
      "        [1.1103],\n",
      "        [1.0738],\n",
      "        [1.0946],\n",
      "        [1.0376],\n",
      "        [1.1138],\n",
      "        [1.0713],\n",
      "        [1.1055],\n",
      "        [1.0947],\n",
      "        [1.1048],\n",
      "        [1.1120],\n",
      "        [1.0714],\n",
      "        [1.0872],\n",
      "        [1.1111],\n",
      "        [1.0665],\n",
      "        [1.0884],\n",
      "        [1.1199],\n",
      "        [1.0879],\n",
      "        [1.0970],\n",
      "        [1.0887],\n",
      "        [1.0935],\n",
      "        [1.0714],\n",
      "        [1.0544],\n",
      "        [1.0623],\n",
      "        [1.0797],\n",
      "        [1.1027],\n",
      "        [1.0853],\n",
      "        [1.0420],\n",
      "        [1.1111],\n",
      "        [1.0744],\n",
      "        [1.1151],\n",
      "        [1.1194],\n",
      "        [1.0752],\n",
      "        [1.0928],\n",
      "        [1.0852],\n",
      "        [1.0707],\n",
      "        [1.1102],\n",
      "        [1.0626],\n",
      "        [1.0182],\n",
      "        [1.0882],\n",
      "        [1.0940],\n",
      "        [1.0772],\n",
      "        [1.0812],\n",
      "        [1.1072],\n",
      "        [1.0770],\n",
      "        [1.0932],\n",
      "        [1.1102],\n",
      "        [1.0839],\n",
      "        [1.0713],\n",
      "        [1.0687],\n",
      "        [1.0661],\n",
      "        [1.0848],\n",
      "        [1.0920],\n",
      "        [1.0864],\n",
      "        [1.0967],\n",
      "        [1.0928],\n",
      "        [1.0619],\n",
      "        [1.1051],\n",
      "        [1.0752],\n",
      "        [1.0573],\n",
      "        [1.1066],\n",
      "        [1.0880],\n",
      "        [1.0925],\n",
      "        [1.1058],\n",
      "        [1.0715],\n",
      "        [1.0656],\n",
      "        [1.0426],\n",
      "        [1.0400],\n",
      "        [1.1123],\n",
      "        [1.1051],\n",
      "        [1.1170],\n",
      "        [1.1115],\n",
      "        [1.0681],\n",
      "        [1.0775],\n",
      "        [1.1072],\n",
      "        [1.0671],\n",
      "        [1.1159],\n",
      "        [1.0876],\n",
      "        [1.0971],\n",
      "        [1.1029],\n",
      "        [1.0809],\n",
      "        [1.1124],\n",
      "        [1.0907],\n",
      "        [1.1027],\n",
      "        [1.0906],\n",
      "        [1.1036],\n",
      "        [1.1168],\n",
      "        [1.0739],\n",
      "        [1.0940],\n",
      "        [1.0613],\n",
      "        [1.0873],\n",
      "        [1.0982],\n",
      "        [1.1078],\n",
      "        [1.1027],\n",
      "        [1.0821],\n",
      "        [1.0449],\n",
      "        [1.1006],\n",
      "        [1.0977],\n",
      "        [1.0914],\n",
      "        [1.0752],\n",
      "        [1.0610],\n",
      "        [1.0942],\n",
      "        [1.0710],\n",
      "        [1.0315],\n",
      "        [1.1002],\n",
      "        [1.0677],\n",
      "        [1.0538],\n",
      "        [1.0688],\n",
      "        [1.0495]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1035],\n",
      "        [1.0871],\n",
      "        [1.0325],\n",
      "        [1.0855],\n",
      "        [1.0928],\n",
      "        [1.0432],\n",
      "        [1.0960],\n",
      "        [1.0801],\n",
      "        [1.1051],\n",
      "        [1.0920],\n",
      "        [1.0666],\n",
      "        [1.0747],\n",
      "        [1.0513],\n",
      "        [1.0964],\n",
      "        [1.0918],\n",
      "        [1.0626],\n",
      "        [1.1034],\n",
      "        [1.0638],\n",
      "        [1.0987],\n",
      "        [1.0512],\n",
      "        [1.1048],\n",
      "        [1.0588],\n",
      "        [1.0833],\n",
      "        [1.0908],\n",
      "        [1.1107],\n",
      "        [1.0932],\n",
      "        [1.0674],\n",
      "        [1.0926],\n",
      "        [1.1160],\n",
      "        [1.0909],\n",
      "        [1.1060],\n",
      "        [1.0652],\n",
      "        [1.0949],\n",
      "        [1.1037],\n",
      "        [1.0986],\n",
      "        [1.0715],\n",
      "        [1.0822],\n",
      "        [1.0921],\n",
      "        [1.1073],\n",
      "        [1.0883],\n",
      "        [1.0976],\n",
      "        [1.0985],\n",
      "        [1.1133],\n",
      "        [1.0967],\n",
      "        [1.0502],\n",
      "        [1.1118],\n",
      "        [1.0869],\n",
      "        [1.0862],\n",
      "        [1.0736],\n",
      "        [1.0851],\n",
      "        [1.0959],\n",
      "        [1.0709],\n",
      "        [1.0366],\n",
      "        [1.1181],\n",
      "        [1.0922],\n",
      "        [1.0998],\n",
      "        [1.0539],\n",
      "        [1.1010],\n",
      "        [1.0987],\n",
      "        [1.0908],\n",
      "        [1.0550],\n",
      "        [1.0901],\n",
      "        [1.1072],\n",
      "        [1.0781],\n",
      "        [1.0846],\n",
      "        [1.0866],\n",
      "        [1.1102],\n",
      "        [1.0690],\n",
      "        [1.0673],\n",
      "        [1.0982],\n",
      "        [1.1134],\n",
      "        [1.1161],\n",
      "        [1.0932],\n",
      "        [1.0602],\n",
      "        [1.0663],\n",
      "        [1.0797],\n",
      "        [1.0657],\n",
      "        [1.0984],\n",
      "        [1.0691],\n",
      "        [1.0860],\n",
      "        [1.1169],\n",
      "        [1.1148],\n",
      "        [1.0799],\n",
      "        [1.1074],\n",
      "        [1.1170],\n",
      "        [1.0768],\n",
      "        [1.1006],\n",
      "        [1.0992],\n",
      "        [1.0919],\n",
      "        [1.0869],\n",
      "        [0.3878],\n",
      "        [1.0162],\n",
      "        [1.0799],\n",
      "        [1.0845],\n",
      "        [1.0957],\n",
      "        [1.0960],\n",
      "        [1.1008],\n",
      "        [1.1029],\n",
      "        [1.1160],\n",
      "        [1.0639],\n",
      "        [1.1074],\n",
      "        [1.0827],\n",
      "        [1.0711],\n",
      "        [1.0604],\n",
      "        [1.0646],\n",
      "        [1.0820],\n",
      "        [1.0774],\n",
      "        [1.0906],\n",
      "        [1.0742],\n",
      "        [1.0666],\n",
      "        [1.0880],\n",
      "        [1.0842],\n",
      "        [1.0811],\n",
      "        [1.1099],\n",
      "        [1.0932],\n",
      "        [1.1101],\n",
      "        [1.1045],\n",
      "        [1.0607],\n",
      "        [1.1095],\n",
      "        [1.0842],\n",
      "        [1.0525],\n",
      "        [1.0645],\n",
      "        [1.0617],\n",
      "        [1.0680],\n",
      "        [1.1009],\n",
      "        [1.1108],\n",
      "        [1.0800],\n",
      "        [1.0917]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0628],\n",
      "        [1.0922],\n",
      "        [1.0880],\n",
      "        [1.0767],\n",
      "        [1.0701],\n",
      "        [1.0963],\n",
      "        [1.0632],\n",
      "        [1.0582],\n",
      "        [1.0624],\n",
      "        [1.0496],\n",
      "        [1.0955],\n",
      "        [1.1077],\n",
      "        [1.1143],\n",
      "        [1.0252],\n",
      "        [1.1081],\n",
      "        [1.0661],\n",
      "        [1.0923],\n",
      "        [1.0764],\n",
      "        [1.1019],\n",
      "        [1.1022],\n",
      "        [1.0746],\n",
      "        [1.0883],\n",
      "        [1.0933],\n",
      "        [1.1092],\n",
      "        [1.0919],\n",
      "        [1.1041],\n",
      "        [1.1027],\n",
      "        [1.1015],\n",
      "        [1.0911],\n",
      "        [1.1045],\n",
      "        [1.0773],\n",
      "        [1.0566],\n",
      "        [1.0896],\n",
      "        [1.0631],\n",
      "        [1.0759],\n",
      "        [1.0845],\n",
      "        [1.1044],\n",
      "        [1.0900],\n",
      "        [1.1123],\n",
      "        [1.0665],\n",
      "        [1.0393],\n",
      "        [1.1010],\n",
      "        [1.0440],\n",
      "        [1.0699],\n",
      "        [1.1095],\n",
      "        [1.0970],\n",
      "        [1.0810],\n",
      "        [1.0766],\n",
      "        [1.1032],\n",
      "        [1.0706],\n",
      "        [1.0813],\n",
      "        [1.0966],\n",
      "        [1.1020],\n",
      "        [1.0882],\n",
      "        [1.0873],\n",
      "        [1.0814],\n",
      "        [1.0511],\n",
      "        [1.1111],\n",
      "        [1.0947],\n",
      "        [1.0802],\n",
      "        [1.0545],\n",
      "        [1.0886],\n",
      "        [1.1120],\n",
      "        [1.0858],\n",
      "        [1.0767],\n",
      "        [1.0519],\n",
      "        [1.0919],\n",
      "        [1.0929],\n",
      "        [1.0540],\n",
      "        [1.0900],\n",
      "        [1.1056],\n",
      "        [1.0813],\n",
      "        [1.0720],\n",
      "        [1.1013],\n",
      "        [1.0833],\n",
      "        [1.0640],\n",
      "        [1.0841],\n",
      "        [1.0924],\n",
      "        [1.0979],\n",
      "        [1.0448],\n",
      "        [1.0602],\n",
      "        [1.0879],\n",
      "        [1.0666],\n",
      "        [1.0726],\n",
      "        [1.0896],\n",
      "        [1.0556],\n",
      "        [1.0694],\n",
      "        [1.0900],\n",
      "        [1.0955],\n",
      "        [1.0883],\n",
      "        [1.0349],\n",
      "        [1.1008],\n",
      "        [1.1119],\n",
      "        [1.1025],\n",
      "        [1.0467],\n",
      "        [1.0170],\n",
      "        [1.0778],\n",
      "        [1.0764],\n",
      "        [1.0461],\n",
      "        [1.1125],\n",
      "        [1.0614],\n",
      "        [1.0568],\n",
      "        [1.0903],\n",
      "        [1.0647],\n",
      "        [1.0856],\n",
      "        [1.1027],\n",
      "        [1.0692],\n",
      "        [1.0887],\n",
      "        [1.0966],\n",
      "        [1.0664],\n",
      "        [1.0483],\n",
      "        [1.0935],\n",
      "        [1.0849],\n",
      "        [1.0996],\n",
      "        [1.0396],\n",
      "        [1.0832],\n",
      "        [1.0163],\n",
      "        [1.0863],\n",
      "        [1.0257],\n",
      "        [1.1021],\n",
      "        [1.0890],\n",
      "        [1.1012],\n",
      "        [1.0627],\n",
      "        [1.0644],\n",
      "        [1.0767],\n",
      "        [1.0391],\n",
      "        [1.0775],\n",
      "        [1.0686]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0697],\n",
      "        [1.0958],\n",
      "        [1.1163],\n",
      "        [1.0768],\n",
      "        [1.0721],\n",
      "        [1.0843],\n",
      "        [1.1168],\n",
      "        [1.0717],\n",
      "        [1.0735],\n",
      "        [1.1111],\n",
      "        [1.0620],\n",
      "        [1.1018],\n",
      "        [1.1143],\n",
      "        [1.0950],\n",
      "        [1.0885],\n",
      "        [1.0514],\n",
      "        [1.0905],\n",
      "        [1.1090],\n",
      "        [1.1049],\n",
      "        [1.0885],\n",
      "        [1.0591],\n",
      "        [1.1107],\n",
      "        [1.0770],\n",
      "        [1.1167],\n",
      "        [1.0481],\n",
      "        [1.0667],\n",
      "        [1.1057],\n",
      "        [1.0957],\n",
      "        [1.0630],\n",
      "        [1.0401],\n",
      "        [1.0867],\n",
      "        [1.0965],\n",
      "        [1.1056],\n",
      "        [1.0830],\n",
      "        [1.1133],\n",
      "        [1.0882],\n",
      "        [1.1029],\n",
      "        [1.0700],\n",
      "        [1.0763],\n",
      "        [1.0935],\n",
      "        [1.0791],\n",
      "        [1.0872],\n",
      "        [1.0564],\n",
      "        [1.0973],\n",
      "        [1.1075],\n",
      "        [1.0810],\n",
      "        [1.0753],\n",
      "        [1.1093],\n",
      "        [1.1071],\n",
      "        [1.1103],\n",
      "        [1.0377],\n",
      "        [1.1144],\n",
      "        [1.0668],\n",
      "        [1.0627],\n",
      "        [1.0763],\n",
      "        [1.0812],\n",
      "        [1.0863],\n",
      "        [1.0823],\n",
      "        [1.0653],\n",
      "        [1.1030],\n",
      "        [1.1052],\n",
      "        [1.1143],\n",
      "        [1.0953],\n",
      "        [1.1015],\n",
      "        [1.0779],\n",
      "        [1.0770],\n",
      "        [1.1058],\n",
      "        [1.1065],\n",
      "        [1.1102],\n",
      "        [1.0956],\n",
      "        [1.1004],\n",
      "        [1.0995],\n",
      "        [1.1052],\n",
      "        [1.0975],\n",
      "        [1.0600],\n",
      "        [1.0906],\n",
      "        [1.0973],\n",
      "        [1.0831],\n",
      "        [1.1069],\n",
      "        [1.0890],\n",
      "        [1.0593],\n",
      "        [1.0784],\n",
      "        [1.0958],\n",
      "        [1.0455],\n",
      "        [1.0799],\n",
      "        [1.0949],\n",
      "        [1.0875],\n",
      "        [1.0753],\n",
      "        [1.0952],\n",
      "        [1.0851],\n",
      "        [1.0889],\n",
      "        [1.1027],\n",
      "        [1.0772],\n",
      "        [1.0672],\n",
      "        [1.0226],\n",
      "        [1.1080],\n",
      "        [1.0977],\n",
      "        [1.0801],\n",
      "        [1.0721],\n",
      "        [1.0632],\n",
      "        [1.0879],\n",
      "        [1.0576],\n",
      "        [1.0712],\n",
      "        [1.1095],\n",
      "        [1.1135],\n",
      "        [1.0867],\n",
      "        [1.1034],\n",
      "        [1.1000],\n",
      "        [1.0365],\n",
      "        [1.0285],\n",
      "        [1.1155],\n",
      "        [1.1061],\n",
      "        [1.0881],\n",
      "        [1.0994],\n",
      "        [1.0416],\n",
      "        [1.0879],\n",
      "        [1.1078],\n",
      "        [1.1133],\n",
      "        [1.0959],\n",
      "        [1.0676],\n",
      "        [1.0520],\n",
      "        [1.0529],\n",
      "        [1.1146],\n",
      "        [1.0987],\n",
      "        [1.0269],\n",
      "        [1.0698],\n",
      "        [1.0864],\n",
      "        [1.0936]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0720],\n",
      "        [1.0893],\n",
      "        [1.0996],\n",
      "        [1.0698],\n",
      "        [1.0860],\n",
      "        [1.0557],\n",
      "        [1.0597],\n",
      "        [1.1145],\n",
      "        [1.1060],\n",
      "        [1.0806],\n",
      "        [1.0903],\n",
      "        [1.1149],\n",
      "        [1.0715],\n",
      "        [1.0549],\n",
      "        [1.0702],\n",
      "        [1.0429],\n",
      "        [1.0906],\n",
      "        [1.1021],\n",
      "        [1.0541],\n",
      "        [1.0933],\n",
      "        [1.1144],\n",
      "        [1.1063],\n",
      "        [1.1160],\n",
      "        [1.0257],\n",
      "        [1.1108],\n",
      "        [1.0808],\n",
      "        [1.0713],\n",
      "        [1.1023],\n",
      "        [1.0739],\n",
      "        [1.0936],\n",
      "        [1.1047],\n",
      "        [1.0501],\n",
      "        [1.0713],\n",
      "        [1.1076],\n",
      "        [1.0278],\n",
      "        [1.0806],\n",
      "        [1.1082],\n",
      "        [1.0881],\n",
      "        [1.1108],\n",
      "        [1.0635],\n",
      "        [1.0751],\n",
      "        [1.0566],\n",
      "        [0.1004],\n",
      "        [1.0707],\n",
      "        [1.0687],\n",
      "        [1.0642],\n",
      "        [1.1054],\n",
      "        [1.1099],\n",
      "        [1.1019],\n",
      "        [1.0812],\n",
      "        [1.0965],\n",
      "        [1.0970],\n",
      "        [1.1080],\n",
      "        [1.1009],\n",
      "        [1.0770],\n",
      "        [1.0922],\n",
      "        [1.0150],\n",
      "        [1.0863],\n",
      "        [1.0940],\n",
      "        [1.0916],\n",
      "        [1.1162],\n",
      "        [1.1086],\n",
      "        [1.0634],\n",
      "        [1.1053],\n",
      "        [1.0942],\n",
      "        [1.0381],\n",
      "        [1.0412],\n",
      "        [1.0850],\n",
      "        [1.0689],\n",
      "        [1.1055],\n",
      "        [1.0913],\n",
      "        [1.1013],\n",
      "        [1.1133],\n",
      "        [1.0643],\n",
      "        [1.0652],\n",
      "        [1.0785],\n",
      "        [1.1084],\n",
      "        [1.0533],\n",
      "        [1.0846],\n",
      "        [1.0646],\n",
      "        [1.0977],\n",
      "        [1.0942],\n",
      "        [1.1149],\n",
      "        [1.1005],\n",
      "        [1.1093],\n",
      "        [1.1104],\n",
      "        [1.0962],\n",
      "        [1.1041],\n",
      "        [1.0676],\n",
      "        [1.0916],\n",
      "        [1.0691],\n",
      "        [1.1072],\n",
      "        [1.0555],\n",
      "        [1.0926],\n",
      "        [1.0996],\n",
      "        [1.1146],\n",
      "        [1.1069],\n",
      "        [1.0862],\n",
      "        [1.0674],\n",
      "        [1.0558],\n",
      "        [1.0840],\n",
      "        [1.1103],\n",
      "        [1.0923],\n",
      "        [1.1102],\n",
      "        [1.0874],\n",
      "        [1.0962],\n",
      "        [1.0903],\n",
      "        [1.1112],\n",
      "        [1.0755],\n",
      "        [1.1145],\n",
      "        [1.1044],\n",
      "        [1.1022],\n",
      "        [1.0913],\n",
      "        [1.1029],\n",
      "        [1.0789],\n",
      "        [1.0803],\n",
      "        [1.1038],\n",
      "        [1.0912],\n",
      "        [1.0958],\n",
      "        [1.0749],\n",
      "        [1.0897],\n",
      "        [1.0635],\n",
      "        [1.0819],\n",
      "        [1.1082],\n",
      "        [1.0357],\n",
      "        [1.0531],\n",
      "        [1.0966],\n",
      "        [1.1160]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1030],\n",
      "        [1.0848],\n",
      "        [1.1020],\n",
      "        [1.0560],\n",
      "        [1.0890],\n",
      "        [1.0947],\n",
      "        [1.0883],\n",
      "        [1.0696],\n",
      "        [1.0908],\n",
      "        [1.0601],\n",
      "        [1.1065],\n",
      "        [1.1068],\n",
      "        [1.0816],\n",
      "        [1.0807],\n",
      "        [1.0761],\n",
      "        [1.0878],\n",
      "        [1.0984],\n",
      "        [1.1119],\n",
      "        [1.0523],\n",
      "        [1.1052],\n",
      "        [1.0746],\n",
      "        [1.0754],\n",
      "        [1.1076],\n",
      "        [1.0751],\n",
      "        [1.0609],\n",
      "        [1.0952],\n",
      "        [1.1090],\n",
      "        [1.0999],\n",
      "        [1.1126],\n",
      "        [1.0013],\n",
      "        [1.0381],\n",
      "        [1.0975],\n",
      "        [1.0707],\n",
      "        [1.0851],\n",
      "        [1.0515],\n",
      "        [1.0423],\n",
      "        [1.0173],\n",
      "        [1.0458],\n",
      "        [1.1155],\n",
      "        [1.0651],\n",
      "        [1.0991],\n",
      "        [1.0626],\n",
      "        [1.0658],\n",
      "        [1.1027],\n",
      "        [1.0737],\n",
      "        [1.1012],\n",
      "        [1.1051],\n",
      "        [1.0772],\n",
      "        [1.0798],\n",
      "        [1.0910],\n",
      "        [1.1028],\n",
      "        [1.1059],\n",
      "        [1.0543],\n",
      "        [1.1023],\n",
      "        [1.0963],\n",
      "        [1.1126],\n",
      "        [1.0588],\n",
      "        [1.0917],\n",
      "        [1.1040],\n",
      "        [1.0907],\n",
      "        [1.0892],\n",
      "        [1.0655],\n",
      "        [1.1143],\n",
      "        [0.7472],\n",
      "        [1.0818],\n",
      "        [1.0992],\n",
      "        [1.1121],\n",
      "        [1.0689],\n",
      "        [1.1022],\n",
      "        [1.0868],\n",
      "        [1.0973],\n",
      "        [1.0762],\n",
      "        [1.0825],\n",
      "        [1.0922],\n",
      "        [1.0941],\n",
      "        [1.0764],\n",
      "        [1.0664],\n",
      "        [1.0938],\n",
      "        [1.1091],\n",
      "        [1.0559],\n",
      "        [1.0862],\n",
      "        [1.0972],\n",
      "        [1.1186],\n",
      "        [1.0973],\n",
      "        [1.1112],\n",
      "        [1.0104],\n",
      "        [1.0992],\n",
      "        [1.0508],\n",
      "        [1.0909],\n",
      "        [1.0763],\n",
      "        [1.1086],\n",
      "        [1.0816],\n",
      "        [1.0522],\n",
      "        [1.0978],\n",
      "        [1.1087],\n",
      "        [1.1035],\n",
      "        [1.1046],\n",
      "        [1.0613],\n",
      "        [1.0612],\n",
      "        [1.1089],\n",
      "        [1.0904],\n",
      "        [1.0946],\n",
      "        [1.0959],\n",
      "        [1.0897],\n",
      "        [1.0581],\n",
      "        [1.0813],\n",
      "        [1.0925],\n",
      "        [1.0433],\n",
      "        [1.0666],\n",
      "        [1.1073],\n",
      "        [1.1122],\n",
      "        [1.0815],\n",
      "        [1.0600],\n",
      "        [1.1004],\n",
      "        [1.0555],\n",
      "        [1.0444],\n",
      "        [1.0714],\n",
      "        [1.1023],\n",
      "        [1.0544],\n",
      "        [1.0732],\n",
      "        [1.0791],\n",
      "        [1.1106],\n",
      "        [1.0632],\n",
      "        [1.0202],\n",
      "        [1.0784],\n",
      "        [1.0964],\n",
      "        [1.0987],\n",
      "        [1.0637]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0440],\n",
      "        [1.0907],\n",
      "        [1.0875],\n",
      "        [1.0989],\n",
      "        [1.0854],\n",
      "        [1.1022],\n",
      "        [1.1087],\n",
      "        [1.0571],\n",
      "        [1.0842],\n",
      "        [1.1022],\n",
      "        [1.0817],\n",
      "        [1.1146],\n",
      "        [1.0961],\n",
      "        [1.1078],\n",
      "        [1.0619],\n",
      "        [1.0915],\n",
      "        [1.0347],\n",
      "        [1.0946],\n",
      "        [1.0973],\n",
      "        [1.0832],\n",
      "        [1.1157],\n",
      "        [1.0815],\n",
      "        [1.1029],\n",
      "        [1.0577],\n",
      "        [1.1016],\n",
      "        [1.0841],\n",
      "        [1.0720],\n",
      "        [1.1010],\n",
      "        [1.0958],\n",
      "        [1.1146],\n",
      "        [1.0899],\n",
      "        [1.1158],\n",
      "        [1.1187],\n",
      "        [1.0385],\n",
      "        [1.1056],\n",
      "        [1.0995],\n",
      "        [1.1164],\n",
      "        [1.1000],\n",
      "        [1.1067],\n",
      "        [1.1021],\n",
      "        [1.0725],\n",
      "        [1.0993],\n",
      "        [1.0752],\n",
      "        [1.0938],\n",
      "        [1.1010],\n",
      "        [1.1147],\n",
      "        [1.1146],\n",
      "        [1.0616],\n",
      "        [1.0797],\n",
      "        [1.0843],\n",
      "        [1.0835],\n",
      "        [1.0790],\n",
      "        [1.0524],\n",
      "        [1.0501],\n",
      "        [1.0892],\n",
      "        [1.1027],\n",
      "        [1.1035],\n",
      "        [1.0786],\n",
      "        [1.1028],\n",
      "        [1.0664],\n",
      "        [1.0878],\n",
      "        [1.0922],\n",
      "        [1.1041],\n",
      "        [1.0603],\n",
      "        [1.0886],\n",
      "        [1.0755],\n",
      "        [1.0905],\n",
      "        [1.0828],\n",
      "        [1.0787],\n",
      "        [1.1160],\n",
      "        [1.0965],\n",
      "        [1.0581],\n",
      "        [1.0968],\n",
      "        [1.0719],\n",
      "        [1.0953],\n",
      "        [1.1020],\n",
      "        [1.0990],\n",
      "        [1.1014],\n",
      "        [1.0268],\n",
      "        [1.0544],\n",
      "        [1.0630],\n",
      "        [1.0776],\n",
      "        [1.0820],\n",
      "        [1.1147],\n",
      "        [1.1006],\n",
      "        [1.1018],\n",
      "        [1.1092],\n",
      "        [1.0707],\n",
      "        [1.0832],\n",
      "        [1.0149],\n",
      "        [1.0903],\n",
      "        [1.0843],\n",
      "        [1.1141],\n",
      "        [1.1046],\n",
      "        [1.0709],\n",
      "        [1.1158],\n",
      "        [1.1046],\n",
      "        [1.1058],\n",
      "        [1.0922],\n",
      "        [1.1157],\n",
      "        [1.1151],\n",
      "        [1.0595],\n",
      "        [1.0927],\n",
      "        [1.0995],\n",
      "        [1.1015],\n",
      "        [1.0952],\n",
      "        [1.1132],\n",
      "        [1.0782],\n",
      "        [1.0665],\n",
      "        [1.0715],\n",
      "        [1.1115],\n",
      "        [1.1110],\n",
      "        [1.0898],\n",
      "        [1.0981],\n",
      "        [1.0542],\n",
      "        [1.1081],\n",
      "        [1.0801],\n",
      "        [1.0692],\n",
      "        [1.0881],\n",
      "        [1.0939],\n",
      "        [1.0763],\n",
      "        [1.0933],\n",
      "        [1.0946],\n",
      "        [1.0965],\n",
      "        [1.0488],\n",
      "        [1.1134],\n",
      "        [1.0971],\n",
      "        [1.0490]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0822],\n",
      "        [1.1044],\n",
      "        [1.1027],\n",
      "        [1.0918]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  36 | lr 0.00010 train_loss 2.12244 | val_loss 2.29343 | val_rmse 1.51441\n",
      "tensor([[1.0649],\n",
      "        [1.1073],\n",
      "        [1.1137],\n",
      "        [1.0717],\n",
      "        [1.0625],\n",
      "        [1.0650],\n",
      "        [1.0735],\n",
      "        [1.0712],\n",
      "        [1.0321],\n",
      "        [1.0928],\n",
      "        [1.1149],\n",
      "        [1.0961],\n",
      "        [1.1067],\n",
      "        [1.1130],\n",
      "        [1.0986],\n",
      "        [1.0830],\n",
      "        [1.0861],\n",
      "        [1.1160],\n",
      "        [1.0442],\n",
      "        [1.1033],\n",
      "        [1.0646],\n",
      "        [1.0908],\n",
      "        [1.0803],\n",
      "        [1.0702],\n",
      "        [1.0616],\n",
      "        [1.1071],\n",
      "        [1.1001],\n",
      "        [1.0842],\n",
      "        [1.0914],\n",
      "        [1.1005],\n",
      "        [1.1060],\n",
      "        [1.0398],\n",
      "        [1.0757],\n",
      "        [1.1051],\n",
      "        [1.0893],\n",
      "        [1.0628],\n",
      "        [1.1033],\n",
      "        [1.0704],\n",
      "        [1.1012],\n",
      "        [1.0632],\n",
      "        [1.0500],\n",
      "        [1.0983],\n",
      "        [1.1088],\n",
      "        [1.0749],\n",
      "        [1.0957],\n",
      "        [1.0948],\n",
      "        [1.0830],\n",
      "        [1.0889],\n",
      "        [1.0204],\n",
      "        [1.1157],\n",
      "        [1.0340],\n",
      "        [1.1009],\n",
      "        [1.0710],\n",
      "        [1.1063],\n",
      "        [1.1019],\n",
      "        [1.0924],\n",
      "        [1.1042],\n",
      "        [1.0973],\n",
      "        [1.1149],\n",
      "        [1.1138],\n",
      "        [1.0739],\n",
      "        [1.0778],\n",
      "        [1.0856],\n",
      "        [1.0901],\n",
      "        [1.1006],\n",
      "        [1.0916],\n",
      "        [1.0771],\n",
      "        [1.0954],\n",
      "        [1.0874],\n",
      "        [1.0401],\n",
      "        [1.0735],\n",
      "        [1.0893],\n",
      "        [1.1134],\n",
      "        [1.0736],\n",
      "        [1.0782],\n",
      "        [1.0290],\n",
      "        [1.0759],\n",
      "        [1.1155],\n",
      "        [1.0805],\n",
      "        [1.1039],\n",
      "        [1.0757],\n",
      "        [1.0810],\n",
      "        [1.0893],\n",
      "        [1.0735],\n",
      "        [1.1150],\n",
      "        [1.0859],\n",
      "        [1.0287],\n",
      "        [1.0925],\n",
      "        [1.1194],\n",
      "        [1.0904],\n",
      "        [1.0881],\n",
      "        [1.0823],\n",
      "        [1.0521],\n",
      "        [1.0968],\n",
      "        [1.0607],\n",
      "        [1.0737],\n",
      "        [1.0995],\n",
      "        [1.0893],\n",
      "        [1.0955],\n",
      "        [1.0559],\n",
      "        [1.1000],\n",
      "        [1.1129],\n",
      "        [1.0738],\n",
      "        [1.0984],\n",
      "        [1.0801],\n",
      "        [1.1159],\n",
      "        [1.1059],\n",
      "        [1.0505],\n",
      "        [1.1059],\n",
      "        [1.0746],\n",
      "        [1.0903],\n",
      "        [1.0866],\n",
      "        [1.0819],\n",
      "        [1.0757],\n",
      "        [1.0920],\n",
      "        [1.0912],\n",
      "        [1.1046],\n",
      "        [1.0853],\n",
      "        [1.0667],\n",
      "        [1.0758],\n",
      "        [1.1035],\n",
      "        [1.0831],\n",
      "        [1.0896],\n",
      "        [1.1067],\n",
      "        [1.1029],\n",
      "        [1.1033],\n",
      "        [1.1138],\n",
      "        [1.0933]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0999],\n",
      "        [1.1106],\n",
      "        [1.0521],\n",
      "        [1.1128],\n",
      "        [1.1107],\n",
      "        [1.0864],\n",
      "        [1.0611],\n",
      "        [1.0367],\n",
      "        [1.0989],\n",
      "        [1.0735],\n",
      "        [1.0890],\n",
      "        [1.1117],\n",
      "        [1.0991],\n",
      "        [1.1069],\n",
      "        [1.0982],\n",
      "        [1.1166],\n",
      "        [1.0322],\n",
      "        [1.1053],\n",
      "        [1.1096],\n",
      "        [1.1031],\n",
      "        [1.0877],\n",
      "        [1.0672],\n",
      "        [1.0794],\n",
      "        [1.0409],\n",
      "        [1.0697],\n",
      "        [1.0803],\n",
      "        [1.1075],\n",
      "        [1.1028],\n",
      "        [1.0697],\n",
      "        [1.0668],\n",
      "        [1.0313],\n",
      "        [1.1004],\n",
      "        [1.0940],\n",
      "        [1.0869],\n",
      "        [1.1183],\n",
      "        [1.1117],\n",
      "        [1.0784],\n",
      "        [1.0828],\n",
      "        [1.1090],\n",
      "        [1.0914],\n",
      "        [1.0985],\n",
      "        [1.0909],\n",
      "        [1.1007],\n",
      "        [1.0907],\n",
      "        [1.1163],\n",
      "        [1.0529],\n",
      "        [1.0592],\n",
      "        [1.0580],\n",
      "        [1.0584],\n",
      "        [1.1001],\n",
      "        [1.1035],\n",
      "        [1.1035],\n",
      "        [1.1075],\n",
      "        [1.1147],\n",
      "        [1.0634],\n",
      "        [1.0457],\n",
      "        [1.0816],\n",
      "        [1.1171],\n",
      "        [1.1142],\n",
      "        [1.0938],\n",
      "        [1.1162],\n",
      "        [1.1145],\n",
      "        [1.1146],\n",
      "        [1.0892],\n",
      "        [1.0902],\n",
      "        [1.0745],\n",
      "        [1.1163],\n",
      "        [1.0836],\n",
      "        [1.0937],\n",
      "        [1.0804],\n",
      "        [1.1106],\n",
      "        [1.0822],\n",
      "        [1.1021],\n",
      "        [1.1145],\n",
      "        [1.0928],\n",
      "        [1.0819],\n",
      "        [1.0857],\n",
      "        [1.0630],\n",
      "        [1.1000],\n",
      "        [1.0947],\n",
      "        [1.0972],\n",
      "        [1.0893],\n",
      "        [1.1118],\n",
      "        [1.0982],\n",
      "        [1.0684],\n",
      "        [1.0973],\n",
      "        [1.0815],\n",
      "        [1.0797],\n",
      "        [1.0966],\n",
      "        [1.0731],\n",
      "        [1.0806],\n",
      "        [1.0875],\n",
      "        [1.0991],\n",
      "        [1.0761],\n",
      "        [1.1040],\n",
      "        [1.1145],\n",
      "        [1.0611],\n",
      "        [1.0982],\n",
      "        [1.0591],\n",
      "        [0.3371],\n",
      "        [1.1134],\n",
      "        [1.0929],\n",
      "        [1.0512],\n",
      "        [1.0916],\n",
      "        [1.0784],\n",
      "        [1.0660],\n",
      "        [1.0481],\n",
      "        [1.1090],\n",
      "        [1.0642],\n",
      "        [1.0783],\n",
      "        [1.0919],\n",
      "        [1.0599],\n",
      "        [1.1126],\n",
      "        [1.0760],\n",
      "        [1.0654],\n",
      "        [1.0267],\n",
      "        [1.0651],\n",
      "        [1.0848],\n",
      "        [1.0957],\n",
      "        [1.1083],\n",
      "        [1.0618],\n",
      "        [1.0887],\n",
      "        [1.0634],\n",
      "        [1.0314],\n",
      "        [1.0976],\n",
      "        [1.1149],\n",
      "        [1.0417],\n",
      "        [1.0703]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1027],\n",
      "        [1.1146],\n",
      "        [1.0293],\n",
      "        [1.1138],\n",
      "        [1.0745],\n",
      "        [1.0951],\n",
      "        [1.0876],\n",
      "        [1.0199],\n",
      "        [1.0663],\n",
      "        [1.1189],\n",
      "        [1.0759],\n",
      "        [1.0327],\n",
      "        [1.1167],\n",
      "        [1.1105],\n",
      "        [1.0825],\n",
      "        [1.0997],\n",
      "        [1.1054],\n",
      "        [1.1001],\n",
      "        [1.1071],\n",
      "        [1.0643],\n",
      "        [1.1179],\n",
      "        [1.0902],\n",
      "        [1.0706],\n",
      "        [1.1058],\n",
      "        [1.0691],\n",
      "        [1.0859],\n",
      "        [1.0621],\n",
      "        [1.0609],\n",
      "        [1.1015],\n",
      "        [1.0506],\n",
      "        [1.1049],\n",
      "        [1.0824],\n",
      "        [1.0703],\n",
      "        [1.1026],\n",
      "        [1.0906],\n",
      "        [1.1044],\n",
      "        [1.1142],\n",
      "        [1.1035],\n",
      "        [1.0567],\n",
      "        [1.0980],\n",
      "        [1.1012],\n",
      "        [1.1030],\n",
      "        [1.0774],\n",
      "        [1.0616],\n",
      "        [1.0949],\n",
      "        [1.0979],\n",
      "        [1.1166],\n",
      "        [1.1003],\n",
      "        [1.1037],\n",
      "        [1.1090],\n",
      "        [1.1064],\n",
      "        [1.1192],\n",
      "        [1.0665],\n",
      "        [1.0803],\n",
      "        [1.0782],\n",
      "        [1.0803],\n",
      "        [1.1004],\n",
      "        [1.0618],\n",
      "        [1.0662],\n",
      "        [1.0790],\n",
      "        [1.1072],\n",
      "        [1.1007],\n",
      "        [1.0558],\n",
      "        [1.0559],\n",
      "        [1.0934],\n",
      "        [1.0734],\n",
      "        [1.0844],\n",
      "        [1.0780],\n",
      "        [1.1019],\n",
      "        [1.0947],\n",
      "        [1.0424],\n",
      "        [1.0654],\n",
      "        [1.0888],\n",
      "        [1.1172],\n",
      "        [1.0797],\n",
      "        [1.0857],\n",
      "        [0.5834],\n",
      "        [1.1022],\n",
      "        [1.1107],\n",
      "        [1.1074],\n",
      "        [1.0950],\n",
      "        [1.1132],\n",
      "        [1.0422],\n",
      "        [1.1066],\n",
      "        [1.0815],\n",
      "        [1.0844],\n",
      "        [1.0825],\n",
      "        [1.0835],\n",
      "        [1.0824],\n",
      "        [1.0745],\n",
      "        [1.0768],\n",
      "        [1.0647],\n",
      "        [1.0675],\n",
      "        [1.0877],\n",
      "        [1.0995],\n",
      "        [1.1047],\n",
      "        [1.0804],\n",
      "        [1.0335],\n",
      "        [1.0583],\n",
      "        [1.0975],\n",
      "        [1.0513],\n",
      "        [1.1160],\n",
      "        [1.0598],\n",
      "        [1.0944],\n",
      "        [1.1070],\n",
      "        [1.1020],\n",
      "        [1.0975],\n",
      "        [1.1019],\n",
      "        [1.1054],\n",
      "        [1.0504],\n",
      "        [1.1167],\n",
      "        [1.1162],\n",
      "        [1.0873],\n",
      "        [1.0738],\n",
      "        [1.0124],\n",
      "        [1.1125],\n",
      "        [1.1040],\n",
      "        [1.0971],\n",
      "        [1.0980],\n",
      "        [1.1070],\n",
      "        [1.1134],\n",
      "        [1.0784],\n",
      "        [1.0804],\n",
      "        [1.0924],\n",
      "        [1.0822],\n",
      "        [1.1164],\n",
      "        [1.0935],\n",
      "        [1.0924]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0890],\n",
      "        [1.0934],\n",
      "        [1.0881],\n",
      "        [1.1012],\n",
      "        [1.0893],\n",
      "        [1.1016],\n",
      "        [1.1018],\n",
      "        [1.1022],\n",
      "        [1.1008],\n",
      "        [1.1012],\n",
      "        [1.0980],\n",
      "        [1.1138],\n",
      "        [1.0810],\n",
      "        [1.0898],\n",
      "        [1.1043],\n",
      "        [1.0504],\n",
      "        [1.1069],\n",
      "        [1.0854],\n",
      "        [1.0995],\n",
      "        [1.1023],\n",
      "        [1.0665],\n",
      "        [1.0315],\n",
      "        [1.0774],\n",
      "        [1.0945],\n",
      "        [1.0733],\n",
      "        [1.1028],\n",
      "        [1.1052],\n",
      "        [1.1015],\n",
      "        [1.0821],\n",
      "        [1.0830],\n",
      "        [1.1037],\n",
      "        [1.0925],\n",
      "        [1.1034],\n",
      "        [1.1088],\n",
      "        [1.0978],\n",
      "        [1.0775],\n",
      "        [1.0912],\n",
      "        [1.0496],\n",
      "        [1.0577],\n",
      "        [1.1028],\n",
      "        [1.0825],\n",
      "        [1.0922],\n",
      "        [1.0930],\n",
      "        [1.1135],\n",
      "        [1.0689],\n",
      "        [1.1130],\n",
      "        [1.1113],\n",
      "        [1.0362],\n",
      "        [1.0934],\n",
      "        [1.0476],\n",
      "        [1.0554],\n",
      "        [1.0759],\n",
      "        [1.1037],\n",
      "        [1.1028],\n",
      "        [1.0779],\n",
      "        [1.1048],\n",
      "        [1.0681],\n",
      "        [1.0664],\n",
      "        [1.0573],\n",
      "        [1.0847],\n",
      "        [1.1157],\n",
      "        [1.0548],\n",
      "        [1.0968],\n",
      "        [1.0982],\n",
      "        [1.0502],\n",
      "        [1.0655],\n",
      "        [1.0942],\n",
      "        [1.0880],\n",
      "        [1.0754],\n",
      "        [1.0954],\n",
      "        [1.1173],\n",
      "        [1.0970],\n",
      "        [1.0720],\n",
      "        [1.0337],\n",
      "        [1.1105],\n",
      "        [1.1169],\n",
      "        [1.0825],\n",
      "        [1.1060],\n",
      "        [1.0826],\n",
      "        [1.0920],\n",
      "        [1.0950],\n",
      "        [1.0741],\n",
      "        [1.1053],\n",
      "        [1.1004],\n",
      "        [1.1054],\n",
      "        [1.0486],\n",
      "        [1.0792],\n",
      "        [1.0864],\n",
      "        [1.1071],\n",
      "        [1.0699],\n",
      "        [1.0893],\n",
      "        [1.0871],\n",
      "        [1.0794],\n",
      "        [1.0795],\n",
      "        [1.0391],\n",
      "        [1.1092],\n",
      "        [1.0778],\n",
      "        [1.1036],\n",
      "        [1.0805],\n",
      "        [1.0776],\n",
      "        [1.0622],\n",
      "        [1.0554],\n",
      "        [1.1179],\n",
      "        [1.0704],\n",
      "        [1.0926],\n",
      "        [1.0867],\n",
      "        [1.1035],\n",
      "        [1.0649],\n",
      "        [1.0783],\n",
      "        [1.1007],\n",
      "        [1.0813],\n",
      "        [1.1050],\n",
      "        [1.1148],\n",
      "        [1.0609],\n",
      "        [1.0802],\n",
      "        [1.0832],\n",
      "        [1.0961],\n",
      "        [1.0726],\n",
      "        [1.0695],\n",
      "        [1.1172],\n",
      "        [1.1007],\n",
      "        [1.0478],\n",
      "        [1.1054],\n",
      "        [1.0987],\n",
      "        [1.0835],\n",
      "        [1.0831],\n",
      "        [1.0691],\n",
      "        [1.0508]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0914],\n",
      "        [1.0566],\n",
      "        [1.1010],\n",
      "        [1.0877],\n",
      "        [1.1107],\n",
      "        [1.0774],\n",
      "        [1.0533],\n",
      "        [1.0707],\n",
      "        [1.1005],\n",
      "        [1.1177],\n",
      "        [1.0579],\n",
      "        [1.1064],\n",
      "        [1.0935],\n",
      "        [1.0591],\n",
      "        [1.1115],\n",
      "        [1.0995],\n",
      "        [1.1064],\n",
      "        [1.0840],\n",
      "        [1.0824],\n",
      "        [1.1141],\n",
      "        [1.1122],\n",
      "        [1.0695],\n",
      "        [1.0888],\n",
      "        [1.0095],\n",
      "        [1.0845],\n",
      "        [1.0773],\n",
      "        [1.0606],\n",
      "        [1.0946],\n",
      "        [1.0638],\n",
      "        [1.1164],\n",
      "        [1.0978],\n",
      "        [1.0870],\n",
      "        [1.0759],\n",
      "        [1.0416],\n",
      "        [1.0498],\n",
      "        [1.0666],\n",
      "        [1.0641],\n",
      "        [1.0969],\n",
      "        [1.0589],\n",
      "        [1.1007],\n",
      "        [1.1042],\n",
      "        [1.0823],\n",
      "        [1.0571],\n",
      "        [1.1219],\n",
      "        [1.0649],\n",
      "        [1.0600],\n",
      "        [1.0821],\n",
      "        [1.0823],\n",
      "        [1.0515],\n",
      "        [1.0818],\n",
      "        [1.0837],\n",
      "        [1.0967],\n",
      "        [1.1099],\n",
      "        [1.0958],\n",
      "        [1.0330],\n",
      "        [1.1174],\n",
      "        [1.0852],\n",
      "        [1.0728],\n",
      "        [1.0977],\n",
      "        [1.0958],\n",
      "        [1.0375],\n",
      "        [1.1055],\n",
      "        [1.0492],\n",
      "        [1.1048],\n",
      "        [1.1087],\n",
      "        [1.0962],\n",
      "        [1.0279],\n",
      "        [1.0966],\n",
      "        [1.0714],\n",
      "        [1.0803],\n",
      "        [1.0697],\n",
      "        [1.0696],\n",
      "        [1.0493],\n",
      "        [1.0665],\n",
      "        [1.1163],\n",
      "        [1.0974],\n",
      "        [1.0871],\n",
      "        [1.0473],\n",
      "        [1.0969],\n",
      "        [1.0545],\n",
      "        [1.0896],\n",
      "        [1.1144],\n",
      "        [1.0989],\n",
      "        [1.0908],\n",
      "        [1.1036],\n",
      "        [1.0661],\n",
      "        [1.0692],\n",
      "        [1.0710],\n",
      "        [1.1003],\n",
      "        [1.0715],\n",
      "        [1.1103],\n",
      "        [1.1199],\n",
      "        [1.0979],\n",
      "        [1.0883],\n",
      "        [1.0677],\n",
      "        [1.1063],\n",
      "        [1.0518],\n",
      "        [1.1115],\n",
      "        [1.0676],\n",
      "        [1.1159],\n",
      "        [1.0195],\n",
      "        [1.1215],\n",
      "        [0.9910],\n",
      "        [1.0924],\n",
      "        [1.1180],\n",
      "        [1.0502],\n",
      "        [1.0590],\n",
      "        [1.0173],\n",
      "        [1.0889],\n",
      "        [1.1052],\n",
      "        [1.0989],\n",
      "        [1.1021],\n",
      "        [1.1205],\n",
      "        [1.1062],\n",
      "        [1.1005],\n",
      "        [1.0949],\n",
      "        [1.1015],\n",
      "        [1.0971],\n",
      "        [1.0931],\n",
      "        [1.0775],\n",
      "        [1.1106],\n",
      "        [1.0862],\n",
      "        [1.1055],\n",
      "        [1.1076],\n",
      "        [1.0769],\n",
      "        [1.1009],\n",
      "        [1.1037],\n",
      "        [1.0961]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1176],\n",
      "        [1.1142],\n",
      "        [1.0510],\n",
      "        [1.0474],\n",
      "        [1.0738],\n",
      "        [1.1155],\n",
      "        [1.0894],\n",
      "        [1.0937],\n",
      "        [1.0953],\n",
      "        [1.1109],\n",
      "        [1.0999],\n",
      "        [1.1141],\n",
      "        [1.1012],\n",
      "        [1.0872],\n",
      "        [1.0997],\n",
      "        [1.1158],\n",
      "        [0.0880],\n",
      "        [1.1094],\n",
      "        [1.1028],\n",
      "        [1.0865],\n",
      "        [1.0864],\n",
      "        [1.0873],\n",
      "        [1.0467],\n",
      "        [1.1145],\n",
      "        [1.0916],\n",
      "        [1.0632],\n",
      "        [1.1027],\n",
      "        [1.0769],\n",
      "        [1.0842],\n",
      "        [1.1102],\n",
      "        [1.0876],\n",
      "        [1.0706],\n",
      "        [1.0893],\n",
      "        [1.0999],\n",
      "        [1.1031],\n",
      "        [1.0868],\n",
      "        [1.0899],\n",
      "        [1.0567],\n",
      "        [1.1007],\n",
      "        [1.0842],\n",
      "        [1.1152],\n",
      "        [1.0536],\n",
      "        [1.1068],\n",
      "        [1.0973],\n",
      "        [1.0587],\n",
      "        [1.1048],\n",
      "        [1.0667],\n",
      "        [1.0993],\n",
      "        [1.1071],\n",
      "        [1.0974],\n",
      "        [1.1155],\n",
      "        [1.0801],\n",
      "        [1.0968],\n",
      "        [1.0945],\n",
      "        [1.0315],\n",
      "        [1.0697],\n",
      "        [1.0888],\n",
      "        [1.0984],\n",
      "        [1.0936],\n",
      "        [1.0543],\n",
      "        [1.0413],\n",
      "        [1.0922],\n",
      "        [1.0793],\n",
      "        [1.0889],\n",
      "        [1.1023],\n",
      "        [1.1146],\n",
      "        [1.0958],\n",
      "        [1.0686],\n",
      "        [1.1167],\n",
      "        [1.1133],\n",
      "        [1.0963],\n",
      "        [1.0888],\n",
      "        [1.0996],\n",
      "        [1.0720],\n",
      "        [1.1140],\n",
      "        [1.0732],\n",
      "        [1.0947],\n",
      "        [1.1127],\n",
      "        [1.0746],\n",
      "        [1.1176],\n",
      "        [1.0931],\n",
      "        [1.0619],\n",
      "        [1.0800],\n",
      "        [1.0504],\n",
      "        [1.0868],\n",
      "        [1.1136],\n",
      "        [1.0387],\n",
      "        [1.1033],\n",
      "        [1.0648],\n",
      "        [1.0936],\n",
      "        [1.1026],\n",
      "        [1.0901],\n",
      "        [1.0820],\n",
      "        [1.1086],\n",
      "        [1.0994],\n",
      "        [1.0647],\n",
      "        [1.0701],\n",
      "        [1.0626],\n",
      "        [1.1065],\n",
      "        [1.0183],\n",
      "        [1.0732],\n",
      "        [1.0873],\n",
      "        [1.1118],\n",
      "        [1.0830],\n",
      "        [1.0438],\n",
      "        [1.0955],\n",
      "        [1.1147],\n",
      "        [1.0813],\n",
      "        [1.1058],\n",
      "        [1.0894],\n",
      "        [1.1132],\n",
      "        [1.0608],\n",
      "        [1.0627],\n",
      "        [1.1063],\n",
      "        [1.1008],\n",
      "        [1.1017],\n",
      "        [1.1178],\n",
      "        [1.1164],\n",
      "        [1.1210],\n",
      "        [1.0783],\n",
      "        [1.0978],\n",
      "        [1.1065],\n",
      "        [1.0974],\n",
      "        [1.0694],\n",
      "        [1.1125],\n",
      "        [1.1148],\n",
      "        [1.0729],\n",
      "        [1.0648]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1012],\n",
      "        [1.0997],\n",
      "        [1.0764],\n",
      "        [1.1037],\n",
      "        [1.1134],\n",
      "        [1.0744],\n",
      "        [1.0614],\n",
      "        [1.0747],\n",
      "        [1.0800],\n",
      "        [1.1130],\n",
      "        [1.0637],\n",
      "        [1.0782],\n",
      "        [1.0922],\n",
      "        [1.0909],\n",
      "        [1.0706],\n",
      "        [1.0731],\n",
      "        [1.1052],\n",
      "        [1.0807],\n",
      "        [1.0663],\n",
      "        [1.0702],\n",
      "        [1.0728],\n",
      "        [1.0737],\n",
      "        [1.0877],\n",
      "        [1.0575],\n",
      "        [1.0811],\n",
      "        [1.0960],\n",
      "        [1.0908],\n",
      "        [1.0444],\n",
      "        [1.0747],\n",
      "        [1.0930],\n",
      "        [1.1076],\n",
      "        [1.0937],\n",
      "        [1.0868],\n",
      "        [1.0818],\n",
      "        [1.0939],\n",
      "        [1.0737],\n",
      "        [1.1120],\n",
      "        [1.0949],\n",
      "        [1.1060],\n",
      "        [1.0335],\n",
      "        [1.0467],\n",
      "        [1.1078],\n",
      "        [1.0935],\n",
      "        [1.0910],\n",
      "        [1.0574],\n",
      "        [1.0867],\n",
      "        [1.0297],\n",
      "        [1.0715],\n",
      "        [1.1013],\n",
      "        [1.0980],\n",
      "        [1.0848],\n",
      "        [1.0865],\n",
      "        [1.0501],\n",
      "        [1.0869],\n",
      "        [1.0910],\n",
      "        [1.0815],\n",
      "        [1.0905],\n",
      "        [1.1048],\n",
      "        [1.0917],\n",
      "        [1.0708],\n",
      "        [1.0827],\n",
      "        [1.1134],\n",
      "        [1.0720],\n",
      "        [1.1006],\n",
      "        [1.1046],\n",
      "        [1.1068],\n",
      "        [1.0356],\n",
      "        [1.1154],\n",
      "        [1.0828],\n",
      "        [1.0758],\n",
      "        [0.1228],\n",
      "        [1.0724],\n",
      "        [1.0946],\n",
      "        [1.0293],\n",
      "        [1.1087],\n",
      "        [1.1033],\n",
      "        [1.0434],\n",
      "        [1.1169],\n",
      "        [1.0791],\n",
      "        [1.0990],\n",
      "        [1.0740],\n",
      "        [1.0907],\n",
      "        [1.1050],\n",
      "        [1.1111],\n",
      "        [1.0751],\n",
      "        [0.4782],\n",
      "        [1.0936],\n",
      "        [1.0973],\n",
      "        [1.0422],\n",
      "        [1.1024],\n",
      "        [1.0729],\n",
      "        [1.1154],\n",
      "        [1.0663],\n",
      "        [1.0556],\n",
      "        [1.0522],\n",
      "        [1.1179],\n",
      "        [1.0980],\n",
      "        [1.1013],\n",
      "        [1.0981],\n",
      "        [1.0977],\n",
      "        [1.0908],\n",
      "        [1.1016],\n",
      "        [1.0816],\n",
      "        [1.1146],\n",
      "        [1.0353],\n",
      "        [1.1188],\n",
      "        [1.0906],\n",
      "        [1.1075],\n",
      "        [1.0744],\n",
      "        [1.0846],\n",
      "        [1.1095],\n",
      "        [1.1166],\n",
      "        [1.1123],\n",
      "        [1.0396],\n",
      "        [1.1088],\n",
      "        [1.0068],\n",
      "        [1.0769],\n",
      "        [1.1099],\n",
      "        [1.1185],\n",
      "        [1.1086],\n",
      "        [1.0956],\n",
      "        [1.1165],\n",
      "        [1.0960],\n",
      "        [1.0839],\n",
      "        [1.1083],\n",
      "        [1.1021],\n",
      "        [1.0891],\n",
      "        [1.0716]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0846],\n",
      "        [1.0710],\n",
      "        [1.0989],\n",
      "        [1.0706]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  37 | lr 0.00010 train_loss 2.12370 | val_loss 2.29284 | val_rmse 1.51421\n",
      "tensor([[1.0786],\n",
      "        [1.0879],\n",
      "        [1.0905],\n",
      "        [1.0968],\n",
      "        [1.0871],\n",
      "        [1.0744],\n",
      "        [1.0797],\n",
      "        [1.1122],\n",
      "        [1.1138],\n",
      "        [1.0939],\n",
      "        [1.0764],\n",
      "        [1.1127],\n",
      "        [1.0969],\n",
      "        [1.0646],\n",
      "        [1.0889],\n",
      "        [1.0913],\n",
      "        [1.1104],\n",
      "        [1.0902],\n",
      "        [1.1019],\n",
      "        [1.1054],\n",
      "        [1.0714],\n",
      "        [1.1103],\n",
      "        [1.1037],\n",
      "        [1.1051],\n",
      "        [1.0578],\n",
      "        [1.1000],\n",
      "        [1.0864],\n",
      "        [1.0876],\n",
      "        [1.0644],\n",
      "        [1.0918],\n",
      "        [1.1121],\n",
      "        [1.0775],\n",
      "        [1.1071],\n",
      "        [1.0654],\n",
      "        [1.1025],\n",
      "        [1.0243],\n",
      "        [1.0919],\n",
      "        [1.1078],\n",
      "        [1.0932],\n",
      "        [1.0913],\n",
      "        [1.0726],\n",
      "        [1.0844],\n",
      "        [1.0796],\n",
      "        [1.1029],\n",
      "        [1.1086],\n",
      "        [1.0569],\n",
      "        [1.0858],\n",
      "        [1.0792],\n",
      "        [1.0896],\n",
      "        [1.0789],\n",
      "        [1.0818],\n",
      "        [1.0949],\n",
      "        [1.0823],\n",
      "        [1.0394],\n",
      "        [1.0471],\n",
      "        [1.0524],\n",
      "        [1.0912],\n",
      "        [1.1058],\n",
      "        [1.1093],\n",
      "        [1.0762],\n",
      "        [1.0517],\n",
      "        [1.1025],\n",
      "        [1.0848],\n",
      "        [1.0590],\n",
      "        [1.0929],\n",
      "        [1.0939],\n",
      "        [1.0543],\n",
      "        [1.1016],\n",
      "        [1.0758],\n",
      "        [1.0671],\n",
      "        [1.0834],\n",
      "        [1.0788],\n",
      "        [1.0335],\n",
      "        [1.0389],\n",
      "        [1.0854],\n",
      "        [1.1180],\n",
      "        [1.0801],\n",
      "        [1.1035],\n",
      "        [1.0901],\n",
      "        [1.0955],\n",
      "        [1.0767],\n",
      "        [1.0742],\n",
      "        [1.1018],\n",
      "        [1.1023],\n",
      "        [1.0965],\n",
      "        [1.0861],\n",
      "        [1.0898],\n",
      "        [1.1008],\n",
      "        [1.0865],\n",
      "        [1.1009],\n",
      "        [1.0872],\n",
      "        [1.0499],\n",
      "        [1.0694],\n",
      "        [1.1032],\n",
      "        [1.0784],\n",
      "        [1.0660],\n",
      "        [1.1066],\n",
      "        [1.1080],\n",
      "        [1.0994],\n",
      "        [1.0771],\n",
      "        [1.0752],\n",
      "        [1.0627],\n",
      "        [1.1158],\n",
      "        [1.0883],\n",
      "        [1.0930],\n",
      "        [1.0932],\n",
      "        [1.0933],\n",
      "        [1.0762],\n",
      "        [0.9787],\n",
      "        [1.1106],\n",
      "        [1.0512],\n",
      "        [1.0918],\n",
      "        [1.1055],\n",
      "        [1.0881],\n",
      "        [1.1122],\n",
      "        [1.1130],\n",
      "        [1.0892],\n",
      "        [1.1019],\n",
      "        [1.0979],\n",
      "        [1.1123],\n",
      "        [1.0746],\n",
      "        [1.1140],\n",
      "        [1.0746],\n",
      "        [1.0996],\n",
      "        [1.0948],\n",
      "        [1.1149],\n",
      "        [1.1145],\n",
      "        [1.0777]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0947],\n",
      "        [1.0955],\n",
      "        [1.0561],\n",
      "        [1.0655],\n",
      "        [1.1122],\n",
      "        [1.0866],\n",
      "        [1.0815],\n",
      "        [1.0900],\n",
      "        [1.0791],\n",
      "        [1.0716],\n",
      "        [1.0893],\n",
      "        [1.0734],\n",
      "        [1.1126],\n",
      "        [1.0611],\n",
      "        [1.0710],\n",
      "        [1.0923],\n",
      "        [1.1120],\n",
      "        [1.1118],\n",
      "        [1.0765],\n",
      "        [1.0813],\n",
      "        [1.0882],\n",
      "        [1.1180],\n",
      "        [1.0691],\n",
      "        [1.0642],\n",
      "        [1.0540],\n",
      "        [1.0388],\n",
      "        [1.0871],\n",
      "        [1.0996],\n",
      "        [1.0888],\n",
      "        [1.1055],\n",
      "        [1.0742],\n",
      "        [1.0691],\n",
      "        [1.0528],\n",
      "        [1.0768],\n",
      "        [1.0280],\n",
      "        [1.1031],\n",
      "        [1.0707],\n",
      "        [1.0858],\n",
      "        [1.1004],\n",
      "        [1.0453],\n",
      "        [1.0976],\n",
      "        [1.0980],\n",
      "        [1.1065],\n",
      "        [1.0865],\n",
      "        [1.1097],\n",
      "        [1.0794],\n",
      "        [1.1073],\n",
      "        [1.0855],\n",
      "        [1.0857],\n",
      "        [1.0999],\n",
      "        [1.1117],\n",
      "        [1.1187],\n",
      "        [1.1061],\n",
      "        [1.0664],\n",
      "        [1.1123],\n",
      "        [1.1013],\n",
      "        [1.0539],\n",
      "        [1.0842],\n",
      "        [1.0991],\n",
      "        [1.0811],\n",
      "        [1.1130],\n",
      "        [1.0876],\n",
      "        [1.1034],\n",
      "        [1.0901],\n",
      "        [1.0118],\n",
      "        [1.1152],\n",
      "        [1.0988],\n",
      "        [1.1017],\n",
      "        [1.1086],\n",
      "        [1.1121],\n",
      "        [1.1066],\n",
      "        [1.0907],\n",
      "        [1.0553],\n",
      "        [1.0745],\n",
      "        [1.1050],\n",
      "        [1.0753],\n",
      "        [1.0859],\n",
      "        [1.1045],\n",
      "        [1.0994],\n",
      "        [1.0703],\n",
      "        [1.0933],\n",
      "        [1.0691],\n",
      "        [1.1141],\n",
      "        [1.0856],\n",
      "        [1.0869],\n",
      "        [1.0903],\n",
      "        [1.1004],\n",
      "        [1.1169],\n",
      "        [1.1109],\n",
      "        [1.0968],\n",
      "        [1.0599],\n",
      "        [1.0820],\n",
      "        [1.1085],\n",
      "        [1.0808],\n",
      "        [1.0344],\n",
      "        [1.0904],\n",
      "        [1.0725],\n",
      "        [1.1008],\n",
      "        [1.1117],\n",
      "        [1.0326],\n",
      "        [1.0979],\n",
      "        [0.4217],\n",
      "        [1.0698],\n",
      "        [1.0941],\n",
      "        [1.0711],\n",
      "        [1.0619],\n",
      "        [1.0886],\n",
      "        [1.0571],\n",
      "        [1.0552],\n",
      "        [1.1162],\n",
      "        [1.1075],\n",
      "        [1.1106],\n",
      "        [1.0927],\n",
      "        [1.0884],\n",
      "        [1.1024],\n",
      "        [1.0942],\n",
      "        [1.0915],\n",
      "        [1.0898],\n",
      "        [1.0538],\n",
      "        [1.0814],\n",
      "        [1.0898],\n",
      "        [1.1102],\n",
      "        [1.0575],\n",
      "        [1.0918],\n",
      "        [1.0683],\n",
      "        [1.0852],\n",
      "        [1.0840],\n",
      "        [1.0980]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0944],\n",
      "        [1.1164],\n",
      "        [1.0562],\n",
      "        [1.1076],\n",
      "        [1.1030],\n",
      "        [1.0684],\n",
      "        [1.1170],\n",
      "        [1.1150],\n",
      "        [1.1101],\n",
      "        [1.1135],\n",
      "        [1.0933],\n",
      "        [1.1178],\n",
      "        [1.0841],\n",
      "        [1.0933],\n",
      "        [1.0844],\n",
      "        [1.0850],\n",
      "        [1.0971],\n",
      "        [1.0808],\n",
      "        [1.0858],\n",
      "        [1.1040],\n",
      "        [1.0841],\n",
      "        [1.0939],\n",
      "        [1.0940],\n",
      "        [1.1024],\n",
      "        [1.0881],\n",
      "        [1.0503],\n",
      "        [1.1092],\n",
      "        [1.0975],\n",
      "        [1.1011],\n",
      "        [1.0558],\n",
      "        [1.0902],\n",
      "        [1.0928],\n",
      "        [1.1074],\n",
      "        [1.0376],\n",
      "        [1.1062],\n",
      "        [1.0985],\n",
      "        [1.0429],\n",
      "        [1.1011],\n",
      "        [1.0953],\n",
      "        [1.0780],\n",
      "        [1.1119],\n",
      "        [1.1019],\n",
      "        [1.1131],\n",
      "        [1.1177],\n",
      "        [1.0920],\n",
      "        [1.1008],\n",
      "        [1.0894],\n",
      "        [1.0859],\n",
      "        [1.0501],\n",
      "        [1.0028],\n",
      "        [1.1021],\n",
      "        [1.0826],\n",
      "        [1.0581],\n",
      "        [1.0956],\n",
      "        [1.0739],\n",
      "        [1.0348],\n",
      "        [1.0938],\n",
      "        [1.0079],\n",
      "        [1.1199],\n",
      "        [1.1151],\n",
      "        [1.0951],\n",
      "        [1.0567],\n",
      "        [1.1113],\n",
      "        [1.1025],\n",
      "        [1.0130],\n",
      "        [1.0844],\n",
      "        [1.1055],\n",
      "        [1.1026],\n",
      "        [1.0660],\n",
      "        [1.0913],\n",
      "        [0.7988],\n",
      "        [1.0922],\n",
      "        [1.0550],\n",
      "        [1.1021],\n",
      "        [1.0802],\n",
      "        [1.0948],\n",
      "        [1.0959],\n",
      "        [1.0810],\n",
      "        [1.1011],\n",
      "        [1.1145],\n",
      "        [1.0287],\n",
      "        [1.1181],\n",
      "        [1.1040],\n",
      "        [1.1055],\n",
      "        [1.0727],\n",
      "        [1.0426],\n",
      "        [1.0892],\n",
      "        [1.1053],\n",
      "        [1.0864],\n",
      "        [1.0987],\n",
      "        [1.1049],\n",
      "        [1.1085],\n",
      "        [1.0788],\n",
      "        [1.1102],\n",
      "        [1.0797],\n",
      "        [1.1078],\n",
      "        [1.1049],\n",
      "        [1.0832],\n",
      "        [1.1004],\n",
      "        [1.1052],\n",
      "        [1.1101],\n",
      "        [1.0889],\n",
      "        [1.0606],\n",
      "        [1.1167],\n",
      "        [1.0868],\n",
      "        [1.0612],\n",
      "        [1.0211],\n",
      "        [1.0797],\n",
      "        [1.0723],\n",
      "        [1.1003],\n",
      "        [1.0800],\n",
      "        [1.0998],\n",
      "        [1.0985],\n",
      "        [1.1036],\n",
      "        [1.1073],\n",
      "        [1.0799],\n",
      "        [1.1029],\n",
      "        [1.0814],\n",
      "        [1.0664],\n",
      "        [1.1161],\n",
      "        [1.0972],\n",
      "        [1.1004],\n",
      "        [1.1200],\n",
      "        [1.0898],\n",
      "        [1.0785],\n",
      "        [1.0867],\n",
      "        [1.1158],\n",
      "        [1.0772]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.2706],\n",
      "        [1.0713],\n",
      "        [1.0810],\n",
      "        [1.0891],\n",
      "        [1.0659],\n",
      "        [1.1016],\n",
      "        [1.0721],\n",
      "        [1.0642],\n",
      "        [1.0930],\n",
      "        [1.0915],\n",
      "        [1.0923],\n",
      "        [1.1043],\n",
      "        [1.0791],\n",
      "        [1.0694],\n",
      "        [1.0910],\n",
      "        [1.1138],\n",
      "        [1.1052],\n",
      "        [1.0788],\n",
      "        [1.0053],\n",
      "        [1.0940],\n",
      "        [1.0964],\n",
      "        [1.0464],\n",
      "        [1.1085],\n",
      "        [1.0956],\n",
      "        [1.0862],\n",
      "        [1.1115],\n",
      "        [1.1042],\n",
      "        [1.0752],\n",
      "        [1.1033],\n",
      "        [1.0977],\n",
      "        [1.1142],\n",
      "        [1.1015],\n",
      "        [1.1104],\n",
      "        [1.0877],\n",
      "        [1.0979],\n",
      "        [1.0518],\n",
      "        [1.1026],\n",
      "        [1.1038],\n",
      "        [1.0752],\n",
      "        [1.0854],\n",
      "        [1.0638],\n",
      "        [1.0614],\n",
      "        [1.0324],\n",
      "        [1.0764],\n",
      "        [1.1021],\n",
      "        [1.0985],\n",
      "        [1.0561],\n",
      "        [1.0766],\n",
      "        [1.0742],\n",
      "        [1.0370],\n",
      "        [1.0482],\n",
      "        [1.9777],\n",
      "        [0.5962],\n",
      "        [1.0767],\n",
      "        [1.1164],\n",
      "        [1.0578],\n",
      "        [1.0808],\n",
      "        [1.0779],\n",
      "        [1.1053],\n",
      "        [1.0846],\n",
      "        [1.0695],\n",
      "        [1.0908],\n",
      "        [1.1175],\n",
      "        [1.0976],\n",
      "        [1.1161],\n",
      "        [1.1002],\n",
      "        [1.1206],\n",
      "        [1.1174],\n",
      "        [1.1035],\n",
      "        [1.1006],\n",
      "        [1.1026],\n",
      "        [1.0805],\n",
      "        [1.0935],\n",
      "        [1.1063],\n",
      "        [1.0474],\n",
      "        [1.0771],\n",
      "        [1.0858],\n",
      "        [1.1076],\n",
      "        [1.1037],\n",
      "        [1.0864],\n",
      "        [1.0807],\n",
      "        [1.0926],\n",
      "        [1.1105],\n",
      "        [1.1093],\n",
      "        [1.1005],\n",
      "        [1.1149],\n",
      "        [1.0383],\n",
      "        [1.1074],\n",
      "        [1.0791],\n",
      "        [1.0526],\n",
      "        [1.0399],\n",
      "        [1.0642],\n",
      "        [1.1038],\n",
      "        [1.0540],\n",
      "        [1.1026],\n",
      "        [1.0789],\n",
      "        [1.0468],\n",
      "        [1.0949],\n",
      "        [1.0646],\n",
      "        [1.1126],\n",
      "        [1.0900],\n",
      "        [1.1078],\n",
      "        [1.1107],\n",
      "        [1.0726],\n",
      "        [1.0980],\n",
      "        [1.0795],\n",
      "        [1.0989],\n",
      "        [1.1059],\n",
      "        [1.0666],\n",
      "        [1.1149],\n",
      "        [1.0907],\n",
      "        [1.0706],\n",
      "        [1.0524],\n",
      "        [1.0730],\n",
      "        [1.0476],\n",
      "        [1.0963],\n",
      "        [1.1075],\n",
      "        [1.0592],\n",
      "        [1.0513],\n",
      "        [1.0688],\n",
      "        [1.0973],\n",
      "        [1.0645],\n",
      "        [1.0684],\n",
      "        [1.0989],\n",
      "        [1.0996],\n",
      "        [1.0986],\n",
      "        [1.1059],\n",
      "        [1.0811]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0637],\n",
      "        [1.0529],\n",
      "        [1.0570],\n",
      "        [1.1117],\n",
      "        [1.0738],\n",
      "        [1.1034],\n",
      "        [1.1046],\n",
      "        [1.0715],\n",
      "        [1.0931],\n",
      "        [1.0987],\n",
      "        [1.0728],\n",
      "        [1.1151],\n",
      "        [1.1054],\n",
      "        [1.0761],\n",
      "        [1.1132],\n",
      "        [1.0940],\n",
      "        [1.0970],\n",
      "        [1.0835],\n",
      "        [1.0837],\n",
      "        [1.1000],\n",
      "        [1.0809],\n",
      "        [1.0785],\n",
      "        [1.0734],\n",
      "        [1.0911],\n",
      "        [1.0751],\n",
      "        [1.0850],\n",
      "        [1.1046],\n",
      "        [1.0527],\n",
      "        [1.0903],\n",
      "        [1.1059],\n",
      "        [1.0952],\n",
      "        [1.0576],\n",
      "        [1.0714],\n",
      "        [1.0777],\n",
      "        [1.0958],\n",
      "        [1.0880],\n",
      "        [1.1123],\n",
      "        [1.0760],\n",
      "        [1.0679],\n",
      "        [1.0676],\n",
      "        [1.0799],\n",
      "        [1.0673],\n",
      "        [1.1115],\n",
      "        [1.1064],\n",
      "        [1.0661],\n",
      "        [1.0790],\n",
      "        [1.0308],\n",
      "        [1.1075],\n",
      "        [1.0714],\n",
      "        [1.1041],\n",
      "        [1.0571],\n",
      "        [1.0738],\n",
      "        [1.1004],\n",
      "        [1.1129],\n",
      "        [1.0999],\n",
      "        [1.0796],\n",
      "        [1.1185],\n",
      "        [1.0866],\n",
      "        [1.0949],\n",
      "        [1.0855],\n",
      "        [1.1004],\n",
      "        [1.0768],\n",
      "        [1.0633],\n",
      "        [1.0771],\n",
      "        [1.0118],\n",
      "        [1.1054],\n",
      "        [1.0622],\n",
      "        [1.0456],\n",
      "        [1.1070],\n",
      "        [1.1131],\n",
      "        [1.1046],\n",
      "        [1.0701],\n",
      "        [1.0786],\n",
      "        [1.1150],\n",
      "        [1.0594],\n",
      "        [1.0841],\n",
      "        [1.1180],\n",
      "        [1.0784],\n",
      "        [1.0981],\n",
      "        [1.0505],\n",
      "        [1.0720],\n",
      "        [1.1068],\n",
      "        [1.0943],\n",
      "        [1.1082],\n",
      "        [1.1130],\n",
      "        [1.1033],\n",
      "        [1.1138],\n",
      "        [1.0951],\n",
      "        [1.0733],\n",
      "        [1.1115],\n",
      "        [1.0945],\n",
      "        [1.0428],\n",
      "        [1.0959],\n",
      "        [1.0574],\n",
      "        [1.0842],\n",
      "        [1.0911],\n",
      "        [1.0469],\n",
      "        [1.0597],\n",
      "        [1.1153],\n",
      "        [1.0724],\n",
      "        [1.1115],\n",
      "        [1.0935],\n",
      "        [1.1009],\n",
      "        [1.1101],\n",
      "        [1.0366],\n",
      "        [1.1043],\n",
      "        [1.1095],\n",
      "        [1.1001],\n",
      "        [1.0526],\n",
      "        [1.0721],\n",
      "        [1.0610],\n",
      "        [1.0847],\n",
      "        [1.0867],\n",
      "        [1.1130],\n",
      "        [1.0862],\n",
      "        [1.0815],\n",
      "        [1.1085],\n",
      "        [1.0429],\n",
      "        [1.0541],\n",
      "        [1.0543],\n",
      "        [1.0857],\n",
      "        [1.0632],\n",
      "        [1.1043],\n",
      "        [1.0831],\n",
      "        [1.0516],\n",
      "        [1.1030],\n",
      "        [1.0583],\n",
      "        [1.0916]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0876],\n",
      "        [1.0811],\n",
      "        [1.0983],\n",
      "        [1.1167],\n",
      "        [1.0914],\n",
      "        [1.0748],\n",
      "        [1.0814],\n",
      "        [1.0950],\n",
      "        [1.1090],\n",
      "        [1.0886],\n",
      "        [1.1008],\n",
      "        [1.0895],\n",
      "        [1.1197],\n",
      "        [1.1032],\n",
      "        [1.1031],\n",
      "        [1.0797],\n",
      "        [1.0452],\n",
      "        [1.0680],\n",
      "        [1.0685],\n",
      "        [1.0866],\n",
      "        [1.1125],\n",
      "        [1.1179],\n",
      "        [1.1000],\n",
      "        [1.0928],\n",
      "        [1.0761],\n",
      "        [1.0959],\n",
      "        [1.0294],\n",
      "        [1.1117],\n",
      "        [1.0660],\n",
      "        [1.1017],\n",
      "        [1.1144],\n",
      "        [1.1030],\n",
      "        [1.1102],\n",
      "        [1.0478],\n",
      "        [1.0749],\n",
      "        [1.0870],\n",
      "        [1.1044],\n",
      "        [1.0607],\n",
      "        [1.0929],\n",
      "        [1.1062],\n",
      "        [1.1125],\n",
      "        [1.0588],\n",
      "        [1.0905],\n",
      "        [1.0831],\n",
      "        [1.1021],\n",
      "        [1.1009],\n",
      "        [1.0517],\n",
      "        [0.1756],\n",
      "        [1.0775],\n",
      "        [1.1123],\n",
      "        [1.0581],\n",
      "        [1.1160],\n",
      "        [1.0647],\n",
      "        [1.1067],\n",
      "        [1.0965],\n",
      "        [1.0995],\n",
      "        [1.0770],\n",
      "        [1.0659],\n",
      "        [1.1131],\n",
      "        [1.0915],\n",
      "        [1.0873],\n",
      "        [1.1096],\n",
      "        [1.0735],\n",
      "        [1.1038],\n",
      "        [1.1173],\n",
      "        [1.0890],\n",
      "        [1.0298],\n",
      "        [1.0737],\n",
      "        [1.0979],\n",
      "        [1.0988],\n",
      "        [1.0792],\n",
      "        [1.0694],\n",
      "        [1.0681],\n",
      "        [1.0980],\n",
      "        [1.0989],\n",
      "        [1.1063],\n",
      "        [1.0587],\n",
      "        [1.0954],\n",
      "        [1.0760],\n",
      "        [1.0746],\n",
      "        [1.0723],\n",
      "        [1.0960],\n",
      "        [1.1117],\n",
      "        [1.0850],\n",
      "        [1.1132],\n",
      "        [1.0843],\n",
      "        [1.0796],\n",
      "        [1.1171],\n",
      "        [1.0893],\n",
      "        [1.1014],\n",
      "        [1.0812],\n",
      "        [1.0822],\n",
      "        [1.0839],\n",
      "        [1.0458],\n",
      "        [1.1145],\n",
      "        [1.0918],\n",
      "        [1.0947],\n",
      "        [1.1075],\n",
      "        [1.0949],\n",
      "        [0.0849],\n",
      "        [1.1095],\n",
      "        [1.0798],\n",
      "        [1.0965],\n",
      "        [1.0114],\n",
      "        [1.0900],\n",
      "        [1.0876],\n",
      "        [1.0302],\n",
      "        [1.1193],\n",
      "        [1.0937],\n",
      "        [1.1127],\n",
      "        [1.0892],\n",
      "        [1.0601],\n",
      "        [1.0736],\n",
      "        [1.0751],\n",
      "        [1.0997],\n",
      "        [1.0747],\n",
      "        [1.1109],\n",
      "        [1.1009],\n",
      "        [1.1110],\n",
      "        [1.0892],\n",
      "        [1.1065],\n",
      "        [1.0935],\n",
      "        [1.1069],\n",
      "        [1.0481],\n",
      "        [1.0619],\n",
      "        [1.0991],\n",
      "        [1.0988],\n",
      "        [1.1010]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0760],\n",
      "        [1.0884],\n",
      "        [1.0342],\n",
      "        [1.1056],\n",
      "        [1.0990],\n",
      "        [1.1032],\n",
      "        [1.0604],\n",
      "        [1.1052],\n",
      "        [1.0739],\n",
      "        [1.0974],\n",
      "        [1.0353],\n",
      "        [1.0863],\n",
      "        [1.0581],\n",
      "        [1.0592],\n",
      "        [1.0753],\n",
      "        [1.0989],\n",
      "        [1.0994],\n",
      "        [1.0976],\n",
      "        [1.0939],\n",
      "        [1.1058],\n",
      "        [1.1118],\n",
      "        [1.0616],\n",
      "        [1.0947],\n",
      "        [1.1081],\n",
      "        [1.0556],\n",
      "        [1.0218],\n",
      "        [1.0824],\n",
      "        [1.0970],\n",
      "        [1.1062],\n",
      "        [1.0790],\n",
      "        [1.0657],\n",
      "        [1.0607],\n",
      "        [1.1073],\n",
      "        [1.0998],\n",
      "        [1.1102],\n",
      "        [1.1208],\n",
      "        [1.0937],\n",
      "        [1.1000],\n",
      "        [1.1174],\n",
      "        [1.1130],\n",
      "        [1.0121],\n",
      "        [1.1087],\n",
      "        [1.0792],\n",
      "        [1.0323],\n",
      "        [1.0760],\n",
      "        [1.0976],\n",
      "        [1.0749],\n",
      "        [1.0378],\n",
      "        [1.1182],\n",
      "        [1.0901],\n",
      "        [1.0818],\n",
      "        [1.0893],\n",
      "        [1.0676],\n",
      "        [1.1172],\n",
      "        [1.0708],\n",
      "        [1.0709],\n",
      "        [1.0476],\n",
      "        [1.0829],\n",
      "        [1.0979],\n",
      "        [1.1054],\n",
      "        [1.0799],\n",
      "        [1.0577],\n",
      "        [1.0995],\n",
      "        [1.0873],\n",
      "        [1.0503],\n",
      "        [1.1174],\n",
      "        [1.0936],\n",
      "        [1.1024],\n",
      "        [1.0504],\n",
      "        [1.1072],\n",
      "        [1.0903],\n",
      "        [1.0890],\n",
      "        [1.0756],\n",
      "        [1.1080],\n",
      "        [1.1066],\n",
      "        [1.0793],\n",
      "        [1.0920],\n",
      "        [1.1169],\n",
      "        [1.0936],\n",
      "        [1.1050],\n",
      "        [1.0471],\n",
      "        [1.0960],\n",
      "        [1.1157],\n",
      "        [1.0929],\n",
      "        [1.0992],\n",
      "        [1.0764],\n",
      "        [1.0809],\n",
      "        [1.0741],\n",
      "        [1.0869],\n",
      "        [1.1082],\n",
      "        [1.1042],\n",
      "        [1.1034],\n",
      "        [1.0791],\n",
      "        [1.0971],\n",
      "        [1.0888],\n",
      "        [1.1044],\n",
      "        [1.1150],\n",
      "        [1.0980],\n",
      "        [1.1186],\n",
      "        [1.1185],\n",
      "        [1.0612],\n",
      "        [1.0815],\n",
      "        [1.0388],\n",
      "        [1.0477],\n",
      "        [1.0801],\n",
      "        [1.0830],\n",
      "        [1.0828],\n",
      "        [1.1106],\n",
      "        [1.0719],\n",
      "        [1.0670],\n",
      "        [1.1110],\n",
      "        [1.0951],\n",
      "        [1.0954],\n",
      "        [1.0706],\n",
      "        [1.0671],\n",
      "        [1.1060],\n",
      "        [1.0841],\n",
      "        [1.1050],\n",
      "        [1.0796],\n",
      "        [1.1040],\n",
      "        [1.0676],\n",
      "        [1.1045],\n",
      "        [1.1050],\n",
      "        [1.1160],\n",
      "        [1.0946],\n",
      "        [1.0811],\n",
      "        [1.1010],\n",
      "        [1.0616]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0789],\n",
      "        [1.0851],\n",
      "        [1.1078],\n",
      "        [1.0889]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  38 | lr 0.00010 train_loss 2.11922 | val_loss 2.29287 | val_rmse 1.51422\n",
      "tensor([[1.1060],\n",
      "        [1.1141],\n",
      "        [1.0995],\n",
      "        [1.0804],\n",
      "        [1.0640],\n",
      "        [1.1061],\n",
      "        [1.0745],\n",
      "        [1.0963],\n",
      "        [1.0700],\n",
      "        [1.0966],\n",
      "        [1.0853],\n",
      "        [1.0713],\n",
      "        [1.0824],\n",
      "        [1.1008],\n",
      "        [1.0744],\n",
      "        [1.0448],\n",
      "        [1.0819],\n",
      "        [1.0579],\n",
      "        [1.0632],\n",
      "        [1.0835],\n",
      "        [1.0384],\n",
      "        [1.1053],\n",
      "        [1.1013],\n",
      "        [1.0904],\n",
      "        [1.0935],\n",
      "        [1.0568],\n",
      "        [1.1046],\n",
      "        [1.0642],\n",
      "        [1.0921],\n",
      "        [1.1131],\n",
      "        [1.1142],\n",
      "        [1.0988],\n",
      "        [1.0726],\n",
      "        [1.0550],\n",
      "        [1.0721],\n",
      "        [1.0800],\n",
      "        [1.0983],\n",
      "        [1.1116],\n",
      "        [1.0728],\n",
      "        [1.0849],\n",
      "        [1.0958],\n",
      "        [1.1169],\n",
      "        [1.1157],\n",
      "        [1.0802],\n",
      "        [1.1045],\n",
      "        [1.0638],\n",
      "        [1.0900],\n",
      "        [1.1093],\n",
      "        [1.0941],\n",
      "        [1.0747],\n",
      "        [1.0089],\n",
      "        [1.0903],\n",
      "        [1.0993],\n",
      "        [1.1167],\n",
      "        [1.0944],\n",
      "        [1.0593],\n",
      "        [1.0853],\n",
      "        [1.1078],\n",
      "        [1.0652],\n",
      "        [1.1164],\n",
      "        [1.0886],\n",
      "        [1.0466],\n",
      "        [1.1213],\n",
      "        [1.1075],\n",
      "        [1.1135],\n",
      "        [1.1123],\n",
      "        [1.0788],\n",
      "        [1.0797],\n",
      "        [1.0831],\n",
      "        [1.0838],\n",
      "        [1.1023],\n",
      "        [1.1001],\n",
      "        [1.1010],\n",
      "        [1.1090],\n",
      "        [1.0281],\n",
      "        [1.1050],\n",
      "        [1.0538],\n",
      "        [1.0627],\n",
      "        [1.0821],\n",
      "        [1.0816],\n",
      "        [1.1030],\n",
      "        [1.0950],\n",
      "        [1.1018],\n",
      "        [1.1110],\n",
      "        [1.0894],\n",
      "        [0.0235],\n",
      "        [1.0456],\n",
      "        [1.1061],\n",
      "        [1.0931],\n",
      "        [1.0695],\n",
      "        [1.1087],\n",
      "        [1.1053],\n",
      "        [1.0881],\n",
      "        [1.1115],\n",
      "        [1.0681],\n",
      "        [1.0931],\n",
      "        [1.0749],\n",
      "        [1.0682],\n",
      "        [1.0799],\n",
      "        [1.0858],\n",
      "        [1.0758],\n",
      "        [1.0673],\n",
      "        [1.0791],\n",
      "        [1.1097],\n",
      "        [1.0877],\n",
      "        [1.0608],\n",
      "        [1.0783],\n",
      "        [1.0740],\n",
      "        [1.0868],\n",
      "        [1.1178],\n",
      "        [1.1194],\n",
      "        [1.0984],\n",
      "        [1.0645],\n",
      "        [1.1115],\n",
      "        [1.1065],\n",
      "        [1.1002],\n",
      "        [1.0766],\n",
      "        [1.0494],\n",
      "        [1.1008],\n",
      "        [1.0760],\n",
      "        [1.0915],\n",
      "        [1.0325],\n",
      "        [1.0852],\n",
      "        [1.0951],\n",
      "        [1.0694],\n",
      "        [1.1121],\n",
      "        [1.1075],\n",
      "        [1.0806]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0734],\n",
      "        [1.0840],\n",
      "        [1.1101],\n",
      "        [1.0702],\n",
      "        [1.0633],\n",
      "        [1.0633],\n",
      "        [1.0950],\n",
      "        [1.0631],\n",
      "        [1.0996],\n",
      "        [1.0477],\n",
      "        [1.1176],\n",
      "        [1.1052],\n",
      "        [1.0716],\n",
      "        [1.0974],\n",
      "        [1.0474],\n",
      "        [1.0794],\n",
      "        [1.1043],\n",
      "        [1.0842],\n",
      "        [1.0958],\n",
      "        [1.0975],\n",
      "        [1.0805],\n",
      "        [1.1006],\n",
      "        [1.0964],\n",
      "        [1.0836],\n",
      "        [1.0495],\n",
      "        [1.0718],\n",
      "        [1.1071],\n",
      "        [1.0780],\n",
      "        [1.0805],\n",
      "        [1.0830],\n",
      "        [1.0953],\n",
      "        [1.0958],\n",
      "        [1.0888],\n",
      "        [1.1141],\n",
      "        [1.0947],\n",
      "        [1.0694],\n",
      "        [1.0952],\n",
      "        [1.0946],\n",
      "        [1.0924],\n",
      "        [1.1076],\n",
      "        [1.1118],\n",
      "        [1.0824],\n",
      "        [1.1171],\n",
      "        [1.0987],\n",
      "        [1.0876],\n",
      "        [1.1035],\n",
      "        [1.0731],\n",
      "        [1.0965],\n",
      "        [1.1155],\n",
      "        [1.1091],\n",
      "        [1.1067],\n",
      "        [1.1139],\n",
      "        [1.0890],\n",
      "        [1.1156],\n",
      "        [1.0608],\n",
      "        [1.0529],\n",
      "        [1.0609],\n",
      "        [1.0985],\n",
      "        [1.0957],\n",
      "        [1.0662],\n",
      "        [1.0820],\n",
      "        [1.1032],\n",
      "        [1.0731],\n",
      "        [1.0365],\n",
      "        [1.1154],\n",
      "        [1.0852],\n",
      "        [1.0948],\n",
      "        [1.0867],\n",
      "        [1.0880],\n",
      "        [1.0418],\n",
      "        [1.1031],\n",
      "        [1.0691],\n",
      "        [1.0994],\n",
      "        [1.0844],\n",
      "        [1.1091],\n",
      "        [1.1061],\n",
      "        [1.0865],\n",
      "        [1.0818],\n",
      "        [1.0115],\n",
      "        [1.0856],\n",
      "        [1.0856],\n",
      "        [1.0987],\n",
      "        [1.0818],\n",
      "        [1.0323],\n",
      "        [1.0545],\n",
      "        [1.0819],\n",
      "        [1.0755],\n",
      "        [1.0741],\n",
      "        [1.1003],\n",
      "        [1.1022],\n",
      "        [1.1042],\n",
      "        [1.0877],\n",
      "        [1.0885],\n",
      "        [1.1102],\n",
      "        [1.1173],\n",
      "        [1.0769],\n",
      "        [1.1175],\n",
      "        [1.0610],\n",
      "        [1.0610],\n",
      "        [1.0959],\n",
      "        [1.1144],\n",
      "        [1.0636],\n",
      "        [1.0849],\n",
      "        [1.0490],\n",
      "        [1.1015],\n",
      "        [1.1071],\n",
      "        [1.1035],\n",
      "        [1.0978],\n",
      "        [1.1092],\n",
      "        [1.0558],\n",
      "        [1.1046],\n",
      "        [1.0552],\n",
      "        [1.1173],\n",
      "        [1.1136],\n",
      "        [1.1132],\n",
      "        [1.0777],\n",
      "        [1.0832],\n",
      "        [1.0755],\n",
      "        [1.0893],\n",
      "        [1.0809],\n",
      "        [1.1158],\n",
      "        [1.0815],\n",
      "        [1.0967],\n",
      "        [1.0942],\n",
      "        [1.0845],\n",
      "        [1.0880],\n",
      "        [1.0674],\n",
      "        [1.0886]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0988],\n",
      "        [1.1153],\n",
      "        [1.1222],\n",
      "        [1.0731],\n",
      "        [1.0990],\n",
      "        [1.1052],\n",
      "        [1.0813],\n",
      "        [1.0553],\n",
      "        [1.0914],\n",
      "        [1.0830],\n",
      "        [1.1150],\n",
      "        [1.0559],\n",
      "        [1.0763],\n",
      "        [1.0574],\n",
      "        [1.0775],\n",
      "        [1.1135],\n",
      "        [1.0834],\n",
      "        [1.1073],\n",
      "        [1.0630],\n",
      "        [1.0935],\n",
      "        [1.1098],\n",
      "        [1.0912],\n",
      "        [1.0931],\n",
      "        [1.1093],\n",
      "        [1.0761],\n",
      "        [1.1071],\n",
      "        [1.1178],\n",
      "        [1.1190],\n",
      "        [1.1009],\n",
      "        [0.9922],\n",
      "        [1.0942],\n",
      "        [1.0648],\n",
      "        [1.0765],\n",
      "        [1.0920],\n",
      "        [1.0943],\n",
      "        [1.0764],\n",
      "        [1.0791],\n",
      "        [1.0570],\n",
      "        [1.0761],\n",
      "        [1.0984],\n",
      "        [1.0994],\n",
      "        [1.1089],\n",
      "        [1.0974],\n",
      "        [1.0816],\n",
      "        [1.0441],\n",
      "        [1.0780],\n",
      "        [1.1023],\n",
      "        [1.0744],\n",
      "        [1.0753],\n",
      "        [1.1120],\n",
      "        [1.1141],\n",
      "        [1.0743],\n",
      "        [1.0278],\n",
      "        [1.0844],\n",
      "        [1.0952],\n",
      "        [1.0208],\n",
      "        [1.1105],\n",
      "        [1.0631],\n",
      "        [1.1158],\n",
      "        [1.0928],\n",
      "        [1.1063],\n",
      "        [1.0412],\n",
      "        [1.1008],\n",
      "        [1.1059],\n",
      "        [1.1094],\n",
      "        [1.0668],\n",
      "        [1.0651],\n",
      "        [1.1019],\n",
      "        [1.1017],\n",
      "        [1.0688],\n",
      "        [0.6168],\n",
      "        [1.1188],\n",
      "        [1.0926],\n",
      "        [1.0906],\n",
      "        [1.1150],\n",
      "        [1.0788],\n",
      "        [1.0953],\n",
      "        [1.0309],\n",
      "        [1.1162],\n",
      "        [1.1066],\n",
      "        [1.0645],\n",
      "        [1.1124],\n",
      "        [1.0892],\n",
      "        [1.0923],\n",
      "        [1.1013],\n",
      "        [1.0877],\n",
      "        [1.1032],\n",
      "        [1.0864],\n",
      "        [1.1028],\n",
      "        [1.0582],\n",
      "        [1.0845],\n",
      "        [1.0736],\n",
      "        [1.1019],\n",
      "        [1.0671],\n",
      "        [1.0869],\n",
      "        [1.1116],\n",
      "        [1.0597],\n",
      "        [1.1192],\n",
      "        [1.1008],\n",
      "        [1.0538],\n",
      "        [1.1009],\n",
      "        [1.0790],\n",
      "        [1.1070],\n",
      "        [1.0799],\n",
      "        [1.0997],\n",
      "        [1.0696],\n",
      "        [1.0641],\n",
      "        [1.0822],\n",
      "        [1.0677],\n",
      "        [1.0851],\n",
      "        [1.1047],\n",
      "        [1.0927],\n",
      "        [1.1023],\n",
      "        [1.1140],\n",
      "        [1.0642],\n",
      "        [1.1117],\n",
      "        [1.1141],\n",
      "        [1.0824],\n",
      "        [1.1134],\n",
      "        [1.1003],\n",
      "        [1.0714],\n",
      "        [1.0996],\n",
      "        [1.1184],\n",
      "        [0.0027],\n",
      "        [1.0860],\n",
      "        [1.0752],\n",
      "        [1.0623],\n",
      "        [1.0718]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1153],\n",
      "        [1.1013],\n",
      "        [1.0893],\n",
      "        [1.1023],\n",
      "        [1.1183],\n",
      "        [1.0823],\n",
      "        [1.1044],\n",
      "        [1.0769],\n",
      "        [1.0840],\n",
      "        [1.0821],\n",
      "        [1.0678],\n",
      "        [1.0482],\n",
      "        [1.0450],\n",
      "        [1.1085],\n",
      "        [1.0807],\n",
      "        [1.1045],\n",
      "        [1.0959],\n",
      "        [1.0955],\n",
      "        [1.1021],\n",
      "        [1.0937],\n",
      "        [1.1177],\n",
      "        [1.1020],\n",
      "        [1.0548],\n",
      "        [1.0663],\n",
      "        [1.0649],\n",
      "        [1.0612],\n",
      "        [1.1133],\n",
      "        [1.1042],\n",
      "        [1.1161],\n",
      "        [1.0892],\n",
      "        [1.1042],\n",
      "        [1.1123],\n",
      "        [1.1107],\n",
      "        [1.1180],\n",
      "        [1.1176],\n",
      "        [1.1032],\n",
      "        [1.1108],\n",
      "        [1.0799],\n",
      "        [1.0686],\n",
      "        [1.1081],\n",
      "        [1.0991],\n",
      "        [1.0933],\n",
      "        [1.1067],\n",
      "        [1.1129],\n",
      "        [1.0791],\n",
      "        [1.1177],\n",
      "        [1.0756],\n",
      "        [1.0992],\n",
      "        [1.1072],\n",
      "        [1.0819],\n",
      "        [1.1065],\n",
      "        [1.0278],\n",
      "        [1.0703],\n",
      "        [1.1192],\n",
      "        [1.0850],\n",
      "        [1.1108],\n",
      "        [1.0901],\n",
      "        [1.0675],\n",
      "        [1.0941],\n",
      "        [1.0772],\n",
      "        [1.0859],\n",
      "        [1.1010],\n",
      "        [1.0988],\n",
      "        [1.0981],\n",
      "        [1.0882],\n",
      "        [1.1003],\n",
      "        [1.1164],\n",
      "        [1.0599],\n",
      "        [1.1120],\n",
      "        [1.0976],\n",
      "        [1.0809],\n",
      "        [1.1150],\n",
      "        [1.0747],\n",
      "        [1.1088],\n",
      "        [1.1052],\n",
      "        [1.0866],\n",
      "        [1.0825],\n",
      "        [1.1160],\n",
      "        [1.0580],\n",
      "        [1.1158],\n",
      "        [1.1188],\n",
      "        [1.0739],\n",
      "        [1.1036],\n",
      "        [1.0904],\n",
      "        [1.1196],\n",
      "        [1.0880],\n",
      "        [1.0797],\n",
      "        [1.0854],\n",
      "        [1.0960],\n",
      "        [1.0984],\n",
      "        [1.1144],\n",
      "        [1.1156],\n",
      "        [1.1145],\n",
      "        [1.0921],\n",
      "        [1.0539],\n",
      "        [1.0863],\n",
      "        [1.0991],\n",
      "        [1.0724],\n",
      "        [1.0474],\n",
      "        [1.1055],\n",
      "        [1.1026],\n",
      "        [1.0931],\n",
      "        [1.0809],\n",
      "        [1.1038],\n",
      "        [1.1176],\n",
      "        [1.0806],\n",
      "        [1.1171],\n",
      "        [1.1075],\n",
      "        [1.1066],\n",
      "        [1.0877],\n",
      "        [1.0618],\n",
      "        [1.0950],\n",
      "        [1.0914],\n",
      "        [1.0759],\n",
      "        [1.0736],\n",
      "        [1.0976],\n",
      "        [1.0740],\n",
      "        [1.1046],\n",
      "        [1.0368],\n",
      "        [1.1006],\n",
      "        [1.0938],\n",
      "        [1.0808],\n",
      "        [1.0675],\n",
      "        [1.0649],\n",
      "        [1.0944],\n",
      "        [1.0914],\n",
      "        [1.1062],\n",
      "        [1.1188]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0671],\n",
      "        [1.0958],\n",
      "        [1.1222],\n",
      "        [1.0674],\n",
      "        [1.0364],\n",
      "        [1.0976],\n",
      "        [1.1222],\n",
      "        [1.0914],\n",
      "        [1.0963],\n",
      "        [1.0978],\n",
      "        [1.1081],\n",
      "        [1.0898],\n",
      "        [1.1208],\n",
      "        [1.1015],\n",
      "        [1.1085],\n",
      "        [1.0755],\n",
      "        [1.1056],\n",
      "        [1.0620],\n",
      "        [1.0848],\n",
      "        [1.1023],\n",
      "        [1.1156],\n",
      "        [1.1090],\n",
      "        [1.0267],\n",
      "        [1.1198],\n",
      "        [1.1103],\n",
      "        [1.1204],\n",
      "        [1.0865],\n",
      "        [1.0765],\n",
      "        [1.0798],\n",
      "        [1.1071],\n",
      "        [1.0781],\n",
      "        [1.1122],\n",
      "        [1.0566],\n",
      "        [1.0976],\n",
      "        [1.1014],\n",
      "        [1.0872],\n",
      "        [1.1090],\n",
      "        [1.0152],\n",
      "        [1.0958],\n",
      "        [1.0566],\n",
      "        [1.0812],\n",
      "        [1.0890],\n",
      "        [1.1178],\n",
      "        [1.0997],\n",
      "        [1.1095],\n",
      "        [1.0688],\n",
      "        [1.1031],\n",
      "        [1.0976],\n",
      "        [1.1062],\n",
      "        [1.0985],\n",
      "        [1.1174],\n",
      "        [1.0551],\n",
      "        [1.0642],\n",
      "        [1.0948],\n",
      "        [1.0158],\n",
      "        [1.0966],\n",
      "        [1.0685],\n",
      "        [1.0427],\n",
      "        [1.0865],\n",
      "        [1.0714],\n",
      "        [1.0698],\n",
      "        [1.1198],\n",
      "        [1.0739],\n",
      "        [1.1077],\n",
      "        [1.0989],\n",
      "        [1.0765],\n",
      "        [1.0799],\n",
      "        [1.0553],\n",
      "        [1.0944],\n",
      "        [1.1025],\n",
      "        [1.0671],\n",
      "        [1.0546],\n",
      "        [1.0802],\n",
      "        [1.0934],\n",
      "        [1.1044],\n",
      "        [1.1105],\n",
      "        [1.1028],\n",
      "        [1.1186],\n",
      "        [1.0862],\n",
      "        [1.0638],\n",
      "        [1.0636],\n",
      "        [1.0997],\n",
      "        [1.1112],\n",
      "        [1.0699],\n",
      "        [1.1090],\n",
      "        [1.1140],\n",
      "        [1.1071],\n",
      "        [1.0977],\n",
      "        [1.0470],\n",
      "        [1.1084],\n",
      "        [1.0527],\n",
      "        [1.0872],\n",
      "        [1.1138],\n",
      "        [1.0517],\n",
      "        [1.0637],\n",
      "        [1.0971],\n",
      "        [1.1066],\n",
      "        [1.0518],\n",
      "        [1.0738],\n",
      "        [1.1183],\n",
      "        [1.0942],\n",
      "        [1.0592],\n",
      "        [1.1012],\n",
      "        [1.0799],\n",
      "        [1.1152],\n",
      "        [1.0550],\n",
      "        [1.0926],\n",
      "        [1.0434],\n",
      "        [1.0954],\n",
      "        [1.1198],\n",
      "        [1.1200],\n",
      "        [1.1196],\n",
      "        [1.0625],\n",
      "        [1.0718],\n",
      "        [1.1219],\n",
      "        [1.1046],\n",
      "        [1.0996],\n",
      "        [1.1140],\n",
      "        [1.0931],\n",
      "        [1.0933],\n",
      "        [1.0961],\n",
      "        [1.1037],\n",
      "        [1.0815],\n",
      "        [1.1198],\n",
      "        [1.0515],\n",
      "        [1.0947],\n",
      "        [1.0761],\n",
      "        [1.1198]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0257],\n",
      "        [1.1205],\n",
      "        [1.1024],\n",
      "        [1.0937],\n",
      "        [1.0613],\n",
      "        [1.0825],\n",
      "        [1.0916],\n",
      "        [1.0880],\n",
      "        [1.0459],\n",
      "        [1.0957],\n",
      "        [1.0994],\n",
      "        [1.1005],\n",
      "        [1.1236],\n",
      "        [1.1109],\n",
      "        [1.1162],\n",
      "        [1.1080],\n",
      "        [1.0871],\n",
      "        [1.0671],\n",
      "        [1.0957],\n",
      "        [1.1195],\n",
      "        [1.1184],\n",
      "        [1.0955],\n",
      "        [1.1095],\n",
      "        [1.1177],\n",
      "        [1.1089],\n",
      "        [1.0916],\n",
      "        [1.1197],\n",
      "        [1.1078],\n",
      "        [1.0966],\n",
      "        [1.0294],\n",
      "        [1.0651],\n",
      "        [1.0929],\n",
      "        [1.0974],\n",
      "        [1.1164],\n",
      "        [1.0884],\n",
      "        [1.1116],\n",
      "        [1.0726],\n",
      "        [1.0557],\n",
      "        [1.0860],\n",
      "        [1.0760],\n",
      "        [1.0914],\n",
      "        [1.0895],\n",
      "        [1.0807],\n",
      "        [1.0711],\n",
      "        [1.1174],\n",
      "        [1.1159],\n",
      "        [1.0846],\n",
      "        [1.1146],\n",
      "        [1.0654],\n",
      "        [1.1000],\n",
      "        [1.0782],\n",
      "        [1.1044],\n",
      "        [1.0812],\n",
      "        [1.0824],\n",
      "        [1.0911],\n",
      "        [1.0987],\n",
      "        [1.1187],\n",
      "        [1.1035],\n",
      "        [1.0258],\n",
      "        [1.1071],\n",
      "        [1.0583],\n",
      "        [1.0764],\n",
      "        [1.0545],\n",
      "        [1.0843],\n",
      "        [1.1085],\n",
      "        [1.0802],\n",
      "        [1.0362],\n",
      "        [1.1064],\n",
      "        [1.1146],\n",
      "        [1.0914],\n",
      "        [1.0976],\n",
      "        [1.1117],\n",
      "        [1.0841],\n",
      "        [1.1202],\n",
      "        [1.0862],\n",
      "        [1.0949],\n",
      "        [1.1167],\n",
      "        [1.0941],\n",
      "        [1.0660],\n",
      "        [1.0809],\n",
      "        [1.1155],\n",
      "        [1.1145],\n",
      "        [1.0673],\n",
      "        [1.1121],\n",
      "        [1.0892],\n",
      "        [1.0634],\n",
      "        [1.0979],\n",
      "        [1.0962],\n",
      "        [1.0971],\n",
      "        [1.0717],\n",
      "        [1.1111],\n",
      "        [1.0991],\n",
      "        [1.0391],\n",
      "        [1.0819],\n",
      "        [1.1202],\n",
      "        [1.0560],\n",
      "        [1.1024],\n",
      "        [1.1104],\n",
      "        [1.0978],\n",
      "        [1.0947],\n",
      "        [1.0619],\n",
      "        [1.0901],\n",
      "        [1.0827],\n",
      "        [1.0946],\n",
      "        [1.1014],\n",
      "        [1.1060],\n",
      "        [1.1107],\n",
      "        [1.1106],\n",
      "        [1.0903],\n",
      "        [1.0818],\n",
      "        [1.1226],\n",
      "        [1.0693],\n",
      "        [1.0663],\n",
      "        [1.0926],\n",
      "        [1.0873],\n",
      "        [1.0867],\n",
      "        [1.1115],\n",
      "        [1.1148],\n",
      "        [1.0644],\n",
      "        [1.0615],\n",
      "        [1.1053],\n",
      "        [1.0977],\n",
      "        [1.0934],\n",
      "        [1.1077],\n",
      "        [1.1225],\n",
      "        [1.1089],\n",
      "        [1.1204],\n",
      "        [1.1001]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0725],\n",
      "        [1.1097],\n",
      "        [1.0930],\n",
      "        [1.1106],\n",
      "        [1.0886],\n",
      "        [1.1006],\n",
      "        [1.1114],\n",
      "        [1.1192],\n",
      "        [1.1188],\n",
      "        [1.0863],\n",
      "        [1.1056],\n",
      "        [1.0898],\n",
      "        [1.0763],\n",
      "        [1.1074],\n",
      "        [1.0904],\n",
      "        [1.1110],\n",
      "        [1.0832],\n",
      "        [1.1042],\n",
      "        [1.1053],\n",
      "        [1.1099],\n",
      "        [1.1134],\n",
      "        [1.1018],\n",
      "        [1.0507],\n",
      "        [1.0938],\n",
      "        [1.0971],\n",
      "        [1.0752],\n",
      "        [1.1039],\n",
      "        [1.0843],\n",
      "        [1.0766],\n",
      "        [1.1211],\n",
      "        [1.0659],\n",
      "        [1.0561],\n",
      "        [1.1168],\n",
      "        [1.0769],\n",
      "        [1.0803],\n",
      "        [1.0893],\n",
      "        [1.1115],\n",
      "        [1.1099],\n",
      "        [1.1201],\n",
      "        [1.1057],\n",
      "        [1.0685],\n",
      "        [1.0866],\n",
      "        [1.0984],\n",
      "        [1.0678],\n",
      "        [1.1089],\n",
      "        [1.0719],\n",
      "        [1.0909],\n",
      "        [1.0612],\n",
      "        [1.1020],\n",
      "        [1.1156],\n",
      "        [1.1191],\n",
      "        [1.0885],\n",
      "        [1.1123],\n",
      "        [1.0705],\n",
      "        [1.0977],\n",
      "        [1.0952],\n",
      "        [0.2458],\n",
      "        [1.0937],\n",
      "        [0.5896],\n",
      "        [1.0962],\n",
      "        [1.0819],\n",
      "        [1.0956],\n",
      "        [1.0513],\n",
      "        [1.1112],\n",
      "        [1.0854],\n",
      "        [1.0990],\n",
      "        [1.1188],\n",
      "        [1.0813],\n",
      "        [1.1032],\n",
      "        [1.0942],\n",
      "        [1.1096],\n",
      "        [1.1042],\n",
      "        [1.0564],\n",
      "        [1.0523],\n",
      "        [1.0986],\n",
      "        [1.1127],\n",
      "        [1.0615],\n",
      "        [1.0625],\n",
      "        [1.0756],\n",
      "        [1.0988],\n",
      "        [1.0913],\n",
      "        [1.1004],\n",
      "        [1.0992],\n",
      "        [1.0836],\n",
      "        [1.0805],\n",
      "        [1.0964],\n",
      "        [1.1054],\n",
      "        [1.1209],\n",
      "        [1.0958],\n",
      "        [1.0252],\n",
      "        [1.0611],\n",
      "        [1.0997],\n",
      "        [1.1186],\n",
      "        [1.1034],\n",
      "        [1.0917],\n",
      "        [1.0865],\n",
      "        [1.0660],\n",
      "        [1.0840],\n",
      "        [1.0844],\n",
      "        [1.1136],\n",
      "        [1.0975],\n",
      "        [1.0911],\n",
      "        [1.0988],\n",
      "        [1.0957],\n",
      "        [1.0489],\n",
      "        [1.0697],\n",
      "        [1.1142],\n",
      "        [1.0745],\n",
      "        [1.0499],\n",
      "        [1.0851],\n",
      "        [1.1048],\n",
      "        [1.1090],\n",
      "        [1.0894],\n",
      "        [1.0697],\n",
      "        [1.0756],\n",
      "        [1.0983],\n",
      "        [1.1199],\n",
      "        [1.1033],\n",
      "        [1.1154],\n",
      "        [1.0562],\n",
      "        [1.1098],\n",
      "        [1.1112],\n",
      "        [1.0808],\n",
      "        [1.0928],\n",
      "        [1.0907],\n",
      "        [1.1153],\n",
      "        [1.0718],\n",
      "        [1.0613]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0195],\n",
      "        [1.1019],\n",
      "        [1.1004],\n",
      "        [1.0974]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  39 | lr 0.00010 train_loss 2.12169 | val_loss 2.29206 | val_rmse 1.51396\n",
      "tensor([[1.0927],\n",
      "        [1.0933],\n",
      "        [1.1128],\n",
      "        [1.1103],\n",
      "        [1.0761],\n",
      "        [1.1096],\n",
      "        [1.1093],\n",
      "        [1.1209],\n",
      "        [1.0791],\n",
      "        [1.0784],\n",
      "        [1.1001],\n",
      "        [1.0677],\n",
      "        [1.1159],\n",
      "        [1.0886],\n",
      "        [1.1061],\n",
      "        [1.0902],\n",
      "        [1.1211],\n",
      "        [1.1025],\n",
      "        [1.0653],\n",
      "        [1.0760],\n",
      "        [1.1020],\n",
      "        [1.1169],\n",
      "        [1.0949],\n",
      "        [1.0884],\n",
      "        [1.0384],\n",
      "        [1.0947],\n",
      "        [1.1132],\n",
      "        [1.1064],\n",
      "        [1.0893],\n",
      "        [1.1209],\n",
      "        [1.0940],\n",
      "        [1.1075],\n",
      "        [1.1046],\n",
      "        [1.1053],\n",
      "        [1.0860],\n",
      "        [1.1189],\n",
      "        [1.1118],\n",
      "        [1.0959],\n",
      "        [1.0728],\n",
      "        [1.0930],\n",
      "        [1.1044],\n",
      "        [1.0879],\n",
      "        [1.1074],\n",
      "        [0.3423],\n",
      "        [1.0880],\n",
      "        [1.0545],\n",
      "        [1.0909],\n",
      "        [1.1104],\n",
      "        [1.0952],\n",
      "        [1.1135],\n",
      "        [1.0752],\n",
      "        [1.0998],\n",
      "        [1.0672],\n",
      "        [1.0869],\n",
      "        [1.1120],\n",
      "        [1.1064],\n",
      "        [1.0862],\n",
      "        [1.1129],\n",
      "        [1.0947],\n",
      "        [1.0966],\n",
      "        [1.0938],\n",
      "        [1.0810],\n",
      "        [1.0904],\n",
      "        [1.0864],\n",
      "        [1.0296],\n",
      "        [1.0783],\n",
      "        [1.1017],\n",
      "        [1.1081],\n",
      "        [1.1004],\n",
      "        [1.1032],\n",
      "        [1.0703],\n",
      "        [1.0928],\n",
      "        [1.1133],\n",
      "        [1.0966],\n",
      "        [1.0617],\n",
      "        [1.1177],\n",
      "        [1.0653],\n",
      "        [1.0845],\n",
      "        [1.1155],\n",
      "        [1.0852],\n",
      "        [1.1218],\n",
      "        [1.0649],\n",
      "        [1.1025],\n",
      "        [1.0652],\n",
      "        [1.1077],\n",
      "        [1.0886],\n",
      "        [1.0858],\n",
      "        [1.0700],\n",
      "        [1.0720],\n",
      "        [1.0841],\n",
      "        [1.0869],\n",
      "        [1.1078],\n",
      "        [1.0754],\n",
      "        [1.1123],\n",
      "        [1.1036],\n",
      "        [1.0873],\n",
      "        [1.0622],\n",
      "        [1.1130],\n",
      "        [1.1075],\n",
      "        [1.0685],\n",
      "        [1.0910],\n",
      "        [1.1186],\n",
      "        [1.0783],\n",
      "        [1.0695],\n",
      "        [1.0946],\n",
      "        [1.0998],\n",
      "        [1.1034],\n",
      "        [1.0750],\n",
      "        [1.1154],\n",
      "        [1.1187],\n",
      "        [1.0995],\n",
      "        [1.1092],\n",
      "        [1.1109],\n",
      "        [1.0658],\n",
      "        [1.0413],\n",
      "        [1.0314],\n",
      "        [1.0865],\n",
      "        [1.0716],\n",
      "        [1.1064],\n",
      "        [1.1013],\n",
      "        [1.1156],\n",
      "        [1.0610],\n",
      "        [1.1021],\n",
      "        [1.0603],\n",
      "        [1.0947],\n",
      "        [1.0771],\n",
      "        [1.1174],\n",
      "        [1.0826]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0871],\n",
      "        [1.0540],\n",
      "        [1.0932],\n",
      "        [1.0880],\n",
      "        [1.0981],\n",
      "        [1.0687],\n",
      "        [1.0683],\n",
      "        [1.0561],\n",
      "        [1.0491],\n",
      "        [1.0885],\n",
      "        [1.0919],\n",
      "        [1.0620],\n",
      "        [1.0972],\n",
      "        [1.0496],\n",
      "        [1.0975],\n",
      "        [1.1165],\n",
      "        [1.1181],\n",
      "        [1.1025],\n",
      "        [1.1074],\n",
      "        [1.0868],\n",
      "        [1.1093],\n",
      "        [1.0924],\n",
      "        [1.0742],\n",
      "        [1.0996],\n",
      "        [1.0933],\n",
      "        [1.0576],\n",
      "        [1.0964],\n",
      "        [1.0675],\n",
      "        [1.0128],\n",
      "        [1.0415],\n",
      "        [1.0855],\n",
      "        [1.0927],\n",
      "        [1.0831],\n",
      "        [1.0839],\n",
      "        [1.1212],\n",
      "        [1.0832],\n",
      "        [1.0927],\n",
      "        [1.0645],\n",
      "        [1.0741],\n",
      "        [1.1162],\n",
      "        [1.0505],\n",
      "        [1.1107],\n",
      "        [1.0976],\n",
      "        [1.1202],\n",
      "        [1.0912],\n",
      "        [1.1098],\n",
      "        [1.0923],\n",
      "        [1.0836],\n",
      "        [1.0878],\n",
      "        [1.0893],\n",
      "        [1.0951],\n",
      "        [1.0914],\n",
      "        [1.0847],\n",
      "        [1.0862],\n",
      "        [1.1189],\n",
      "        [1.0828],\n",
      "        [1.0646],\n",
      "        [1.0740],\n",
      "        [1.1031],\n",
      "        [1.1108],\n",
      "        [1.0982],\n",
      "        [1.0848],\n",
      "        [1.0757],\n",
      "        [1.1073],\n",
      "        [1.0826],\n",
      "        [1.1157],\n",
      "        [1.1039],\n",
      "        [1.0638],\n",
      "        [1.0426],\n",
      "        [1.1130],\n",
      "        [1.0936],\n",
      "        [1.0682],\n",
      "        [1.1102],\n",
      "        [1.1194],\n",
      "        [1.1209],\n",
      "        [1.1130],\n",
      "        [1.0835],\n",
      "        [1.0604],\n",
      "        [1.0948],\n",
      "        [1.0849],\n",
      "        [1.1054],\n",
      "        [1.0801],\n",
      "        [1.0973],\n",
      "        [1.0753],\n",
      "        [1.1061],\n",
      "        [1.0677],\n",
      "        [1.1160],\n",
      "        [1.0905],\n",
      "        [1.0628],\n",
      "        [1.1042],\n",
      "        [1.1047],\n",
      "        [1.1122],\n",
      "        [1.0817],\n",
      "        [1.0779],\n",
      "        [1.0415],\n",
      "        [1.1133],\n",
      "        [1.1058],\n",
      "        [1.1150],\n",
      "        [1.1064],\n",
      "        [1.0784],\n",
      "        [1.1067],\n",
      "        [1.0940],\n",
      "        [1.1059],\n",
      "        [1.0726],\n",
      "        [1.1117],\n",
      "        [1.1038],\n",
      "        [1.0890],\n",
      "        [1.0756],\n",
      "        [1.1109],\n",
      "        [1.0738],\n",
      "        [1.0630],\n",
      "        [1.1029],\n",
      "        [1.0944],\n",
      "        [1.0552],\n",
      "        [1.1233],\n",
      "        [1.0635],\n",
      "        [1.0195],\n",
      "        [1.1034],\n",
      "        [1.0950],\n",
      "        [1.0954],\n",
      "        [1.0951],\n",
      "        [1.0932],\n",
      "        [1.0611],\n",
      "        [1.0654],\n",
      "        [1.0824],\n",
      "        [1.1106],\n",
      "        [1.1024],\n",
      "        [1.1166]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1035],\n",
      "        [1.0852],\n",
      "        [1.0956],\n",
      "        [1.0993],\n",
      "        [1.1042],\n",
      "        [1.0891],\n",
      "        [1.1180],\n",
      "        [1.1114],\n",
      "        [1.0982],\n",
      "        [1.0733],\n",
      "        [1.0838],\n",
      "        [1.1102],\n",
      "        [1.0909],\n",
      "        [1.0973],\n",
      "        [1.1028],\n",
      "        [1.1235],\n",
      "        [1.0354],\n",
      "        [1.1172],\n",
      "        [1.0939],\n",
      "        [1.0987],\n",
      "        [1.1141],\n",
      "        [1.0773],\n",
      "        [1.1179],\n",
      "        [1.0958],\n",
      "        [1.1119],\n",
      "        [1.1018],\n",
      "        [1.0679],\n",
      "        [1.0931],\n",
      "        [1.0960],\n",
      "        [1.0564],\n",
      "        [1.0910],\n",
      "        [1.1148],\n",
      "        [1.0723],\n",
      "        [1.0699],\n",
      "        [1.1188],\n",
      "        [1.1173],\n",
      "        [1.0150],\n",
      "        [1.1029],\n",
      "        [1.0240],\n",
      "        [1.0602],\n",
      "        [1.0532],\n",
      "        [1.0598],\n",
      "        [1.0942],\n",
      "        [1.0930],\n",
      "        [1.0604],\n",
      "        [1.1149],\n",
      "        [1.0808],\n",
      "        [1.0712],\n",
      "        [1.1072],\n",
      "        [1.0389],\n",
      "        [1.0819],\n",
      "        [1.0832],\n",
      "        [1.1008],\n",
      "        [1.1088],\n",
      "        [1.1179],\n",
      "        [1.0973],\n",
      "        [1.0808],\n",
      "        [1.0756],\n",
      "        [1.0625],\n",
      "        [1.0916],\n",
      "        [1.0738],\n",
      "        [1.0839],\n",
      "        [1.1066],\n",
      "        [1.0702],\n",
      "        [1.1010],\n",
      "        [1.1111],\n",
      "        [1.1000],\n",
      "        [1.1117],\n",
      "        [1.0931],\n",
      "        [1.0892],\n",
      "        [1.1169],\n",
      "        [1.0631],\n",
      "        [1.1104],\n",
      "        [1.0689],\n",
      "        [1.0649],\n",
      "        [1.1196],\n",
      "        [1.0167],\n",
      "        [1.1091],\n",
      "        [1.0957],\n",
      "        [1.0809],\n",
      "        [1.0998],\n",
      "        [1.1030],\n",
      "        [1.1043],\n",
      "        [1.1043],\n",
      "        [1.0759],\n",
      "        [1.1067],\n",
      "        [1.0996],\n",
      "        [1.0977],\n",
      "        [1.0986],\n",
      "        [1.1196],\n",
      "        [1.0739],\n",
      "        [1.0861],\n",
      "        [1.0547],\n",
      "        [1.0563],\n",
      "        [1.0777],\n",
      "        [1.0799],\n",
      "        [1.0942],\n",
      "        [1.0794],\n",
      "        [1.0953],\n",
      "        [1.0922],\n",
      "        [1.1026],\n",
      "        [1.0990],\n",
      "        [1.0792],\n",
      "        [1.0777],\n",
      "        [1.0740],\n",
      "        [1.0877],\n",
      "        [1.1180],\n",
      "        [1.0938],\n",
      "        [1.0945],\n",
      "        [1.0749],\n",
      "        [1.0926],\n",
      "        [1.0660],\n",
      "        [1.0689],\n",
      "        [1.1191],\n",
      "        [1.0557],\n",
      "        [1.0783],\n",
      "        [1.0794],\n",
      "        [1.0980],\n",
      "        [1.1151],\n",
      "        [1.0816],\n",
      "        [1.0795],\n",
      "        [1.0859],\n",
      "        [1.0951],\n",
      "        [1.0926],\n",
      "        [1.1068],\n",
      "        [1.1153],\n",
      "        [1.1174],\n",
      "        [1.1158]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0856],\n",
      "        [1.1118],\n",
      "        [1.1138],\n",
      "        [1.1197],\n",
      "        [1.0809],\n",
      "        [1.0921],\n",
      "        [1.0238],\n",
      "        [1.0904],\n",
      "        [1.0806],\n",
      "        [1.0706],\n",
      "        [1.0577],\n",
      "        [1.0916],\n",
      "        [1.1046],\n",
      "        [1.0618],\n",
      "        [1.1060],\n",
      "        [1.1128],\n",
      "        [1.1155],\n",
      "        [1.0311],\n",
      "        [1.0838],\n",
      "        [1.0408],\n",
      "        [1.1037],\n",
      "        [1.0692],\n",
      "        [1.0402],\n",
      "        [1.1202],\n",
      "        [1.0945],\n",
      "        [1.0803],\n",
      "        [1.1091],\n",
      "        [1.0916],\n",
      "        [1.0757],\n",
      "        [1.0969],\n",
      "        [1.0762],\n",
      "        [1.1032],\n",
      "        [1.0940],\n",
      "        [1.0471],\n",
      "        [1.1053],\n",
      "        [1.0227],\n",
      "        [1.1134],\n",
      "        [1.1080],\n",
      "        [1.0938],\n",
      "        [1.0837],\n",
      "        [1.0792],\n",
      "        [1.1041],\n",
      "        [1.1252],\n",
      "        [1.0915],\n",
      "        [1.0967],\n",
      "        [1.0824],\n",
      "        [1.1050],\n",
      "        [1.0899],\n",
      "        [1.1004],\n",
      "        [1.0696],\n",
      "        [1.1162],\n",
      "        [1.1063],\n",
      "        [1.0743],\n",
      "        [1.0921],\n",
      "        [1.0970],\n",
      "        [1.1179],\n",
      "        [1.1078],\n",
      "        [1.0679],\n",
      "        [1.0796],\n",
      "        [1.0703],\n",
      "        [1.0819],\n",
      "        [1.0725],\n",
      "        [1.0679],\n",
      "        [1.1180],\n",
      "        [1.0436],\n",
      "        [1.1076],\n",
      "        [1.0838],\n",
      "        [1.0753],\n",
      "        [1.1113],\n",
      "        [1.0552],\n",
      "        [1.0768],\n",
      "        [1.0569],\n",
      "        [1.1007],\n",
      "        [1.0580],\n",
      "        [1.1079],\n",
      "        [1.1076],\n",
      "        [1.0370],\n",
      "        [1.1189],\n",
      "        [1.0859],\n",
      "        [1.0871],\n",
      "        [1.0244],\n",
      "        [1.1114],\n",
      "        [1.0827],\n",
      "        [1.0633],\n",
      "        [1.0874],\n",
      "        [1.0991],\n",
      "        [1.0886],\n",
      "        [1.1177],\n",
      "        [1.0760],\n",
      "        [1.0984],\n",
      "        [1.0782],\n",
      "        [1.0894],\n",
      "        [1.0719],\n",
      "        [1.0924],\n",
      "        [1.0593],\n",
      "        [1.1178],\n",
      "        [1.1161],\n",
      "        [1.1106],\n",
      "        [1.1137],\n",
      "        [1.1098],\n",
      "        [1.0805],\n",
      "        [1.1179],\n",
      "        [1.1037],\n",
      "        [1.1168],\n",
      "        [1.0773],\n",
      "        [1.0940],\n",
      "        [1.0988],\n",
      "        [1.0939],\n",
      "        [1.0881],\n",
      "        [1.1150],\n",
      "        [1.0917],\n",
      "        [1.0958],\n",
      "        [1.1031],\n",
      "        [1.0629],\n",
      "        [1.0914],\n",
      "        [1.1029],\n",
      "        [1.1210],\n",
      "        [1.0823],\n",
      "        [1.1184],\n",
      "        [1.1162],\n",
      "        [1.1242],\n",
      "        [1.1110],\n",
      "        [1.0968],\n",
      "        [1.0888],\n",
      "        [1.1037],\n",
      "        [1.0882],\n",
      "        [1.1042],\n",
      "        [1.1197]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0937],\n",
      "        [1.0579],\n",
      "        [1.0705],\n",
      "        [1.0939],\n",
      "        [1.1055],\n",
      "        [1.1130],\n",
      "        [1.0912],\n",
      "        [1.1110],\n",
      "        [1.1171],\n",
      "        [1.0717],\n",
      "        [1.1173],\n",
      "        [1.1070],\n",
      "        [1.0893],\n",
      "        [1.0887],\n",
      "        [1.0366],\n",
      "        [1.0707],\n",
      "        [1.0880],\n",
      "        [1.0929],\n",
      "        [1.0869],\n",
      "        [1.0840],\n",
      "        [1.0676],\n",
      "        [1.0296],\n",
      "        [1.0609],\n",
      "        [1.0920],\n",
      "        [1.0879],\n",
      "        [1.1021],\n",
      "        [1.1147],\n",
      "        [1.0628],\n",
      "        [1.0839],\n",
      "        [1.1043],\n",
      "        [1.1062],\n",
      "        [1.1175],\n",
      "        [1.0718],\n",
      "        [1.1135],\n",
      "        [1.1255],\n",
      "        [1.0927],\n",
      "        [1.1109],\n",
      "        [1.1131],\n",
      "        [1.0756],\n",
      "        [1.0823],\n",
      "        [1.0941],\n",
      "        [1.0677],\n",
      "        [1.1056],\n",
      "        [1.0319],\n",
      "        [1.0996],\n",
      "        [1.1072],\n",
      "        [1.0617],\n",
      "        [1.1201],\n",
      "        [1.0858],\n",
      "        [1.1137],\n",
      "        [1.0377],\n",
      "        [1.1012],\n",
      "        [1.0855],\n",
      "        [1.0529],\n",
      "        [1.1121],\n",
      "        [1.0861],\n",
      "        [1.0980],\n",
      "        [1.0918],\n",
      "        [1.1047],\n",
      "        [1.1003],\n",
      "        [1.0454],\n",
      "        [1.0567],\n",
      "        [1.0931],\n",
      "        [1.0391],\n",
      "        [1.0977],\n",
      "        [1.0851],\n",
      "        [1.0718],\n",
      "        [1.1075],\n",
      "        [1.1000],\n",
      "        [1.1183],\n",
      "        [1.0921],\n",
      "        [1.0871],\n",
      "        [1.1071],\n",
      "        [1.0907],\n",
      "        [1.0884],\n",
      "        [1.1039],\n",
      "        [1.1094],\n",
      "        [1.0878],\n",
      "        [1.1141],\n",
      "        [1.0602],\n",
      "        [1.0997],\n",
      "        [1.0917],\n",
      "        [1.0866],\n",
      "        [1.1162],\n",
      "        [1.1116],\n",
      "        [1.0688],\n",
      "        [1.0861],\n",
      "        [1.0819],\n",
      "        [1.0943],\n",
      "        [1.0772],\n",
      "        [1.0605],\n",
      "        [1.1089],\n",
      "        [1.0789],\n",
      "        [1.1002],\n",
      "        [1.0889],\n",
      "        [1.0958],\n",
      "        [1.0552],\n",
      "        [1.0806],\n",
      "        [1.0674],\n",
      "        [1.0637],\n",
      "        [1.0742],\n",
      "        [1.0947],\n",
      "        [1.1250],\n",
      "        [1.0873],\n",
      "        [1.0990],\n",
      "        [1.1168],\n",
      "        [1.0918],\n",
      "        [1.0653],\n",
      "        [1.0965],\n",
      "        [1.0592],\n",
      "        [1.1061],\n",
      "        [1.1184],\n",
      "        [1.1146],\n",
      "        [1.1149],\n",
      "        [1.1086],\n",
      "        [1.0944],\n",
      "        [1.0995],\n",
      "        [1.1194],\n",
      "        [1.1158],\n",
      "        [1.0941],\n",
      "        [1.0735],\n",
      "        [1.0925],\n",
      "        [1.0752],\n",
      "        [1.1043],\n",
      "        [0.2302],\n",
      "        [1.0644],\n",
      "        [1.1030],\n",
      "        [1.1059]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0517],\n",
      "        [1.0985],\n",
      "        [1.0914],\n",
      "        [1.0806],\n",
      "        [1.0682],\n",
      "        [1.0869],\n",
      "        [1.0816],\n",
      "        [1.0593],\n",
      "        [1.0902],\n",
      "        [1.0691],\n",
      "        [1.1152],\n",
      "        [0.6578],\n",
      "        [1.0993],\n",
      "        [1.0980],\n",
      "        [1.0939],\n",
      "        [1.0992],\n",
      "        [1.1247],\n",
      "        [1.0991],\n",
      "        [1.1071],\n",
      "        [1.0723],\n",
      "        [1.1077],\n",
      "        [1.0730],\n",
      "        [1.0874],\n",
      "        [1.1138],\n",
      "        [1.1059],\n",
      "        [1.0912],\n",
      "        [1.1043],\n",
      "        [1.1199],\n",
      "        [1.0809],\n",
      "        [1.0966],\n",
      "        [1.0785],\n",
      "        [1.0837],\n",
      "        [1.1022],\n",
      "        [1.1120],\n",
      "        [1.1057],\n",
      "        [1.1127],\n",
      "        [1.1102],\n",
      "        [1.0645],\n",
      "        [1.0788],\n",
      "        [1.0935],\n",
      "        [1.0522],\n",
      "        [1.1120],\n",
      "        [1.0681],\n",
      "        [1.1050],\n",
      "        [1.0582],\n",
      "        [1.0313],\n",
      "        [1.0620],\n",
      "        [1.1049],\n",
      "        [1.0531],\n",
      "        [1.0516],\n",
      "        [1.1088],\n",
      "        [1.1017],\n",
      "        [1.0764],\n",
      "        [1.0984],\n",
      "        [1.0531],\n",
      "        [1.0608],\n",
      "        [1.1073],\n",
      "        [1.1181],\n",
      "        [1.1014],\n",
      "        [1.1112],\n",
      "        [1.0873],\n",
      "        [1.1007],\n",
      "        [1.0686],\n",
      "        [1.0903],\n",
      "        [1.0654],\n",
      "        [1.0908],\n",
      "        [1.1054],\n",
      "        [1.1145],\n",
      "        [1.0878],\n",
      "        [1.0970],\n",
      "        [1.0692],\n",
      "        [1.0953],\n",
      "        [1.1067],\n",
      "        [1.0580],\n",
      "        [1.1041],\n",
      "        [1.0715],\n",
      "        [1.0993],\n",
      "        [1.0799],\n",
      "        [1.0935],\n",
      "        [1.0961],\n",
      "        [1.1133],\n",
      "        [1.0706],\n",
      "        [1.0506],\n",
      "        [1.0825],\n",
      "        [1.0824],\n",
      "        [1.0653],\n",
      "        [1.1201],\n",
      "        [1.1162],\n",
      "        [1.0940],\n",
      "        [1.1123],\n",
      "        [1.1114],\n",
      "        [1.0963],\n",
      "        [1.0688],\n",
      "        [1.0802],\n",
      "        [1.1117],\n",
      "        [1.0533],\n",
      "        [1.0305],\n",
      "        [1.1163],\n",
      "        [1.0688],\n",
      "        [1.0781],\n",
      "        [1.0789],\n",
      "        [1.0958],\n",
      "        [1.0713],\n",
      "        [1.0859],\n",
      "        [1.1110],\n",
      "        [1.0854],\n",
      "        [1.0816],\n",
      "        [1.1124],\n",
      "        [1.0695],\n",
      "        [1.0948],\n",
      "        [1.0912],\n",
      "        [1.0764],\n",
      "        [1.1152],\n",
      "        [1.0824],\n",
      "        [1.0928],\n",
      "        [1.0842],\n",
      "        [1.1025],\n",
      "        [1.0831],\n",
      "        [1.1006],\n",
      "        [1.0962],\n",
      "        [1.1173],\n",
      "        [1.1198],\n",
      "        [1.0876],\n",
      "        [1.0899],\n",
      "        [1.1209],\n",
      "        [1.0866],\n",
      "        [1.0188],\n",
      "        [1.1042]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0804],\n",
      "        [1.0812],\n",
      "        [1.1129],\n",
      "        [1.1209],\n",
      "        [1.1057],\n",
      "        [1.0995],\n",
      "        [1.1212],\n",
      "        [1.0912],\n",
      "        [1.0962],\n",
      "        [1.1116],\n",
      "        [1.1080],\n",
      "        [1.0553],\n",
      "        [1.0941],\n",
      "        [1.0805],\n",
      "        [1.0673],\n",
      "        [1.0990],\n",
      "        [1.1210],\n",
      "        [1.0968],\n",
      "        [1.1000],\n",
      "        [1.0926],\n",
      "        [1.0823],\n",
      "        [1.1184],\n",
      "        [1.0735],\n",
      "        [1.1180],\n",
      "        [1.1209],\n",
      "        [1.0627],\n",
      "        [1.0783],\n",
      "        [1.0866],\n",
      "        [1.0737],\n",
      "        [1.1189],\n",
      "        [1.0958],\n",
      "        [1.0821],\n",
      "        [1.0826],\n",
      "        [1.1087],\n",
      "        [1.1191],\n",
      "        [1.1029],\n",
      "        [1.1147],\n",
      "        [1.1071],\n",
      "        [1.1035],\n",
      "        [1.0870],\n",
      "        [1.0895],\n",
      "        [1.0715],\n",
      "        [1.1026],\n",
      "        [1.0285],\n",
      "        [1.0520],\n",
      "        [1.1030],\n",
      "        [1.0517],\n",
      "        [1.0779],\n",
      "        [1.0689],\n",
      "        [1.0793],\n",
      "        [1.1024],\n",
      "        [1.1106],\n",
      "        [1.0955],\n",
      "        [1.0359],\n",
      "        [1.0965],\n",
      "        [1.0843],\n",
      "        [1.0958],\n",
      "        [1.0940],\n",
      "        [1.0746],\n",
      "        [1.1033],\n",
      "        [1.0691],\n",
      "        [1.1151],\n",
      "        [1.0604],\n",
      "        [1.0898],\n",
      "        [1.0620],\n",
      "        [1.0861],\n",
      "        [1.1109],\n",
      "        [1.0796],\n",
      "        [1.1170],\n",
      "        [1.1170],\n",
      "        [1.0743],\n",
      "        [1.0591],\n",
      "        [1.0795],\n",
      "        [1.0821],\n",
      "        [1.1088],\n",
      "        [1.0537],\n",
      "        [1.0878],\n",
      "        [1.1077],\n",
      "        [1.0482],\n",
      "        [1.0578],\n",
      "        [1.0862],\n",
      "        [1.1154],\n",
      "        [1.0806],\n",
      "        [1.0949],\n",
      "        [1.0848],\n",
      "        [1.0697],\n",
      "        [1.1150],\n",
      "        [1.1043],\n",
      "        [1.0708],\n",
      "        [1.0753],\n",
      "        [1.0740],\n",
      "        [1.0629],\n",
      "        [1.0710],\n",
      "        [1.0685],\n",
      "        [1.1132],\n",
      "        [1.1053],\n",
      "        [1.0829],\n",
      "        [1.1196],\n",
      "        [1.0911],\n",
      "        [1.1042],\n",
      "        [1.0999],\n",
      "        [1.0952],\n",
      "        [1.0873],\n",
      "        [1.0975],\n",
      "        [1.0612],\n",
      "        [1.1100],\n",
      "        [1.0812],\n",
      "        [1.1168],\n",
      "        [1.1054],\n",
      "        [1.1085],\n",
      "        [1.1120],\n",
      "        [1.1011],\n",
      "        [1.1166],\n",
      "        [1.0538],\n",
      "        [1.0904],\n",
      "        [1.1153],\n",
      "        [1.1185],\n",
      "        [1.0604],\n",
      "        [1.0771],\n",
      "        [1.0986],\n",
      "        [1.0679],\n",
      "        [1.0675],\n",
      "        [1.0872],\n",
      "        [1.0788],\n",
      "        [1.0867],\n",
      "        [1.0954],\n",
      "        [1.0893],\n",
      "        [1.1216]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0949],\n",
      "        [1.1032],\n",
      "        [1.0666],\n",
      "        [1.1197]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  40 | lr 0.00010 train_loss 2.12533 | val_loss 2.29206 | val_rmse 1.51395\n",
      "tensor([[1.0838],\n",
      "        [1.0794],\n",
      "        [1.1038],\n",
      "        [1.0703],\n",
      "        [1.0724],\n",
      "        [1.1055],\n",
      "        [1.0740],\n",
      "        [1.0982],\n",
      "        [1.0841],\n",
      "        [1.1183],\n",
      "        [1.1084],\n",
      "        [1.0816],\n",
      "        [1.1122],\n",
      "        [1.1209],\n",
      "        [1.1080],\n",
      "        [1.1159],\n",
      "        [1.0932],\n",
      "        [1.1061],\n",
      "        [1.0654],\n",
      "        [1.0941],\n",
      "        [1.0239],\n",
      "        [1.0717],\n",
      "        [1.0904],\n",
      "        [1.1048],\n",
      "        [1.1179],\n",
      "        [1.1251],\n",
      "        [1.0894],\n",
      "        [1.0589],\n",
      "        [1.1068],\n",
      "        [1.1137],\n",
      "        [1.1013],\n",
      "        [1.0403],\n",
      "        [1.1156],\n",
      "        [1.0824],\n",
      "        [1.0826],\n",
      "        [1.0735],\n",
      "        [1.1181],\n",
      "        [1.0910],\n",
      "        [1.0763],\n",
      "        [1.1190],\n",
      "        [1.1000],\n",
      "        [1.0705],\n",
      "        [1.0319],\n",
      "        [1.1007],\n",
      "        [1.0906],\n",
      "        [1.1096],\n",
      "        [1.1120],\n",
      "        [1.0743],\n",
      "        [1.1113],\n",
      "        [1.0657],\n",
      "        [1.0768],\n",
      "        [1.0699],\n",
      "        [1.0676],\n",
      "        [1.0895],\n",
      "        [1.0933],\n",
      "        [1.1029],\n",
      "        [1.0757],\n",
      "        [1.1044],\n",
      "        [1.0066],\n",
      "        [1.0964],\n",
      "        [1.0997],\n",
      "        [1.1077],\n",
      "        [1.0740],\n",
      "        [1.0996],\n",
      "        [1.0855],\n",
      "        [1.0822],\n",
      "        [1.0883],\n",
      "        [1.1146],\n",
      "        [1.0599],\n",
      "        [1.1038],\n",
      "        [1.0990],\n",
      "        [1.1062],\n",
      "        [1.1106],\n",
      "        [1.0461],\n",
      "        [1.0549],\n",
      "        [1.1140],\n",
      "        [1.0890],\n",
      "        [1.0601],\n",
      "        [1.1137],\n",
      "        [1.0479],\n",
      "        [1.0647],\n",
      "        [1.0947],\n",
      "        [1.1061],\n",
      "        [1.0964],\n",
      "        [1.1154],\n",
      "        [1.0968],\n",
      "        [1.1052],\n",
      "        [1.0925],\n",
      "        [1.1122],\n",
      "        [1.0740],\n",
      "        [1.0805],\n",
      "        [1.1127],\n",
      "        [1.1084],\n",
      "        [1.1154],\n",
      "        [1.0844],\n",
      "        [1.0986],\n",
      "        [1.1074],\n",
      "        [1.0719],\n",
      "        [1.1070],\n",
      "        [1.0573],\n",
      "        [1.1120],\n",
      "        [1.0946],\n",
      "        [1.0924],\n",
      "        [1.0969],\n",
      "        [1.1113],\n",
      "        [1.1090],\n",
      "        [1.0812],\n",
      "        [1.0949],\n",
      "        [1.1060],\n",
      "        [1.1108],\n",
      "        [1.0802],\n",
      "        [1.0882],\n",
      "        [1.0678],\n",
      "        [1.0932],\n",
      "        [1.0805],\n",
      "        [1.1058],\n",
      "        [1.0626],\n",
      "        [1.1028],\n",
      "        [1.0823],\n",
      "        [1.0906],\n",
      "        [1.1180],\n",
      "        [1.0904],\n",
      "        [1.0901],\n",
      "        [1.0984],\n",
      "        [1.1125],\n",
      "        [1.0725],\n",
      "        [1.0928],\n",
      "        [1.0833]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0929],\n",
      "        [1.0964],\n",
      "        [1.1167],\n",
      "        [1.0829],\n",
      "        [1.1227],\n",
      "        [1.1210],\n",
      "        [1.0906],\n",
      "        [1.1129],\n",
      "        [1.1035],\n",
      "        [1.0468],\n",
      "        [1.0953],\n",
      "        [1.0948],\n",
      "        [1.0616],\n",
      "        [1.0673],\n",
      "        [1.1171],\n",
      "        [1.0907],\n",
      "        [1.0509],\n",
      "        [1.0755],\n",
      "        [1.0700],\n",
      "        [1.0689],\n",
      "        [1.0904],\n",
      "        [1.1121],\n",
      "        [1.1004],\n",
      "        [1.0987],\n",
      "        [1.1008],\n",
      "        [1.0959],\n",
      "        [1.0875],\n",
      "        [1.1100],\n",
      "        [1.0865],\n",
      "        [1.0854],\n",
      "        [1.1213],\n",
      "        [1.0901],\n",
      "        [1.0998],\n",
      "        [1.1098],\n",
      "        [1.0961],\n",
      "        [1.0881],\n",
      "        [1.1199],\n",
      "        [1.0697],\n",
      "        [1.0915],\n",
      "        [1.1099],\n",
      "        [1.0920],\n",
      "        [1.0824],\n",
      "        [1.0746],\n",
      "        [1.0751],\n",
      "        [1.1194],\n",
      "        [1.0689],\n",
      "        [1.0443],\n",
      "        [1.0901],\n",
      "        [1.1106],\n",
      "        [1.1055],\n",
      "        [1.1070],\n",
      "        [1.0757],\n",
      "        [1.0665],\n",
      "        [1.0910],\n",
      "        [1.1072],\n",
      "        [1.0845],\n",
      "        [1.0863],\n",
      "        [1.0817],\n",
      "        [1.1018],\n",
      "        [1.0688],\n",
      "        [1.1015],\n",
      "        [1.1114],\n",
      "        [1.1129],\n",
      "        [1.0744],\n",
      "        [1.1056],\n",
      "        [1.0582],\n",
      "        [1.1070],\n",
      "        [1.0677],\n",
      "        [1.0655],\n",
      "        [1.0755],\n",
      "        [1.1057],\n",
      "        [1.0951],\n",
      "        [1.1144],\n",
      "        [1.0640],\n",
      "        [1.0921],\n",
      "        [1.0835],\n",
      "        [1.1133],\n",
      "        [1.0986],\n",
      "        [1.1118],\n",
      "        [1.0918],\n",
      "        [1.0951],\n",
      "        [1.0827],\n",
      "        [1.0564],\n",
      "        [1.0945],\n",
      "        [1.0513],\n",
      "        [1.1086],\n",
      "        [1.1191],\n",
      "        [1.0830],\n",
      "        [1.0550],\n",
      "        [1.0963],\n",
      "        [1.0584],\n",
      "        [1.0985],\n",
      "        [1.0820],\n",
      "        [1.0768],\n",
      "        [1.0967],\n",
      "        [1.0423],\n",
      "        [1.1140],\n",
      "        [1.0808],\n",
      "        [1.0958],\n",
      "        [1.1020],\n",
      "        [1.1088],\n",
      "        [1.0796],\n",
      "        [1.0042],\n",
      "        [1.1006],\n",
      "        [1.1077],\n",
      "        [1.0777],\n",
      "        [1.0972],\n",
      "        [1.1112],\n",
      "        [1.1051],\n",
      "        [1.1015],\n",
      "        [1.1026],\n",
      "        [1.0973],\n",
      "        [1.0899],\n",
      "        [1.0777],\n",
      "        [1.0850],\n",
      "        [1.0601],\n",
      "        [1.0838],\n",
      "        [1.1103],\n",
      "        [1.0714],\n",
      "        [1.1205],\n",
      "        [1.0939],\n",
      "        [1.0903],\n",
      "        [1.0490],\n",
      "        [1.0771],\n",
      "        [1.1054],\n",
      "        [1.1146],\n",
      "        [1.1155],\n",
      "        [1.0786]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0924],\n",
      "        [1.0743],\n",
      "        [1.1188],\n",
      "        [1.0842],\n",
      "        [1.0925],\n",
      "        [1.0889],\n",
      "        [1.0784],\n",
      "        [1.0568],\n",
      "        [1.0807],\n",
      "        [1.1026],\n",
      "        [1.0822],\n",
      "        [1.1169],\n",
      "        [1.0506],\n",
      "        [1.1105],\n",
      "        [1.1186],\n",
      "        [1.1194],\n",
      "        [1.0943],\n",
      "        [1.0766],\n",
      "        [1.0812],\n",
      "        [1.0849],\n",
      "        [1.1165],\n",
      "        [0.2937],\n",
      "        [1.1099],\n",
      "        [1.0934],\n",
      "        [1.0896],\n",
      "        [1.0793],\n",
      "        [1.0947],\n",
      "        [1.0736],\n",
      "        [1.1115],\n",
      "        [1.1168],\n",
      "        [1.0989],\n",
      "        [1.0805],\n",
      "        [1.1229],\n",
      "        [1.1096],\n",
      "        [1.0880],\n",
      "        [1.0826],\n",
      "        [1.1001],\n",
      "        [1.1071],\n",
      "        [1.0928],\n",
      "        [1.0696],\n",
      "        [1.1067],\n",
      "        [1.1052],\n",
      "        [1.0667],\n",
      "        [1.0729],\n",
      "        [1.0670],\n",
      "        [1.0689],\n",
      "        [1.1056],\n",
      "        [1.0530],\n",
      "        [1.1192],\n",
      "        [1.0683],\n",
      "        [1.0829],\n",
      "        [0.9839],\n",
      "        [1.0695],\n",
      "        [1.0793],\n",
      "        [1.0910],\n",
      "        [1.0857],\n",
      "        [1.1001],\n",
      "        [1.0438],\n",
      "        [1.1109],\n",
      "        [1.0884],\n",
      "        [1.0472],\n",
      "        [1.0677],\n",
      "        [1.0852],\n",
      "        [1.0864],\n",
      "        [1.1186],\n",
      "        [1.0782],\n",
      "        [1.0978],\n",
      "        [1.1051],\n",
      "        [1.0870],\n",
      "        [1.1032],\n",
      "        [1.0823],\n",
      "        [1.0852],\n",
      "        [1.0765],\n",
      "        [1.0694],\n",
      "        [1.1128],\n",
      "        [1.0997],\n",
      "        [1.1094],\n",
      "        [1.0717],\n",
      "        [1.1131],\n",
      "        [1.1153],\n",
      "        [1.0577],\n",
      "        [1.1040],\n",
      "        [1.0373],\n",
      "        [1.0665],\n",
      "        [1.0666],\n",
      "        [1.0830],\n",
      "        [1.1150],\n",
      "        [1.1033],\n",
      "        [1.0891],\n",
      "        [1.1874],\n",
      "        [1.0636],\n",
      "        [1.0678],\n",
      "        [1.0884],\n",
      "        [1.1072],\n",
      "        [1.0946],\n",
      "        [1.1216],\n",
      "        [1.1075],\n",
      "        [1.0589],\n",
      "        [1.1065],\n",
      "        [1.0957],\n",
      "        [1.0893],\n",
      "        [1.0857],\n",
      "        [1.0825],\n",
      "        [1.0790],\n",
      "        [1.1198],\n",
      "        [1.0905],\n",
      "        [1.0873],\n",
      "        [1.0856],\n",
      "        [1.0582],\n",
      "        [1.0849],\n",
      "        [1.0675],\n",
      "        [1.1114],\n",
      "        [1.1093],\n",
      "        [1.0532],\n",
      "        [1.0839],\n",
      "        [1.1115],\n",
      "        [1.0850],\n",
      "        [1.0928],\n",
      "        [1.1013],\n",
      "        [1.1106],\n",
      "        [1.0767],\n",
      "        [1.0855],\n",
      "        [1.1038],\n",
      "        [1.0627],\n",
      "        [1.0984],\n",
      "        [1.0886],\n",
      "        [1.0988],\n",
      "        [1.1164]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0609],\n",
      "        [1.1042],\n",
      "        [1.0500],\n",
      "        [1.0508],\n",
      "        [1.1094],\n",
      "        [1.1199],\n",
      "        [1.0745],\n",
      "        [1.0942],\n",
      "        [1.0863],\n",
      "        [1.1154],\n",
      "        [1.0875],\n",
      "        [1.0698],\n",
      "        [1.0800],\n",
      "        [1.0954],\n",
      "        [1.0462],\n",
      "        [1.0726],\n",
      "        [1.0234],\n",
      "        [1.0914],\n",
      "        [1.0460],\n",
      "        [1.0912],\n",
      "        [1.1121],\n",
      "        [1.1208],\n",
      "        [1.0818],\n",
      "        [1.0506],\n",
      "        [1.1182],\n",
      "        [1.0867],\n",
      "        [1.0768],\n",
      "        [1.1007],\n",
      "        [1.1027],\n",
      "        [1.0948],\n",
      "        [1.0757],\n",
      "        [1.0339],\n",
      "        [1.0482],\n",
      "        [1.0949],\n",
      "        [1.0961],\n",
      "        [1.1112],\n",
      "        [1.0964],\n",
      "        [1.0982],\n",
      "        [1.0964],\n",
      "        [1.0951],\n",
      "        [1.0235],\n",
      "        [1.0747],\n",
      "        [1.1105],\n",
      "        [1.1146],\n",
      "        [1.0936],\n",
      "        [1.1048],\n",
      "        [1.1049],\n",
      "        [1.1088],\n",
      "        [1.0724],\n",
      "        [1.0865],\n",
      "        [1.0553],\n",
      "        [1.0631],\n",
      "        [1.0960],\n",
      "        [1.0936],\n",
      "        [1.0755],\n",
      "        [1.1036],\n",
      "        [1.0845],\n",
      "        [1.1024],\n",
      "        [1.1195],\n",
      "        [1.1050],\n",
      "        [1.1036],\n",
      "        [1.1038],\n",
      "        [1.0773],\n",
      "        [1.1109],\n",
      "        [1.1057],\n",
      "        [1.1049],\n",
      "        [1.0874],\n",
      "        [1.0762],\n",
      "        [1.0951],\n",
      "        [1.0842],\n",
      "        [1.0497],\n",
      "        [1.1242],\n",
      "        [1.1199],\n",
      "        [1.1025],\n",
      "        [1.0902],\n",
      "        [1.0901],\n",
      "        [1.0933],\n",
      "        [1.0866],\n",
      "        [1.1179],\n",
      "        [1.0924],\n",
      "        [1.1156],\n",
      "        [1.1098],\n",
      "        [1.0827],\n",
      "        [1.1048],\n",
      "        [1.1110],\n",
      "        [1.0902],\n",
      "        [1.0915],\n",
      "        [1.0541],\n",
      "        [1.0717],\n",
      "        [1.0878],\n",
      "        [1.0812],\n",
      "        [1.0756],\n",
      "        [1.0706],\n",
      "        [1.0849],\n",
      "        [1.1042],\n",
      "        [1.0817],\n",
      "        [1.1077],\n",
      "        [1.1104],\n",
      "        [1.0944],\n",
      "        [1.0783],\n",
      "        [1.1161],\n",
      "        [1.0812],\n",
      "        [1.0652],\n",
      "        [1.1123],\n",
      "        [1.1110],\n",
      "        [1.0923],\n",
      "        [1.0946],\n",
      "        [1.1076],\n",
      "        [1.0838],\n",
      "        [1.0838],\n",
      "        [1.0805],\n",
      "        [1.0646],\n",
      "        [1.0937],\n",
      "        [1.0993],\n",
      "        [1.0942],\n",
      "        [1.1113],\n",
      "        [1.0490],\n",
      "        [1.0765],\n",
      "        [1.1026],\n",
      "        [1.0712],\n",
      "        [1.0730],\n",
      "        [1.1156],\n",
      "        [1.1154],\n",
      "        [1.1208],\n",
      "        [1.0577],\n",
      "        [1.0984],\n",
      "        [1.1138],\n",
      "        [1.0960]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.1099],\n",
      "        [ 1.0541],\n",
      "        [ 1.0622],\n",
      "        [ 1.0711],\n",
      "        [ 1.0574],\n",
      "        [ 1.0874],\n",
      "        [ 1.1030],\n",
      "        [ 1.1024],\n",
      "        [ 1.1177],\n",
      "        [ 1.1047],\n",
      "        [ 1.1020],\n",
      "        [ 1.1177],\n",
      "        [ 1.1028],\n",
      "        [ 1.0218],\n",
      "        [ 1.0898],\n",
      "        [ 1.0929],\n",
      "        [ 1.1107],\n",
      "        [ 1.1063],\n",
      "        [ 1.0681],\n",
      "        [ 1.1079],\n",
      "        [ 1.1015],\n",
      "        [ 1.0953],\n",
      "        [ 1.0814],\n",
      "        [ 1.0774],\n",
      "        [ 1.0746],\n",
      "        [ 1.1241],\n",
      "        [ 1.0977],\n",
      "        [ 1.0886],\n",
      "        [ 1.0972],\n",
      "        [ 1.0645],\n",
      "        [ 0.0423],\n",
      "        [ 1.0926],\n",
      "        [ 1.0913],\n",
      "        [ 1.0904],\n",
      "        [ 1.0988],\n",
      "        [ 1.0878],\n",
      "        [ 1.0935],\n",
      "        [ 1.0357],\n",
      "        [ 1.1120],\n",
      "        [ 1.0990],\n",
      "        [ 1.0745],\n",
      "        [ 1.0767],\n",
      "        [ 1.1193],\n",
      "        [ 1.0926],\n",
      "        [ 1.0409],\n",
      "        [ 1.0905],\n",
      "        [ 1.0955],\n",
      "        [ 1.0687],\n",
      "        [ 1.1090],\n",
      "        [ 1.0958],\n",
      "        [ 1.0689],\n",
      "        [ 1.0568],\n",
      "        [ 1.0914],\n",
      "        [ 1.1195],\n",
      "        [ 1.0700],\n",
      "        [ 1.1207],\n",
      "        [ 1.1206],\n",
      "        [-0.0091],\n",
      "        [ 1.0888],\n",
      "        [ 1.0750],\n",
      "        [ 1.1173],\n",
      "        [ 1.0794],\n",
      "        [ 1.0675],\n",
      "        [ 1.0649],\n",
      "        [ 1.0926],\n",
      "        [ 1.1081],\n",
      "        [ 1.0967],\n",
      "        [ 1.0651],\n",
      "        [ 1.1084],\n",
      "        [ 1.0720],\n",
      "        [ 1.0987],\n",
      "        [ 1.0536],\n",
      "        [ 1.1063],\n",
      "        [ 1.1152],\n",
      "        [ 1.0883],\n",
      "        [ 1.1214],\n",
      "        [ 1.1137],\n",
      "        [ 1.0769],\n",
      "        [ 1.1127],\n",
      "        [ 1.0905],\n",
      "        [ 1.0847],\n",
      "        [ 1.0931],\n",
      "        [ 1.0877],\n",
      "        [ 1.1072],\n",
      "        [ 1.1091],\n",
      "        [ 1.1058],\n",
      "        [ 1.0319],\n",
      "        [ 1.0688],\n",
      "        [ 1.0696],\n",
      "        [ 1.0902],\n",
      "        [ 1.0306],\n",
      "        [ 1.1046],\n",
      "        [ 1.0635],\n",
      "        [ 1.1071],\n",
      "        [ 1.0826],\n",
      "        [ 1.0819],\n",
      "        [ 1.1048],\n",
      "        [ 1.0941],\n",
      "        [ 1.0639],\n",
      "        [ 1.0643],\n",
      "        [ 1.0467],\n",
      "        [ 1.0544],\n",
      "        [ 1.1119],\n",
      "        [ 1.0515],\n",
      "        [ 1.0523],\n",
      "        [ 1.0909],\n",
      "        [ 1.1216],\n",
      "        [ 1.0719],\n",
      "        [ 1.0804],\n",
      "        [ 1.1062],\n",
      "        [ 1.0922],\n",
      "        [ 1.1221],\n",
      "        [ 1.0774],\n",
      "        [ 1.0685],\n",
      "        [ 1.0803],\n",
      "        [ 1.1206],\n",
      "        [ 1.0964],\n",
      "        [ 1.1052],\n",
      "        [ 1.1214],\n",
      "        [ 1.0892],\n",
      "        [ 1.0746],\n",
      "        [ 1.0451],\n",
      "        [ 1.0799],\n",
      "        [ 1.0990],\n",
      "        [ 1.1197],\n",
      "        [ 1.0727],\n",
      "        [ 1.0873],\n",
      "        [ 1.0517]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0592],\n",
      "        [1.1043],\n",
      "        [1.1178],\n",
      "        [1.0522],\n",
      "        [1.0720],\n",
      "        [1.0709],\n",
      "        [1.0724],\n",
      "        [1.0978],\n",
      "        [1.0965],\n",
      "        [1.0837],\n",
      "        [1.1165],\n",
      "        [1.0881],\n",
      "        [1.0802],\n",
      "        [1.1018],\n",
      "        [1.1190],\n",
      "        [1.0796],\n",
      "        [1.0907],\n",
      "        [1.1123],\n",
      "        [1.0976],\n",
      "        [1.0456],\n",
      "        [1.1160],\n",
      "        [1.0881],\n",
      "        [1.0776],\n",
      "        [1.0884],\n",
      "        [1.1101],\n",
      "        [1.0903],\n",
      "        [1.0880],\n",
      "        [1.1030],\n",
      "        [1.1016],\n",
      "        [1.0453],\n",
      "        [1.0818],\n",
      "        [1.1117],\n",
      "        [1.1061],\n",
      "        [1.0996],\n",
      "        [1.0866],\n",
      "        [1.1142],\n",
      "        [1.1180],\n",
      "        [1.1237],\n",
      "        [1.1069],\n",
      "        [1.1150],\n",
      "        [1.0967],\n",
      "        [1.0849],\n",
      "        [1.0910],\n",
      "        [1.0871],\n",
      "        [1.0667],\n",
      "        [1.0693],\n",
      "        [1.1197],\n",
      "        [1.1021],\n",
      "        [1.1056],\n",
      "        [1.0776],\n",
      "        [1.1045],\n",
      "        [1.0909],\n",
      "        [1.0889],\n",
      "        [1.1063],\n",
      "        [1.0673],\n",
      "        [1.0751],\n",
      "        [1.1126],\n",
      "        [1.1051],\n",
      "        [1.0784],\n",
      "        [1.0746],\n",
      "        [1.0825],\n",
      "        [1.1117],\n",
      "        [1.0811],\n",
      "        [1.1052],\n",
      "        [1.1082],\n",
      "        [1.0991],\n",
      "        [1.0806],\n",
      "        [1.0834],\n",
      "        [1.0944],\n",
      "        [1.0959],\n",
      "        [1.0899],\n",
      "        [1.1131],\n",
      "        [1.0890],\n",
      "        [1.1150],\n",
      "        [1.1158],\n",
      "        [1.0480],\n",
      "        [1.1164],\n",
      "        [0.1203],\n",
      "        [1.0751],\n",
      "        [1.0891],\n",
      "        [1.1053],\n",
      "        [1.0911],\n",
      "        [1.1151],\n",
      "        [1.1048],\n",
      "        [1.1088],\n",
      "        [1.1190],\n",
      "        [1.0933],\n",
      "        [1.1156],\n",
      "        [1.1096],\n",
      "        [1.0922],\n",
      "        [1.1152],\n",
      "        [1.0471],\n",
      "        [1.0554],\n",
      "        [1.0813],\n",
      "        [1.0797],\n",
      "        [1.1084],\n",
      "        [1.0973],\n",
      "        [1.0931],\n",
      "        [1.1028],\n",
      "        [1.0757],\n",
      "        [1.0715],\n",
      "        [1.1045],\n",
      "        [1.0869],\n",
      "        [1.1100],\n",
      "        [1.0872],\n",
      "        [1.1134],\n",
      "        [1.0726],\n",
      "        [1.1207],\n",
      "        [1.1165],\n",
      "        [1.0797],\n",
      "        [1.0826],\n",
      "        [1.1119],\n",
      "        [1.1149],\n",
      "        [1.0801],\n",
      "        [1.0842],\n",
      "        [1.0972],\n",
      "        [1.0850],\n",
      "        [1.0106],\n",
      "        [1.0864],\n",
      "        [1.0983],\n",
      "        [1.0855],\n",
      "        [1.0716],\n",
      "        [1.1150],\n",
      "        [1.0893],\n",
      "        [1.0919],\n",
      "        [1.0336],\n",
      "        [1.1164],\n",
      "        [1.0794]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0879],\n",
      "        [1.0986],\n",
      "        [1.1118],\n",
      "        [1.1005],\n",
      "        [1.0769],\n",
      "        [1.0758],\n",
      "        [1.0920],\n",
      "        [1.0683],\n",
      "        [1.0963],\n",
      "        [1.1160],\n",
      "        [1.0952],\n",
      "        [1.0787],\n",
      "        [1.0735],\n",
      "        [1.0907],\n",
      "        [1.1058],\n",
      "        [1.0702],\n",
      "        [1.1084],\n",
      "        [1.1129],\n",
      "        [1.1082],\n",
      "        [1.1073],\n",
      "        [1.0801],\n",
      "        [1.0894],\n",
      "        [1.0986],\n",
      "        [1.1055],\n",
      "        [1.1036],\n",
      "        [1.0693],\n",
      "        [1.0653],\n",
      "        [1.1241],\n",
      "        [1.0653],\n",
      "        [1.1160],\n",
      "        [1.0481],\n",
      "        [1.0736],\n",
      "        [1.1200],\n",
      "        [1.0794],\n",
      "        [1.1096],\n",
      "        [1.1027],\n",
      "        [1.0945],\n",
      "        [1.0771],\n",
      "        [1.1133],\n",
      "        [1.0525],\n",
      "        [1.0902],\n",
      "        [1.0438],\n",
      "        [1.1031],\n",
      "        [1.0998],\n",
      "        [1.1160],\n",
      "        [1.0704],\n",
      "        [1.1173],\n",
      "        [1.1082],\n",
      "        [1.1204],\n",
      "        [1.0830],\n",
      "        [1.0768],\n",
      "        [1.1007],\n",
      "        [1.0926],\n",
      "        [1.0633],\n",
      "        [1.0933],\n",
      "        [1.1062],\n",
      "        [1.1106],\n",
      "        [1.1183],\n",
      "        [1.0845],\n",
      "        [1.0632],\n",
      "        [1.0579],\n",
      "        [1.1023],\n",
      "        [1.0961],\n",
      "        [1.1036],\n",
      "        [1.1102],\n",
      "        [1.0463],\n",
      "        [1.1055],\n",
      "        [1.0899],\n",
      "        [1.0843],\n",
      "        [1.1139],\n",
      "        [1.1241],\n",
      "        [1.0744],\n",
      "        [1.1158],\n",
      "        [1.0686],\n",
      "        [1.0613],\n",
      "        [1.1141],\n",
      "        [1.0788],\n",
      "        [1.0423],\n",
      "        [1.0951],\n",
      "        [1.1197],\n",
      "        [1.0990],\n",
      "        [1.0813],\n",
      "        [1.0934],\n",
      "        [1.1018],\n",
      "        [1.1202],\n",
      "        [1.0800],\n",
      "        [1.0877],\n",
      "        [1.0681],\n",
      "        [1.1053],\n",
      "        [1.0842],\n",
      "        [1.0961],\n",
      "        [1.0764],\n",
      "        [1.1144],\n",
      "        [1.0760],\n",
      "        [1.1088],\n",
      "        [1.0898],\n",
      "        [1.0903],\n",
      "        [1.0684],\n",
      "        [1.0635],\n",
      "        [1.0587],\n",
      "        [1.1031],\n",
      "        [1.0827],\n",
      "        [1.0948],\n",
      "        [1.1179],\n",
      "        [1.1161],\n",
      "        [1.1072],\n",
      "        [1.0986],\n",
      "        [1.0995],\n",
      "        [1.1207],\n",
      "        [1.0968],\n",
      "        [1.1067],\n",
      "        [1.1104],\n",
      "        [1.1193],\n",
      "        [1.0769],\n",
      "        [1.0900],\n",
      "        [1.0749],\n",
      "        [1.1051],\n",
      "        [1.0894],\n",
      "        [1.0942],\n",
      "        [1.1036],\n",
      "        [1.1223],\n",
      "        [1.0784],\n",
      "        [1.0753],\n",
      "        [1.0406],\n",
      "        [1.1050],\n",
      "        [1.0775],\n",
      "        [1.0983],\n",
      "        [1.1083]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1207],\n",
      "        [1.1057],\n",
      "        [1.0931],\n",
      "        [1.0741]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  41 | lr 0.00010 train_loss 2.13087 | val_loss 2.29218 | val_rmse 1.51399\n",
      "tensor([[1.0889],\n",
      "        [1.0902],\n",
      "        [1.1131],\n",
      "        [1.0889],\n",
      "        [1.1186],\n",
      "        [1.0653],\n",
      "        [1.0246],\n",
      "        [1.1175],\n",
      "        [1.0630],\n",
      "        [1.1039],\n",
      "        [1.0717],\n",
      "        [1.0999],\n",
      "        [1.0921],\n",
      "        [1.0943],\n",
      "        [1.0462],\n",
      "        [1.0953],\n",
      "        [1.0860],\n",
      "        [1.0839],\n",
      "        [1.1112],\n",
      "        [1.0919],\n",
      "        [1.0826],\n",
      "        [1.0986],\n",
      "        [1.1048],\n",
      "        [1.0502],\n",
      "        [1.0882],\n",
      "        [1.0862],\n",
      "        [1.0939],\n",
      "        [1.0724],\n",
      "        [1.0892],\n",
      "        [1.0671],\n",
      "        [1.1031],\n",
      "        [1.0974],\n",
      "        [1.0456],\n",
      "        [1.0677],\n",
      "        [1.0730],\n",
      "        [1.0819],\n",
      "        [1.1196],\n",
      "        [1.0326],\n",
      "        [1.0798],\n",
      "        [1.1227],\n",
      "        [1.0301],\n",
      "        [1.1185],\n",
      "        [1.1000],\n",
      "        [1.1158],\n",
      "        [1.0324],\n",
      "        [1.0993],\n",
      "        [1.0970],\n",
      "        [1.0938],\n",
      "        [1.0677],\n",
      "        [1.0620],\n",
      "        [1.0830],\n",
      "        [1.1149],\n",
      "        [1.1078],\n",
      "        [1.1093],\n",
      "        [1.0935],\n",
      "        [1.0923],\n",
      "        [1.0947],\n",
      "        [1.0847],\n",
      "        [1.0977],\n",
      "        [1.1107],\n",
      "        [1.1030],\n",
      "        [1.1067],\n",
      "        [1.0857],\n",
      "        [1.0597],\n",
      "        [1.0754],\n",
      "        [1.0595],\n",
      "        [1.0912],\n",
      "        [1.0982],\n",
      "        [1.0796],\n",
      "        [1.0566],\n",
      "        [1.1159],\n",
      "        [1.0622],\n",
      "        [1.0645],\n",
      "        [1.0985],\n",
      "        [1.0639],\n",
      "        [1.1023],\n",
      "        [1.0874],\n",
      "        [1.1006],\n",
      "        [1.1079],\n",
      "        [1.1016],\n",
      "        [1.0998],\n",
      "        [1.0878],\n",
      "        [1.1109],\n",
      "        [1.1023],\n",
      "        [1.0609],\n",
      "        [1.0333],\n",
      "        [1.0745],\n",
      "        [1.1009],\n",
      "        [1.0905],\n",
      "        [1.0908],\n",
      "        [1.1026],\n",
      "        [1.1165],\n",
      "        [1.1139],\n",
      "        [1.1062],\n",
      "        [1.0693],\n",
      "        [1.0959],\n",
      "        [1.1182],\n",
      "        [1.1130],\n",
      "        [1.0643],\n",
      "        [1.0771],\n",
      "        [1.1204],\n",
      "        [1.0715],\n",
      "        [1.1095],\n",
      "        [1.1114],\n",
      "        [1.0550],\n",
      "        [1.0844],\n",
      "        [1.0931],\n",
      "        [1.1013],\n",
      "        [2.4932],\n",
      "        [1.0884],\n",
      "        [1.0706],\n",
      "        [1.1200],\n",
      "        [1.0942],\n",
      "        [1.1098],\n",
      "        [1.1074],\n",
      "        [1.1132],\n",
      "        [1.1151],\n",
      "        [1.0860],\n",
      "        [1.1068],\n",
      "        [1.0975],\n",
      "        [1.1004],\n",
      "        [1.0784],\n",
      "        [1.1162],\n",
      "        [1.0838],\n",
      "        [1.0809],\n",
      "        [1.0932],\n",
      "        [1.0969],\n",
      "        [1.1001]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1158],\n",
      "        [1.0251],\n",
      "        [1.1099],\n",
      "        [1.0864],\n",
      "        [1.1042],\n",
      "        [1.0492],\n",
      "        [1.0533],\n",
      "        [1.0401],\n",
      "        [1.1181],\n",
      "        [1.1149],\n",
      "        [1.0700],\n",
      "        [1.1144],\n",
      "        [1.1057],\n",
      "        [1.0609],\n",
      "        [1.1002],\n",
      "        [1.0948],\n",
      "        [1.0674],\n",
      "        [1.0625],\n",
      "        [1.1068],\n",
      "        [1.1052],\n",
      "        [1.0959],\n",
      "        [1.1046],\n",
      "        [1.1140],\n",
      "        [1.0131],\n",
      "        [1.1203],\n",
      "        [1.1095],\n",
      "        [1.0788],\n",
      "        [1.0680],\n",
      "        [1.0520],\n",
      "        [1.1033],\n",
      "        [1.0329],\n",
      "        [1.0800],\n",
      "        [1.0547],\n",
      "        [1.0932],\n",
      "        [1.1180],\n",
      "        [1.1128],\n",
      "        [1.0674],\n",
      "        [1.0847],\n",
      "        [1.0978],\n",
      "        [1.0846],\n",
      "        [1.0892],\n",
      "        [1.1200],\n",
      "        [1.1099],\n",
      "        [1.1011],\n",
      "        [1.1121],\n",
      "        [1.0492],\n",
      "        [1.1145],\n",
      "        [1.0995],\n",
      "        [1.0667],\n",
      "        [1.1055],\n",
      "        [1.0943],\n",
      "        [1.0532],\n",
      "        [1.0974],\n",
      "        [1.1063],\n",
      "        [1.0512],\n",
      "        [1.1053],\n",
      "        [1.0836],\n",
      "        [1.1066],\n",
      "        [1.0934],\n",
      "        [1.1081],\n",
      "        [1.0881],\n",
      "        [1.0867],\n",
      "        [1.1059],\n",
      "        [1.0896],\n",
      "        [1.0778],\n",
      "        [1.1089],\n",
      "        [1.1094],\n",
      "        [1.0640],\n",
      "        [1.1135],\n",
      "        [1.0326],\n",
      "        [1.0789],\n",
      "        [1.1116],\n",
      "        [1.1141],\n",
      "        [1.1081],\n",
      "        [1.1121],\n",
      "        [1.0920],\n",
      "        [1.0672],\n",
      "        [1.0994],\n",
      "        [1.0871],\n",
      "        [1.0974],\n",
      "        [1.0929],\n",
      "        [1.0838],\n",
      "        [1.1203],\n",
      "        [1.0739],\n",
      "        [1.0605],\n",
      "        [1.1094],\n",
      "        [1.0724],\n",
      "        [1.0845],\n",
      "        [1.0698],\n",
      "        [1.0773],\n",
      "        [1.1086],\n",
      "        [1.1206],\n",
      "        [1.1014],\n",
      "        [1.0936],\n",
      "        [1.0562],\n",
      "        [1.0384],\n",
      "        [1.1150],\n",
      "        [1.0954],\n",
      "        [1.0843],\n",
      "        [1.1100],\n",
      "        [1.0919],\n",
      "        [1.0415],\n",
      "        [1.0706],\n",
      "        [1.0826],\n",
      "        [1.0915],\n",
      "        [1.0555],\n",
      "        [1.0987],\n",
      "        [1.1173],\n",
      "        [1.0819],\n",
      "        [1.0977],\n",
      "        [1.0732],\n",
      "        [1.1179],\n",
      "        [1.1060],\n",
      "        [0.1119],\n",
      "        [1.0458],\n",
      "        [1.1022],\n",
      "        [1.0799],\n",
      "        [1.0417],\n",
      "        [1.1058],\n",
      "        [1.0906],\n",
      "        [1.1142],\n",
      "        [1.0976],\n",
      "        [1.0763],\n",
      "        [1.1117],\n",
      "        [1.0936],\n",
      "        [1.0632],\n",
      "        [1.1014],\n",
      "        [1.0949]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0633],\n",
      "        [1.1061],\n",
      "        [1.0597],\n",
      "        [1.0888],\n",
      "        [0.9911],\n",
      "        [1.0874],\n",
      "        [1.1113],\n",
      "        [1.0872],\n",
      "        [1.1177],\n",
      "        [1.0602],\n",
      "        [1.1073],\n",
      "        [1.0974],\n",
      "        [1.0586],\n",
      "        [1.0802],\n",
      "        [1.1110],\n",
      "        [1.1034],\n",
      "        [1.0845],\n",
      "        [1.0963],\n",
      "        [1.1022],\n",
      "        [1.0955],\n",
      "        [1.0889],\n",
      "        [1.0715],\n",
      "        [1.1119],\n",
      "        [1.1001],\n",
      "        [1.1025],\n",
      "        [1.1200],\n",
      "        [1.0658],\n",
      "        [1.1178],\n",
      "        [1.1189],\n",
      "        [1.0833],\n",
      "        [1.0975],\n",
      "        [1.0967],\n",
      "        [1.0930],\n",
      "        [1.0269],\n",
      "        [1.0702],\n",
      "        [1.1111],\n",
      "        [1.0705],\n",
      "        [1.1118],\n",
      "        [1.1174],\n",
      "        [1.1099],\n",
      "        [1.1010],\n",
      "        [1.0869],\n",
      "        [1.0948],\n",
      "        [1.1054],\n",
      "        [1.0777],\n",
      "        [1.1065],\n",
      "        [1.0957],\n",
      "        [1.1021],\n",
      "        [1.0944],\n",
      "        [1.1208],\n",
      "        [1.0871],\n",
      "        [1.0676],\n",
      "        [1.0498],\n",
      "        [1.0919],\n",
      "        [1.1189],\n",
      "        [1.0760],\n",
      "        [1.1008],\n",
      "        [1.0987],\n",
      "        [1.0994],\n",
      "        [1.1147],\n",
      "        [1.1050],\n",
      "        [1.0341],\n",
      "        [1.0822],\n",
      "        [1.0855],\n",
      "        [1.0723],\n",
      "        [1.1093],\n",
      "        [1.1195],\n",
      "        [1.0959],\n",
      "        [1.1111],\n",
      "        [1.0997],\n",
      "        [1.0983],\n",
      "        [1.0875],\n",
      "        [1.0733],\n",
      "        [1.1100],\n",
      "        [1.1196],\n",
      "        [1.0901],\n",
      "        [1.1107],\n",
      "        [1.0806],\n",
      "        [1.1039],\n",
      "        [1.1025],\n",
      "        [1.1018],\n",
      "        [1.0947],\n",
      "        [1.0752],\n",
      "        [1.0881],\n",
      "        [1.1004],\n",
      "        [1.1096],\n",
      "        [1.0750],\n",
      "        [1.0641],\n",
      "        [1.0628],\n",
      "        [1.0673],\n",
      "        [1.1004],\n",
      "        [1.0724],\n",
      "        [1.0664],\n",
      "        [1.0793],\n",
      "        [1.1130],\n",
      "        [1.1007],\n",
      "        [1.1146],\n",
      "        [1.0965],\n",
      "        [1.0910],\n",
      "        [1.1125],\n",
      "        [1.0567],\n",
      "        [1.1112],\n",
      "        [1.0712],\n",
      "        [1.0917],\n",
      "        [1.0855],\n",
      "        [1.1058],\n",
      "        [1.1018],\n",
      "        [1.0547],\n",
      "        [1.1185],\n",
      "        [1.0963],\n",
      "        [1.0605],\n",
      "        [1.1082],\n",
      "        [1.0884],\n",
      "        [1.1017],\n",
      "        [1.0990],\n",
      "        [1.0952],\n",
      "        [1.1121],\n",
      "        [1.0771],\n",
      "        [1.0795],\n",
      "        [1.1101],\n",
      "        [1.0884],\n",
      "        [1.0550],\n",
      "        [1.1104],\n",
      "        [1.1092],\n",
      "        [1.0745],\n",
      "        [1.0892],\n",
      "        [1.0946],\n",
      "        [1.1204]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0460],\n",
      "        [1.0519],\n",
      "        [1.1193],\n",
      "        [1.0788],\n",
      "        [1.0901],\n",
      "        [1.1017],\n",
      "        [1.0762],\n",
      "        [1.0536],\n",
      "        [1.1094],\n",
      "        [1.0627],\n",
      "        [1.0779],\n",
      "        [1.1030],\n",
      "        [1.0973],\n",
      "        [1.0455],\n",
      "        [1.1022],\n",
      "        [1.0509],\n",
      "        [1.0912],\n",
      "        [1.0884],\n",
      "        [1.1152],\n",
      "        [1.1149],\n",
      "        [1.1062],\n",
      "        [1.1138],\n",
      "        [1.0972],\n",
      "        [1.1143],\n",
      "        [1.0761],\n",
      "        [1.0912],\n",
      "        [1.0784],\n",
      "        [1.0527],\n",
      "        [1.0968],\n",
      "        [1.1110],\n",
      "        [1.0782],\n",
      "        [1.1059],\n",
      "        [1.1048],\n",
      "        [1.0916],\n",
      "        [1.1148],\n",
      "        [1.0992],\n",
      "        [1.0753],\n",
      "        [1.1020],\n",
      "        [1.0829],\n",
      "        [1.0883],\n",
      "        [1.0840],\n",
      "        [1.1097],\n",
      "        [1.0900],\n",
      "        [1.0810],\n",
      "        [1.0863],\n",
      "        [1.1083],\n",
      "        [1.0878],\n",
      "        [1.1109],\n",
      "        [1.0962],\n",
      "        [1.1176],\n",
      "        [1.0276],\n",
      "        [1.1141],\n",
      "        [1.1128],\n",
      "        [1.1080],\n",
      "        [1.0786],\n",
      "        [1.0760],\n",
      "        [1.1024],\n",
      "        [1.0723],\n",
      "        [1.1077],\n",
      "        [1.1213],\n",
      "        [1.0837],\n",
      "        [1.1076],\n",
      "        [1.1010],\n",
      "        [1.0771],\n",
      "        [1.0907],\n",
      "        [1.1143],\n",
      "        [1.0958],\n",
      "        [1.0993],\n",
      "        [1.1043],\n",
      "        [1.0775],\n",
      "        [1.0568],\n",
      "        [1.0942],\n",
      "        [1.1032],\n",
      "        [1.0400],\n",
      "        [1.0574],\n",
      "        [1.1169],\n",
      "        [1.0985],\n",
      "        [1.1132],\n",
      "        [1.1036],\n",
      "        [1.0632],\n",
      "        [1.1199],\n",
      "        [1.1125],\n",
      "        [1.0795],\n",
      "        [1.0969],\n",
      "        [1.1146],\n",
      "        [1.0925],\n",
      "        [1.1074],\n",
      "        [1.0937],\n",
      "        [1.1134],\n",
      "        [1.1074],\n",
      "        [1.0933],\n",
      "        [1.1047],\n",
      "        [1.0921],\n",
      "        [1.1072],\n",
      "        [1.1010],\n",
      "        [1.1043],\n",
      "        [1.0820],\n",
      "        [1.0867],\n",
      "        [1.0592],\n",
      "        [1.1167],\n",
      "        [1.1081],\n",
      "        [1.0975],\n",
      "        [1.0733],\n",
      "        [1.1019],\n",
      "        [1.1085],\n",
      "        [1.0871],\n",
      "        [1.0960],\n",
      "        [1.0924],\n",
      "        [1.0937],\n",
      "        [1.1037],\n",
      "        [1.1030],\n",
      "        [1.0992],\n",
      "        [1.1133],\n",
      "        [1.1204],\n",
      "        [1.0806],\n",
      "        [1.1015],\n",
      "        [1.0758],\n",
      "        [1.1063],\n",
      "        [1.1073],\n",
      "        [1.1205],\n",
      "        [1.1128],\n",
      "        [1.1077],\n",
      "        [1.0869],\n",
      "        [1.1129],\n",
      "        [1.0931],\n",
      "        [1.1156],\n",
      "        [1.0824],\n",
      "        [1.0631]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0601],\n",
      "        [1.1144],\n",
      "        [1.0933],\n",
      "        [1.0793],\n",
      "        [1.0663],\n",
      "        [1.1190],\n",
      "        [1.0829],\n",
      "        [1.0986],\n",
      "        [1.0702],\n",
      "        [1.0758],\n",
      "        [1.0784],\n",
      "        [1.0833],\n",
      "        [1.0465],\n",
      "        [1.1068],\n",
      "        [1.1064],\n",
      "        [1.0774],\n",
      "        [1.0876],\n",
      "        [1.0867],\n",
      "        [1.0674],\n",
      "        [1.1093],\n",
      "        [1.0889],\n",
      "        [1.0750],\n",
      "        [1.0409],\n",
      "        [1.0483],\n",
      "        [1.1003],\n",
      "        [1.1129],\n",
      "        [1.0910],\n",
      "        [1.1155],\n",
      "        [1.0951],\n",
      "        [1.0853],\n",
      "        [1.0696],\n",
      "        [1.0868],\n",
      "        [1.1156],\n",
      "        [1.0788],\n",
      "        [1.0442],\n",
      "        [1.0579],\n",
      "        [1.1142],\n",
      "        [1.1102],\n",
      "        [1.1042],\n",
      "        [1.0689],\n",
      "        [1.1000],\n",
      "        [1.0819],\n",
      "        [1.1010],\n",
      "        [1.0980],\n",
      "        [1.0817],\n",
      "        [1.1114],\n",
      "        [1.0816],\n",
      "        [1.0739],\n",
      "        [1.0977],\n",
      "        [1.1146],\n",
      "        [1.0746],\n",
      "        [1.0880],\n",
      "        [1.1061],\n",
      "        [1.0724],\n",
      "        [1.1113],\n",
      "        [1.0876],\n",
      "        [1.1056],\n",
      "        [1.0926],\n",
      "        [1.1152],\n",
      "        [1.1039],\n",
      "        [1.0871],\n",
      "        [1.0696],\n",
      "        [1.0801],\n",
      "        [1.1091],\n",
      "        [1.1117],\n",
      "        [1.1014],\n",
      "        [1.0726],\n",
      "        [1.0596],\n",
      "        [1.0833],\n",
      "        [1.0951],\n",
      "        [1.1026],\n",
      "        [1.1005],\n",
      "        [1.1199],\n",
      "        [1.1027],\n",
      "        [1.1088],\n",
      "        [1.0581],\n",
      "        [1.1188],\n",
      "        [1.0910],\n",
      "        [1.1090],\n",
      "        [1.0844],\n",
      "        [1.0777],\n",
      "        [1.0946],\n",
      "        [1.1195],\n",
      "        [1.0650],\n",
      "        [1.0733],\n",
      "        [1.1130],\n",
      "        [1.0740],\n",
      "        [1.1049],\n",
      "        [1.0958],\n",
      "        [1.0867],\n",
      "        [1.0821],\n",
      "        [1.1036],\n",
      "        [1.0841],\n",
      "        [1.1042],\n",
      "        [1.0974],\n",
      "        [1.0922],\n",
      "        [1.1131],\n",
      "        [1.1126],\n",
      "        [1.0981],\n",
      "        [1.1147],\n",
      "        [1.1080],\n",
      "        [1.0833],\n",
      "        [1.0699],\n",
      "        [1.0676],\n",
      "        [1.1101],\n",
      "        [1.1084],\n",
      "        [1.0952],\n",
      "        [1.0889],\n",
      "        [1.0785],\n",
      "        [1.0992],\n",
      "        [1.1126],\n",
      "        [1.1072],\n",
      "        [1.0776],\n",
      "        [1.0489],\n",
      "        [1.0865],\n",
      "        [1.1183],\n",
      "        [1.0951],\n",
      "        [1.1019],\n",
      "        [1.0799],\n",
      "        [1.1026],\n",
      "        [1.1002],\n",
      "        [1.0768],\n",
      "        [1.0939],\n",
      "        [1.0563],\n",
      "        [1.0682],\n",
      "        [1.1209],\n",
      "        [1.1062],\n",
      "        [1.1149]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0961],\n",
      "        [1.0715],\n",
      "        [1.0695],\n",
      "        [1.1068],\n",
      "        [1.0836],\n",
      "        [1.0803],\n",
      "        [1.1137],\n",
      "        [1.0884],\n",
      "        [1.0706],\n",
      "        [1.0947],\n",
      "        [1.0853],\n",
      "        [1.0714],\n",
      "        [1.0787],\n",
      "        [1.0855],\n",
      "        [1.0917],\n",
      "        [1.0929],\n",
      "        [1.1103],\n",
      "        [1.0915],\n",
      "        [1.0853],\n",
      "        [1.1075],\n",
      "        [1.1194],\n",
      "        [1.0831],\n",
      "        [1.0181],\n",
      "        [0.9977],\n",
      "        [1.0689],\n",
      "        [1.0904],\n",
      "        [1.0957],\n",
      "        [1.1014],\n",
      "        [1.0675],\n",
      "        [1.0465],\n",
      "        [1.0938],\n",
      "        [1.0869],\n",
      "        [1.0901],\n",
      "        [1.0838],\n",
      "        [1.1115],\n",
      "        [1.0744],\n",
      "        [1.0684],\n",
      "        [1.0992],\n",
      "        [1.0661],\n",
      "        [1.0782],\n",
      "        [1.0989],\n",
      "        [1.1172],\n",
      "        [1.0500],\n",
      "        [1.0715],\n",
      "        [1.0493],\n",
      "        [1.0704],\n",
      "        [1.0995],\n",
      "        [1.0998],\n",
      "        [1.0638],\n",
      "        [1.0691],\n",
      "        [1.0944],\n",
      "        [1.0956],\n",
      "        [1.0835],\n",
      "        [1.0898],\n",
      "        [1.0895],\n",
      "        [1.1059],\n",
      "        [1.0768],\n",
      "        [1.0820],\n",
      "        [1.0925],\n",
      "        [1.1058],\n",
      "        [1.0615],\n",
      "        [0.3782],\n",
      "        [1.0519],\n",
      "        [1.1066],\n",
      "        [1.0850],\n",
      "        [1.1171],\n",
      "        [1.0978],\n",
      "        [1.1047],\n",
      "        [1.1046],\n",
      "        [1.0752],\n",
      "        [1.0827],\n",
      "        [1.0562],\n",
      "        [1.0837],\n",
      "        [1.0862],\n",
      "        [1.1022],\n",
      "        [1.1081],\n",
      "        [1.0942],\n",
      "        [1.0789],\n",
      "        [1.0905],\n",
      "        [1.1194],\n",
      "        [1.0792],\n",
      "        [1.0929],\n",
      "        [1.0964],\n",
      "        [1.1130],\n",
      "        [1.0700],\n",
      "        [1.0440],\n",
      "        [1.1098],\n",
      "        [1.0892],\n",
      "        [1.1071],\n",
      "        [1.1164],\n",
      "        [1.1012],\n",
      "        [1.0847],\n",
      "        [1.1010],\n",
      "        [1.0687],\n",
      "        [1.1004],\n",
      "        [1.1086],\n",
      "        [1.0930],\n",
      "        [1.0485],\n",
      "        [1.1045],\n",
      "        [1.1083],\n",
      "        [1.0906],\n",
      "        [1.1000],\n",
      "        [1.0953],\n",
      "        [1.1041],\n",
      "        [1.0732],\n",
      "        [1.0935],\n",
      "        [1.1075],\n",
      "        [1.1089],\n",
      "        [1.1064],\n",
      "        [1.1190],\n",
      "        [1.1115],\n",
      "        [1.0546],\n",
      "        [1.0880],\n",
      "        [1.1070],\n",
      "        [1.1092],\n",
      "        [1.0529],\n",
      "        [1.1040],\n",
      "        [1.0890],\n",
      "        [1.0997],\n",
      "        [1.0635],\n",
      "        [1.1171],\n",
      "        [1.0761],\n",
      "        [1.0531],\n",
      "        [1.0983],\n",
      "        [1.0801],\n",
      "        [1.1094],\n",
      "        [1.0929],\n",
      "        [1.0969]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1041],\n",
      "        [1.0663],\n",
      "        [1.1051],\n",
      "        [1.0968],\n",
      "        [1.0793],\n",
      "        [1.0951],\n",
      "        [1.1024],\n",
      "        [1.0711],\n",
      "        [1.0618],\n",
      "        [1.1162],\n",
      "        [1.0979],\n",
      "        [1.1052],\n",
      "        [1.0545],\n",
      "        [1.1045],\n",
      "        [1.0951],\n",
      "        [1.1072],\n",
      "        [1.0974],\n",
      "        [1.0386],\n",
      "        [1.1023],\n",
      "        [1.1087],\n",
      "        [1.0928],\n",
      "        [1.0900],\n",
      "        [1.0920],\n",
      "        [1.0748],\n",
      "        [1.0905],\n",
      "        [1.0285],\n",
      "        [1.1100],\n",
      "        [1.0626],\n",
      "        [1.0490],\n",
      "        [1.0857],\n",
      "        [1.0798],\n",
      "        [1.0944],\n",
      "        [1.0702],\n",
      "        [1.0712],\n",
      "        [1.1034],\n",
      "        [1.1121],\n",
      "        [1.1214],\n",
      "        [1.1052],\n",
      "        [1.1078],\n",
      "        [1.1179],\n",
      "        [1.1018],\n",
      "        [1.0743],\n",
      "        [1.1149],\n",
      "        [1.1086],\n",
      "        [1.1144],\n",
      "        [1.0786],\n",
      "        [1.0528],\n",
      "        [1.1056],\n",
      "        [1.0637],\n",
      "        [1.0964],\n",
      "        [1.1190],\n",
      "        [1.0944],\n",
      "        [1.0655],\n",
      "        [1.0616],\n",
      "        [1.0850],\n",
      "        [1.1082],\n",
      "        [1.0945],\n",
      "        [1.0811],\n",
      "        [1.1090],\n",
      "        [1.1080],\n",
      "        [1.0592],\n",
      "        [1.0481],\n",
      "        [1.0245],\n",
      "        [1.1141],\n",
      "        [1.0889],\n",
      "        [1.0701],\n",
      "        [1.0879],\n",
      "        [1.1080],\n",
      "        [1.1023],\n",
      "        [1.0749],\n",
      "        [1.1093],\n",
      "        [1.0703],\n",
      "        [1.0946],\n",
      "        [1.1184],\n",
      "        [1.0319],\n",
      "        [1.0825],\n",
      "        [1.1020],\n",
      "        [1.1083],\n",
      "        [1.0755],\n",
      "        [1.0853],\n",
      "        [1.0851],\n",
      "        [1.1068],\n",
      "        [1.0928],\n",
      "        [1.0853],\n",
      "        [1.1026],\n",
      "        [1.0394],\n",
      "        [1.0854],\n",
      "        [1.1038],\n",
      "        [1.0901],\n",
      "        [1.1157],\n",
      "        [1.0976],\n",
      "        [1.0776],\n",
      "        [1.1106],\n",
      "        [1.0487],\n",
      "        [1.0601],\n",
      "        [1.1151],\n",
      "        [1.1077],\n",
      "        [1.0887],\n",
      "        [1.0928],\n",
      "        [1.0784],\n",
      "        [1.0997],\n",
      "        [1.0736],\n",
      "        [1.0098],\n",
      "        [1.1189],\n",
      "        [1.0905],\n",
      "        [1.0730],\n",
      "        [1.1103],\n",
      "        [1.0382],\n",
      "        [1.1191],\n",
      "        [1.0629],\n",
      "        [1.0811],\n",
      "        [1.1014],\n",
      "        [1.0877],\n",
      "        [1.1052],\n",
      "        [1.1164],\n",
      "        [1.0665],\n",
      "        [1.1053],\n",
      "        [1.0848],\n",
      "        [1.0818],\n",
      "        [1.1136],\n",
      "        [1.0829],\n",
      "        [1.0740],\n",
      "        [1.0930],\n",
      "        [1.0467],\n",
      "        [1.0773],\n",
      "        [1.0773],\n",
      "        [1.0850],\n",
      "        [1.0921]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0871],\n",
      "        [1.0992],\n",
      "        [1.1026],\n",
      "        [1.1012]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  42 | lr 0.00010 train_loss 2.12621 | val_loss 2.29263 | val_rmse 1.51414\n",
      "tensor([[1.1178],\n",
      "        [1.1100],\n",
      "        [1.0682],\n",
      "        [1.0937],\n",
      "        [1.0677],\n",
      "        [1.0658],\n",
      "        [1.0971],\n",
      "        [1.0820],\n",
      "        [1.0789],\n",
      "        [1.0981],\n",
      "        [1.0741],\n",
      "        [1.1066],\n",
      "        [1.0975],\n",
      "        [1.0832],\n",
      "        [1.0852],\n",
      "        [1.1134],\n",
      "        [1.1189],\n",
      "        [1.0944],\n",
      "        [1.0617],\n",
      "        [1.1166],\n",
      "        [1.0991],\n",
      "        [1.0874],\n",
      "        [1.0570],\n",
      "        [1.0972],\n",
      "        [1.1028],\n",
      "        [1.0905],\n",
      "        [1.0653],\n",
      "        [1.1001],\n",
      "        [1.0724],\n",
      "        [1.1038],\n",
      "        [1.0998],\n",
      "        [1.0565],\n",
      "        [1.1104],\n",
      "        [1.1096],\n",
      "        [1.0851],\n",
      "        [1.0579],\n",
      "        [1.0159],\n",
      "        [1.1079],\n",
      "        [1.0564],\n",
      "        [1.1040],\n",
      "        [1.0819],\n",
      "        [1.1029],\n",
      "        [1.1189],\n",
      "        [1.0611],\n",
      "        [1.1077],\n",
      "        [1.1185],\n",
      "        [1.0864],\n",
      "        [1.1086],\n",
      "        [1.0741],\n",
      "        [1.0746],\n",
      "        [1.0666],\n",
      "        [1.0986],\n",
      "        [1.1006],\n",
      "        [1.0166],\n",
      "        [1.0484],\n",
      "        [1.1097],\n",
      "        [1.0616],\n",
      "        [1.0758],\n",
      "        [1.0848],\n",
      "        [1.0974],\n",
      "        [1.1063],\n",
      "        [1.0911],\n",
      "        [1.1076],\n",
      "        [1.0966],\n",
      "        [1.0812],\n",
      "        [1.0699],\n",
      "        [1.0600],\n",
      "        [1.1094],\n",
      "        [1.0621],\n",
      "        [1.0764],\n",
      "        [1.1006],\n",
      "        [1.0783],\n",
      "        [1.1016],\n",
      "        [1.1122],\n",
      "        [1.1170],\n",
      "        [1.1188],\n",
      "        [1.0632],\n",
      "        [1.1028],\n",
      "        [1.1044],\n",
      "        [1.0406],\n",
      "        [1.0442],\n",
      "        [1.0745],\n",
      "        [1.0988],\n",
      "        [1.0927],\n",
      "        [1.0734],\n",
      "        [1.0867],\n",
      "        [1.1063],\n",
      "        [1.1101],\n",
      "        [1.0516],\n",
      "        [1.0517],\n",
      "        [1.0914],\n",
      "        [1.1010],\n",
      "        [1.0610],\n",
      "        [1.0773],\n",
      "        [1.0896],\n",
      "        [1.1015],\n",
      "        [1.0811],\n",
      "        [1.0728],\n",
      "        [1.0960],\n",
      "        [1.0748],\n",
      "        [1.0814],\n",
      "        [1.0967],\n",
      "        [1.1214],\n",
      "        [1.0807],\n",
      "        [1.1087],\n",
      "        [1.1143],\n",
      "        [1.0962],\n",
      "        [1.0765],\n",
      "        [1.1082],\n",
      "        [1.1055],\n",
      "        [1.0960],\n",
      "        [1.0365],\n",
      "        [1.0695],\n",
      "        [1.0579],\n",
      "        [1.0849],\n",
      "        [1.1152],\n",
      "        [1.0973],\n",
      "        [1.1053],\n",
      "        [1.0749],\n",
      "        [1.0768],\n",
      "        [1.1087],\n",
      "        [1.0520],\n",
      "        [1.1019],\n",
      "        [1.0874],\n",
      "        [1.0846],\n",
      "        [1.1194],\n",
      "        [1.0730],\n",
      "        [1.1104]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1151],\n",
      "        [1.0887],\n",
      "        [1.0686],\n",
      "        [1.0469],\n",
      "        [1.0846],\n",
      "        [1.0440],\n",
      "        [1.0800],\n",
      "        [1.1037],\n",
      "        [1.0790],\n",
      "        [1.1044],\n",
      "        [1.0886],\n",
      "        [1.0959],\n",
      "        [1.0988],\n",
      "        [1.0959],\n",
      "        [1.1033],\n",
      "        [1.0892],\n",
      "        [1.0676],\n",
      "        [1.1033],\n",
      "        [1.1092],\n",
      "        [1.0501],\n",
      "        [1.1113],\n",
      "        [1.0614],\n",
      "        [1.0430],\n",
      "        [1.0553],\n",
      "        [1.1075],\n",
      "        [1.0542],\n",
      "        [1.1000],\n",
      "        [1.1188],\n",
      "        [1.0794],\n",
      "        [1.0859],\n",
      "        [1.0987],\n",
      "        [1.0989],\n",
      "        [1.0893],\n",
      "        [1.0663],\n",
      "        [1.0984],\n",
      "        [1.0973],\n",
      "        [1.0736],\n",
      "        [1.0815],\n",
      "        [1.0761],\n",
      "        [1.1151],\n",
      "        [1.0226],\n",
      "        [1.1131],\n",
      "        [1.1150],\n",
      "        [1.1030],\n",
      "        [1.1021],\n",
      "        [1.0916],\n",
      "        [1.1046],\n",
      "        [1.0862],\n",
      "        [1.0920],\n",
      "        [1.0739],\n",
      "        [1.1074],\n",
      "        [1.1062],\n",
      "        [1.1172],\n",
      "        [1.1070],\n",
      "        [1.0988],\n",
      "        [1.1103],\n",
      "        [1.0998],\n",
      "        [1.0978],\n",
      "        [1.0750],\n",
      "        [1.0842],\n",
      "        [1.1012],\n",
      "        [1.0826],\n",
      "        [1.1116],\n",
      "        [1.0933],\n",
      "        [1.1103],\n",
      "        [1.1006],\n",
      "        [1.1195],\n",
      "        [1.0829],\n",
      "        [1.0408],\n",
      "        [1.1207],\n",
      "        [1.0885],\n",
      "        [1.1149],\n",
      "        [1.0810],\n",
      "        [1.0094],\n",
      "        [1.1204],\n",
      "        [1.0813],\n",
      "        [1.1165],\n",
      "        [1.0858],\n",
      "        [1.1227],\n",
      "        [1.0771],\n",
      "        [1.1187],\n",
      "        [1.0949],\n",
      "        [1.0789],\n",
      "        [1.1184],\n",
      "        [1.0493],\n",
      "        [1.1033],\n",
      "        [1.0838],\n",
      "        [1.0745],\n",
      "        [1.0877],\n",
      "        [1.0685],\n",
      "        [1.0937],\n",
      "        [1.1007],\n",
      "        [1.1120],\n",
      "        [1.0551],\n",
      "        [1.0812],\n",
      "        [1.0863],\n",
      "        [1.0942],\n",
      "        [1.0818],\n",
      "        [1.0372],\n",
      "        [1.1110],\n",
      "        [1.0638],\n",
      "        [1.1235],\n",
      "        [1.0715],\n",
      "        [1.0911],\n",
      "        [1.0747],\n",
      "        [1.0726],\n",
      "        [1.1045],\n",
      "        [1.0873],\n",
      "        [1.1042],\n",
      "        [1.0750],\n",
      "        [1.0896],\n",
      "        [1.0743],\n",
      "        [1.1179],\n",
      "        [1.0959],\n",
      "        [1.1087],\n",
      "        [1.0881],\n",
      "        [1.0964],\n",
      "        [1.0972],\n",
      "        [1.0987],\n",
      "        [1.1074],\n",
      "        [1.0967],\n",
      "        [1.0847],\n",
      "        [1.0827],\n",
      "        [1.0733],\n",
      "        [1.0984],\n",
      "        [1.0857],\n",
      "        [1.0925],\n",
      "        [1.1103]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0597],\n",
      "        [1.0495],\n",
      "        [1.0757],\n",
      "        [1.1166],\n",
      "        [1.0381],\n",
      "        [1.1151],\n",
      "        [1.0753],\n",
      "        [1.0868],\n",
      "        [1.0864],\n",
      "        [1.0832],\n",
      "        [1.1081],\n",
      "        [1.1125],\n",
      "        [1.0611],\n",
      "        [1.0950],\n",
      "        [1.0694],\n",
      "        [1.0835],\n",
      "        [1.0837],\n",
      "        [1.0978],\n",
      "        [1.1197],\n",
      "        [1.0988],\n",
      "        [1.0661],\n",
      "        [1.1056],\n",
      "        [1.1157],\n",
      "        [1.0921],\n",
      "        [1.1019],\n",
      "        [1.0511],\n",
      "        [1.0961],\n",
      "        [1.0942],\n",
      "        [1.1167],\n",
      "        [1.1166],\n",
      "        [1.1039],\n",
      "        [0.2858],\n",
      "        [1.1060],\n",
      "        [1.0513],\n",
      "        [1.1036],\n",
      "        [1.0852],\n",
      "        [1.1174],\n",
      "        [1.0758],\n",
      "        [1.1150],\n",
      "        [1.0781],\n",
      "        [1.0666],\n",
      "        [1.0519],\n",
      "        [1.1007],\n",
      "        [1.0588],\n",
      "        [1.1108],\n",
      "        [1.0986],\n",
      "        [1.0844],\n",
      "        [1.0843],\n",
      "        [1.0422],\n",
      "        [1.0980],\n",
      "        [1.0908],\n",
      "        [1.0790],\n",
      "        [1.1096],\n",
      "        [1.0940],\n",
      "        [1.1109],\n",
      "        [1.1142],\n",
      "        [1.1081],\n",
      "        [1.0952],\n",
      "        [1.0835],\n",
      "        [1.1035],\n",
      "        [1.1024],\n",
      "        [0.1867],\n",
      "        [1.1184],\n",
      "        [1.1080],\n",
      "        [1.1056],\n",
      "        [1.0687],\n",
      "        [1.0998],\n",
      "        [1.0929],\n",
      "        [1.0792],\n",
      "        [1.0873],\n",
      "        [1.0300],\n",
      "        [1.0915],\n",
      "        [1.1051],\n",
      "        [1.0774],\n",
      "        [1.1124],\n",
      "        [1.0783],\n",
      "        [1.1159],\n",
      "        [1.1204],\n",
      "        [1.0924],\n",
      "        [1.0887],\n",
      "        [1.1186],\n",
      "        [1.0666],\n",
      "        [1.0892],\n",
      "        [1.0621],\n",
      "        [1.1175],\n",
      "        [1.0835],\n",
      "        [1.1036],\n",
      "        [1.0653],\n",
      "        [1.0803],\n",
      "        [1.1034],\n",
      "        [1.0473],\n",
      "        [1.0832],\n",
      "        [1.1186],\n",
      "        [1.0967],\n",
      "        [1.0909],\n",
      "        [1.1041],\n",
      "        [1.1119],\n",
      "        [1.0804],\n",
      "        [1.0955],\n",
      "        [1.0435],\n",
      "        [1.0769],\n",
      "        [1.0793],\n",
      "        [1.0940],\n",
      "        [1.1053],\n",
      "        [1.1018],\n",
      "        [1.0827],\n",
      "        [1.1131],\n",
      "        [1.0974],\n",
      "        [1.0915],\n",
      "        [1.1018],\n",
      "        [1.0998],\n",
      "        [1.1001],\n",
      "        [1.0654],\n",
      "        [1.1056],\n",
      "        [1.1182],\n",
      "        [1.0897],\n",
      "        [1.0999],\n",
      "        [1.0330],\n",
      "        [1.1029],\n",
      "        [1.0843],\n",
      "        [1.0710],\n",
      "        [1.1082],\n",
      "        [1.1104],\n",
      "        [1.1156],\n",
      "        [1.0832],\n",
      "        [1.1035],\n",
      "        [1.0812],\n",
      "        [1.0844]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1018],\n",
      "        [1.0866],\n",
      "        [1.1167],\n",
      "        [1.0788],\n",
      "        [1.1041],\n",
      "        [1.1022],\n",
      "        [1.0977],\n",
      "        [1.0863],\n",
      "        [1.0962],\n",
      "        [1.0760],\n",
      "        [1.0792],\n",
      "        [1.1115],\n",
      "        [1.0959],\n",
      "        [1.0659],\n",
      "        [1.0815],\n",
      "        [1.0743],\n",
      "        [1.0769],\n",
      "        [1.0896],\n",
      "        [1.1082],\n",
      "        [1.0952],\n",
      "        [1.0858],\n",
      "        [1.0729],\n",
      "        [1.1114],\n",
      "        [1.1046],\n",
      "        [1.0952],\n",
      "        [1.0919],\n",
      "        [1.1082],\n",
      "        [1.1115],\n",
      "        [1.0829],\n",
      "        [1.0871],\n",
      "        [1.1059],\n",
      "        [1.0649],\n",
      "        [1.0671],\n",
      "        [1.0635],\n",
      "        [1.0926],\n",
      "        [1.0764],\n",
      "        [1.1156],\n",
      "        [1.0084],\n",
      "        [1.0968],\n",
      "        [1.0945],\n",
      "        [1.1074],\n",
      "        [1.0968],\n",
      "        [1.0910],\n",
      "        [1.1064],\n",
      "        [1.0929],\n",
      "        [1.0780],\n",
      "        [1.0899],\n",
      "        [1.0966],\n",
      "        [1.0946],\n",
      "        [1.0572],\n",
      "        [1.1098],\n",
      "        [1.1003],\n",
      "        [1.0964],\n",
      "        [1.0898],\n",
      "        [1.1073],\n",
      "        [1.0818],\n",
      "        [1.1066],\n",
      "        [1.1025],\n",
      "        [1.0767],\n",
      "        [1.0658],\n",
      "        [1.0964],\n",
      "        [1.0932],\n",
      "        [1.1072],\n",
      "        [1.0850],\n",
      "        [1.0886],\n",
      "        [1.1137],\n",
      "        [1.0709],\n",
      "        [1.1035],\n",
      "        [1.1008],\n",
      "        [1.0961],\n",
      "        [1.0573],\n",
      "        [1.1028],\n",
      "        [1.1033],\n",
      "        [1.0979],\n",
      "        [1.1038],\n",
      "        [1.1030],\n",
      "        [1.0370],\n",
      "        [1.0695],\n",
      "        [1.1073],\n",
      "        [1.0777],\n",
      "        [1.0785],\n",
      "        [1.1046],\n",
      "        [1.1170],\n",
      "        [1.0636],\n",
      "        [1.0970],\n",
      "        [1.0575],\n",
      "        [1.1021],\n",
      "        [1.1033],\n",
      "        [1.0458],\n",
      "        [1.0900],\n",
      "        [1.0891],\n",
      "        [1.0668],\n",
      "        [1.1036],\n",
      "        [1.1164],\n",
      "        [1.0957],\n",
      "        [1.0905],\n",
      "        [1.0407],\n",
      "        [1.1003],\n",
      "        [1.1058],\n",
      "        [1.0798],\n",
      "        [1.0564],\n",
      "        [1.1097],\n",
      "        [1.1105],\n",
      "        [1.0936],\n",
      "        [1.0772],\n",
      "        [1.1018],\n",
      "        [1.0623],\n",
      "        [1.0643],\n",
      "        [1.1080],\n",
      "        [1.1018],\n",
      "        [1.0544],\n",
      "        [1.0582],\n",
      "        [1.0796],\n",
      "        [1.0411],\n",
      "        [1.0786],\n",
      "        [1.1186],\n",
      "        [1.1140],\n",
      "        [1.0618],\n",
      "        [1.0805],\n",
      "        [1.1173],\n",
      "        [1.0689],\n",
      "        [1.1001],\n",
      "        [1.0773],\n",
      "        [1.1099],\n",
      "        [1.0679],\n",
      "        [1.0835],\n",
      "        [1.0411],\n",
      "        [1.1076]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1132],\n",
      "        [1.0840],\n",
      "        [1.0703],\n",
      "        [1.1184],\n",
      "        [1.0665],\n",
      "        [0.3085],\n",
      "        [1.0815],\n",
      "        [1.1183],\n",
      "        [1.0692],\n",
      "        [1.1075],\n",
      "        [1.1062],\n",
      "        [1.1148],\n",
      "        [1.1098],\n",
      "        [1.1195],\n",
      "        [1.0856],\n",
      "        [1.0427],\n",
      "        [1.0698],\n",
      "        [1.0790],\n",
      "        [1.0768],\n",
      "        [1.0983],\n",
      "        [1.1182],\n",
      "        [1.1004],\n",
      "        [1.1177],\n",
      "        [1.0611],\n",
      "        [1.0684],\n",
      "        [1.0786],\n",
      "        [1.0847],\n",
      "        [1.1185],\n",
      "        [1.0984],\n",
      "        [1.1060],\n",
      "        [1.0926],\n",
      "        [1.0898],\n",
      "        [1.0789],\n",
      "        [1.0766],\n",
      "        [1.1134],\n",
      "        [1.1210],\n",
      "        [1.0517],\n",
      "        [1.0729],\n",
      "        [1.0706],\n",
      "        [1.0860],\n",
      "        [1.0716],\n",
      "        [1.1092],\n",
      "        [1.0919],\n",
      "        [1.1074],\n",
      "        [1.0902],\n",
      "        [1.0825],\n",
      "        [1.1167],\n",
      "        [1.1000],\n",
      "        [1.0745],\n",
      "        [1.0350],\n",
      "        [1.0285],\n",
      "        [1.1045],\n",
      "        [1.0757],\n",
      "        [1.0917],\n",
      "        [1.1093],\n",
      "        [1.1171],\n",
      "        [1.0703],\n",
      "        [1.0895],\n",
      "        [1.0703],\n",
      "        [1.0675],\n",
      "        [1.0686],\n",
      "        [1.0892],\n",
      "        [1.0627],\n",
      "        [1.1014],\n",
      "        [1.1180],\n",
      "        [1.0721],\n",
      "        [1.0900],\n",
      "        [1.0921],\n",
      "        [1.0972],\n",
      "        [1.1017],\n",
      "        [1.0724],\n",
      "        [1.0630],\n",
      "        [1.0915],\n",
      "        [1.1026],\n",
      "        [1.0912],\n",
      "        [1.0896],\n",
      "        [1.0506],\n",
      "        [1.1036],\n",
      "        [1.1073],\n",
      "        [1.0636],\n",
      "        [1.0760],\n",
      "        [1.1036],\n",
      "        [1.1130],\n",
      "        [1.0889],\n",
      "        [1.1015],\n",
      "        [1.0962],\n",
      "        [1.1026],\n",
      "        [1.0682],\n",
      "        [1.0827],\n",
      "        [1.0610],\n",
      "        [1.1091],\n",
      "        [1.0798],\n",
      "        [1.0689],\n",
      "        [1.0448],\n",
      "        [1.0901],\n",
      "        [1.0875],\n",
      "        [1.0302],\n",
      "        [1.1121],\n",
      "        [1.1186],\n",
      "        [1.0697],\n",
      "        [1.1084],\n",
      "        [1.0980],\n",
      "        [1.0862],\n",
      "        [1.1107],\n",
      "        [1.0758],\n",
      "        [1.0766],\n",
      "        [1.0747],\n",
      "        [1.0886],\n",
      "        [1.1042],\n",
      "        [1.0912],\n",
      "        [1.1049],\n",
      "        [1.0868],\n",
      "        [1.0960],\n",
      "        [1.1003],\n",
      "        [1.0885],\n",
      "        [1.0956],\n",
      "        [1.0857],\n",
      "        [1.0687],\n",
      "        [1.1005],\n",
      "        [1.0725],\n",
      "        [1.1139],\n",
      "        [1.0930],\n",
      "        [1.0662],\n",
      "        [1.1128],\n",
      "        [1.0926],\n",
      "        [1.0899],\n",
      "        [1.0984],\n",
      "        [1.1025]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1044],\n",
      "        [1.0917],\n",
      "        [1.0520],\n",
      "        [1.0313],\n",
      "        [1.0936],\n",
      "        [1.1147],\n",
      "        [1.0938],\n",
      "        [1.0770],\n",
      "        [1.0887],\n",
      "        [1.0519],\n",
      "        [1.0864],\n",
      "        [1.1122],\n",
      "        [1.0781],\n",
      "        [1.0745],\n",
      "        [1.1031],\n",
      "        [1.0704],\n",
      "        [1.1080],\n",
      "        [1.0106],\n",
      "        [1.0931],\n",
      "        [1.0921],\n",
      "        [1.0506],\n",
      "        [1.0660],\n",
      "        [1.1009],\n",
      "        [1.0894],\n",
      "        [1.1184],\n",
      "        [1.0540],\n",
      "        [1.0345],\n",
      "        [1.0890],\n",
      "        [1.0908],\n",
      "        [1.1179],\n",
      "        [1.0836],\n",
      "        [1.1184],\n",
      "        [1.1129],\n",
      "        [1.0951],\n",
      "        [1.0779],\n",
      "        [1.0758],\n",
      "        [1.0896],\n",
      "        [1.0956],\n",
      "        [1.0368],\n",
      "        [1.1036],\n",
      "        [1.0990],\n",
      "        [1.0791],\n",
      "        [1.0563],\n",
      "        [1.0519],\n",
      "        [1.0797],\n",
      "        [1.1027],\n",
      "        [1.0683],\n",
      "        [1.0898],\n",
      "        [1.1020],\n",
      "        [1.0912],\n",
      "        [1.1047],\n",
      "        [1.1013],\n",
      "        [1.0954],\n",
      "        [1.0967],\n",
      "        [1.0548],\n",
      "        [1.1243],\n",
      "        [1.0898],\n",
      "        [1.1171],\n",
      "        [1.1072],\n",
      "        [1.0786],\n",
      "        [1.0704],\n",
      "        [1.0933],\n",
      "        [1.0975],\n",
      "        [1.0760],\n",
      "        [1.0819],\n",
      "        [1.0734],\n",
      "        [1.0856],\n",
      "        [1.0971],\n",
      "        [1.0485],\n",
      "        [1.0326],\n",
      "        [1.1113],\n",
      "        [1.0940],\n",
      "        [1.0622],\n",
      "        [1.0521],\n",
      "        [1.1089],\n",
      "        [1.1125],\n",
      "        [1.1186],\n",
      "        [1.1038],\n",
      "        [1.0971],\n",
      "        [1.0935],\n",
      "        [1.0966],\n",
      "        [1.0826],\n",
      "        [1.0780],\n",
      "        [1.1047],\n",
      "        [1.0958],\n",
      "        [1.0665],\n",
      "        [1.1070],\n",
      "        [1.1166],\n",
      "        [1.1114],\n",
      "        [1.1116],\n",
      "        [1.0926],\n",
      "        [1.0965],\n",
      "        [1.0819],\n",
      "        [1.1178],\n",
      "        [1.1162],\n",
      "        [1.0865],\n",
      "        [1.0663],\n",
      "        [1.1179],\n",
      "        [1.0991],\n",
      "        [1.0596],\n",
      "        [1.1048],\n",
      "        [1.0824],\n",
      "        [1.1048],\n",
      "        [1.0706],\n",
      "        [1.0953],\n",
      "        [1.1060],\n",
      "        [1.0654],\n",
      "        [1.1192],\n",
      "        [1.0677],\n",
      "        [1.0679],\n",
      "        [1.0797],\n",
      "        [1.0826],\n",
      "        [1.0726],\n",
      "        [1.1047],\n",
      "        [1.0812],\n",
      "        [1.1102],\n",
      "        [1.0693],\n",
      "        [1.0709],\n",
      "        [1.0912],\n",
      "        [1.0771],\n",
      "        [1.0350],\n",
      "        [1.1190],\n",
      "        [1.0928],\n",
      "        [1.0725],\n",
      "        [1.0863],\n",
      "        [1.0948],\n",
      "        [1.0906],\n",
      "        [1.0955]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0888],\n",
      "        [1.1138],\n",
      "        [1.1139],\n",
      "        [1.0400],\n",
      "        [1.1161],\n",
      "        [1.0706],\n",
      "        [1.1119],\n",
      "        [1.0985],\n",
      "        [1.0910],\n",
      "        [1.1067],\n",
      "        [1.0668],\n",
      "        [1.0915],\n",
      "        [1.0685],\n",
      "        [1.1071],\n",
      "        [1.0936],\n",
      "        [1.1086],\n",
      "        [1.0823],\n",
      "        [1.1173],\n",
      "        [1.0632],\n",
      "        [1.0453],\n",
      "        [1.0885],\n",
      "        [0.1130],\n",
      "        [1.0802],\n",
      "        [1.0473],\n",
      "        [1.0938],\n",
      "        [1.1083],\n",
      "        [0.9873],\n",
      "        [1.0861],\n",
      "        [1.0866],\n",
      "        [1.1146],\n",
      "        [1.0853],\n",
      "        [1.0646],\n",
      "        [1.0732],\n",
      "        [1.0970],\n",
      "        [1.0871],\n",
      "        [1.0839],\n",
      "        [1.1032],\n",
      "        [1.0709],\n",
      "        [1.1082],\n",
      "        [1.0731],\n",
      "        [1.1183],\n",
      "        [1.1074],\n",
      "        [1.0968],\n",
      "        [1.0919],\n",
      "        [1.0853],\n",
      "        [1.1098],\n",
      "        [1.1146],\n",
      "        [1.0980],\n",
      "        [1.0888],\n",
      "        [1.1178],\n",
      "        [1.0555],\n",
      "        [1.0733],\n",
      "        [1.1082],\n",
      "        [1.1085],\n",
      "        [1.0907],\n",
      "        [1.1024],\n",
      "        [1.0776],\n",
      "        [1.1109],\n",
      "        [1.1061],\n",
      "        [1.0618],\n",
      "        [1.0735],\n",
      "        [1.0826],\n",
      "        [1.1034],\n",
      "        [1.1007],\n",
      "        [1.0919],\n",
      "        [1.0978],\n",
      "        [1.0900],\n",
      "        [1.0910],\n",
      "        [1.0715],\n",
      "        [1.0986],\n",
      "        [1.0805],\n",
      "        [1.0478],\n",
      "        [1.0840],\n",
      "        [1.0928],\n",
      "        [1.0910],\n",
      "        [1.1119],\n",
      "        [1.1047],\n",
      "        [1.0994],\n",
      "        [1.0691],\n",
      "        [1.0738],\n",
      "        [0.2194],\n",
      "        [1.0941],\n",
      "        [1.0972],\n",
      "        [1.0956],\n",
      "        [1.0443],\n",
      "        [1.1137],\n",
      "        [1.0724],\n",
      "        [1.1031],\n",
      "        [1.1093],\n",
      "        [1.1170],\n",
      "        [1.0954],\n",
      "        [1.0933],\n",
      "        [1.0759],\n",
      "        [1.0962],\n",
      "        [1.1136],\n",
      "        [1.1173],\n",
      "        [1.0802],\n",
      "        [1.0844],\n",
      "        [1.0283],\n",
      "        [1.0948],\n",
      "        [1.1130],\n",
      "        [1.0606],\n",
      "        [1.0802],\n",
      "        [1.0938],\n",
      "        [1.0923],\n",
      "        [1.0869],\n",
      "        [1.1000],\n",
      "        [1.0979],\n",
      "        [1.0964],\n",
      "        [1.1183],\n",
      "        [1.0772],\n",
      "        [1.0651],\n",
      "        [1.0835],\n",
      "        [1.0526],\n",
      "        [1.0977],\n",
      "        [1.0409],\n",
      "        [1.1114],\n",
      "        [1.0933],\n",
      "        [1.1072],\n",
      "        [1.1161],\n",
      "        [1.1216],\n",
      "        [1.1093],\n",
      "        [1.0851],\n",
      "        [1.1057],\n",
      "        [1.0886],\n",
      "        [1.0564],\n",
      "        [1.0959],\n",
      "        [1.1153]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1128],\n",
      "        [1.1070],\n",
      "        [1.0649],\n",
      "        [1.0791]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  43 | lr 0.00010 train_loss 2.13395 | val_loss 2.29268 | val_rmse 1.51416\n",
      "tensor([[1.0843],\n",
      "        [1.1187],\n",
      "        [1.1129],\n",
      "        [1.1007],\n",
      "        [1.1160],\n",
      "        [1.1083],\n",
      "        [1.0668],\n",
      "        [1.0834],\n",
      "        [1.0918],\n",
      "        [1.0719],\n",
      "        [1.0504],\n",
      "        [1.0595],\n",
      "        [1.0645],\n",
      "        [1.0992],\n",
      "        [1.0812],\n",
      "        [1.0807],\n",
      "        [1.0770],\n",
      "        [1.1052],\n",
      "        [1.0340],\n",
      "        [1.0883],\n",
      "        [1.0674],\n",
      "        [1.0773],\n",
      "        [1.0836],\n",
      "        [1.0697],\n",
      "        [1.0949],\n",
      "        [1.0771],\n",
      "        [1.1049],\n",
      "        [1.1040],\n",
      "        [1.0418],\n",
      "        [1.0922],\n",
      "        [1.0735],\n",
      "        [1.0890],\n",
      "        [1.1040],\n",
      "        [1.0819],\n",
      "        [1.0972],\n",
      "        [1.0677],\n",
      "        [1.0861],\n",
      "        [1.0410],\n",
      "        [1.0976],\n",
      "        [1.0964],\n",
      "        [1.0821],\n",
      "        [1.0939],\n",
      "        [1.1148],\n",
      "        [1.1150],\n",
      "        [1.0955],\n",
      "        [1.0607],\n",
      "        [1.0416],\n",
      "        [1.0935],\n",
      "        [1.0946],\n",
      "        [1.0822],\n",
      "        [1.0712],\n",
      "        [1.0790],\n",
      "        [1.0959],\n",
      "        [1.0979],\n",
      "        [1.0652],\n",
      "        [1.0918],\n",
      "        [1.0927],\n",
      "        [1.1039],\n",
      "        [1.1112],\n",
      "        [1.0803],\n",
      "        [1.0893],\n",
      "        [1.0830],\n",
      "        [1.0863],\n",
      "        [1.1192],\n",
      "        [1.1151],\n",
      "        [1.1138],\n",
      "        [1.0439],\n",
      "        [1.0832],\n",
      "        [1.0999],\n",
      "        [1.0755],\n",
      "        [1.1183],\n",
      "        [1.1061],\n",
      "        [1.0987],\n",
      "        [1.0994],\n",
      "        [1.0867],\n",
      "        [1.1188],\n",
      "        [1.0609],\n",
      "        [1.1094],\n",
      "        [1.0967],\n",
      "        [1.0948],\n",
      "        [1.0946],\n",
      "        [1.0727],\n",
      "        [1.0921],\n",
      "        [1.1205],\n",
      "        [1.0647],\n",
      "        [1.0734],\n",
      "        [1.0578],\n",
      "        [1.1093],\n",
      "        [1.1146],\n",
      "        [1.1228],\n",
      "        [1.1140],\n",
      "        [1.0580],\n",
      "        [1.0297],\n",
      "        [1.0739],\n",
      "        [1.0912],\n",
      "        [1.1050],\n",
      "        [1.0833],\n",
      "        [1.1034],\n",
      "        [1.0643],\n",
      "        [1.1086],\n",
      "        [1.1046],\n",
      "        [1.0766],\n",
      "        [1.0827],\n",
      "        [1.0987],\n",
      "        [1.0787],\n",
      "        [1.0872],\n",
      "        [1.0612],\n",
      "        [1.1191],\n",
      "        [1.1043],\n",
      "        [1.0179],\n",
      "        [1.0964],\n",
      "        [1.0807],\n",
      "        [1.1015],\n",
      "        [1.1021],\n",
      "        [1.0386],\n",
      "        [1.1037],\n",
      "        [1.1006],\n",
      "        [1.0564],\n",
      "        [1.0955],\n",
      "        [1.0711],\n",
      "        [1.1078],\n",
      "        [1.0590],\n",
      "        [1.0962],\n",
      "        [1.0794],\n",
      "        [1.1042],\n",
      "        [1.0822],\n",
      "        [1.1020],\n",
      "        [1.0973]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0798],\n",
      "        [1.1042],\n",
      "        [1.0517],\n",
      "        [1.0802],\n",
      "        [1.1029],\n",
      "        [1.0856],\n",
      "        [1.1009],\n",
      "        [1.0405],\n",
      "        [1.0984],\n",
      "        [1.1002],\n",
      "        [1.1022],\n",
      "        [1.0678],\n",
      "        [1.1010],\n",
      "        [1.0579],\n",
      "        [1.1095],\n",
      "        [1.0858],\n",
      "        [1.0669],\n",
      "        [1.0845],\n",
      "        [1.0524],\n",
      "        [1.1090],\n",
      "        [1.0525],\n",
      "        [1.0911],\n",
      "        [1.1032],\n",
      "        [1.0834],\n",
      "        [1.0949],\n",
      "        [1.1082],\n",
      "        [1.0737],\n",
      "        [1.1166],\n",
      "        [1.0868],\n",
      "        [1.1136],\n",
      "        [1.1143],\n",
      "        [1.0689],\n",
      "        [1.0774],\n",
      "        [1.0940],\n",
      "        [1.1056],\n",
      "        [1.0756],\n",
      "        [1.0881],\n",
      "        [1.0828],\n",
      "        [1.1017],\n",
      "        [1.1193],\n",
      "        [1.1173],\n",
      "        [1.0694],\n",
      "        [1.0565],\n",
      "        [1.1123],\n",
      "        [1.0746],\n",
      "        [1.0925],\n",
      "        [1.0910],\n",
      "        [1.1131],\n",
      "        [1.0929],\n",
      "        [1.0983],\n",
      "        [1.0474],\n",
      "        [1.0964],\n",
      "        [1.1041],\n",
      "        [1.0783],\n",
      "        [1.1063],\n",
      "        [1.1160],\n",
      "        [1.0688],\n",
      "        [1.0822],\n",
      "        [1.0961],\n",
      "        [1.1091],\n",
      "        [1.0730],\n",
      "        [1.1083],\n",
      "        [1.1144],\n",
      "        [1.0737],\n",
      "        [1.1178],\n",
      "        [1.0995],\n",
      "        [1.1190],\n",
      "        [1.0921],\n",
      "        [1.1190],\n",
      "        [1.0981],\n",
      "        [1.0924],\n",
      "        [1.0589],\n",
      "        [1.0886],\n",
      "        [1.0870],\n",
      "        [1.1054],\n",
      "        [1.1065],\n",
      "        [1.1030],\n",
      "        [1.0624],\n",
      "        [1.0814],\n",
      "        [1.1061],\n",
      "        [1.0482],\n",
      "        [1.0430],\n",
      "        [1.0717],\n",
      "        [1.0888],\n",
      "        [1.0519],\n",
      "        [1.0955],\n",
      "        [1.0914],\n",
      "        [1.0847],\n",
      "        [1.0763],\n",
      "        [1.0902],\n",
      "        [0.5884],\n",
      "        [1.0583],\n",
      "        [1.0885],\n",
      "        [1.0928],\n",
      "        [1.1141],\n",
      "        [1.0630],\n",
      "        [1.0786],\n",
      "        [1.0605],\n",
      "        [1.1119],\n",
      "        [1.0758],\n",
      "        [1.0371],\n",
      "        [1.1132],\n",
      "        [1.0810],\n",
      "        [1.0948],\n",
      "        [1.1095],\n",
      "        [1.1054],\n",
      "        [1.0826],\n",
      "        [1.1051],\n",
      "        [1.1088],\n",
      "        [1.1069],\n",
      "        [1.0995],\n",
      "        [1.0984],\n",
      "        [1.0855],\n",
      "        [1.0750],\n",
      "        [1.0897],\n",
      "        [1.0968],\n",
      "        [1.1049],\n",
      "        [1.0828],\n",
      "        [1.1097],\n",
      "        [1.1182],\n",
      "        [1.1098],\n",
      "        [1.1026],\n",
      "        [1.1159],\n",
      "        [1.1010],\n",
      "        [1.0778],\n",
      "        [1.0790],\n",
      "        [1.1096],\n",
      "        [1.1193]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1004],\n",
      "        [1.0796],\n",
      "        [1.0278],\n",
      "        [1.0969],\n",
      "        [1.0870],\n",
      "        [1.1011],\n",
      "        [1.1159],\n",
      "        [1.0990],\n",
      "        [1.1154],\n",
      "        [1.0772],\n",
      "        [1.0845],\n",
      "        [1.1041],\n",
      "        [1.0846],\n",
      "        [1.1043],\n",
      "        [1.0932],\n",
      "        [1.0881],\n",
      "        [1.0770],\n",
      "        [1.1056],\n",
      "        [1.0663],\n",
      "        [1.0760],\n",
      "        [1.0663],\n",
      "        [1.1055],\n",
      "        [1.0628],\n",
      "        [1.0897],\n",
      "        [1.0940],\n",
      "        [1.1209],\n",
      "        [1.0661],\n",
      "        [1.0792],\n",
      "        [1.0812],\n",
      "        [1.0916],\n",
      "        [1.0892],\n",
      "        [1.0844],\n",
      "        [1.0444],\n",
      "        [1.1179],\n",
      "        [1.0919],\n",
      "        [1.0345],\n",
      "        [1.0893],\n",
      "        [1.0990],\n",
      "        [1.0951],\n",
      "        [1.0335],\n",
      "        [1.0698],\n",
      "        [1.0783],\n",
      "        [1.1011],\n",
      "        [1.1157],\n",
      "        [1.0884],\n",
      "        [1.0749],\n",
      "        [1.0951],\n",
      "        [1.1083],\n",
      "        [1.1191],\n",
      "        [1.0061],\n",
      "        [1.1186],\n",
      "        [1.1049],\n",
      "        [1.0615],\n",
      "        [1.0995],\n",
      "        [1.1184],\n",
      "        [1.1162],\n",
      "        [1.0765],\n",
      "        [1.0825],\n",
      "        [1.0942],\n",
      "        [1.0934],\n",
      "        [1.0781],\n",
      "        [1.0936],\n",
      "        [1.1080],\n",
      "        [1.1128],\n",
      "        [1.0884],\n",
      "        [1.1038],\n",
      "        [1.0979],\n",
      "        [1.1171],\n",
      "        [1.0766],\n",
      "        [1.1003],\n",
      "        [1.1176],\n",
      "        [1.0800],\n",
      "        [1.1002],\n",
      "        [1.0972],\n",
      "        [1.0622],\n",
      "        [1.0609],\n",
      "        [1.1016],\n",
      "        [1.0794],\n",
      "        [1.0742],\n",
      "        [1.0830],\n",
      "        [1.1058],\n",
      "        [1.0691],\n",
      "        [1.0832],\n",
      "        [1.1203],\n",
      "        [1.1068],\n",
      "        [1.1062],\n",
      "        [1.1142],\n",
      "        [1.0602],\n",
      "        [1.0873],\n",
      "        [1.0588],\n",
      "        [1.0939],\n",
      "        [1.1007],\n",
      "        [0.7217],\n",
      "        [1.1160],\n",
      "        [1.0640],\n",
      "        [1.0926],\n",
      "        [1.1133],\n",
      "        [1.1006],\n",
      "        [1.0640],\n",
      "        [1.1176],\n",
      "        [1.0861],\n",
      "        [1.1120],\n",
      "        [1.1065],\n",
      "        [1.1119],\n",
      "        [1.1026],\n",
      "        [1.0558],\n",
      "        [1.1148],\n",
      "        [1.0911],\n",
      "        [1.0990],\n",
      "        [1.0826],\n",
      "        [1.0582],\n",
      "        [1.0731],\n",
      "        [1.0822],\n",
      "        [1.1128],\n",
      "        [1.1041],\n",
      "        [1.0657],\n",
      "        [1.0938],\n",
      "        [1.0817],\n",
      "        [1.1113],\n",
      "        [1.0908],\n",
      "        [1.1015],\n",
      "        [1.0925],\n",
      "        [1.0998],\n",
      "        [1.0755],\n",
      "        [1.0704],\n",
      "        [1.1099],\n",
      "        [1.0799],\n",
      "        [1.0893]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0966],\n",
      "        [1.0741],\n",
      "        [1.0819],\n",
      "        [1.0893],\n",
      "        [1.0792],\n",
      "        [1.0787],\n",
      "        [1.0435],\n",
      "        [1.0969],\n",
      "        [1.1105],\n",
      "        [1.0128],\n",
      "        [1.1130],\n",
      "        [1.0628],\n",
      "        [1.1169],\n",
      "        [1.1153],\n",
      "        [1.0695],\n",
      "        [1.0931],\n",
      "        [1.0611],\n",
      "        [1.0927],\n",
      "        [1.0220],\n",
      "        [1.1078],\n",
      "        [1.1107],\n",
      "        [1.0367],\n",
      "        [1.0961],\n",
      "        [1.0789],\n",
      "        [1.0606],\n",
      "        [1.0817],\n",
      "        [1.1205],\n",
      "        [1.0863],\n",
      "        [1.1183],\n",
      "        [1.1022],\n",
      "        [1.1083],\n",
      "        [1.0745],\n",
      "        [1.1180],\n",
      "        [1.0906],\n",
      "        [1.0981],\n",
      "        [1.0825],\n",
      "        [1.1029],\n",
      "        [1.1099],\n",
      "        [1.0717],\n",
      "        [1.0716],\n",
      "        [1.0932],\n",
      "        [1.0710],\n",
      "        [1.0907],\n",
      "        [1.0905],\n",
      "        [1.0993],\n",
      "        [1.0825],\n",
      "        [1.1106],\n",
      "        [1.0677],\n",
      "        [1.0441],\n",
      "        [1.1055],\n",
      "        [1.0488],\n",
      "        [1.0711],\n",
      "        [1.0892],\n",
      "        [1.0943],\n",
      "        [1.0630],\n",
      "        [1.0978],\n",
      "        [1.1085],\n",
      "        [1.0658],\n",
      "        [1.1138],\n",
      "        [1.1039],\n",
      "        [1.0655],\n",
      "        [1.0732],\n",
      "        [1.0803],\n",
      "        [1.1193],\n",
      "        [1.0926],\n",
      "        [1.0926],\n",
      "        [1.0786],\n",
      "        [1.0934],\n",
      "        [1.1065],\n",
      "        [1.0969],\n",
      "        [1.0541],\n",
      "        [1.0558],\n",
      "        [1.1074],\n",
      "        [1.0753],\n",
      "        [1.0637],\n",
      "        [1.0287],\n",
      "        [1.0775],\n",
      "        [1.0761],\n",
      "        [1.0962],\n",
      "        [1.1013],\n",
      "        [1.0840],\n",
      "        [1.1020],\n",
      "        [1.0254],\n",
      "        [1.0987],\n",
      "        [1.0934],\n",
      "        [1.0594],\n",
      "        [1.1003],\n",
      "        [1.1074],\n",
      "        [1.1186],\n",
      "        [1.1144],\n",
      "        [1.0910],\n",
      "        [1.0375],\n",
      "        [1.1151],\n",
      "        [1.1011],\n",
      "        [1.1118],\n",
      "        [1.0616],\n",
      "        [1.0858],\n",
      "        [1.0834],\n",
      "        [1.1041],\n",
      "        [1.1158],\n",
      "        [1.0592],\n",
      "        [1.1129],\n",
      "        [1.1069],\n",
      "        [1.1032],\n",
      "        [1.0629],\n",
      "        [1.0979],\n",
      "        [1.0906],\n",
      "        [1.0823],\n",
      "        [1.0960],\n",
      "        [1.0668],\n",
      "        [1.0803],\n",
      "        [1.0616],\n",
      "        [1.0824],\n",
      "        [1.0945],\n",
      "        [1.0688],\n",
      "        [1.1002],\n",
      "        [1.0781],\n",
      "        [1.0657],\n",
      "        [1.1194],\n",
      "        [1.0589],\n",
      "        [1.1048],\n",
      "        [1.1045],\n",
      "        [1.1176],\n",
      "        [1.0938],\n",
      "        [1.0993],\n",
      "        [1.1070],\n",
      "        [1.0448],\n",
      "        [1.0940]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0941],\n",
      "        [1.0167],\n",
      "        [1.0955],\n",
      "        [1.1043],\n",
      "        [1.0643],\n",
      "        [1.1020],\n",
      "        [1.0712],\n",
      "        [1.0933],\n",
      "        [1.0941],\n",
      "        [1.1152],\n",
      "        [1.0831],\n",
      "        [1.1099],\n",
      "        [1.0784],\n",
      "        [1.0537],\n",
      "        [1.1209],\n",
      "        [1.0625],\n",
      "        [1.0785],\n",
      "        [1.1110],\n",
      "        [1.0694],\n",
      "        [1.0952],\n",
      "        [1.0841],\n",
      "        [1.1036],\n",
      "        [1.0963],\n",
      "        [1.0877],\n",
      "        [1.0953],\n",
      "        [1.1017],\n",
      "        [1.0819],\n",
      "        [1.0788],\n",
      "        [1.1206],\n",
      "        [1.0916],\n",
      "        [1.1154],\n",
      "        [1.0908],\n",
      "        [1.0826],\n",
      "        [1.0781],\n",
      "        [1.1054],\n",
      "        [1.1015],\n",
      "        [1.0880],\n",
      "        [1.0991],\n",
      "        [1.0895],\n",
      "        [1.0682],\n",
      "        [1.0930],\n",
      "        [1.0821],\n",
      "        [1.1071],\n",
      "        [1.0130],\n",
      "        [1.0821],\n",
      "        [1.1006],\n",
      "        [1.0878],\n",
      "        [1.1180],\n",
      "        [1.0943],\n",
      "        [1.0956],\n",
      "        [1.0953],\n",
      "        [1.0947],\n",
      "        [1.0161],\n",
      "        [1.0927],\n",
      "        [1.1081],\n",
      "        [1.1008],\n",
      "        [1.0846],\n",
      "        [1.0899],\n",
      "        [1.0323],\n",
      "        [1.0610],\n",
      "        [1.1083],\n",
      "        [1.1067],\n",
      "        [1.1164],\n",
      "        [1.0671],\n",
      "        [1.0985],\n",
      "        [1.0998],\n",
      "        [1.0666],\n",
      "        [1.1029],\n",
      "        [1.0869],\n",
      "        [1.1029],\n",
      "        [1.0771],\n",
      "        [1.0972],\n",
      "        [1.0490],\n",
      "        [1.1133],\n",
      "        [1.0748],\n",
      "        [1.1173],\n",
      "        [1.1073],\n",
      "        [1.1217],\n",
      "        [1.0290],\n",
      "        [1.1185],\n",
      "        [1.0896],\n",
      "        [1.1043],\n",
      "        [1.1204],\n",
      "        [1.1199],\n",
      "        [1.0928],\n",
      "        [1.0846],\n",
      "        [1.0123],\n",
      "        [1.1067],\n",
      "        [1.0998],\n",
      "        [1.0703],\n",
      "        [1.0992],\n",
      "        [1.0624],\n",
      "        [1.0465],\n",
      "        [1.0037],\n",
      "        [1.1052],\n",
      "        [1.0872],\n",
      "        [1.0874],\n",
      "        [1.0825],\n",
      "        [1.1173],\n",
      "        [1.1041],\n",
      "        [1.1081],\n",
      "        [1.0594],\n",
      "        [1.1198],\n",
      "        [1.1091],\n",
      "        [1.0753],\n",
      "        [1.1013],\n",
      "        [1.0932],\n",
      "        [1.0105],\n",
      "        [1.1102],\n",
      "        [1.0885],\n",
      "        [1.1061],\n",
      "        [1.0667],\n",
      "        [1.1204],\n",
      "        [1.0161],\n",
      "        [1.1176],\n",
      "        [1.0972],\n",
      "        [1.0538],\n",
      "        [1.0825],\n",
      "        [1.0474],\n",
      "        [1.1060],\n",
      "        [1.0494],\n",
      "        [1.0489],\n",
      "        [1.0960],\n",
      "        [1.1187],\n",
      "        [1.0585],\n",
      "        [1.1097],\n",
      "        [1.1103],\n",
      "        [1.0994]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0341],\n",
      "        [1.1016],\n",
      "        [1.0909],\n",
      "        [1.0756],\n",
      "        [1.0373],\n",
      "        [1.1070],\n",
      "        [1.1206],\n",
      "        [1.1198],\n",
      "        [1.1011],\n",
      "        [1.1063],\n",
      "        [1.1192],\n",
      "        [1.0782],\n",
      "        [1.1043],\n",
      "        [1.0945],\n",
      "        [1.0877],\n",
      "        [1.0698],\n",
      "        [1.1090],\n",
      "        [1.0774],\n",
      "        [1.0930],\n",
      "        [1.1133],\n",
      "        [1.1018],\n",
      "        [1.0951],\n",
      "        [1.1094],\n",
      "        [1.0796],\n",
      "        [1.1066],\n",
      "        [1.0899],\n",
      "        [1.1152],\n",
      "        [1.1147],\n",
      "        [1.0730],\n",
      "        [1.0501],\n",
      "        [1.1047],\n",
      "        [1.0638],\n",
      "        [1.0589],\n",
      "        [1.0507],\n",
      "        [1.1147],\n",
      "        [1.0833],\n",
      "        [1.1190],\n",
      "        [1.1077],\n",
      "        [1.1161],\n",
      "        [1.1208],\n",
      "        [1.0775],\n",
      "        [1.0990],\n",
      "        [1.1115],\n",
      "        [1.1164],\n",
      "        [1.0996],\n",
      "        [1.1185],\n",
      "        [1.0957],\n",
      "        [1.1066],\n",
      "        [1.0642],\n",
      "        [1.0848],\n",
      "        [1.0955],\n",
      "        [1.0980],\n",
      "        [1.0779],\n",
      "        [1.0721],\n",
      "        [1.1047],\n",
      "        [1.1093],\n",
      "        [1.0535],\n",
      "        [1.1070],\n",
      "        [1.0808],\n",
      "        [1.0709],\n",
      "        [1.0607],\n",
      "        [1.1013],\n",
      "        [1.0759],\n",
      "        [1.0743],\n",
      "        [1.0869],\n",
      "        [1.0587],\n",
      "        [1.1143],\n",
      "        [1.1045],\n",
      "        [1.0806],\n",
      "        [1.1062],\n",
      "        [1.1152],\n",
      "        [1.0906],\n",
      "        [1.0569],\n",
      "        [1.1232],\n",
      "        [1.0938],\n",
      "        [1.0946],\n",
      "        [1.1102],\n",
      "        [1.1036],\n",
      "        [1.1073],\n",
      "        [1.1182],\n",
      "        [1.1145],\n",
      "        [1.0980],\n",
      "        [1.0527],\n",
      "        [1.1088],\n",
      "        [1.0513],\n",
      "        [1.0983],\n",
      "        [1.0839],\n",
      "        [1.0767],\n",
      "        [1.1055],\n",
      "        [1.0916],\n",
      "        [1.1070],\n",
      "        [1.1184],\n",
      "        [1.0954],\n",
      "        [1.0845],\n",
      "        [1.1074],\n",
      "        [1.0578],\n",
      "        [1.0820],\n",
      "        [1.0606],\n",
      "        [1.0873],\n",
      "        [1.0884],\n",
      "        [1.0475],\n",
      "        [1.1011],\n",
      "        [1.0588],\n",
      "        [1.0861],\n",
      "        [1.0924],\n",
      "        [1.0673],\n",
      "        [1.1083],\n",
      "        [1.1049],\n",
      "        [1.0785],\n",
      "        [1.1139],\n",
      "        [1.1102],\n",
      "        [1.1057],\n",
      "        [1.0887],\n",
      "        [1.1003],\n",
      "        [1.0461],\n",
      "        [1.1089],\n",
      "        [1.1167],\n",
      "        [1.0702],\n",
      "        [1.0651],\n",
      "        [1.0759],\n",
      "        [1.0282],\n",
      "        [1.0643],\n",
      "        [1.0802],\n",
      "        [1.0922],\n",
      "        [1.1126],\n",
      "        [1.0896],\n",
      "        [1.0816],\n",
      "        [1.0675]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0597],\n",
      "        [1.1076],\n",
      "        [1.0595],\n",
      "        [1.0736],\n",
      "        [1.1157],\n",
      "        [1.0891],\n",
      "        [1.1034],\n",
      "        [1.0611],\n",
      "        [1.1167],\n",
      "        [1.0771],\n",
      "        [1.0702],\n",
      "        [1.1143],\n",
      "        [1.0907],\n",
      "        [1.0465],\n",
      "        [1.0681],\n",
      "        [1.0681],\n",
      "        [1.1186],\n",
      "        [1.0604],\n",
      "        [1.0840],\n",
      "        [1.1224],\n",
      "        [1.1103],\n",
      "        [1.0787],\n",
      "        [1.0883],\n",
      "        [1.0840],\n",
      "        [1.1066],\n",
      "        [1.1150],\n",
      "        [1.1188],\n",
      "        [1.0897],\n",
      "        [1.1119],\n",
      "        [1.0947],\n",
      "        [1.1164],\n",
      "        [1.1037],\n",
      "        [1.1150],\n",
      "        [1.0975],\n",
      "        [1.0658],\n",
      "        [1.1156],\n",
      "        [1.0636],\n",
      "        [1.0900],\n",
      "        [1.0932],\n",
      "        [1.1045],\n",
      "        [1.1107],\n",
      "        [1.0858],\n",
      "        [1.0564],\n",
      "        [1.0838],\n",
      "        [1.1084],\n",
      "        [1.0982],\n",
      "        [1.1141],\n",
      "        [1.0846],\n",
      "        [1.1248],\n",
      "        [1.0905],\n",
      "        [1.0956],\n",
      "        [1.1219],\n",
      "        [1.1115],\n",
      "        [1.0934],\n",
      "        [1.1062],\n",
      "        [1.0742],\n",
      "        [1.0720],\n",
      "        [1.1049],\n",
      "        [1.0753],\n",
      "        [1.1049],\n",
      "        [1.0838],\n",
      "        [1.1007],\n",
      "        [1.0977],\n",
      "        [1.0776],\n",
      "        [1.1136],\n",
      "        [1.0878],\n",
      "        [0.9879],\n",
      "        [1.0872],\n",
      "        [1.1138],\n",
      "        [1.0983],\n",
      "        [1.1078],\n",
      "        [1.0914],\n",
      "        [1.0941],\n",
      "        [1.0493],\n",
      "        [1.0460],\n",
      "        [1.1128],\n",
      "        [1.0861],\n",
      "        [1.0898],\n",
      "        [1.0875],\n",
      "        [1.0598],\n",
      "        [1.0870],\n",
      "        [1.1208],\n",
      "        [1.0940],\n",
      "        [1.1179],\n",
      "        [1.1148],\n",
      "        [1.0976],\n",
      "        [1.1032],\n",
      "        [1.1032],\n",
      "        [1.0957],\n",
      "        [1.1113],\n",
      "        [1.1163],\n",
      "        [1.0938],\n",
      "        [1.0586],\n",
      "        [1.0891],\n",
      "        [1.0878],\n",
      "        [1.1091],\n",
      "        [1.0688],\n",
      "        [1.1153],\n",
      "        [1.0901],\n",
      "        [1.1043],\n",
      "        [1.0886],\n",
      "        [1.0405],\n",
      "        [1.0843],\n",
      "        [1.0803],\n",
      "        [1.0504],\n",
      "        [1.1217],\n",
      "        [1.1039],\n",
      "        [1.0776],\n",
      "        [1.0932],\n",
      "        [1.1096],\n",
      "        [1.0922],\n",
      "        [1.0582],\n",
      "        [1.0888],\n",
      "        [1.0872],\n",
      "        [1.0641],\n",
      "        [1.1058],\n",
      "        [1.1023],\n",
      "        [1.0887],\n",
      "        [1.1069],\n",
      "        [1.1023],\n",
      "        [1.0914],\n",
      "        [1.0687],\n",
      "        [1.0753],\n",
      "        [1.0522],\n",
      "        [1.0292],\n",
      "        [1.0780],\n",
      "        [1.0982],\n",
      "        [1.0892]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0989],\n",
      "        [1.0667],\n",
      "        [1.0993],\n",
      "        [1.1200]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  44 | lr 0.00010 train_loss 2.12489 | val_loss 2.29207 | val_rmse 1.51396\n",
      "tensor([[1.0965],\n",
      "        [1.1176],\n",
      "        [1.0785],\n",
      "        [1.0753],\n",
      "        [1.0975],\n",
      "        [1.1116],\n",
      "        [1.0971],\n",
      "        [1.0985],\n",
      "        [1.1012],\n",
      "        [1.0880],\n",
      "        [1.1161],\n",
      "        [1.1102],\n",
      "        [1.1209],\n",
      "        [1.1005],\n",
      "        [1.0749],\n",
      "        [1.1181],\n",
      "        [1.0825],\n",
      "        [1.0753],\n",
      "        [1.1119],\n",
      "        [1.1130],\n",
      "        [1.0875],\n",
      "        [1.1002],\n",
      "        [1.0922],\n",
      "        [1.0978],\n",
      "        [1.0918],\n",
      "        [1.1209],\n",
      "        [1.0836],\n",
      "        [1.1126],\n",
      "        [1.0876],\n",
      "        [1.1001],\n",
      "        [1.0803],\n",
      "        [1.0942],\n",
      "        [1.0576],\n",
      "        [1.0901],\n",
      "        [1.0244],\n",
      "        [1.0715],\n",
      "        [1.0600],\n",
      "        [1.1133],\n",
      "        [1.1070],\n",
      "        [1.1115],\n",
      "        [1.1001],\n",
      "        [1.1075],\n",
      "        [1.0491],\n",
      "        [1.0848],\n",
      "        [1.1107],\n",
      "        [1.0589],\n",
      "        [1.1088],\n",
      "        [1.0999],\n",
      "        [1.0790],\n",
      "        [1.1158],\n",
      "        [1.1152],\n",
      "        [1.1053],\n",
      "        [1.0997],\n",
      "        [1.0911],\n",
      "        [1.0407],\n",
      "        [1.0794],\n",
      "        [1.0247],\n",
      "        [1.1021],\n",
      "        [1.0971],\n",
      "        [1.0920],\n",
      "        [1.1208],\n",
      "        [1.0879],\n",
      "        [1.0791],\n",
      "        [1.1209],\n",
      "        [1.1172],\n",
      "        [1.0887],\n",
      "        [1.0867],\n",
      "        [1.0622],\n",
      "        [1.1062],\n",
      "        [1.0935],\n",
      "        [1.1181],\n",
      "        [1.0987],\n",
      "        [1.0873],\n",
      "        [1.1011],\n",
      "        [1.0767],\n",
      "        [1.1145],\n",
      "        [1.1151],\n",
      "        [1.0921],\n",
      "        [1.1161],\n",
      "        [1.0626],\n",
      "        [1.0866],\n",
      "        [1.1223],\n",
      "        [1.0818],\n",
      "        [1.0786],\n",
      "        [1.1104],\n",
      "        [1.1124],\n",
      "        [1.1016],\n",
      "        [1.1001],\n",
      "        [1.0727],\n",
      "        [1.0775],\n",
      "        [1.0954],\n",
      "        [1.0844],\n",
      "        [1.1082],\n",
      "        [1.1064],\n",
      "        [1.0773],\n",
      "        [1.0651],\n",
      "        [1.1161],\n",
      "        [1.0899],\n",
      "        [1.0854],\n",
      "        [1.1069],\n",
      "        [1.0815],\n",
      "        [1.0845],\n",
      "        [1.0993],\n",
      "        [1.1071],\n",
      "        [1.1028],\n",
      "        [1.0692],\n",
      "        [1.0908],\n",
      "        [1.0896],\n",
      "        [1.1186],\n",
      "        [1.1156],\n",
      "        [1.0797],\n",
      "        [1.0684],\n",
      "        [1.0955],\n",
      "        [1.1164],\n",
      "        [1.0909],\n",
      "        [1.0691],\n",
      "        [1.0935],\n",
      "        [1.0419],\n",
      "        [1.0715],\n",
      "        [1.0599],\n",
      "        [1.0820],\n",
      "        [1.0941],\n",
      "        [1.0844],\n",
      "        [1.0983],\n",
      "        [1.0969],\n",
      "        [1.0944],\n",
      "        [1.1042],\n",
      "        [1.1072]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1021],\n",
      "        [1.0773],\n",
      "        [1.0078],\n",
      "        [1.0588],\n",
      "        [1.0980],\n",
      "        [1.0956],\n",
      "        [1.0950],\n",
      "        [1.1110],\n",
      "        [1.0878],\n",
      "        [1.0691],\n",
      "        [1.0609],\n",
      "        [1.0919],\n",
      "        [1.1175],\n",
      "        [1.1087],\n",
      "        [1.1117],\n",
      "        [1.1047],\n",
      "        [1.1138],\n",
      "        [1.1131],\n",
      "        [1.1026],\n",
      "        [1.1159],\n",
      "        [1.0475],\n",
      "        [1.0958],\n",
      "        [1.1120],\n",
      "        [1.0782],\n",
      "        [1.0658],\n",
      "        [1.1060],\n",
      "        [1.0683],\n",
      "        [1.1191],\n",
      "        [1.1018],\n",
      "        [1.1215],\n",
      "        [1.1084],\n",
      "        [1.0943],\n",
      "        [1.0990],\n",
      "        [1.0966],\n",
      "        [1.0937],\n",
      "        [1.0834],\n",
      "        [1.0869],\n",
      "        [1.0755],\n",
      "        [1.0927],\n",
      "        [1.1040],\n",
      "        [1.1052],\n",
      "        [1.1024],\n",
      "        [1.1106],\n",
      "        [1.1042],\n",
      "        [1.1105],\n",
      "        [1.0655],\n",
      "        [1.1156],\n",
      "        [1.0544],\n",
      "        [1.1125],\n",
      "        [1.0951],\n",
      "        [1.0627],\n",
      "        [1.1103],\n",
      "        [1.0492],\n",
      "        [1.1026],\n",
      "        [1.0922],\n",
      "        [1.0558],\n",
      "        [1.1152],\n",
      "        [1.0933],\n",
      "        [1.0834],\n",
      "        [1.1128],\n",
      "        [1.0982],\n",
      "        [1.1034],\n",
      "        [1.0679],\n",
      "        [1.1065],\n",
      "        [1.0377],\n",
      "        [1.1035],\n",
      "        [1.0864],\n",
      "        [1.0897],\n",
      "        [1.0906],\n",
      "        [1.0465],\n",
      "        [1.1014],\n",
      "        [1.0845],\n",
      "        [1.0988],\n",
      "        [1.0566],\n",
      "        [1.0675],\n",
      "        [1.0905],\n",
      "        [1.0979],\n",
      "        [1.0853],\n",
      "        [1.0822],\n",
      "        [1.0600],\n",
      "        [1.0770],\n",
      "        [1.0985],\n",
      "        [1.1188],\n",
      "        [1.0978],\n",
      "        [1.1146],\n",
      "        [1.1051],\n",
      "        [1.0714],\n",
      "        [1.0902],\n",
      "        [1.1100],\n",
      "        [1.0978],\n",
      "        [1.1118],\n",
      "        [1.0870],\n",
      "        [1.1000],\n",
      "        [1.0917],\n",
      "        [1.1177],\n",
      "        [1.0854],\n",
      "        [1.0536],\n",
      "        [1.0637],\n",
      "        [1.0894],\n",
      "        [1.1173],\n",
      "        [1.1139],\n",
      "        [1.0691],\n",
      "        [1.0306],\n",
      "        [1.0873],\n",
      "        [1.0928],\n",
      "        [1.1091],\n",
      "        [1.0411],\n",
      "        [1.1022],\n",
      "        [1.0991],\n",
      "        [1.0751],\n",
      "        [1.1037],\n",
      "        [1.0716],\n",
      "        [1.0768],\n",
      "        [1.0442],\n",
      "        [1.0205],\n",
      "        [1.1161],\n",
      "        [1.1026],\n",
      "        [1.1111],\n",
      "        [1.0638],\n",
      "        [1.1044],\n",
      "        [1.1003],\n",
      "        [1.0881],\n",
      "        [1.1032],\n",
      "        [1.1061],\n",
      "        [1.1044],\n",
      "        [1.1132],\n",
      "        [1.1142],\n",
      "        [1.0451]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1077],\n",
      "        [1.0910],\n",
      "        [1.0913],\n",
      "        [1.0884],\n",
      "        [1.0895],\n",
      "        [1.1061],\n",
      "        [1.0944],\n",
      "        [1.1183],\n",
      "        [1.1049],\n",
      "        [1.0699],\n",
      "        [1.1204],\n",
      "        [1.1061],\n",
      "        [1.0922],\n",
      "        [1.0832],\n",
      "        [1.0754],\n",
      "        [1.1161],\n",
      "        [1.1152],\n",
      "        [1.0667],\n",
      "        [1.0890],\n",
      "        [1.0946],\n",
      "        [1.0705],\n",
      "        [1.1049],\n",
      "        [1.1072],\n",
      "        [1.0836],\n",
      "        [1.1056],\n",
      "        [1.0977],\n",
      "        [1.1215],\n",
      "        [1.0926],\n",
      "        [1.1149],\n",
      "        [1.0624],\n",
      "        [1.0819],\n",
      "        [1.1078],\n",
      "        [1.0462],\n",
      "        [1.0660],\n",
      "        [1.1043],\n",
      "        [1.1184],\n",
      "        [1.0970],\n",
      "        [1.1010],\n",
      "        [1.1199],\n",
      "        [1.0805],\n",
      "        [1.0656],\n",
      "        [1.1181],\n",
      "        [1.0653],\n",
      "        [1.0929],\n",
      "        [1.0756],\n",
      "        [1.1148],\n",
      "        [1.0703],\n",
      "        [1.0928],\n",
      "        [1.1047],\n",
      "        [1.1202],\n",
      "        [1.0592],\n",
      "        [1.1036],\n",
      "        [1.0915],\n",
      "        [1.1008],\n",
      "        [1.1041],\n",
      "        [1.0562],\n",
      "        [1.1025],\n",
      "        [1.0905],\n",
      "        [1.0904],\n",
      "        [1.0953],\n",
      "        [1.1147],\n",
      "        [1.1097],\n",
      "        [1.0824],\n",
      "        [1.1045],\n",
      "        [1.0927],\n",
      "        [1.1005],\n",
      "        [1.0940],\n",
      "        [1.0575],\n",
      "        [1.0753],\n",
      "        [1.1096],\n",
      "        [1.0789],\n",
      "        [1.0944],\n",
      "        [1.1069],\n",
      "        [1.0721],\n",
      "        [1.0961],\n",
      "        [1.1005],\n",
      "        [1.0829],\n",
      "        [1.1235],\n",
      "        [1.1130],\n",
      "        [1.0774],\n",
      "        [1.0960],\n",
      "        [1.1056],\n",
      "        [1.1059],\n",
      "        [1.1024],\n",
      "        [1.0892],\n",
      "        [1.0821],\n",
      "        [1.0710],\n",
      "        [1.1199],\n",
      "        [1.1204],\n",
      "        [1.1011],\n",
      "        [1.0782],\n",
      "        [1.0530],\n",
      "        [1.0972],\n",
      "        [1.1074],\n",
      "        [1.1193],\n",
      "        [1.1113],\n",
      "        [1.0781],\n",
      "        [1.0745],\n",
      "        [1.0800],\n",
      "        [1.0781],\n",
      "        [1.0578],\n",
      "        [1.0804],\n",
      "        [1.0468],\n",
      "        [1.0966],\n",
      "        [1.1000],\n",
      "        [1.1202],\n",
      "        [1.0790],\n",
      "        [1.1059],\n",
      "        [0.4010],\n",
      "        [1.0822],\n",
      "        [1.1094],\n",
      "        [1.1203],\n",
      "        [1.0806],\n",
      "        [1.1137],\n",
      "        [1.0815],\n",
      "        [1.0923],\n",
      "        [1.0744],\n",
      "        [1.0998],\n",
      "        [1.0998],\n",
      "        [1.0642],\n",
      "        [1.0871],\n",
      "        [1.1013],\n",
      "        [1.0890],\n",
      "        [1.0738],\n",
      "        [1.0975],\n",
      "        [1.0977],\n",
      "        [1.0779],\n",
      "        [1.0983]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0875],\n",
      "        [1.0884],\n",
      "        [1.0707],\n",
      "        [1.1237],\n",
      "        [1.0992],\n",
      "        [1.0837],\n",
      "        [1.0877],\n",
      "        [1.1134],\n",
      "        [1.0844],\n",
      "        [1.0654],\n",
      "        [1.1075],\n",
      "        [1.0958],\n",
      "        [1.1154],\n",
      "        [1.1052],\n",
      "        [1.1070],\n",
      "        [1.0378],\n",
      "        [1.0505],\n",
      "        [1.1057],\n",
      "        [1.1059],\n",
      "        [1.0836],\n",
      "        [1.1038],\n",
      "        [1.1055],\n",
      "        [1.0861],\n",
      "        [1.1087],\n",
      "        [1.0918],\n",
      "        [1.1089],\n",
      "        [1.0611],\n",
      "        [1.0680],\n",
      "        [1.0712],\n",
      "        [1.1052],\n",
      "        [1.1210],\n",
      "        [1.0758],\n",
      "        [1.0644],\n",
      "        [1.0871],\n",
      "        [1.0765],\n",
      "        [1.0972],\n",
      "        [1.1180],\n",
      "        [1.0717],\n",
      "        [1.1197],\n",
      "        [1.0890],\n",
      "        [1.1210],\n",
      "        [1.1074],\n",
      "        [1.0965],\n",
      "        [1.1110],\n",
      "        [1.0987],\n",
      "        [1.0712],\n",
      "        [1.1209],\n",
      "        [1.1077],\n",
      "        [1.1101],\n",
      "        [1.0844],\n",
      "        [1.0530],\n",
      "        [1.1138],\n",
      "        [1.0909],\n",
      "        [1.0758],\n",
      "        [1.0779],\n",
      "        [1.1052],\n",
      "        [1.1043],\n",
      "        [1.1153],\n",
      "        [1.0707],\n",
      "        [1.1079],\n",
      "        [1.0781],\n",
      "        [1.0526],\n",
      "        [1.0521],\n",
      "        [1.1009],\n",
      "        [1.1116],\n",
      "        [1.0611],\n",
      "        [1.0971],\n",
      "        [1.0664],\n",
      "        [1.1050],\n",
      "        [1.1020],\n",
      "        [1.1006],\n",
      "        [1.1064],\n",
      "        [1.0897],\n",
      "        [1.1008],\n",
      "        [1.0889],\n",
      "        [1.0212],\n",
      "        [1.1052],\n",
      "        [1.0643],\n",
      "        [1.1089],\n",
      "        [1.1142],\n",
      "        [1.0998],\n",
      "        [1.1038],\n",
      "        [1.1131],\n",
      "        [1.1070],\n",
      "        [1.0968],\n",
      "        [1.0867],\n",
      "        [1.1015],\n",
      "        [1.1142],\n",
      "        [1.0692],\n",
      "        [1.1096],\n",
      "        [1.0507],\n",
      "        [1.0705],\n",
      "        [1.0767],\n",
      "        [1.0848],\n",
      "        [1.1064],\n",
      "        [1.0793],\n",
      "        [1.0498],\n",
      "        [1.0971],\n",
      "        [1.0630],\n",
      "        [1.0997],\n",
      "        [1.0873],\n",
      "        [1.1028],\n",
      "        [1.1207],\n",
      "        [1.1003],\n",
      "        [1.1082],\n",
      "        [1.0889],\n",
      "        [1.0458],\n",
      "        [1.0861],\n",
      "        [1.0403],\n",
      "        [1.1090],\n",
      "        [1.0252],\n",
      "        [1.0844],\n",
      "        [1.0388],\n",
      "        [1.0982],\n",
      "        [1.1017],\n",
      "        [1.0511],\n",
      "        [1.0817],\n",
      "        [1.1202],\n",
      "        [1.0834],\n",
      "        [1.0925],\n",
      "        [1.0455],\n",
      "        [1.0712],\n",
      "        [1.1001],\n",
      "        [1.1028],\n",
      "        [1.1000],\n",
      "        [1.0342],\n",
      "        [1.0700],\n",
      "        [1.0832]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1073],\n",
      "        [1.1058],\n",
      "        [1.1065],\n",
      "        [1.1158],\n",
      "        [1.0765],\n",
      "        [1.0817],\n",
      "        [1.0998],\n",
      "        [1.1154],\n",
      "        [1.0832],\n",
      "        [1.0902],\n",
      "        [1.1088],\n",
      "        [1.0793],\n",
      "        [1.1044],\n",
      "        [1.0972],\n",
      "        [1.0566],\n",
      "        [1.0966],\n",
      "        [1.0960],\n",
      "        [1.0873],\n",
      "        [1.1097],\n",
      "        [1.0791],\n",
      "        [1.0444],\n",
      "        [1.0643],\n",
      "        [1.0634],\n",
      "        [1.0367],\n",
      "        [1.0756],\n",
      "        [1.0882],\n",
      "        [1.0694],\n",
      "        [1.0853],\n",
      "        [1.0836],\n",
      "        [1.0573],\n",
      "        [1.0491],\n",
      "        [1.0807],\n",
      "        [1.1014],\n",
      "        [1.1178],\n",
      "        [1.1048],\n",
      "        [1.1131],\n",
      "        [1.0980],\n",
      "        [1.0885],\n",
      "        [1.0965],\n",
      "        [1.1160],\n",
      "        [1.0738],\n",
      "        [1.0796],\n",
      "        [1.0898],\n",
      "        [1.1012],\n",
      "        [1.0861],\n",
      "        [1.1102],\n",
      "        [1.0733],\n",
      "        [1.0365],\n",
      "        [1.1007],\n",
      "        [1.0975],\n",
      "        [1.0303],\n",
      "        [1.1013],\n",
      "        [1.1108],\n",
      "        [1.0581],\n",
      "        [1.0806],\n",
      "        [1.0689],\n",
      "        [1.0924],\n",
      "        [1.1186],\n",
      "        [1.1143],\n",
      "        [1.1031],\n",
      "        [1.0670],\n",
      "        [1.0688],\n",
      "        [1.0554],\n",
      "        [1.0574],\n",
      "        [1.0786],\n",
      "        [1.0895],\n",
      "        [1.1048],\n",
      "        [1.0790],\n",
      "        [1.0736],\n",
      "        [1.0925],\n",
      "        [1.0793],\n",
      "        [1.0831],\n",
      "        [1.0671],\n",
      "        [1.0850],\n",
      "        [1.1224],\n",
      "        [1.1061],\n",
      "        [1.0945],\n",
      "        [1.1159],\n",
      "        [1.1034],\n",
      "        [1.1017],\n",
      "        [1.0843],\n",
      "        [1.0487],\n",
      "        [0.9902],\n",
      "        [1.1065],\n",
      "        [1.0865],\n",
      "        [1.0634],\n",
      "        [1.1214],\n",
      "        [1.1098],\n",
      "        [1.0866],\n",
      "        [1.0718],\n",
      "        [1.0815],\n",
      "        [1.0945],\n",
      "        [1.1044],\n",
      "        [1.0962],\n",
      "        [1.1184],\n",
      "        [1.0902],\n",
      "        [1.0534],\n",
      "        [1.1127],\n",
      "        [1.0685],\n",
      "        [1.0944],\n",
      "        [1.0586],\n",
      "        [1.0668],\n",
      "        [1.0690],\n",
      "        [1.1101],\n",
      "        [1.1043],\n",
      "        [1.1137],\n",
      "        [1.1078],\n",
      "        [1.0971],\n",
      "        [1.0806],\n",
      "        [1.0988],\n",
      "        [1.1035],\n",
      "        [1.0980],\n",
      "        [1.1042],\n",
      "        [1.0861],\n",
      "        [1.1166],\n",
      "        [1.0846],\n",
      "        [1.1091],\n",
      "        [1.0018],\n",
      "        [1.0990],\n",
      "        [1.0829],\n",
      "        [1.0783],\n",
      "        [1.0951],\n",
      "        [1.1084],\n",
      "        [1.0805],\n",
      "        [1.0500],\n",
      "        [1.1164],\n",
      "        [1.0808],\n",
      "        [1.0678]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1233],\n",
      "        [1.0798],\n",
      "        [1.0758],\n",
      "        [1.0921],\n",
      "        [1.0462],\n",
      "        [1.0567],\n",
      "        [1.0920],\n",
      "        [1.0709],\n",
      "        [1.0751],\n",
      "        [1.0881],\n",
      "        [1.1025],\n",
      "        [1.1017],\n",
      "        [1.0957],\n",
      "        [1.1174],\n",
      "        [1.1147],\n",
      "        [1.1150],\n",
      "        [1.1050],\n",
      "        [1.0835],\n",
      "        [1.1007],\n",
      "        [1.1037],\n",
      "        [1.0779],\n",
      "        [1.0863],\n",
      "        [1.1066],\n",
      "        [1.0696],\n",
      "        [1.1007],\n",
      "        [1.0651],\n",
      "        [1.1147],\n",
      "        [1.0792],\n",
      "        [1.0341],\n",
      "        [1.0152],\n",
      "        [1.0566],\n",
      "        [1.1070],\n",
      "        [1.0836],\n",
      "        [1.1035],\n",
      "        [1.0458],\n",
      "        [1.0775],\n",
      "        [1.0764],\n",
      "        [1.0871],\n",
      "        [1.0886],\n",
      "        [1.0936],\n",
      "        [1.1053],\n",
      "        [1.0952],\n",
      "        [1.0687],\n",
      "        [1.0963],\n",
      "        [1.1092],\n",
      "        [1.1168],\n",
      "        [1.0747],\n",
      "        [1.1014],\n",
      "        [1.0961],\n",
      "        [1.0716],\n",
      "        [1.0924],\n",
      "        [1.1053],\n",
      "        [1.0649],\n",
      "        [1.1172],\n",
      "        [1.1064],\n",
      "        [1.1061],\n",
      "        [1.0962],\n",
      "        [1.0902],\n",
      "        [1.0486],\n",
      "        [1.1144],\n",
      "        [1.0807],\n",
      "        [1.0899],\n",
      "        [1.1007],\n",
      "        [1.0722],\n",
      "        [1.0813],\n",
      "        [1.0979],\n",
      "        [1.0844],\n",
      "        [1.0949],\n",
      "        [1.1031],\n",
      "        [1.0736],\n",
      "        [1.1030],\n",
      "        [1.0966],\n",
      "        [1.1080],\n",
      "        [1.0825],\n",
      "        [1.1055],\n",
      "        [1.0421],\n",
      "        [1.1190],\n",
      "        [1.1041],\n",
      "        [1.0962],\n",
      "        [1.1187],\n",
      "        [1.1145],\n",
      "        [1.0424],\n",
      "        [1.0646],\n",
      "        [0.0562],\n",
      "        [1.1055],\n",
      "        [1.1103],\n",
      "        [1.0939],\n",
      "        [1.0554],\n",
      "        [1.1027],\n",
      "        [1.1161],\n",
      "        [1.0902],\n",
      "        [1.1011],\n",
      "        [1.1138],\n",
      "        [1.0710],\n",
      "        [1.0976],\n",
      "        [1.0646],\n",
      "        [1.1171],\n",
      "        [1.0736],\n",
      "        [1.0984],\n",
      "        [1.0887],\n",
      "        [1.0620],\n",
      "        [1.0837],\n",
      "        [1.1062],\n",
      "        [1.0326],\n",
      "        [1.1156],\n",
      "        [1.0734],\n",
      "        [1.1143],\n",
      "        [1.0830],\n",
      "        [1.0616],\n",
      "        [1.1049],\n",
      "        [1.0384],\n",
      "        [1.0882],\n",
      "        [1.0776],\n",
      "        [1.1096],\n",
      "        [1.0654],\n",
      "        [1.1020],\n",
      "        [1.0826],\n",
      "        [1.1161],\n",
      "        [1.0774],\n",
      "        [1.0533],\n",
      "        [1.1173],\n",
      "        [1.1156],\n",
      "        [1.0886],\n",
      "        [1.0855],\n",
      "        [1.0590],\n",
      "        [1.0672],\n",
      "        [1.0288],\n",
      "        [1.0970]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0858],\n",
      "        [1.1056],\n",
      "        [1.1176],\n",
      "        [1.0890],\n",
      "        [1.0908],\n",
      "        [1.0722],\n",
      "        [1.1082],\n",
      "        [1.1002],\n",
      "        [1.0681],\n",
      "        [1.0932],\n",
      "        [1.0533],\n",
      "        [1.1149],\n",
      "        [1.0978],\n",
      "        [1.1042],\n",
      "        [1.0739],\n",
      "        [1.0958],\n",
      "        [1.1025],\n",
      "        [1.1228],\n",
      "        [1.1124],\n",
      "        [1.1054],\n",
      "        [1.0954],\n",
      "        [1.0707],\n",
      "        [1.0492],\n",
      "        [1.0791],\n",
      "        [1.1166],\n",
      "        [1.0963],\n",
      "        [1.0930],\n",
      "        [1.0929],\n",
      "        [1.1014],\n",
      "        [1.0766],\n",
      "        [1.0863],\n",
      "        [1.1142],\n",
      "        [1.1108],\n",
      "        [1.0830],\n",
      "        [1.1042],\n",
      "        [1.1030],\n",
      "        [1.0695],\n",
      "        [1.0900],\n",
      "        [1.0956],\n",
      "        [1.0974],\n",
      "        [1.0890],\n",
      "        [1.1171],\n",
      "        [1.0932],\n",
      "        [1.0791],\n",
      "        [1.1072],\n",
      "        [1.0845],\n",
      "        [1.0922],\n",
      "        [1.0896],\n",
      "        [1.1130],\n",
      "        [1.0654],\n",
      "        [1.0672],\n",
      "        [1.1001],\n",
      "        [1.0822],\n",
      "        [1.1164],\n",
      "        [1.1053],\n",
      "        [1.0980],\n",
      "        [1.0682],\n",
      "        [1.0873],\n",
      "        [1.0929],\n",
      "        [1.0838],\n",
      "        [1.0527],\n",
      "        [1.1179],\n",
      "        [1.0682],\n",
      "        [1.0666],\n",
      "        [1.0774],\n",
      "        [1.0723],\n",
      "        [1.0903],\n",
      "        [1.1125],\n",
      "        [1.0864],\n",
      "        [1.1059],\n",
      "        [1.0758],\n",
      "        [1.1151],\n",
      "        [1.1132],\n",
      "        [1.0962],\n",
      "        [1.1026],\n",
      "        [1.1093],\n",
      "        [1.0747],\n",
      "        [1.1144],\n",
      "        [1.1190],\n",
      "        [1.0978],\n",
      "        [1.0745],\n",
      "        [1.0923],\n",
      "        [1.0893],\n",
      "        [1.0982],\n",
      "        [1.0040],\n",
      "        [1.0809],\n",
      "        [1.0991],\n",
      "        [1.1027],\n",
      "        [1.1151],\n",
      "        [1.0974],\n",
      "        [1.0732],\n",
      "        [1.1008],\n",
      "        [1.0508],\n",
      "        [1.1181],\n",
      "        [1.0969],\n",
      "        [1.1157],\n",
      "        [1.1105],\n",
      "        [1.0974],\n",
      "        [1.0847],\n",
      "        [1.0860],\n",
      "        [1.0773],\n",
      "        [1.0842],\n",
      "        [1.0944],\n",
      "        [1.1140],\n",
      "        [1.0452],\n",
      "        [1.0806],\n",
      "        [1.0722],\n",
      "        [1.0418],\n",
      "        [1.0577],\n",
      "        [1.1102],\n",
      "        [1.0633],\n",
      "        [1.1014],\n",
      "        [1.1192],\n",
      "        [1.0894],\n",
      "        [1.1050],\n",
      "        [1.0849],\n",
      "        [1.0673],\n",
      "        [1.0474],\n",
      "        [1.0626],\n",
      "        [1.1003],\n",
      "        [1.1142],\n",
      "        [1.1064],\n",
      "        [1.0948],\n",
      "        [1.1028],\n",
      "        [1.0852],\n",
      "        [1.0805],\n",
      "        [1.0820],\n",
      "        [1.0742]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0865],\n",
      "        [1.0685],\n",
      "        [1.0849],\n",
      "        [1.0685]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  45 | lr 0.00010 train_loss 2.12105 | val_loss 2.29261 | val_rmse 1.51414\n",
      "tensor([[1.0271],\n",
      "        [1.0392],\n",
      "        [1.1053],\n",
      "        [1.0625],\n",
      "        [1.1027],\n",
      "        [1.0602],\n",
      "        [1.1076],\n",
      "        [1.1140],\n",
      "        [1.0679],\n",
      "        [1.0405],\n",
      "        [1.0898],\n",
      "        [1.1010],\n",
      "        [1.1134],\n",
      "        [1.0881],\n",
      "        [1.0954],\n",
      "        [1.1048],\n",
      "        [1.1167],\n",
      "        [1.0727],\n",
      "        [1.1026],\n",
      "        [1.1186],\n",
      "        [1.0358],\n",
      "        [1.0997],\n",
      "        [1.1139],\n",
      "        [1.0505],\n",
      "        [1.0861],\n",
      "        [1.0889],\n",
      "        [1.0886],\n",
      "        [1.1029],\n",
      "        [1.0813],\n",
      "        [1.0859],\n",
      "        [1.0379],\n",
      "        [1.1207],\n",
      "        [1.1042],\n",
      "        [1.0624],\n",
      "        [1.0684],\n",
      "        [1.0829],\n",
      "        [1.0879],\n",
      "        [1.0635],\n",
      "        [1.0874],\n",
      "        [1.1213],\n",
      "        [1.0786],\n",
      "        [1.0752],\n",
      "        [1.1133],\n",
      "        [1.0981],\n",
      "        [1.1189],\n",
      "        [1.0339],\n",
      "        [1.0379],\n",
      "        [1.0803],\n",
      "        [1.0971],\n",
      "        [1.1076],\n",
      "        [1.1119],\n",
      "        [1.1076],\n",
      "        [1.0993],\n",
      "        [1.1201],\n",
      "        [1.1192],\n",
      "        [1.0573],\n",
      "        [1.0989],\n",
      "        [1.0951],\n",
      "        [1.0947],\n",
      "        [1.0577],\n",
      "        [1.1096],\n",
      "        [1.1000],\n",
      "        [1.1135],\n",
      "        [1.0918],\n",
      "        [1.0819],\n",
      "        [1.1104],\n",
      "        [1.0515],\n",
      "        [1.0956],\n",
      "        [1.0795],\n",
      "        [1.1167],\n",
      "        [1.1052],\n",
      "        [1.0995],\n",
      "        [1.0490],\n",
      "        [1.1093],\n",
      "        [1.0994],\n",
      "        [1.1136],\n",
      "        [1.0935],\n",
      "        [1.0775],\n",
      "        [1.0825],\n",
      "        [1.0821],\n",
      "        [1.1030],\n",
      "        [1.0935],\n",
      "        [1.0528],\n",
      "        [1.1177],\n",
      "        [1.0818],\n",
      "        [1.1109],\n",
      "        [1.0763],\n",
      "        [1.0994],\n",
      "        [1.0620],\n",
      "        [1.0794],\n",
      "        [1.0876],\n",
      "        [1.0461],\n",
      "        [1.1126],\n",
      "        [1.0990],\n",
      "        [1.0991],\n",
      "        [1.1025],\n",
      "        [1.0703],\n",
      "        [1.0693],\n",
      "        [1.1034],\n",
      "        [1.1084],\n",
      "        [1.1043],\n",
      "        [1.0850],\n",
      "        [1.1113],\n",
      "        [1.0876],\n",
      "        [1.0917],\n",
      "        [1.0982],\n",
      "        [1.0357],\n",
      "        [1.1083],\n",
      "        [1.0680],\n",
      "        [1.1136],\n",
      "        [1.1048],\n",
      "        [1.0832],\n",
      "        [1.0996],\n",
      "        [1.0803],\n",
      "        [1.0933],\n",
      "        [1.0763],\n",
      "        [1.0857],\n",
      "        [1.0915],\n",
      "        [1.1154],\n",
      "        [1.1106],\n",
      "        [1.0477],\n",
      "        [1.0496],\n",
      "        [1.1166],\n",
      "        [1.1124],\n",
      "        [1.0953],\n",
      "        [3.1135],\n",
      "        [1.0961],\n",
      "        [1.0822]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0677],\n",
      "        [1.1218],\n",
      "        [1.0878],\n",
      "        [1.0561],\n",
      "        [1.1158],\n",
      "        [1.0904],\n",
      "        [1.0829],\n",
      "        [1.0868],\n",
      "        [1.1058],\n",
      "        [1.1062],\n",
      "        [1.0895],\n",
      "        [1.1145],\n",
      "        [1.0790],\n",
      "        [1.0928],\n",
      "        [1.0806],\n",
      "        [1.0749],\n",
      "        [1.1075],\n",
      "        [1.0959],\n",
      "        [1.1082],\n",
      "        [1.0720],\n",
      "        [1.1108],\n",
      "        [1.0583],\n",
      "        [1.0617],\n",
      "        [1.0807],\n",
      "        [1.0881],\n",
      "        [1.0680],\n",
      "        [1.0757],\n",
      "        [1.0929],\n",
      "        [1.0870],\n",
      "        [1.0938],\n",
      "        [1.1019],\n",
      "        [1.0660],\n",
      "        [1.0708],\n",
      "        [1.0962],\n",
      "        [1.1208],\n",
      "        [1.0956],\n",
      "        [1.0950],\n",
      "        [1.0410],\n",
      "        [1.0932],\n",
      "        [1.0772],\n",
      "        [1.0689],\n",
      "        [1.0467],\n",
      "        [1.0666],\n",
      "        [1.0869],\n",
      "        [1.1155],\n",
      "        [1.0710],\n",
      "        [1.0445],\n",
      "        [1.0611],\n",
      "        [1.1110],\n",
      "        [1.1048],\n",
      "        [1.0923],\n",
      "        [1.0858],\n",
      "        [1.1053],\n",
      "        [1.0737],\n",
      "        [1.0997],\n",
      "        [1.0481],\n",
      "        [1.0618],\n",
      "        [1.1161],\n",
      "        [1.0934],\n",
      "        [1.1049],\n",
      "        [1.0920],\n",
      "        [1.0424],\n",
      "        [1.0566],\n",
      "        [1.0473],\n",
      "        [1.0884],\n",
      "        [1.1169],\n",
      "        [1.1036],\n",
      "        [1.0847],\n",
      "        [1.1136],\n",
      "        [1.0841],\n",
      "        [1.1067],\n",
      "        [1.0896],\n",
      "        [1.0895],\n",
      "        [1.1128],\n",
      "        [1.0689],\n",
      "        [1.0413],\n",
      "        [1.0601],\n",
      "        [1.0801],\n",
      "        [1.0479],\n",
      "        [1.0812],\n",
      "        [1.0901],\n",
      "        [1.1177],\n",
      "        [1.0873],\n",
      "        [1.0469],\n",
      "        [1.0645],\n",
      "        [1.0576],\n",
      "        [1.1007],\n",
      "        [1.0839],\n",
      "        [1.0921],\n",
      "        [1.0875],\n",
      "        [1.1158],\n",
      "        [1.1129],\n",
      "        [1.0954],\n",
      "        [1.1140],\n",
      "        [1.0986],\n",
      "        [0.0571],\n",
      "        [1.1102],\n",
      "        [1.1185],\n",
      "        [1.0867],\n",
      "        [1.0824],\n",
      "        [1.1123],\n",
      "        [1.1076],\n",
      "        [1.0939],\n",
      "        [1.0978],\n",
      "        [1.0987],\n",
      "        [1.0898],\n",
      "        [1.1012],\n",
      "        [1.1004],\n",
      "        [1.0802],\n",
      "        [1.0888],\n",
      "        [1.0773],\n",
      "        [1.1188],\n",
      "        [1.1164],\n",
      "        [1.0745],\n",
      "        [1.1023],\n",
      "        [1.0973],\n",
      "        [1.0914],\n",
      "        [1.0911],\n",
      "        [1.0809],\n",
      "        [1.0320],\n",
      "        [1.0988],\n",
      "        [1.0942],\n",
      "        [1.0510],\n",
      "        [1.0596],\n",
      "        [1.1118],\n",
      "        [1.0925],\n",
      "        [1.0720],\n",
      "        [1.0928]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1011],\n",
      "        [1.1088],\n",
      "        [1.0970],\n",
      "        [1.1154],\n",
      "        [1.0901],\n",
      "        [1.0746],\n",
      "        [1.0910],\n",
      "        [1.0940],\n",
      "        [1.0843],\n",
      "        [1.0854],\n",
      "        [1.0868],\n",
      "        [1.0768],\n",
      "        [1.1100],\n",
      "        [1.0869],\n",
      "        [1.1110],\n",
      "        [1.0973],\n",
      "        [1.0678],\n",
      "        [1.0494],\n",
      "        [1.0897],\n",
      "        [1.0646],\n",
      "        [1.0808],\n",
      "        [1.1082],\n",
      "        [1.1058],\n",
      "        [1.0465],\n",
      "        [1.1121],\n",
      "        [1.0943],\n",
      "        [1.0728],\n",
      "        [1.0976],\n",
      "        [1.1180],\n",
      "        [1.0852],\n",
      "        [1.0804],\n",
      "        [1.1128],\n",
      "        [1.0505],\n",
      "        [1.1037],\n",
      "        [1.1180],\n",
      "        [1.0913],\n",
      "        [1.1166],\n",
      "        [1.1141],\n",
      "        [1.1092],\n",
      "        [1.0714],\n",
      "        [1.1092],\n",
      "        [1.0673],\n",
      "        [1.0800],\n",
      "        [1.1111],\n",
      "        [1.1165],\n",
      "        [1.0429],\n",
      "        [1.0893],\n",
      "        [1.0758],\n",
      "        [1.0929],\n",
      "        [1.0279],\n",
      "        [1.1019],\n",
      "        [1.1164],\n",
      "        [1.1113],\n",
      "        [1.0750],\n",
      "        [1.1188],\n",
      "        [1.0978],\n",
      "        [1.1099],\n",
      "        [1.1094],\n",
      "        [1.0383],\n",
      "        [1.1085],\n",
      "        [1.0807],\n",
      "        [1.0775],\n",
      "        [1.1008],\n",
      "        [1.1110],\n",
      "        [1.1058],\n",
      "        [1.0784],\n",
      "        [1.0926],\n",
      "        [1.0398],\n",
      "        [1.0982],\n",
      "        [1.0911],\n",
      "        [1.0930],\n",
      "        [1.0933],\n",
      "        [1.1011],\n",
      "        [1.1108],\n",
      "        [1.0920],\n",
      "        [1.0559],\n",
      "        [1.1133],\n",
      "        [1.0425],\n",
      "        [1.0939],\n",
      "        [1.0884],\n",
      "        [1.0629],\n",
      "        [1.0625],\n",
      "        [1.0913],\n",
      "        [1.0683],\n",
      "        [1.1070],\n",
      "        [1.0783],\n",
      "        [1.0346],\n",
      "        [1.0936],\n",
      "        [1.1132],\n",
      "        [1.0723],\n",
      "        [1.1091],\n",
      "        [1.1146],\n",
      "        [1.0410],\n",
      "        [1.0896],\n",
      "        [1.1063],\n",
      "        [1.0438],\n",
      "        [1.0949],\n",
      "        [1.1030],\n",
      "        [1.1068],\n",
      "        [1.1093],\n",
      "        [1.1188],\n",
      "        [1.1032],\n",
      "        [1.0982],\n",
      "        [1.1132],\n",
      "        [1.0839],\n",
      "        [1.0561],\n",
      "        [1.1020],\n",
      "        [1.0992],\n",
      "        [1.0954],\n",
      "        [1.0912],\n",
      "        [1.1017],\n",
      "        [1.0925],\n",
      "        [1.0532],\n",
      "        [1.0840],\n",
      "        [1.1001],\n",
      "        [1.1163],\n",
      "        [1.0756],\n",
      "        [1.0681],\n",
      "        [1.0952],\n",
      "        [1.1092],\n",
      "        [1.0822],\n",
      "        [1.0963],\n",
      "        [1.0863],\n",
      "        [1.1055],\n",
      "        [1.0945],\n",
      "        [1.0942],\n",
      "        [1.0914],\n",
      "        [1.0897]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0999],\n",
      "        [1.0845],\n",
      "        [1.0989],\n",
      "        [1.1141],\n",
      "        [1.0121],\n",
      "        [1.0856],\n",
      "        [1.0987],\n",
      "        [1.1178],\n",
      "        [1.0606],\n",
      "        [1.0593],\n",
      "        [1.0458],\n",
      "        [1.0870],\n",
      "        [1.1122],\n",
      "        [1.0641],\n",
      "        [1.0767],\n",
      "        [1.0996],\n",
      "        [1.0979],\n",
      "        [1.0933],\n",
      "        [1.0850],\n",
      "        [1.1178],\n",
      "        [1.0364],\n",
      "        [1.0937],\n",
      "        [1.0452],\n",
      "        [1.1010],\n",
      "        [1.0750],\n",
      "        [1.1061],\n",
      "        [1.1077],\n",
      "        [1.1156],\n",
      "        [1.0517],\n",
      "        [1.1037],\n",
      "        [1.0836],\n",
      "        [1.1025],\n",
      "        [1.1021],\n",
      "        [1.0943],\n",
      "        [1.0838],\n",
      "        [1.0998],\n",
      "        [1.0889],\n",
      "        [1.0878],\n",
      "        [1.1019],\n",
      "        [1.1112],\n",
      "        [1.0843],\n",
      "        [1.1030],\n",
      "        [1.1134],\n",
      "        [1.1094],\n",
      "        [1.0932],\n",
      "        [1.1054],\n",
      "        [1.1018],\n",
      "        [1.0695],\n",
      "        [1.0656],\n",
      "        [1.0767],\n",
      "        [1.1202],\n",
      "        [1.1107],\n",
      "        [1.0808],\n",
      "        [1.0770],\n",
      "        [1.0739],\n",
      "        [1.0996],\n",
      "        [1.0487],\n",
      "        [1.0648],\n",
      "        [1.0215],\n",
      "        [1.0789],\n",
      "        [1.0838],\n",
      "        [1.1005],\n",
      "        [1.0754],\n",
      "        [1.0999],\n",
      "        [1.0820],\n",
      "        [1.1139],\n",
      "        [1.0671],\n",
      "        [1.0762],\n",
      "        [1.1073],\n",
      "        [1.1107],\n",
      "        [1.0900],\n",
      "        [1.1040],\n",
      "        [1.0556],\n",
      "        [1.0831],\n",
      "        [1.0574],\n",
      "        [1.0862],\n",
      "        [1.1109],\n",
      "        [1.0898],\n",
      "        [1.0704],\n",
      "        [1.0670],\n",
      "        [1.0596],\n",
      "        [1.1054],\n",
      "        [1.1059],\n",
      "        [1.0931],\n",
      "        [1.1075],\n",
      "        [1.1150],\n",
      "        [1.1046],\n",
      "        [1.1168],\n",
      "        [1.1102],\n",
      "        [1.0715],\n",
      "        [1.1021],\n",
      "        [1.0949],\n",
      "        [1.0707],\n",
      "        [1.1177],\n",
      "        [1.0822],\n",
      "        [1.1070],\n",
      "        [1.1023],\n",
      "        [1.1023],\n",
      "        [1.1093],\n",
      "        [1.0931],\n",
      "        [1.1018],\n",
      "        [1.0262],\n",
      "        [1.0777],\n",
      "        [1.0668],\n",
      "        [1.0844],\n",
      "        [1.0557],\n",
      "        [1.0822],\n",
      "        [1.0963],\n",
      "        [1.0849],\n",
      "        [1.0528],\n",
      "        [1.0544],\n",
      "        [1.0938],\n",
      "        [1.1085],\n",
      "        [1.1168],\n",
      "        [1.0726],\n",
      "        [1.0665],\n",
      "        [1.0983],\n",
      "        [1.0826],\n",
      "        [1.1051],\n",
      "        [1.1047],\n",
      "        [1.0860],\n",
      "        [1.0945],\n",
      "        [1.0993],\n",
      "        [1.0574],\n",
      "        [1.0665],\n",
      "        [1.0475],\n",
      "        [1.1148],\n",
      "        [1.0634]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1022],\n",
      "        [1.1107],\n",
      "        [1.1177],\n",
      "        [1.0952],\n",
      "        [1.0955],\n",
      "        [1.0685],\n",
      "        [1.0963],\n",
      "        [1.0956],\n",
      "        [1.1091],\n",
      "        [1.0558],\n",
      "        [1.1103],\n",
      "        [1.0847],\n",
      "        [1.0953],\n",
      "        [1.0891],\n",
      "        [1.0938],\n",
      "        [1.0698],\n",
      "        [1.0605],\n",
      "        [1.0955],\n",
      "        [1.1003],\n",
      "        [1.1114],\n",
      "        [1.0584],\n",
      "        [1.1020],\n",
      "        [1.1078],\n",
      "        [1.1134],\n",
      "        [1.0991],\n",
      "        [1.0911],\n",
      "        [1.1023],\n",
      "        [1.1035],\n",
      "        [1.0919],\n",
      "        [1.0959],\n",
      "        [1.0379],\n",
      "        [1.0962],\n",
      "        [1.0687],\n",
      "        [1.1084],\n",
      "        [1.0898],\n",
      "        [1.0367],\n",
      "        [1.0785],\n",
      "        [1.0898],\n",
      "        [1.0961],\n",
      "        [1.0829],\n",
      "        [1.0981],\n",
      "        [1.0842],\n",
      "        [1.1091],\n",
      "        [1.0540],\n",
      "        [1.1103],\n",
      "        [1.0506],\n",
      "        [1.1028],\n",
      "        [1.1174],\n",
      "        [1.1096],\n",
      "        [1.0697],\n",
      "        [1.0347],\n",
      "        [1.0957],\n",
      "        [1.1087],\n",
      "        [1.0727],\n",
      "        [1.1002],\n",
      "        [1.0865],\n",
      "        [1.0695],\n",
      "        [1.0916],\n",
      "        [1.0994],\n",
      "        [1.0987],\n",
      "        [1.0630],\n",
      "        [1.0616],\n",
      "        [1.0959],\n",
      "        [1.0714],\n",
      "        [1.1003],\n",
      "        [1.0939],\n",
      "        [1.0873],\n",
      "        [1.0635],\n",
      "        [1.0713],\n",
      "        [1.0827],\n",
      "        [1.0729],\n",
      "        [1.0954],\n",
      "        [1.1076],\n",
      "        [1.0781],\n",
      "        [1.0962],\n",
      "        [1.1073],\n",
      "        [1.0564],\n",
      "        [1.0758],\n",
      "        [1.0980],\n",
      "        [1.0320],\n",
      "        [1.1118],\n",
      "        [1.0754],\n",
      "        [1.1047],\n",
      "        [1.0621],\n",
      "        [1.0574],\n",
      "        [1.0856],\n",
      "        [1.1076],\n",
      "        [1.0887],\n",
      "        [1.0523],\n",
      "        [1.0953],\n",
      "        [1.1146],\n",
      "        [1.1124],\n",
      "        [1.0852],\n",
      "        [1.1102],\n",
      "        [1.1152],\n",
      "        [1.0894],\n",
      "        [1.1049],\n",
      "        [1.1112],\n",
      "        [1.0583],\n",
      "        [1.1043],\n",
      "        [1.0779],\n",
      "        [1.0349],\n",
      "        [1.0588],\n",
      "        [1.1052],\n",
      "        [1.0664],\n",
      "        [1.0982],\n",
      "        [1.0637],\n",
      "        [1.0831],\n",
      "        [1.0521],\n",
      "        [1.0443],\n",
      "        [1.1177],\n",
      "        [1.0921],\n",
      "        [1.0749],\n",
      "        [1.1174],\n",
      "        [1.1024],\n",
      "        [1.0961],\n",
      "        [1.0794],\n",
      "        [1.0955],\n",
      "        [1.0626],\n",
      "        [1.0763],\n",
      "        [1.0669],\n",
      "        [1.0777],\n",
      "        [1.1072],\n",
      "        [1.0734],\n",
      "        [1.0703],\n",
      "        [1.0977],\n",
      "        [1.1175],\n",
      "        [1.0943]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1119],\n",
      "        [1.0788],\n",
      "        [1.0527],\n",
      "        [1.0715],\n",
      "        [1.0907],\n",
      "        [1.1016],\n",
      "        [1.0556],\n",
      "        [1.0756],\n",
      "        [1.0951],\n",
      "        [1.0921],\n",
      "        [1.0193],\n",
      "        [1.0976],\n",
      "        [1.1061],\n",
      "        [1.1060],\n",
      "        [1.1079],\n",
      "        [1.0832],\n",
      "        [1.1167],\n",
      "        [1.0963],\n",
      "        [1.0837],\n",
      "        [1.0943],\n",
      "        [1.0849],\n",
      "        [1.0488],\n",
      "        [1.0715],\n",
      "        [1.1107],\n",
      "        [1.0411],\n",
      "        [1.0996],\n",
      "        [1.0792],\n",
      "        [1.0394],\n",
      "        [1.1173],\n",
      "        [1.0511],\n",
      "        [1.1101],\n",
      "        [1.1001],\n",
      "        [1.1000],\n",
      "        [1.0592],\n",
      "        [1.1143],\n",
      "        [1.1121],\n",
      "        [1.1121],\n",
      "        [1.0964],\n",
      "        [1.0546],\n",
      "        [1.0809],\n",
      "        [1.0800],\n",
      "        [1.1000],\n",
      "        [1.0953],\n",
      "        [1.1114],\n",
      "        [1.0948],\n",
      "        [1.1068],\n",
      "        [1.1020],\n",
      "        [0.5953],\n",
      "        [1.1159],\n",
      "        [1.1055],\n",
      "        [1.0563],\n",
      "        [1.0718],\n",
      "        [1.0818],\n",
      "        [1.1017],\n",
      "        [1.1038],\n",
      "        [1.0580],\n",
      "        [1.0766],\n",
      "        [1.0759],\n",
      "        [1.0810],\n",
      "        [1.0833],\n",
      "        [1.0526],\n",
      "        [1.0674],\n",
      "        [1.0902],\n",
      "        [1.1151],\n",
      "        [1.0941],\n",
      "        [1.0677],\n",
      "        [1.1093],\n",
      "        [1.0847],\n",
      "        [1.0511],\n",
      "        [1.1038],\n",
      "        [1.0952],\n",
      "        [1.0748],\n",
      "        [1.0488],\n",
      "        [1.0865],\n",
      "        [1.1075],\n",
      "        [1.0953],\n",
      "        [0.9971],\n",
      "        [1.0698],\n",
      "        [1.0632],\n",
      "        [1.0457],\n",
      "        [1.1073],\n",
      "        [1.0721],\n",
      "        [1.0837],\n",
      "        [1.0965],\n",
      "        [1.1075],\n",
      "        [1.0778],\n",
      "        [1.0926],\n",
      "        [1.0800],\n",
      "        [1.0679],\n",
      "        [1.1040],\n",
      "        [1.1023],\n",
      "        [1.0958],\n",
      "        [1.0832],\n",
      "        [1.0912],\n",
      "        [1.0860],\n",
      "        [1.1085],\n",
      "        [1.1022],\n",
      "        [1.0673],\n",
      "        [1.1162],\n",
      "        [1.0862],\n",
      "        [1.0837],\n",
      "        [1.0877],\n",
      "        [1.0850],\n",
      "        [1.0855],\n",
      "        [1.1058],\n",
      "        [1.1041],\n",
      "        [1.1012],\n",
      "        [1.1077],\n",
      "        [1.0899],\n",
      "        [1.0838],\n",
      "        [1.0813],\n",
      "        [1.0975],\n",
      "        [1.0771],\n",
      "        [1.0978],\n",
      "        [1.0911],\n",
      "        [1.1031],\n",
      "        [1.0833],\n",
      "        [1.0834],\n",
      "        [1.0977],\n",
      "        [1.0927],\n",
      "        [1.0999],\n",
      "        [1.0938],\n",
      "        [1.0692],\n",
      "        [1.0888],\n",
      "        [1.0959],\n",
      "        [1.0658],\n",
      "        [1.0416],\n",
      "        [1.0805]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0344],\n",
      "        [1.1020],\n",
      "        [1.0807],\n",
      "        [0.9748],\n",
      "        [1.0118],\n",
      "        [1.0657],\n",
      "        [1.1048],\n",
      "        [1.0927],\n",
      "        [1.1076],\n",
      "        [1.0949],\n",
      "        [1.1051],\n",
      "        [1.0772],\n",
      "        [1.0844],\n",
      "        [1.1043],\n",
      "        [1.1066],\n",
      "        [1.1017],\n",
      "        [1.0924],\n",
      "        [1.0501],\n",
      "        [1.1094],\n",
      "        [1.0959],\n",
      "        [1.0808],\n",
      "        [1.0592],\n",
      "        [1.0787],\n",
      "        [1.1007],\n",
      "        [1.0925],\n",
      "        [1.0638],\n",
      "        [1.1030],\n",
      "        [1.0792],\n",
      "        [1.0581],\n",
      "        [1.1008],\n",
      "        [1.1005],\n",
      "        [1.0891],\n",
      "        [1.0572],\n",
      "        [1.0963],\n",
      "        [1.0959],\n",
      "        [1.0918],\n",
      "        [1.1158],\n",
      "        [1.0527],\n",
      "        [1.1169],\n",
      "        [1.1131],\n",
      "        [1.0854],\n",
      "        [1.1103],\n",
      "        [1.1066],\n",
      "        [1.0908],\n",
      "        [1.1121],\n",
      "        [1.0549],\n",
      "        [1.0916],\n",
      "        [1.0790],\n",
      "        [1.1122],\n",
      "        [1.1085],\n",
      "        [1.0797],\n",
      "        [1.0644],\n",
      "        [1.0536],\n",
      "        [1.0869],\n",
      "        [1.0799],\n",
      "        [1.1126],\n",
      "        [1.0858],\n",
      "        [1.0747],\n",
      "        [1.0617],\n",
      "        [1.1048],\n",
      "        [1.0793],\n",
      "        [1.0965],\n",
      "        [1.0670],\n",
      "        [1.0988],\n",
      "        [1.1166],\n",
      "        [1.1126],\n",
      "        [1.0895],\n",
      "        [1.1098],\n",
      "        [1.1173],\n",
      "        [1.1034],\n",
      "        [1.0508],\n",
      "        [1.0789],\n",
      "        [1.1073],\n",
      "        [1.0959],\n",
      "        [1.0841],\n",
      "        [1.0211],\n",
      "        [1.0898],\n",
      "        [1.0495],\n",
      "        [1.0595],\n",
      "        [1.0932],\n",
      "        [1.0829],\n",
      "        [1.1053],\n",
      "        [1.0937],\n",
      "        [1.0586],\n",
      "        [1.1019],\n",
      "        [1.0596],\n",
      "        [1.0937],\n",
      "        [1.1099],\n",
      "        [1.0870],\n",
      "        [1.0824],\n",
      "        [1.0901],\n",
      "        [1.0941],\n",
      "        [1.0613],\n",
      "        [1.0715],\n",
      "        [1.0835],\n",
      "        [1.1056],\n",
      "        [1.1021],\n",
      "        [1.0419],\n",
      "        [1.1143],\n",
      "        [1.1054],\n",
      "        [1.0912],\n",
      "        [1.1127],\n",
      "        [1.0838],\n",
      "        [1.0620],\n",
      "        [1.0803],\n",
      "        [1.1011],\n",
      "        [1.0826],\n",
      "        [1.0885],\n",
      "        [1.0927],\n",
      "        [1.1047],\n",
      "        [1.0466],\n",
      "        [1.0955],\n",
      "        [1.0886],\n",
      "        [1.0894],\n",
      "        [1.0849],\n",
      "        [1.0586],\n",
      "        [1.0998],\n",
      "        [1.0724],\n",
      "        [1.0712],\n",
      "        [1.0918],\n",
      "        [1.0832],\n",
      "        [0.9984],\n",
      "        [1.0644],\n",
      "        [1.0798],\n",
      "        [1.1164],\n",
      "        [1.0670],\n",
      "        [1.0390],\n",
      "        [1.0904]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0990],\n",
      "        [1.0639],\n",
      "        [1.0901],\n",
      "        [1.0879]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  46 | lr 0.00010 train_loss 2.13009 | val_loss 2.29338 | val_rmse 1.51439\n",
      "tensor([[1.0838],\n",
      "        [1.1065],\n",
      "        [1.0657],\n",
      "        [1.1105],\n",
      "        [1.0766],\n",
      "        [1.0986],\n",
      "        [1.0914],\n",
      "        [1.1086],\n",
      "        [1.0760],\n",
      "        [1.0622],\n",
      "        [1.0610],\n",
      "        [1.0769],\n",
      "        [1.0838],\n",
      "        [1.0726],\n",
      "        [1.0693],\n",
      "        [1.0846],\n",
      "        [1.1071],\n",
      "        [1.0361],\n",
      "        [1.0784],\n",
      "        [1.0299],\n",
      "        [1.0803],\n",
      "        [1.0248],\n",
      "        [1.0984],\n",
      "        [1.0927],\n",
      "        [1.0871],\n",
      "        [1.1068],\n",
      "        [1.0974],\n",
      "        [1.0764],\n",
      "        [1.0945],\n",
      "        [1.0980],\n",
      "        [1.0839],\n",
      "        [1.0779],\n",
      "        [1.1079],\n",
      "        [1.1045],\n",
      "        [1.1147],\n",
      "        [1.0556],\n",
      "        [1.0827],\n",
      "        [1.0088],\n",
      "        [1.0925],\n",
      "        [1.0611],\n",
      "        [1.0654],\n",
      "        [1.0706],\n",
      "        [1.0509],\n",
      "        [1.0752],\n",
      "        [1.0758],\n",
      "        [1.0795],\n",
      "        [1.0547],\n",
      "        [1.0374],\n",
      "        [1.0937],\n",
      "        [1.1123],\n",
      "        [1.0766],\n",
      "        [1.0367],\n",
      "        [1.0919],\n",
      "        [1.0932],\n",
      "        [1.0718],\n",
      "        [1.1002],\n",
      "        [1.0867],\n",
      "        [1.1025],\n",
      "        [1.0467],\n",
      "        [1.0654],\n",
      "        [1.0828],\n",
      "        [1.0704],\n",
      "        [1.1146],\n",
      "        [1.0784],\n",
      "        [1.0816],\n",
      "        [1.1150],\n",
      "        [1.0874],\n",
      "        [1.1006],\n",
      "        [1.0282],\n",
      "        [1.0884],\n",
      "        [1.0240],\n",
      "        [1.0912],\n",
      "        [1.0208],\n",
      "        [1.0814],\n",
      "        [1.0508],\n",
      "        [1.1150],\n",
      "        [1.1011],\n",
      "        [1.0912],\n",
      "        [1.1076],\n",
      "        [1.1144],\n",
      "        [1.0512],\n",
      "        [1.0841],\n",
      "        [1.0733],\n",
      "        [1.0990],\n",
      "        [1.0838],\n",
      "        [1.0840],\n",
      "        [1.1045],\n",
      "        [1.1056],\n",
      "        [1.0933],\n",
      "        [1.1160],\n",
      "        [1.0751],\n",
      "        [1.1042],\n",
      "        [1.0940],\n",
      "        [1.1021],\n",
      "        [1.0645],\n",
      "        [1.0867],\n",
      "        [1.0784],\n",
      "        [1.1066],\n",
      "        [1.0583],\n",
      "        [1.1134],\n",
      "        [1.0571],\n",
      "        [1.0881],\n",
      "        [1.0861],\n",
      "        [1.0831],\n",
      "        [1.0715],\n",
      "        [1.0428],\n",
      "        [1.0697],\n",
      "        [1.0815],\n",
      "        [1.0784],\n",
      "        [1.1141],\n",
      "        [1.1022],\n",
      "        [1.0799],\n",
      "        [1.0785],\n",
      "        [1.0637],\n",
      "        [1.1014],\n",
      "        [1.0725],\n",
      "        [1.1001],\n",
      "        [1.0847],\n",
      "        [1.0731],\n",
      "        [1.0963],\n",
      "        [1.0950],\n",
      "        [1.0241],\n",
      "        [1.1124],\n",
      "        [1.0842],\n",
      "        [1.0686],\n",
      "        [1.0696],\n",
      "        [1.1094],\n",
      "        [1.0808]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1026],\n",
      "        [1.0376],\n",
      "        [1.0925],\n",
      "        [1.0847],\n",
      "        [1.0885],\n",
      "        [1.0553],\n",
      "        [1.0673],\n",
      "        [1.0837],\n",
      "        [1.1046],\n",
      "        [1.0976],\n",
      "        [1.0756],\n",
      "        [1.0525],\n",
      "        [1.0469],\n",
      "        [1.1154],\n",
      "        [1.1070],\n",
      "        [1.0824],\n",
      "        [1.0256],\n",
      "        [1.0784],\n",
      "        [1.0986],\n",
      "        [1.1122],\n",
      "        [1.0984],\n",
      "        [1.1041],\n",
      "        [1.0956],\n",
      "        [1.1023],\n",
      "        [1.1183],\n",
      "        [1.0794],\n",
      "        [1.0537],\n",
      "        [1.0694],\n",
      "        [1.0647],\n",
      "        [1.0962],\n",
      "        [1.0777],\n",
      "        [1.0491],\n",
      "        [1.0305],\n",
      "        [1.1056],\n",
      "        [1.0931],\n",
      "        [1.0749],\n",
      "        [1.1030],\n",
      "        [1.1154],\n",
      "        [1.0699],\n",
      "        [1.1020],\n",
      "        [1.0991],\n",
      "        [1.1026],\n",
      "        [1.0380],\n",
      "        [1.0972],\n",
      "        [1.0826],\n",
      "        [1.0718],\n",
      "        [1.0631],\n",
      "        [1.0722],\n",
      "        [1.0679],\n",
      "        [1.0953],\n",
      "        [1.0810],\n",
      "        [1.0822],\n",
      "        [1.0975],\n",
      "        [1.0963],\n",
      "        [1.1145],\n",
      "        [1.1091],\n",
      "        [1.1111],\n",
      "        [1.0747],\n",
      "        [1.1116],\n",
      "        [1.0696],\n",
      "        [1.0924],\n",
      "        [1.1118],\n",
      "        [1.0892],\n",
      "        [1.0842],\n",
      "        [1.0776],\n",
      "        [1.1044],\n",
      "        [1.0859],\n",
      "        [1.1031],\n",
      "        [1.1098],\n",
      "        [1.0876],\n",
      "        [1.0795],\n",
      "        [1.0712],\n",
      "        [1.1039],\n",
      "        [1.0870],\n",
      "        [1.0876],\n",
      "        [1.1076],\n",
      "        [1.1096],\n",
      "        [1.0879],\n",
      "        [1.1009],\n",
      "        [1.0603],\n",
      "        [1.0273],\n",
      "        [1.0579],\n",
      "        [1.0333],\n",
      "        [1.0702],\n",
      "        [1.1005],\n",
      "        [1.0753],\n",
      "        [1.0488],\n",
      "        [1.0783],\n",
      "        [1.0670],\n",
      "        [1.0941],\n",
      "        [1.0952],\n",
      "        [1.1106],\n",
      "        [1.0954],\n",
      "        [1.0959],\n",
      "        [1.0751],\n",
      "        [1.1017],\n",
      "        [1.0963],\n",
      "        [1.0782],\n",
      "        [1.0777],\n",
      "        [1.0995],\n",
      "        [1.0837],\n",
      "        [1.1073],\n",
      "        [1.0777],\n",
      "        [1.1119],\n",
      "        [1.0462],\n",
      "        [1.0897],\n",
      "        [1.1091],\n",
      "        [1.0512],\n",
      "        [1.1011],\n",
      "        [1.0966],\n",
      "        [1.1162],\n",
      "        [1.0920],\n",
      "        [1.0775],\n",
      "        [1.0728],\n",
      "        [1.0818],\n",
      "        [1.0649],\n",
      "        [1.1118],\n",
      "        [1.0605],\n",
      "        [1.0726],\n",
      "        [1.0997],\n",
      "        [1.0675],\n",
      "        [1.0627],\n",
      "        [1.0880],\n",
      "        [1.1043],\n",
      "        [1.0984],\n",
      "        [1.0828],\n",
      "        [1.0810],\n",
      "        [1.0442]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0924],\n",
      "        [1.1131],\n",
      "        [1.1038],\n",
      "        [1.0970],\n",
      "        [1.0997],\n",
      "        [1.1125],\n",
      "        [1.0622],\n",
      "        [1.0407],\n",
      "        [1.0742],\n",
      "        [1.0958],\n",
      "        [1.1102],\n",
      "        [1.1014],\n",
      "        [1.0693],\n",
      "        [1.1129],\n",
      "        [1.0863],\n",
      "        [1.0481],\n",
      "        [1.0987],\n",
      "        [1.0607],\n",
      "        [1.0464],\n",
      "        [1.1030],\n",
      "        [1.0436],\n",
      "        [1.0763],\n",
      "        [1.0260],\n",
      "        [1.0460],\n",
      "        [1.0994],\n",
      "        [1.0890],\n",
      "        [1.1023],\n",
      "        [1.0924],\n",
      "        [1.0624],\n",
      "        [1.0784],\n",
      "        [1.0520],\n",
      "        [1.0755],\n",
      "        [1.1129],\n",
      "        [1.1151],\n",
      "        [1.0921],\n",
      "        [1.0864],\n",
      "        [1.1147],\n",
      "        [1.0922],\n",
      "        [1.0833],\n",
      "        [1.0890],\n",
      "        [1.0878],\n",
      "        [1.1028],\n",
      "        [1.0896],\n",
      "        [1.0782],\n",
      "        [1.0690],\n",
      "        [1.0780],\n",
      "        [1.0844],\n",
      "        [1.0683],\n",
      "        [1.0900],\n",
      "        [1.0831],\n",
      "        [1.0985],\n",
      "        [1.1043],\n",
      "        [1.0763],\n",
      "        [1.0991],\n",
      "        [1.0693],\n",
      "        [1.0985],\n",
      "        [1.0825],\n",
      "        [1.0635],\n",
      "        [1.0585],\n",
      "        [1.0771],\n",
      "        [1.1071],\n",
      "        [1.1046],\n",
      "        [1.0780],\n",
      "        [1.0522],\n",
      "        [1.0715],\n",
      "        [1.0783],\n",
      "        [1.0919],\n",
      "        [1.0786],\n",
      "        [1.0715],\n",
      "        [1.0998],\n",
      "        [1.1095],\n",
      "        [1.0803],\n",
      "        [1.0971],\n",
      "        [1.1107],\n",
      "        [1.0598],\n",
      "        [1.1003],\n",
      "        [1.0948],\n",
      "        [1.0983],\n",
      "        [1.0875],\n",
      "        [1.0770],\n",
      "        [1.0788],\n",
      "        [1.0802],\n",
      "        [1.0920],\n",
      "        [1.0717],\n",
      "        [1.0768],\n",
      "        [1.1151],\n",
      "        [1.0829],\n",
      "        [1.0771],\n",
      "        [1.0992],\n",
      "        [1.0676],\n",
      "        [1.0983],\n",
      "        [1.0899],\n",
      "        [1.0985],\n",
      "        [1.1021],\n",
      "        [1.1037],\n",
      "        [1.0725],\n",
      "        [1.1112],\n",
      "        [1.1130],\n",
      "        [1.0736],\n",
      "        [1.1113],\n",
      "        [1.0370],\n",
      "        [1.0758],\n",
      "        [1.0998],\n",
      "        [1.0339],\n",
      "        [1.0888],\n",
      "        [1.1048],\n",
      "        [1.0760],\n",
      "        [1.1043],\n",
      "        [1.0882],\n",
      "        [1.0998],\n",
      "        [1.0531],\n",
      "        [1.0922],\n",
      "        [1.1153],\n",
      "        [1.0962],\n",
      "        [1.0816],\n",
      "        [1.1143],\n",
      "        [1.0986],\n",
      "        [1.0794],\n",
      "        [1.0829],\n",
      "        [1.0927],\n",
      "        [1.0644],\n",
      "        [1.0747],\n",
      "        [1.0677],\n",
      "        [1.0884],\n",
      "        [1.0967],\n",
      "        [1.0395],\n",
      "        [1.0195],\n",
      "        [1.1114]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1149],\n",
      "        [1.0842],\n",
      "        [1.0775],\n",
      "        [1.1000],\n",
      "        [1.0859],\n",
      "        [1.0729],\n",
      "        [1.0564],\n",
      "        [1.0937],\n",
      "        [1.0890],\n",
      "        [1.1001],\n",
      "        [1.0312],\n",
      "        [1.1021],\n",
      "        [1.0747],\n",
      "        [1.0806],\n",
      "        [1.1070],\n",
      "        [1.1043],\n",
      "        [1.0370],\n",
      "        [1.0729],\n",
      "        [1.1122],\n",
      "        [1.0704],\n",
      "        [1.0742],\n",
      "        [1.1183],\n",
      "        [1.0791],\n",
      "        [1.0286],\n",
      "        [1.0413],\n",
      "        [1.0850],\n",
      "        [1.1103],\n",
      "        [1.0549],\n",
      "        [1.1002],\n",
      "        [1.0893],\n",
      "        [1.0956],\n",
      "        [0.2481],\n",
      "        [1.1101],\n",
      "        [1.0747],\n",
      "        [1.0970],\n",
      "        [1.0957],\n",
      "        [1.0672],\n",
      "        [1.0520],\n",
      "        [1.1004],\n",
      "        [1.1149],\n",
      "        [1.0758],\n",
      "        [1.0724],\n",
      "        [1.1099],\n",
      "        [1.0559],\n",
      "        [1.1048],\n",
      "        [1.1068],\n",
      "        [1.0691],\n",
      "        [1.0919],\n",
      "        [1.0791],\n",
      "        [1.1077],\n",
      "        [1.0473],\n",
      "        [1.1039],\n",
      "        [1.0757],\n",
      "        [1.0974],\n",
      "        [1.0729],\n",
      "        [1.0642],\n",
      "        [1.0750],\n",
      "        [1.1105],\n",
      "        [1.1042],\n",
      "        [1.0582],\n",
      "        [1.0766],\n",
      "        [1.0942],\n",
      "        [1.0940],\n",
      "        [1.0625],\n",
      "        [1.0933],\n",
      "        [1.0618],\n",
      "        [1.1147],\n",
      "        [1.1103],\n",
      "        [1.1040],\n",
      "        [1.1073],\n",
      "        [1.1018],\n",
      "        [1.0912],\n",
      "        [1.1112],\n",
      "        [1.0702],\n",
      "        [1.1008],\n",
      "        [1.0949],\n",
      "        [1.0898],\n",
      "        [1.0759],\n",
      "        [1.0583],\n",
      "        [1.0741],\n",
      "        [1.1085],\n",
      "        [1.0250],\n",
      "        [1.0377],\n",
      "        [1.1081],\n",
      "        [1.0528],\n",
      "        [1.0789],\n",
      "        [1.0684],\n",
      "        [1.0809],\n",
      "        [1.0782],\n",
      "        [1.0896],\n",
      "        [1.0719],\n",
      "        [1.1004],\n",
      "        [1.0788],\n",
      "        [1.1076],\n",
      "        [1.1016],\n",
      "        [1.1071],\n",
      "        [1.0587],\n",
      "        [1.0906],\n",
      "        [1.0749],\n",
      "        [1.1101],\n",
      "        [1.1033],\n",
      "        [1.0410],\n",
      "        [1.0565],\n",
      "        [1.0689],\n",
      "        [0.1329],\n",
      "        [1.0715],\n",
      "        [1.0758],\n",
      "        [1.0908],\n",
      "        [1.1057],\n",
      "        [1.0868],\n",
      "        [1.0995],\n",
      "        [1.1153],\n",
      "        [1.1140],\n",
      "        [1.1005],\n",
      "        [1.0374],\n",
      "        [1.0620],\n",
      "        [1.0973],\n",
      "        [1.1022],\n",
      "        [1.0666],\n",
      "        [1.0629],\n",
      "        [1.1150],\n",
      "        [1.0795],\n",
      "        [1.1038],\n",
      "        [1.0791],\n",
      "        [1.1150],\n",
      "        [1.0685],\n",
      "        [1.0787],\n",
      "        [1.0808]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0876],\n",
      "        [1.0893],\n",
      "        [1.1144],\n",
      "        [1.0768],\n",
      "        [1.0799],\n",
      "        [1.1109],\n",
      "        [1.1140],\n",
      "        [1.0741],\n",
      "        [1.0667],\n",
      "        [1.0728],\n",
      "        [1.0611],\n",
      "        [1.0692],\n",
      "        [1.0728],\n",
      "        [1.0703],\n",
      "        [1.0393],\n",
      "        [1.0863],\n",
      "        [1.1170],\n",
      "        [1.0898],\n",
      "        [1.0699],\n",
      "        [1.1091],\n",
      "        [1.0793],\n",
      "        [1.0954],\n",
      "        [1.0806],\n",
      "        [1.0773],\n",
      "        [1.1074],\n",
      "        [1.1154],\n",
      "        [1.1020],\n",
      "        [1.0976],\n",
      "        [1.0883],\n",
      "        [1.0825],\n",
      "        [1.0977],\n",
      "        [1.0975],\n",
      "        [1.0653],\n",
      "        [1.1016],\n",
      "        [1.0983],\n",
      "        [1.1136],\n",
      "        [1.0481],\n",
      "        [1.1073],\n",
      "        [1.1044],\n",
      "        [1.1007],\n",
      "        [1.0870],\n",
      "        [1.1069],\n",
      "        [1.0895],\n",
      "        [1.0920],\n",
      "        [1.1047],\n",
      "        [1.0664],\n",
      "        [1.1060],\n",
      "        [1.0779],\n",
      "        [1.0765],\n",
      "        [1.0838],\n",
      "        [0.9909],\n",
      "        [1.0900],\n",
      "        [1.0846],\n",
      "        [1.0733],\n",
      "        [1.0924],\n",
      "        [1.1027],\n",
      "        [1.0961],\n",
      "        [1.0913],\n",
      "        [1.1002],\n",
      "        [1.1106],\n",
      "        [1.0456],\n",
      "        [1.1133],\n",
      "        [1.0623],\n",
      "        [1.1092],\n",
      "        [1.1018],\n",
      "        [1.0682],\n",
      "        [1.0745],\n",
      "        [1.0635],\n",
      "        [1.0799],\n",
      "        [1.0637],\n",
      "        [1.0737],\n",
      "        [1.0674],\n",
      "        [1.0415],\n",
      "        [1.0018],\n",
      "        [1.0705],\n",
      "        [1.0687],\n",
      "        [1.0731],\n",
      "        [1.0768],\n",
      "        [1.0645],\n",
      "        [1.0944],\n",
      "        [1.1096],\n",
      "        [1.0805],\n",
      "        [1.0949],\n",
      "        [1.0960],\n",
      "        [1.1022],\n",
      "        [1.0909],\n",
      "        [1.0989],\n",
      "        [1.0779],\n",
      "        [1.0468],\n",
      "        [1.0814],\n",
      "        [1.0751],\n",
      "        [1.1019],\n",
      "        [1.0893],\n",
      "        [1.1041],\n",
      "        [1.0558],\n",
      "        [1.0746],\n",
      "        [1.0346],\n",
      "        [1.1001],\n",
      "        [1.1122],\n",
      "        [1.0956],\n",
      "        [1.1052],\n",
      "        [1.1070],\n",
      "        [1.0589],\n",
      "        [1.0672],\n",
      "        [1.1070],\n",
      "        [1.0967],\n",
      "        [1.0985],\n",
      "        [1.0972],\n",
      "        [1.1111],\n",
      "        [1.1012],\n",
      "        [1.0713],\n",
      "        [1.1108],\n",
      "        [1.0375],\n",
      "        [1.0841],\n",
      "        [1.0672],\n",
      "        [1.0629],\n",
      "        [1.1087],\n",
      "        [1.1065],\n",
      "        [1.0858],\n",
      "        [1.1084],\n",
      "        [1.0729],\n",
      "        [1.0374],\n",
      "        [1.1010],\n",
      "        [1.0958],\n",
      "        [1.0498],\n",
      "        [1.0479],\n",
      "        [1.0996],\n",
      "        [1.0453]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0777],\n",
      "        [1.0964],\n",
      "        [1.0971],\n",
      "        [1.0620],\n",
      "        [1.0522],\n",
      "        [1.0701],\n",
      "        [1.1110],\n",
      "        [1.0663],\n",
      "        [1.1114],\n",
      "        [1.1103],\n",
      "        [1.0813],\n",
      "        [1.1127],\n",
      "        [1.0897],\n",
      "        [1.0927],\n",
      "        [1.0899],\n",
      "        [1.0919],\n",
      "        [1.0818],\n",
      "        [1.0681],\n",
      "        [1.1133],\n",
      "        [1.1030],\n",
      "        [1.0668],\n",
      "        [1.0772],\n",
      "        [1.0553],\n",
      "        [1.0890],\n",
      "        [1.0737],\n",
      "        [1.1129],\n",
      "        [1.0377],\n",
      "        [1.0895],\n",
      "        [1.0984],\n",
      "        [1.0956],\n",
      "        [1.0903],\n",
      "        [1.0430],\n",
      "        [1.0772],\n",
      "        [1.1048],\n",
      "        [1.0515],\n",
      "        [1.1033],\n",
      "        [1.0760],\n",
      "        [1.0664],\n",
      "        [1.1120],\n",
      "        [1.1026],\n",
      "        [1.0830],\n",
      "        [1.1005],\n",
      "        [0.1729],\n",
      "        [1.0675],\n",
      "        [1.0649],\n",
      "        [1.0928],\n",
      "        [1.0962],\n",
      "        [1.1031],\n",
      "        [1.1125],\n",
      "        [1.1074],\n",
      "        [1.0672],\n",
      "        [1.1011],\n",
      "        [1.0931],\n",
      "        [1.0794],\n",
      "        [1.0841],\n",
      "        [1.0899],\n",
      "        [1.0969],\n",
      "        [1.0895],\n",
      "        [1.0928],\n",
      "        [1.1038],\n",
      "        [1.0438],\n",
      "        [1.0819],\n",
      "        [1.0985],\n",
      "        [1.0174],\n",
      "        [1.0692],\n",
      "        [1.1139],\n",
      "        [1.0822],\n",
      "        [1.1036],\n",
      "        [1.0454],\n",
      "        [1.0490],\n",
      "        [1.1036],\n",
      "        [1.1135],\n",
      "        [1.0720],\n",
      "        [1.0991],\n",
      "        [1.0883],\n",
      "        [1.0808],\n",
      "        [1.0701],\n",
      "        [1.0349],\n",
      "        [1.0951],\n",
      "        [1.1098],\n",
      "        [1.1100],\n",
      "        [1.0494],\n",
      "        [1.1136],\n",
      "        [1.0999],\n",
      "        [1.0902],\n",
      "        [1.1098],\n",
      "        [1.0897],\n",
      "        [1.0991],\n",
      "        [1.0791],\n",
      "        [1.0924],\n",
      "        [1.0772],\n",
      "        [1.0832],\n",
      "        [1.0767],\n",
      "        [1.0814],\n",
      "        [1.0996],\n",
      "        [1.0905],\n",
      "        [1.0881],\n",
      "        [1.1044],\n",
      "        [1.0628],\n",
      "        [1.1042],\n",
      "        [1.1130],\n",
      "        [1.1152],\n",
      "        [1.0917],\n",
      "        [1.1142],\n",
      "        [1.0918],\n",
      "        [1.0761],\n",
      "        [1.0764],\n",
      "        [1.1094],\n",
      "        [1.0913],\n",
      "        [1.1116],\n",
      "        [1.0821],\n",
      "        [1.1151],\n",
      "        [1.0987],\n",
      "        [1.0878],\n",
      "        [1.0937],\n",
      "        [1.0980],\n",
      "        [1.0925],\n",
      "        [1.0908],\n",
      "        [1.0642],\n",
      "        [1.1102],\n",
      "        [1.1063],\n",
      "        [1.0754],\n",
      "        [1.1027],\n",
      "        [1.0649],\n",
      "        [1.0782],\n",
      "        [1.0472],\n",
      "        [1.0532],\n",
      "        [1.0727]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0905],\n",
      "        [1.1011],\n",
      "        [1.0650],\n",
      "        [1.0625],\n",
      "        [1.1075],\n",
      "        [1.0908],\n",
      "        [1.0666],\n",
      "        [1.0656],\n",
      "        [1.1149],\n",
      "        [1.0336],\n",
      "        [1.0934],\n",
      "        [1.0709],\n",
      "        [1.1020],\n",
      "        [1.0429],\n",
      "        [1.0764],\n",
      "        [1.0716],\n",
      "        [1.1104],\n",
      "        [1.0873],\n",
      "        [1.0759],\n",
      "        [1.0598],\n",
      "        [1.0809],\n",
      "        [1.0730],\n",
      "        [1.0846],\n",
      "        [1.0659],\n",
      "        [1.0634],\n",
      "        [1.0506],\n",
      "        [1.0418],\n",
      "        [1.0880],\n",
      "        [1.0935],\n",
      "        [0.0782],\n",
      "        [1.0992],\n",
      "        [1.1041],\n",
      "        [1.0688],\n",
      "        [1.0668],\n",
      "        [1.0732],\n",
      "        [1.1072],\n",
      "        [1.0934],\n",
      "        [1.1028],\n",
      "        [1.0621],\n",
      "        [1.0191],\n",
      "        [1.0662],\n",
      "        [1.0628],\n",
      "        [1.0804],\n",
      "        [1.1008],\n",
      "        [1.0898],\n",
      "        [1.0316],\n",
      "        [1.0822],\n",
      "        [1.0927],\n",
      "        [1.0847],\n",
      "        [1.0522],\n",
      "        [1.0865],\n",
      "        [1.1064],\n",
      "        [1.1082],\n",
      "        [1.1112],\n",
      "        [1.1063],\n",
      "        [1.0659],\n",
      "        [1.0590],\n",
      "        [1.0746],\n",
      "        [1.0583],\n",
      "        [1.0461],\n",
      "        [1.0732],\n",
      "        [1.0956],\n",
      "        [1.0841],\n",
      "        [1.0987],\n",
      "        [1.0867],\n",
      "        [1.1136],\n",
      "        [1.0829],\n",
      "        [1.1040],\n",
      "        [1.1036],\n",
      "        [1.0383],\n",
      "        [1.0972],\n",
      "        [1.0941],\n",
      "        [1.0727],\n",
      "        [1.0653],\n",
      "        [1.0887],\n",
      "        [1.0977],\n",
      "        [1.0653],\n",
      "        [1.0939],\n",
      "        [1.0976],\n",
      "        [1.0741],\n",
      "        [1.1132],\n",
      "        [1.0747],\n",
      "        [1.0388],\n",
      "        [1.0937],\n",
      "        [1.0887],\n",
      "        [1.0899],\n",
      "        [1.0758],\n",
      "        [1.0579],\n",
      "        [1.1014],\n",
      "        [1.1005],\n",
      "        [1.0932],\n",
      "        [1.1120],\n",
      "        [1.1045],\n",
      "        [1.0735],\n",
      "        [1.1041],\n",
      "        [1.0789],\n",
      "        [1.0778],\n",
      "        [1.0225],\n",
      "        [1.1141],\n",
      "        [1.0989],\n",
      "        [1.0878],\n",
      "        [1.1139],\n",
      "        [1.0880],\n",
      "        [1.0725],\n",
      "        [1.0943],\n",
      "        [1.0972],\n",
      "        [1.1068],\n",
      "        [1.0605],\n",
      "        [1.1178],\n",
      "        [1.0852],\n",
      "        [1.0885],\n",
      "        [1.0972],\n",
      "        [1.1070],\n",
      "        [1.1056],\n",
      "        [1.0852],\n",
      "        [1.1113],\n",
      "        [1.0473],\n",
      "        [1.0852],\n",
      "        [1.1065],\n",
      "        [1.0369],\n",
      "        [1.0463],\n",
      "        [1.1038],\n",
      "        [1.1017],\n",
      "        [1.0918],\n",
      "        [1.0763],\n",
      "        [1.1000],\n",
      "        [1.1101],\n",
      "        [1.0285]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1024],\n",
      "        [1.0593],\n",
      "        [1.0993],\n",
      "        [1.0765]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  47 | lr 0.00010 train_loss 2.13389 | val_loss 2.29404 | val_rmse 1.51461\n",
      "tensor([[1.0659],\n",
      "        [1.1075],\n",
      "        [1.0903],\n",
      "        [1.0989],\n",
      "        [1.0935],\n",
      "        [1.0730],\n",
      "        [1.0907],\n",
      "        [1.0872],\n",
      "        [1.0626],\n",
      "        [1.1078],\n",
      "        [1.1036],\n",
      "        [1.0647],\n",
      "        [1.0754],\n",
      "        [1.0797],\n",
      "        [1.0985],\n",
      "        [1.0903],\n",
      "        [1.0876],\n",
      "        [1.0823],\n",
      "        [1.0989],\n",
      "        [1.0761],\n",
      "        [1.0850],\n",
      "        [1.0860],\n",
      "        [1.0968],\n",
      "        [1.0770],\n",
      "        [1.0568],\n",
      "        [1.0918],\n",
      "        [1.0589],\n",
      "        [1.0771],\n",
      "        [1.0583],\n",
      "        [1.0773],\n",
      "        [1.0802],\n",
      "        [1.1018],\n",
      "        [1.0360],\n",
      "        [1.0672],\n",
      "        [1.0543],\n",
      "        [1.0800],\n",
      "        [1.0705],\n",
      "        [1.0705],\n",
      "        [1.0943],\n",
      "        [1.1036],\n",
      "        [1.0528],\n",
      "        [1.1113],\n",
      "        [1.0790],\n",
      "        [1.0562],\n",
      "        [1.0955],\n",
      "        [1.0744],\n",
      "        [1.0705],\n",
      "        [1.1059],\n",
      "        [1.0646],\n",
      "        [1.0931],\n",
      "        [1.1102],\n",
      "        [1.1026],\n",
      "        [1.0954],\n",
      "        [1.1000],\n",
      "        [1.0953],\n",
      "        [1.0735],\n",
      "        [1.0841],\n",
      "        [1.0941],\n",
      "        [1.1138],\n",
      "        [1.0977],\n",
      "        [1.0972],\n",
      "        [1.0468],\n",
      "        [1.0326],\n",
      "        [1.0937],\n",
      "        [1.0565],\n",
      "        [1.0768],\n",
      "        [1.0175],\n",
      "        [1.0833],\n",
      "        [1.0890],\n",
      "        [1.0818],\n",
      "        [1.1052],\n",
      "        [1.0864],\n",
      "        [1.0721],\n",
      "        [1.0677],\n",
      "        [1.0922],\n",
      "        [1.0797],\n",
      "        [1.0989],\n",
      "        [1.0689],\n",
      "        [1.1136],\n",
      "        [1.0973],\n",
      "        [1.0806],\n",
      "        [1.0971],\n",
      "        [1.0851],\n",
      "        [1.0670],\n",
      "        [1.0997],\n",
      "        [1.1108],\n",
      "        [1.1115],\n",
      "        [1.1096],\n",
      "        [1.1138],\n",
      "        [1.1035],\n",
      "        [1.1096],\n",
      "        [1.0716],\n",
      "        [1.0917],\n",
      "        [1.0754],\n",
      "        [1.0702],\n",
      "        [1.0946],\n",
      "        [1.0846],\n",
      "        [1.0977],\n",
      "        [1.1083],\n",
      "        [1.0878],\n",
      "        [1.0433],\n",
      "        [1.0908],\n",
      "        [1.0488],\n",
      "        [1.1004],\n",
      "        [1.0668],\n",
      "        [1.0959],\n",
      "        [1.1135],\n",
      "        [1.0766],\n",
      "        [1.0564],\n",
      "        [1.0751],\n",
      "        [1.1045],\n",
      "        [1.1043],\n",
      "        [1.1145],\n",
      "        [1.1121],\n",
      "        [1.0935],\n",
      "        [1.1099],\n",
      "        [1.0816],\n",
      "        [1.1054],\n",
      "        [1.0761],\n",
      "        [1.0599],\n",
      "        [1.0802],\n",
      "        [1.0788],\n",
      "        [1.0858],\n",
      "        [1.0763],\n",
      "        [1.0556],\n",
      "        [1.0392],\n",
      "        [1.0918],\n",
      "        [1.0974]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0903],\n",
      "        [1.1133],\n",
      "        [1.0711],\n",
      "        [1.0842],\n",
      "        [1.1146],\n",
      "        [1.1116],\n",
      "        [1.0510],\n",
      "        [1.0946],\n",
      "        [1.0909],\n",
      "        [1.0843],\n",
      "        [1.0702],\n",
      "        [1.0883],\n",
      "        [1.0704],\n",
      "        [1.1114],\n",
      "        [1.0991],\n",
      "        [1.0681],\n",
      "        [1.0577],\n",
      "        [1.0989],\n",
      "        [1.0618],\n",
      "        [1.0551],\n",
      "        [1.0716],\n",
      "        [1.0922],\n",
      "        [1.0689],\n",
      "        [1.1088],\n",
      "        [1.0914],\n",
      "        [1.0795],\n",
      "        [1.0957],\n",
      "        [1.0857],\n",
      "        [1.0850],\n",
      "        [1.0999],\n",
      "        [1.0860],\n",
      "        [1.1151],\n",
      "        [1.0842],\n",
      "        [1.0817],\n",
      "        [1.1014],\n",
      "        [1.0856],\n",
      "        [1.0452],\n",
      "        [1.1019],\n",
      "        [1.0775],\n",
      "        [1.0775],\n",
      "        [1.0941],\n",
      "        [1.0682],\n",
      "        [1.0836],\n",
      "        [1.0404],\n",
      "        [1.0778],\n",
      "        [1.0915],\n",
      "        [1.0656],\n",
      "        [1.0656],\n",
      "        [1.1027],\n",
      "        [1.0965],\n",
      "        [1.0656],\n",
      "        [1.1137],\n",
      "        [1.0751],\n",
      "        [1.0785],\n",
      "        [1.1117],\n",
      "        [1.0653],\n",
      "        [1.0831],\n",
      "        [1.0950],\n",
      "        [1.0375],\n",
      "        [1.0281],\n",
      "        [1.1059],\n",
      "        [1.0333],\n",
      "        [1.0543],\n",
      "        [1.0842],\n",
      "        [1.0977],\n",
      "        [1.1102],\n",
      "        [1.1088],\n",
      "        [1.1062],\n",
      "        [1.0803],\n",
      "        [1.0877],\n",
      "        [1.0668],\n",
      "        [1.1063],\n",
      "        [1.0946],\n",
      "        [1.0918],\n",
      "        [1.0957],\n",
      "        [1.0758],\n",
      "        [1.1027],\n",
      "        [1.0693],\n",
      "        [1.1093],\n",
      "        [1.0954],\n",
      "        [1.0999],\n",
      "        [1.1045],\n",
      "        [1.0732],\n",
      "        [1.0890],\n",
      "        [1.1081],\n",
      "        [1.0799],\n",
      "        [1.0913],\n",
      "        [1.1032],\n",
      "        [1.0747],\n",
      "        [1.0764],\n",
      "        [1.0746],\n",
      "        [1.0851],\n",
      "        [1.0967],\n",
      "        [1.0779],\n",
      "        [1.0648],\n",
      "        [1.0669],\n",
      "        [1.0412],\n",
      "        [1.1087],\n",
      "        [1.0864],\n",
      "        [1.0946],\n",
      "        [1.0884],\n",
      "        [0.6828],\n",
      "        [1.0990],\n",
      "        [1.0773],\n",
      "        [1.0651],\n",
      "        [1.0702],\n",
      "        [1.0854],\n",
      "        [1.0503],\n",
      "        [1.1111],\n",
      "        [1.1063],\n",
      "        [1.1147],\n",
      "        [1.0746],\n",
      "        [1.0548],\n",
      "        [1.0472],\n",
      "        [1.0708],\n",
      "        [1.1037],\n",
      "        [1.0943],\n",
      "        [1.0528],\n",
      "        [1.0833],\n",
      "        [1.0994],\n",
      "        [1.0888],\n",
      "        [1.1069],\n",
      "        [1.1136],\n",
      "        [1.1135],\n",
      "        [1.0906],\n",
      "        [1.0703],\n",
      "        [1.0212],\n",
      "        [1.1119]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0438],\n",
      "        [1.0511],\n",
      "        [1.0987],\n",
      "        [1.1161],\n",
      "        [1.0741],\n",
      "        [1.0499],\n",
      "        [1.0697],\n",
      "        [1.0884],\n",
      "        [1.0906],\n",
      "        [1.0865],\n",
      "        [1.0646],\n",
      "        [1.0875],\n",
      "        [1.0794],\n",
      "        [1.0953],\n",
      "        [1.0998],\n",
      "        [1.0818],\n",
      "        [1.0558],\n",
      "        [1.0423],\n",
      "        [1.0640],\n",
      "        [0.0963],\n",
      "        [1.0729],\n",
      "        [1.0367],\n",
      "        [1.0419],\n",
      "        [1.0702],\n",
      "        [1.0867],\n",
      "        [1.1075],\n",
      "        [1.0857],\n",
      "        [1.0713],\n",
      "        [0.9919],\n",
      "        [1.0489],\n",
      "        [1.0475],\n",
      "        [1.1088],\n",
      "        [1.0997],\n",
      "        [1.1152],\n",
      "        [1.0990],\n",
      "        [1.0424],\n",
      "        [1.0783],\n",
      "        [1.0880],\n",
      "        [1.1080],\n",
      "        [1.1019],\n",
      "        [1.0880],\n",
      "        [1.1084],\n",
      "        [1.1054],\n",
      "        [1.0833],\n",
      "        [1.0964],\n",
      "        [1.0908],\n",
      "        [1.0805],\n",
      "        [1.0894],\n",
      "        [1.0335],\n",
      "        [1.0974],\n",
      "        [1.0834],\n",
      "        [1.0429],\n",
      "        [1.0509],\n",
      "        [1.1014],\n",
      "        [1.0583],\n",
      "        [1.0697],\n",
      "        [1.0920],\n",
      "        [1.0892],\n",
      "        [1.0742],\n",
      "        [1.0990],\n",
      "        [1.0773],\n",
      "        [1.0801],\n",
      "        [1.0911],\n",
      "        [1.0830],\n",
      "        [1.0999],\n",
      "        [1.0722],\n",
      "        [1.1068],\n",
      "        [1.0735],\n",
      "        [1.0716],\n",
      "        [1.0961],\n",
      "        [1.0498],\n",
      "        [1.0731],\n",
      "        [1.1108],\n",
      "        [1.0888],\n",
      "        [1.0724],\n",
      "        [1.0920],\n",
      "        [1.0704],\n",
      "        [1.1144],\n",
      "        [1.0999],\n",
      "        [1.0828],\n",
      "        [1.0685],\n",
      "        [1.0877],\n",
      "        [1.1052],\n",
      "        [1.0817],\n",
      "        [1.0924],\n",
      "        [1.1075],\n",
      "        [1.0647],\n",
      "        [1.0994],\n",
      "        [1.1132],\n",
      "        [1.0927],\n",
      "        [1.1048],\n",
      "        [1.0901],\n",
      "        [1.0929],\n",
      "        [1.0527],\n",
      "        [1.1094],\n",
      "        [1.0974],\n",
      "        [1.0900],\n",
      "        [1.0870],\n",
      "        [1.0889],\n",
      "        [1.1135],\n",
      "        [1.0544],\n",
      "        [1.1018],\n",
      "        [1.1082],\n",
      "        [1.0874],\n",
      "        [1.1124],\n",
      "        [1.0862],\n",
      "        [1.0765],\n",
      "        [1.1147],\n",
      "        [1.0652],\n",
      "        [1.0707],\n",
      "        [1.0792],\n",
      "        [1.1101],\n",
      "        [1.1060],\n",
      "        [1.1174],\n",
      "        [1.1008],\n",
      "        [1.0499],\n",
      "        [1.0674],\n",
      "        [1.0816],\n",
      "        [1.0475],\n",
      "        [1.0757],\n",
      "        [1.1057],\n",
      "        [1.0713],\n",
      "        [1.0994],\n",
      "        [1.0887],\n",
      "        [1.1035],\n",
      "        [1.0929],\n",
      "        [1.0849],\n",
      "        [1.0735]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0930],\n",
      "        [1.0928],\n",
      "        [1.0969],\n",
      "        [1.0464],\n",
      "        [1.0884],\n",
      "        [1.0916],\n",
      "        [1.0751],\n",
      "        [1.0803],\n",
      "        [1.0427],\n",
      "        [1.1013],\n",
      "        [1.1022],\n",
      "        [1.0904],\n",
      "        [1.0525],\n",
      "        [1.0811],\n",
      "        [1.0653],\n",
      "        [1.1085],\n",
      "        [1.0672],\n",
      "        [1.0378],\n",
      "        [1.0705],\n",
      "        [1.1066],\n",
      "        [1.0666],\n",
      "        [1.0675],\n",
      "        [1.1082],\n",
      "        [1.0888],\n",
      "        [1.0872],\n",
      "        [1.1041],\n",
      "        [1.0873],\n",
      "        [1.0832],\n",
      "        [1.0739],\n",
      "        [1.0773],\n",
      "        [1.0828],\n",
      "        [1.0520],\n",
      "        [1.0766],\n",
      "        [1.0964],\n",
      "        [1.0699],\n",
      "        [1.1160],\n",
      "        [1.0884],\n",
      "        [1.1019],\n",
      "        [1.0633],\n",
      "        [1.0930],\n",
      "        [1.1005],\n",
      "        [1.1057],\n",
      "        [1.0899],\n",
      "        [1.0915],\n",
      "        [1.0496],\n",
      "        [1.0779],\n",
      "        [1.0681],\n",
      "        [1.0666],\n",
      "        [1.0829],\n",
      "        [1.0759],\n",
      "        [1.1101],\n",
      "        [1.1041],\n",
      "        [1.0596],\n",
      "        [1.0817],\n",
      "        [1.0651],\n",
      "        [1.1008],\n",
      "        [1.0650],\n",
      "        [1.0916],\n",
      "        [1.1037],\n",
      "        [1.0887],\n",
      "        [1.1095],\n",
      "        [1.0610],\n",
      "        [1.0947],\n",
      "        [1.0715],\n",
      "        [1.0950],\n",
      "        [1.0794],\n",
      "        [1.0723],\n",
      "        [1.0855],\n",
      "        [1.1085],\n",
      "        [1.1058],\n",
      "        [1.0323],\n",
      "        [1.1123],\n",
      "        [1.0743],\n",
      "        [1.0878],\n",
      "        [1.0986],\n",
      "        [1.0585],\n",
      "        [1.0662],\n",
      "        [1.0894],\n",
      "        [1.1009],\n",
      "        [1.0692],\n",
      "        [1.0807],\n",
      "        [1.0804],\n",
      "        [1.1109],\n",
      "        [1.0927],\n",
      "        [1.0639],\n",
      "        [1.1026],\n",
      "        [1.0535],\n",
      "        [1.1013],\n",
      "        [1.1013],\n",
      "        [1.0469],\n",
      "        [1.0588],\n",
      "        [1.0901],\n",
      "        [1.0873],\n",
      "        [1.0990],\n",
      "        [1.0804],\n",
      "        [1.0974],\n",
      "        [1.0626],\n",
      "        [1.0342],\n",
      "        [1.0819],\n",
      "        [1.0466],\n",
      "        [1.0666],\n",
      "        [1.0694],\n",
      "        [1.0698],\n",
      "        [1.0871],\n",
      "        [1.1140],\n",
      "        [1.0901],\n",
      "        [1.0444],\n",
      "        [1.0914],\n",
      "        [1.0675],\n",
      "        [1.0845],\n",
      "        [1.1124],\n",
      "        [1.0718],\n",
      "        [1.0915],\n",
      "        [1.0936],\n",
      "        [1.1156],\n",
      "        [1.1082],\n",
      "        [1.0979],\n",
      "        [1.0827],\n",
      "        [1.1010],\n",
      "        [1.1096],\n",
      "        [1.0681],\n",
      "        [1.0715],\n",
      "        [1.1007],\n",
      "        [1.0670],\n",
      "        [1.0677],\n",
      "        [1.0691],\n",
      "        [1.1131],\n",
      "        [1.0797]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1077],\n",
      "        [1.1135],\n",
      "        [1.0294],\n",
      "        [1.1077],\n",
      "        [1.0740],\n",
      "        [1.0682],\n",
      "        [1.0607],\n",
      "        [1.1063],\n",
      "        [1.0724],\n",
      "        [1.0838],\n",
      "        [1.0928],\n",
      "        [1.0725],\n",
      "        [1.1143],\n",
      "        [1.0263],\n",
      "        [1.0892],\n",
      "        [1.0896],\n",
      "        [1.1091],\n",
      "        [1.1065],\n",
      "        [1.1022],\n",
      "        [1.0892],\n",
      "        [1.1028],\n",
      "        [1.0948],\n",
      "        [1.0876],\n",
      "        [1.0543],\n",
      "        [1.0973],\n",
      "        [1.1135],\n",
      "        [1.0497],\n",
      "        [1.1100],\n",
      "        [1.0871],\n",
      "        [1.1062],\n",
      "        [1.1125],\n",
      "        [1.0899],\n",
      "        [1.0616],\n",
      "        [1.0858],\n",
      "        [1.1087],\n",
      "        [1.1023],\n",
      "        [1.1042],\n",
      "        [1.0819],\n",
      "        [1.0693],\n",
      "        [1.0722],\n",
      "        [1.0477],\n",
      "        [1.0949],\n",
      "        [1.0849],\n",
      "        [1.0610],\n",
      "        [1.0891],\n",
      "        [1.0773],\n",
      "        [1.0533],\n",
      "        [1.1014],\n",
      "        [1.0939],\n",
      "        [1.0816],\n",
      "        [1.0727],\n",
      "        [1.0800],\n",
      "        [1.1051],\n",
      "        [1.0936],\n",
      "        [1.0264],\n",
      "        [1.1135],\n",
      "        [1.1050],\n",
      "        [1.1008],\n",
      "        [1.1114],\n",
      "        [1.0855],\n",
      "        [1.0673],\n",
      "        [1.1021],\n",
      "        [1.0448],\n",
      "        [1.1013],\n",
      "        [1.0975],\n",
      "        [1.0665],\n",
      "        [1.1071],\n",
      "        [1.1098],\n",
      "        [1.1027],\n",
      "        [1.0923],\n",
      "        [1.1026],\n",
      "        [1.1110],\n",
      "        [1.0567],\n",
      "        [1.0994],\n",
      "        [1.1037],\n",
      "        [1.1105],\n",
      "        [1.1060],\n",
      "        [1.0004],\n",
      "        [1.0506],\n",
      "        [1.0799],\n",
      "        [1.1102],\n",
      "        [1.0449],\n",
      "        [1.1032],\n",
      "        [1.0917],\n",
      "        [1.0890],\n",
      "        [1.0664],\n",
      "        [1.1016],\n",
      "        [1.0652],\n",
      "        [1.0685],\n",
      "        [1.1058],\n",
      "        [1.0342],\n",
      "        [1.0828],\n",
      "        [1.0884],\n",
      "        [1.1005],\n",
      "        [1.0800],\n",
      "        [1.0896],\n",
      "        [1.0721],\n",
      "        [1.0889],\n",
      "        [1.1117],\n",
      "        [1.0697],\n",
      "        [1.1143],\n",
      "        [1.1005],\n",
      "        [1.0925],\n",
      "        [1.1016],\n",
      "        [1.0756],\n",
      "        [1.0958],\n",
      "        [1.0929],\n",
      "        [1.0877],\n",
      "        [1.0991],\n",
      "        [1.0662],\n",
      "        [1.1112],\n",
      "        [1.1060],\n",
      "        [1.0952],\n",
      "        [1.0464],\n",
      "        [1.0792],\n",
      "        [1.1119],\n",
      "        [1.0735],\n",
      "        [1.0920],\n",
      "        [1.1011],\n",
      "        [1.0484],\n",
      "        [1.1142],\n",
      "        [1.0824],\n",
      "        [0.1587],\n",
      "        [1.0453],\n",
      "        [1.1006],\n",
      "        [1.0701],\n",
      "        [1.0706],\n",
      "        [1.0999]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0922],\n",
      "        [1.0862],\n",
      "        [1.0697],\n",
      "        [1.0921],\n",
      "        [1.0952],\n",
      "        [1.0443],\n",
      "        [1.0885],\n",
      "        [1.0879],\n",
      "        [1.0661],\n",
      "        [1.0351],\n",
      "        [1.0869],\n",
      "        [1.1076],\n",
      "        [1.0807],\n",
      "        [1.0741],\n",
      "        [1.0847],\n",
      "        [1.1152],\n",
      "        [1.1061],\n",
      "        [1.0805],\n",
      "        [1.0563],\n",
      "        [1.1106],\n",
      "        [1.0872],\n",
      "        [1.1113],\n",
      "        [1.1135],\n",
      "        [1.1072],\n",
      "        [1.1110],\n",
      "        [1.0589],\n",
      "        [1.0268],\n",
      "        [1.0924],\n",
      "        [1.0935],\n",
      "        [1.0915],\n",
      "        [1.0898],\n",
      "        [1.0854],\n",
      "        [1.0881],\n",
      "        [1.0797],\n",
      "        [1.0858],\n",
      "        [1.0851],\n",
      "        [1.1056],\n",
      "        [1.0665],\n",
      "        [1.0822],\n",
      "        [1.0767],\n",
      "        [1.0672],\n",
      "        [1.0918],\n",
      "        [1.0498],\n",
      "        [1.0643],\n",
      "        [1.0448],\n",
      "        [1.0902],\n",
      "        [1.1023],\n",
      "        [1.0939],\n",
      "        [1.0924],\n",
      "        [1.0590],\n",
      "        [1.0399],\n",
      "        [1.0454],\n",
      "        [1.0928],\n",
      "        [1.0579],\n",
      "        [1.0832],\n",
      "        [1.0894],\n",
      "        [1.0839],\n",
      "        [1.0869],\n",
      "        [1.0765],\n",
      "        [1.0596],\n",
      "        [1.1037],\n",
      "        [1.0610],\n",
      "        [1.0933],\n",
      "        [1.1013],\n",
      "        [1.0907],\n",
      "        [1.1114],\n",
      "        [1.1001],\n",
      "        [1.0573],\n",
      "        [1.0845],\n",
      "        [1.1135],\n",
      "        [1.0935],\n",
      "        [1.1064],\n",
      "        [1.1049],\n",
      "        [1.0884],\n",
      "        [1.0806],\n",
      "        [1.0814],\n",
      "        [1.1194],\n",
      "        [1.1000],\n",
      "        [1.0830],\n",
      "        [1.1017],\n",
      "        [1.0926],\n",
      "        [1.1051],\n",
      "        [1.1143],\n",
      "        [1.1049],\n",
      "        [1.1120],\n",
      "        [1.0949],\n",
      "        [1.1044],\n",
      "        [1.1017],\n",
      "        [1.0647],\n",
      "        [1.0813],\n",
      "        [1.0286],\n",
      "        [1.0543],\n",
      "        [1.1064],\n",
      "        [1.0929],\n",
      "        [1.1130],\n",
      "        [1.1035],\n",
      "        [1.0721],\n",
      "        [1.0807],\n",
      "        [1.0906],\n",
      "        [1.0988],\n",
      "        [1.0485],\n",
      "        [1.0680],\n",
      "        [1.0671],\n",
      "        [1.0610],\n",
      "        [1.0760],\n",
      "        [1.1143],\n",
      "        [1.0680],\n",
      "        [1.1095],\n",
      "        [1.1036],\n",
      "        [1.0505],\n",
      "        [1.0852],\n",
      "        [1.0917],\n",
      "        [1.1028],\n",
      "        [1.0853],\n",
      "        [1.0933],\n",
      "        [1.0788],\n",
      "        [1.0809],\n",
      "        [1.0984],\n",
      "        [1.0860],\n",
      "        [1.1141],\n",
      "        [1.0503],\n",
      "        [1.0690],\n",
      "        [1.0757],\n",
      "        [1.0971],\n",
      "        [1.0679],\n",
      "        [1.1061],\n",
      "        [1.0685],\n",
      "        [1.1047]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0861],\n",
      "        [1.0568],\n",
      "        [1.0994],\n",
      "        [1.1010],\n",
      "        [1.0731],\n",
      "        [1.0373],\n",
      "        [1.0762],\n",
      "        [1.1101],\n",
      "        [1.0801],\n",
      "        [1.0795],\n",
      "        [1.1010],\n",
      "        [1.0954],\n",
      "        [1.1009],\n",
      "        [1.0949],\n",
      "        [1.0752],\n",
      "        [1.1036],\n",
      "        [1.0742],\n",
      "        [1.0532],\n",
      "        [1.0650],\n",
      "        [1.0920],\n",
      "        [1.0959],\n",
      "        [1.0861],\n",
      "        [1.0944],\n",
      "        [1.1083],\n",
      "        [1.0510],\n",
      "        [1.0983],\n",
      "        [1.0372],\n",
      "        [1.0751],\n",
      "        [1.0926],\n",
      "        [1.0943],\n",
      "        [1.0429],\n",
      "        [1.0996],\n",
      "        [1.0815],\n",
      "        [1.0790],\n",
      "        [1.0577],\n",
      "        [1.0312],\n",
      "        [1.0625],\n",
      "        [1.0929],\n",
      "        [1.0728],\n",
      "        [1.0947],\n",
      "        [1.0880],\n",
      "        [1.0787],\n",
      "        [1.0917],\n",
      "        [1.0426],\n",
      "        [1.0621],\n",
      "        [1.0723],\n",
      "        [1.0796],\n",
      "        [1.0994],\n",
      "        [1.1104],\n",
      "        [1.1024],\n",
      "        [1.0711],\n",
      "        [1.0891],\n",
      "        [1.0523],\n",
      "        [1.0881],\n",
      "        [1.1097],\n",
      "        [1.0982],\n",
      "        [1.1087],\n",
      "        [1.0853],\n",
      "        [1.0756],\n",
      "        [1.0536],\n",
      "        [1.0893],\n",
      "        [1.0473],\n",
      "        [1.0972],\n",
      "        [1.0602],\n",
      "        [1.1101],\n",
      "        [1.0954],\n",
      "        [1.0359],\n",
      "        [1.0942],\n",
      "        [1.0921],\n",
      "        [1.0689],\n",
      "        [1.0985],\n",
      "        [1.0288],\n",
      "        [1.0934],\n",
      "        [1.0852],\n",
      "        [1.0973],\n",
      "        [1.0932],\n",
      "        [1.0761],\n",
      "        [1.0361],\n",
      "        [1.1019],\n",
      "        [1.1092],\n",
      "        [1.0832],\n",
      "        [1.0976],\n",
      "        [1.1126],\n",
      "        [1.0904],\n",
      "        [1.1009],\n",
      "        [1.0917],\n",
      "        [0.2965],\n",
      "        [1.0788],\n",
      "        [1.0821],\n",
      "        [1.0441],\n",
      "        [1.0904],\n",
      "        [1.0977],\n",
      "        [1.1089],\n",
      "        [1.0731],\n",
      "        [1.1163],\n",
      "        [1.0867],\n",
      "        [1.0704],\n",
      "        [1.1079],\n",
      "        [1.0771],\n",
      "        [1.0789],\n",
      "        [1.0447],\n",
      "        [1.0440],\n",
      "        [1.0640],\n",
      "        [1.0700],\n",
      "        [1.0665],\n",
      "        [1.0905],\n",
      "        [1.0934],\n",
      "        [1.0607],\n",
      "        [1.0753],\n",
      "        [1.0936],\n",
      "        [1.1135],\n",
      "        [1.0552],\n",
      "        [1.0633],\n",
      "        [1.0713],\n",
      "        [1.0526],\n",
      "        [1.1040],\n",
      "        [1.0903],\n",
      "        [1.0754],\n",
      "        [1.1065],\n",
      "        [1.1013],\n",
      "        [1.0818],\n",
      "        [1.0790],\n",
      "        [1.1030],\n",
      "        [1.0515],\n",
      "        [1.0883],\n",
      "        [1.0763],\n",
      "        [1.0778],\n",
      "        [0.3765]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1112],\n",
      "        [1.0901],\n",
      "        [1.0621],\n",
      "        [1.0782]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  48 | lr 0.00010 train_loss 2.12399 | val_loss 2.29403 | val_rmse 1.51461\n",
      "tensor([[1.0572],\n",
      "        [1.0923],\n",
      "        [1.0922],\n",
      "        [1.0662],\n",
      "        [1.1044],\n",
      "        [1.0764],\n",
      "        [1.1039],\n",
      "        [1.0930],\n",
      "        [1.0507],\n",
      "        [1.0921],\n",
      "        [1.0899],\n",
      "        [1.0822],\n",
      "        [1.0814],\n",
      "        [1.1058],\n",
      "        [1.1139],\n",
      "        [1.0754],\n",
      "        [1.0629],\n",
      "        [1.0225],\n",
      "        [1.0986],\n",
      "        [1.1119],\n",
      "        [1.1123],\n",
      "        [1.0646],\n",
      "        [1.0818],\n",
      "        [1.0919],\n",
      "        [1.0996],\n",
      "        [1.0864],\n",
      "        [1.0984],\n",
      "        [1.1112],\n",
      "        [1.0865],\n",
      "        [1.0793],\n",
      "        [1.0530],\n",
      "        [1.1082],\n",
      "        [1.0937],\n",
      "        [1.0125],\n",
      "        [1.1065],\n",
      "        [1.1142],\n",
      "        [1.0984],\n",
      "        [1.1080],\n",
      "        [1.1086],\n",
      "        [1.0911],\n",
      "        [1.0968],\n",
      "        [1.0373],\n",
      "        [1.0677],\n",
      "        [1.0726],\n",
      "        [1.0800],\n",
      "        [1.0876],\n",
      "        [1.1138],\n",
      "        [1.0799],\n",
      "        [1.1044],\n",
      "        [1.0768],\n",
      "        [1.0662],\n",
      "        [1.0639],\n",
      "        [1.0956],\n",
      "        [1.0567],\n",
      "        [1.0881],\n",
      "        [1.1023],\n",
      "        [1.0804],\n",
      "        [1.0890],\n",
      "        [1.1088],\n",
      "        [1.0414],\n",
      "        [1.0313],\n",
      "        [0.0638],\n",
      "        [1.0885],\n",
      "        [1.0667],\n",
      "        [1.1145],\n",
      "        [1.0994],\n",
      "        [1.0761],\n",
      "        [1.0322],\n",
      "        [1.0766],\n",
      "        [1.0984],\n",
      "        [1.1013],\n",
      "        [1.0540],\n",
      "        [1.0981],\n",
      "        [1.0518],\n",
      "        [1.0467],\n",
      "        [1.0993],\n",
      "        [1.0439],\n",
      "        [1.1058],\n",
      "        [1.1112],\n",
      "        [1.0989],\n",
      "        [1.0608],\n",
      "        [1.1101],\n",
      "        [1.0769],\n",
      "        [1.0538],\n",
      "        [1.0807],\n",
      "        [1.0920],\n",
      "        [1.0991],\n",
      "        [1.0874],\n",
      "        [1.1001],\n",
      "        [1.0796],\n",
      "        [1.0628],\n",
      "        [1.1088],\n",
      "        [1.1028],\n",
      "        [1.1025],\n",
      "        [1.0681],\n",
      "        [1.0121],\n",
      "        [1.0731],\n",
      "        [1.0559],\n",
      "        [1.0952],\n",
      "        [1.0713],\n",
      "        [1.0557],\n",
      "        [1.0580],\n",
      "        [1.0648],\n",
      "        [1.0985],\n",
      "        [1.0851],\n",
      "        [1.0953],\n",
      "        [1.1042],\n",
      "        [1.0507],\n",
      "        [1.0709],\n",
      "        [1.0421],\n",
      "        [1.1025],\n",
      "        [1.0941],\n",
      "        [1.0798],\n",
      "        [1.0861],\n",
      "        [1.0996],\n",
      "        [1.1100],\n",
      "        [1.0809],\n",
      "        [1.0732],\n",
      "        [1.0616],\n",
      "        [1.0757],\n",
      "        [1.1031],\n",
      "        [1.0996],\n",
      "        [1.0493],\n",
      "        [1.1049],\n",
      "        [1.0985],\n",
      "        [1.0870],\n",
      "        [1.0816],\n",
      "        [1.1019]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0640],\n",
      "        [1.0914],\n",
      "        [1.0897],\n",
      "        [1.0595],\n",
      "        [1.0555],\n",
      "        [1.0827],\n",
      "        [1.0973],\n",
      "        [1.0783],\n",
      "        [1.0859],\n",
      "        [1.0792],\n",
      "        [1.0871],\n",
      "        [1.0864],\n",
      "        [1.0562],\n",
      "        [1.0993],\n",
      "        [1.1140],\n",
      "        [1.1025],\n",
      "        [1.0974],\n",
      "        [1.0528],\n",
      "        [1.0842],\n",
      "        [1.0968],\n",
      "        [1.0999],\n",
      "        [1.1095],\n",
      "        [1.0799],\n",
      "        [1.0879],\n",
      "        [1.1052],\n",
      "        [1.1017],\n",
      "        [1.0929],\n",
      "        [1.0348],\n",
      "        [1.0937],\n",
      "        [1.0802],\n",
      "        [1.1098],\n",
      "        [1.0945],\n",
      "        [1.1147],\n",
      "        [1.0785],\n",
      "        [1.0817],\n",
      "        [1.0390],\n",
      "        [1.0994],\n",
      "        [1.1104],\n",
      "        [1.0882],\n",
      "        [1.0804],\n",
      "        [1.0963],\n",
      "        [1.0864],\n",
      "        [1.1052],\n",
      "        [1.0407],\n",
      "        [1.0904],\n",
      "        [1.1042],\n",
      "        [1.0732],\n",
      "        [1.0998],\n",
      "        [1.0659],\n",
      "        [1.0743],\n",
      "        [1.0950],\n",
      "        [1.1034],\n",
      "        [1.0837],\n",
      "        [1.0521],\n",
      "        [1.1125],\n",
      "        [1.0679],\n",
      "        [1.0837],\n",
      "        [1.0893],\n",
      "        [1.1038],\n",
      "        [1.0875],\n",
      "        [1.1082],\n",
      "        [1.1031],\n",
      "        [1.0878],\n",
      "        [1.0376],\n",
      "        [1.0652],\n",
      "        [1.0614],\n",
      "        [1.0922],\n",
      "        [1.0569],\n",
      "        [1.0640],\n",
      "        [1.0843],\n",
      "        [1.0848],\n",
      "        [1.1064],\n",
      "        [1.1098],\n",
      "        [1.1007],\n",
      "        [1.0382],\n",
      "        [1.0701],\n",
      "        [1.0862],\n",
      "        [1.0906],\n",
      "        [1.0928],\n",
      "        [1.1030],\n",
      "        [1.0665],\n",
      "        [1.0978],\n",
      "        [1.0714],\n",
      "        [1.0665],\n",
      "        [1.0644],\n",
      "        [1.0753],\n",
      "        [1.0581],\n",
      "        [1.0568],\n",
      "        [1.0925],\n",
      "        [1.0772],\n",
      "        [1.1002],\n",
      "        [1.1115],\n",
      "        [1.0800],\n",
      "        [1.1009],\n",
      "        [1.0924],\n",
      "        [1.0313],\n",
      "        [1.0942],\n",
      "        [1.0830],\n",
      "        [1.0737],\n",
      "        [1.0840],\n",
      "        [1.1141],\n",
      "        [1.0892],\n",
      "        [1.0875],\n",
      "        [1.1136],\n",
      "        [1.0668],\n",
      "        [1.0571],\n",
      "        [1.0438],\n",
      "        [1.0718],\n",
      "        [1.1017],\n",
      "        [1.0361],\n",
      "        [1.0710],\n",
      "        [1.0567],\n",
      "        [1.0630],\n",
      "        [1.1001],\n",
      "        [1.0842],\n",
      "        [1.0979],\n",
      "        [1.0590],\n",
      "        [1.1089],\n",
      "        [1.0549],\n",
      "        [1.0870],\n",
      "        [1.0662],\n",
      "        [1.1117],\n",
      "        [1.0721],\n",
      "        [1.0656],\n",
      "        [1.0903],\n",
      "        [1.0582],\n",
      "        [1.1022],\n",
      "        [1.0818]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1039],\n",
      "        [1.1131],\n",
      "        [1.0729],\n",
      "        [1.0762],\n",
      "        [1.0869],\n",
      "        [1.0932],\n",
      "        [1.0163],\n",
      "        [1.0723],\n",
      "        [1.0922],\n",
      "        [1.1070],\n",
      "        [1.0808],\n",
      "        [1.0884],\n",
      "        [1.1051],\n",
      "        [1.0291],\n",
      "        [1.1007],\n",
      "        [1.1095],\n",
      "        [1.0927],\n",
      "        [1.1126],\n",
      "        [1.0783],\n",
      "        [1.0926],\n",
      "        [1.0945],\n",
      "        [1.0667],\n",
      "        [1.0873],\n",
      "        [1.1152],\n",
      "        [1.0852],\n",
      "        [1.1027],\n",
      "        [1.0792],\n",
      "        [1.0883],\n",
      "        [1.1101],\n",
      "        [1.0464],\n",
      "        [1.0574],\n",
      "        [1.0706],\n",
      "        [1.1144],\n",
      "        [1.1043],\n",
      "        [1.1085],\n",
      "        [1.0687],\n",
      "        [1.0644],\n",
      "        [1.0554],\n",
      "        [1.1150],\n",
      "        [1.0881],\n",
      "        [1.1074],\n",
      "        [1.0520],\n",
      "        [1.0874],\n",
      "        [1.0565],\n",
      "        [1.0878],\n",
      "        [1.0928],\n",
      "        [1.1060],\n",
      "        [1.0958],\n",
      "        [1.0670],\n",
      "        [1.1030],\n",
      "        [1.0712],\n",
      "        [1.0965],\n",
      "        [1.1031],\n",
      "        [1.0719],\n",
      "        [1.0977],\n",
      "        [1.0648],\n",
      "        [1.1143],\n",
      "        [1.0807],\n",
      "        [1.1150],\n",
      "        [1.1095],\n",
      "        [1.1008],\n",
      "        [1.0524],\n",
      "        [1.0757],\n",
      "        [1.0702],\n",
      "        [1.0712],\n",
      "        [1.0770],\n",
      "        [1.0623],\n",
      "        [1.0697],\n",
      "        [1.0963],\n",
      "        [1.0900],\n",
      "        [1.1047],\n",
      "        [1.0986],\n",
      "        [1.1096],\n",
      "        [1.0756],\n",
      "        [1.1044],\n",
      "        [1.1142],\n",
      "        [1.0878],\n",
      "        [1.0447],\n",
      "        [1.0875],\n",
      "        [1.0916],\n",
      "        [1.0856],\n",
      "        [1.0493],\n",
      "        [1.1088],\n",
      "        [1.0949],\n",
      "        [1.1087],\n",
      "        [1.1144],\n",
      "        [1.1082],\n",
      "        [1.1021],\n",
      "        [1.0934],\n",
      "        [1.0863],\n",
      "        [1.0756],\n",
      "        [1.0976],\n",
      "        [1.0921],\n",
      "        [1.0780],\n",
      "        [1.0687],\n",
      "        [1.0925],\n",
      "        [1.0893],\n",
      "        [1.0984],\n",
      "        [1.0877],\n",
      "        [1.0309],\n",
      "        [1.0882],\n",
      "        [1.0681],\n",
      "        [1.0618],\n",
      "        [1.0719],\n",
      "        [1.0959],\n",
      "        [1.0870],\n",
      "        [1.0944],\n",
      "        [1.0690],\n",
      "        [1.0906],\n",
      "        [1.0779],\n",
      "        [1.0796],\n",
      "        [1.1078],\n",
      "        [1.0974],\n",
      "        [1.1032],\n",
      "        [1.0736],\n",
      "        [1.0971],\n",
      "        [1.1090],\n",
      "        [1.0837],\n",
      "        [1.1039],\n",
      "        [1.0919],\n",
      "        [1.0820],\n",
      "        [1.0909],\n",
      "        [1.1149],\n",
      "        [1.0943],\n",
      "        [1.0864],\n",
      "        [1.0302],\n",
      "        [1.0939],\n",
      "        [1.1076]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0997],\n",
      "        [1.0819],\n",
      "        [1.0982],\n",
      "        [1.0441],\n",
      "        [1.0939],\n",
      "        [1.1134],\n",
      "        [1.0646],\n",
      "        [1.0785],\n",
      "        [1.1019],\n",
      "        [1.0730],\n",
      "        [1.0632],\n",
      "        [1.0752],\n",
      "        [1.0791],\n",
      "        [1.1100],\n",
      "        [1.0795],\n",
      "        [1.1091],\n",
      "        [1.0947],\n",
      "        [1.0850],\n",
      "        [1.1028],\n",
      "        [1.0708],\n",
      "        [1.0784],\n",
      "        [1.0885],\n",
      "        [1.1147],\n",
      "        [1.0936],\n",
      "        [1.0603],\n",
      "        [1.0826],\n",
      "        [1.0973],\n",
      "        [1.0804],\n",
      "        [1.0997],\n",
      "        [1.0923],\n",
      "        [1.1062],\n",
      "        [1.0915],\n",
      "        [1.0538],\n",
      "        [1.0551],\n",
      "        [1.0901],\n",
      "        [1.0584],\n",
      "        [1.0579],\n",
      "        [1.0479],\n",
      "        [1.0972],\n",
      "        [1.0962],\n",
      "        [1.1022],\n",
      "        [1.1061],\n",
      "        [1.0897],\n",
      "        [1.0704],\n",
      "        [1.1006],\n",
      "        [1.1018],\n",
      "        [1.0906],\n",
      "        [1.1022],\n",
      "        [1.1062],\n",
      "        [1.1122],\n",
      "        [1.0903],\n",
      "        [1.0403],\n",
      "        [1.0938],\n",
      "        [1.0702],\n",
      "        [1.1110],\n",
      "        [1.0959],\n",
      "        [1.0968],\n",
      "        [1.0837],\n",
      "        [1.1091],\n",
      "        [1.1086],\n",
      "        [1.0967],\n",
      "        [1.1003],\n",
      "        [1.0944],\n",
      "        [1.0777],\n",
      "        [1.0800],\n",
      "        [1.0992],\n",
      "        [1.0895],\n",
      "        [1.0951],\n",
      "        [1.0779],\n",
      "        [1.0542],\n",
      "        [1.0900],\n",
      "        [1.0364],\n",
      "        [1.0297],\n",
      "        [1.0615],\n",
      "        [1.1064],\n",
      "        [1.0452],\n",
      "        [1.0695],\n",
      "        [1.0499],\n",
      "        [1.0479],\n",
      "        [1.1125],\n",
      "        [1.0811],\n",
      "        [1.0624],\n",
      "        [1.0786],\n",
      "        [1.0848],\n",
      "        [1.0486],\n",
      "        [1.1115],\n",
      "        [1.0958],\n",
      "        [1.0760],\n",
      "        [1.0974],\n",
      "        [1.1160],\n",
      "        [1.0537],\n",
      "        [1.0785],\n",
      "        [1.0977],\n",
      "        [1.0983],\n",
      "        [1.0825],\n",
      "        [1.0483],\n",
      "        [1.0470],\n",
      "        [1.0625],\n",
      "        [1.1144],\n",
      "        [1.0626],\n",
      "        [1.0884],\n",
      "        [1.0649],\n",
      "        [1.1153],\n",
      "        [1.0903],\n",
      "        [1.1121],\n",
      "        [1.1110],\n",
      "        [1.1032],\n",
      "        [1.0717],\n",
      "        [1.0832],\n",
      "        [1.0786],\n",
      "        [1.0749],\n",
      "        [1.0836],\n",
      "        [1.0543],\n",
      "        [1.0700],\n",
      "        [1.0719],\n",
      "        [1.1145],\n",
      "        [1.1089],\n",
      "        [1.0679],\n",
      "        [1.1050],\n",
      "        [1.0742],\n",
      "        [1.1056],\n",
      "        [1.0974],\n",
      "        [1.0936],\n",
      "        [1.0781],\n",
      "        [1.0878],\n",
      "        [1.0587],\n",
      "        [1.0915],\n",
      "        [1.0933]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0941],\n",
      "        [1.1072],\n",
      "        [1.0613],\n",
      "        [1.0648],\n",
      "        [1.0937],\n",
      "        [1.1057],\n",
      "        [1.1057],\n",
      "        [1.1045],\n",
      "        [1.0530],\n",
      "        [1.0985],\n",
      "        [1.1175],\n",
      "        [1.0744],\n",
      "        [1.0902],\n",
      "        [1.0992],\n",
      "        [1.0686],\n",
      "        [1.0897],\n",
      "        [1.0923],\n",
      "        [1.0410],\n",
      "        [1.0868],\n",
      "        [1.0921],\n",
      "        [1.1141],\n",
      "        [1.0754],\n",
      "        [1.0737],\n",
      "        [1.0889],\n",
      "        [1.1100],\n",
      "        [1.0987],\n",
      "        [1.1149],\n",
      "        [1.1098],\n",
      "        [1.1077],\n",
      "        [1.0877],\n",
      "        [1.0953],\n",
      "        [1.0814],\n",
      "        [1.1032],\n",
      "        [1.1041],\n",
      "        [1.0783],\n",
      "        [1.0347],\n",
      "        [1.1093],\n",
      "        [1.0690],\n",
      "        [1.0523],\n",
      "        [1.0604],\n",
      "        [1.0896],\n",
      "        [1.1079],\n",
      "        [1.1014],\n",
      "        [1.0989],\n",
      "        [1.0380],\n",
      "        [1.0957],\n",
      "        [1.0541],\n",
      "        [1.0406],\n",
      "        [1.0835],\n",
      "        [1.0750],\n",
      "        [1.0800],\n",
      "        [1.0379],\n",
      "        [1.0852],\n",
      "        [1.0940],\n",
      "        [1.0551],\n",
      "        [1.1028],\n",
      "        [1.0275],\n",
      "        [1.1149],\n",
      "        [1.0679],\n",
      "        [1.1003],\n",
      "        [1.0661],\n",
      "        [1.0900],\n",
      "        [1.0751],\n",
      "        [1.0400],\n",
      "        [1.1058],\n",
      "        [1.0624],\n",
      "        [1.0948],\n",
      "        [1.1013],\n",
      "        [1.0929],\n",
      "        [1.1033],\n",
      "        [1.1000],\n",
      "        [1.0813],\n",
      "        [1.0998],\n",
      "        [1.0683],\n",
      "        [1.0940],\n",
      "        [1.1134],\n",
      "        [1.0828],\n",
      "        [1.0651],\n",
      "        [1.1001],\n",
      "        [1.0973],\n",
      "        [1.0870],\n",
      "        [1.0920],\n",
      "        [1.0448],\n",
      "        [1.0312],\n",
      "        [1.0716],\n",
      "        [1.0968],\n",
      "        [1.0935],\n",
      "        [1.0248],\n",
      "        [1.0615],\n",
      "        [1.0819],\n",
      "        [1.0993],\n",
      "        [1.0625],\n",
      "        [1.0835],\n",
      "        [1.0891],\n",
      "        [1.1091],\n",
      "        [1.1100],\n",
      "        [1.0885],\n",
      "        [1.0757],\n",
      "        [1.0840],\n",
      "        [1.0946],\n",
      "        [1.0624],\n",
      "        [1.0772],\n",
      "        [1.0857],\n",
      "        [1.0571],\n",
      "        [1.0938],\n",
      "        [1.0983],\n",
      "        [1.1137],\n",
      "        [1.0875],\n",
      "        [1.0381],\n",
      "        [1.1088],\n",
      "        [1.1143],\n",
      "        [1.1149],\n",
      "        [1.0999],\n",
      "        [1.0703],\n",
      "        [1.0568],\n",
      "        [1.0644],\n",
      "        [1.0841],\n",
      "        [1.1017],\n",
      "        [1.0965],\n",
      "        [1.0633],\n",
      "        [1.0570],\n",
      "        [1.0960],\n",
      "        [1.0569],\n",
      "        [1.1063],\n",
      "        [1.0540],\n",
      "        [1.0800],\n",
      "        [1.0997],\n",
      "        [1.1149]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0928],\n",
      "        [1.0563],\n",
      "        [1.0760],\n",
      "        [1.0607],\n",
      "        [1.0668],\n",
      "        [1.1155],\n",
      "        [1.0771],\n",
      "        [1.0932],\n",
      "        [1.0969],\n",
      "        [1.1138],\n",
      "        [1.0642],\n",
      "        [1.1129],\n",
      "        [1.1031],\n",
      "        [1.0377],\n",
      "        [1.0796],\n",
      "        [1.0813],\n",
      "        [1.0606],\n",
      "        [1.1133],\n",
      "        [1.0862],\n",
      "        [1.0618],\n",
      "        [1.0683],\n",
      "        [1.0601],\n",
      "        [1.0985],\n",
      "        [1.0979],\n",
      "        [1.0986],\n",
      "        [1.0905],\n",
      "        [1.0607],\n",
      "        [1.0681],\n",
      "        [1.0834],\n",
      "        [1.1053],\n",
      "        [1.0722],\n",
      "        [1.0884],\n",
      "        [1.1001],\n",
      "        [1.0523],\n",
      "        [1.0917],\n",
      "        [1.0720],\n",
      "        [1.0978],\n",
      "        [1.0452],\n",
      "        [1.0852],\n",
      "        [1.0988],\n",
      "        [1.0934],\n",
      "        [1.0644],\n",
      "        [1.0554],\n",
      "        [1.0870],\n",
      "        [1.0843],\n",
      "        [1.0976],\n",
      "        [1.0879],\n",
      "        [1.0906],\n",
      "        [1.0864],\n",
      "        [1.0878],\n",
      "        [1.1055],\n",
      "        [1.0813],\n",
      "        [1.0929],\n",
      "        [1.0969],\n",
      "        [1.1031],\n",
      "        [1.0980],\n",
      "        [1.0611],\n",
      "        [1.0792],\n",
      "        [1.0909],\n",
      "        [1.1005],\n",
      "        [0.9809],\n",
      "        [1.0982],\n",
      "        [1.0861],\n",
      "        [1.0576],\n",
      "        [1.1051],\n",
      "        [1.1128],\n",
      "        [1.0987],\n",
      "        [1.0908],\n",
      "        [1.0774],\n",
      "        [1.1036],\n",
      "        [1.0948],\n",
      "        [1.0995],\n",
      "        [1.0484],\n",
      "        [1.1064],\n",
      "        [1.0586],\n",
      "        [1.1026],\n",
      "        [1.1111],\n",
      "        [1.0546],\n",
      "        [1.0418],\n",
      "        [1.1095],\n",
      "        [1.0720],\n",
      "        [1.0655],\n",
      "        [1.1068],\n",
      "        [1.0826],\n",
      "        [1.0627],\n",
      "        [1.0977],\n",
      "        [1.0627],\n",
      "        [1.1187],\n",
      "        [1.1068],\n",
      "        [1.1145],\n",
      "        [1.1035],\n",
      "        [1.0907],\n",
      "        [1.1073],\n",
      "        [1.0970],\n",
      "        [1.1094],\n",
      "        [1.1106],\n",
      "        [1.0885],\n",
      "        [1.0672],\n",
      "        [1.1028],\n",
      "        [1.1015],\n",
      "        [1.0517],\n",
      "        [1.0876],\n",
      "        [1.0870],\n",
      "        [0.1892],\n",
      "        [1.0870],\n",
      "        [1.0814],\n",
      "        [1.0348],\n",
      "        [1.0751],\n",
      "        [1.0570],\n",
      "        [1.0957],\n",
      "        [1.1049],\n",
      "        [1.1071],\n",
      "        [1.1010],\n",
      "        [1.0863],\n",
      "        [1.1167],\n",
      "        [1.0638],\n",
      "        [1.0941],\n",
      "        [1.0699],\n",
      "        [1.0905],\n",
      "        [1.0693],\n",
      "        [1.0558],\n",
      "        [1.1002],\n",
      "        [1.1037],\n",
      "        [1.0596],\n",
      "        [1.0747],\n",
      "        [1.0647],\n",
      "        [1.0679],\n",
      "        [1.1091]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0808],\n",
      "        [1.0831],\n",
      "        [1.0439],\n",
      "        [1.1083],\n",
      "        [1.1121],\n",
      "        [1.1113],\n",
      "        [1.1068],\n",
      "        [1.0281],\n",
      "        [1.1065],\n",
      "        [1.0795],\n",
      "        [1.1003],\n",
      "        [1.0910],\n",
      "        [1.0809],\n",
      "        [1.0678],\n",
      "        [1.0905],\n",
      "        [1.0937],\n",
      "        [1.0453],\n",
      "        [1.1025],\n",
      "        [1.0520],\n",
      "        [1.0592],\n",
      "        [1.0573],\n",
      "        [1.0995],\n",
      "        [1.0914],\n",
      "        [1.0948],\n",
      "        [1.0953],\n",
      "        [1.0832],\n",
      "        [1.0817],\n",
      "        [1.0444],\n",
      "        [1.0421],\n",
      "        [1.0770],\n",
      "        [1.0948],\n",
      "        [1.1036],\n",
      "        [1.1089],\n",
      "        [1.0734],\n",
      "        [1.0795],\n",
      "        [1.0984],\n",
      "        [1.0638],\n",
      "        [1.0952],\n",
      "        [1.0753],\n",
      "        [1.0769],\n",
      "        [1.0508],\n",
      "        [1.1183],\n",
      "        [1.1054],\n",
      "        [1.0917],\n",
      "        [1.0793],\n",
      "        [1.0749],\n",
      "        [1.1004],\n",
      "        [1.1106],\n",
      "        [1.1042],\n",
      "        [1.0754],\n",
      "        [1.0860],\n",
      "        [1.0382],\n",
      "        [1.0787],\n",
      "        [1.0301],\n",
      "        [1.0725],\n",
      "        [1.0550],\n",
      "        [1.0717],\n",
      "        [1.0966],\n",
      "        [1.0989],\n",
      "        [1.0832],\n",
      "        [1.0664],\n",
      "        [1.0958],\n",
      "        [1.0846],\n",
      "        [1.0807],\n",
      "        [1.0856],\n",
      "        [1.1134],\n",
      "        [1.0998],\n",
      "        [1.0684],\n",
      "        [1.1150],\n",
      "        [1.1013],\n",
      "        [1.0833],\n",
      "        [1.0894],\n",
      "        [1.1057],\n",
      "        [1.0918],\n",
      "        [1.0710],\n",
      "        [1.0703],\n",
      "        [1.1067],\n",
      "        [1.0626],\n",
      "        [1.0950],\n",
      "        [0.4711],\n",
      "        [1.1036],\n",
      "        [1.0418],\n",
      "        [1.0322],\n",
      "        [1.0478],\n",
      "        [1.0771],\n",
      "        [1.0412],\n",
      "        [1.0797],\n",
      "        [1.0657],\n",
      "        [1.0662],\n",
      "        [1.0699],\n",
      "        [1.0365],\n",
      "        [1.0856],\n",
      "        [1.0998],\n",
      "        [1.1116],\n",
      "        [1.0845],\n",
      "        [1.0810],\n",
      "        [1.1084],\n",
      "        [1.0610],\n",
      "        [1.0672],\n",
      "        [1.0874],\n",
      "        [1.1004],\n",
      "        [1.0812],\n",
      "        [1.0859],\n",
      "        [1.0820],\n",
      "        [1.1149],\n",
      "        [1.1055],\n",
      "        [1.1001],\n",
      "        [1.0908],\n",
      "        [1.0490],\n",
      "        [1.0752],\n",
      "        [1.1041],\n",
      "        [1.0689],\n",
      "        [1.1056],\n",
      "        [1.0836],\n",
      "        [1.0992],\n",
      "        [1.0966],\n",
      "        [1.0789],\n",
      "        [1.0713],\n",
      "        [1.0930],\n",
      "        [1.0986],\n",
      "        [1.1017],\n",
      "        [1.1019],\n",
      "        [1.0551],\n",
      "        [1.1028],\n",
      "        [1.0849],\n",
      "        [1.0779],\n",
      "        [1.0781],\n",
      "        [1.0389]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0873],\n",
      "        [1.0926],\n",
      "        [1.0836],\n",
      "        [1.0838]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  49 | lr 0.00010 train_loss 2.12404 | val_loss 2.29368 | val_rmse 1.51449\n",
      "tensor([[1.1070],\n",
      "        [1.0975],\n",
      "        [1.0583],\n",
      "        [1.1010],\n",
      "        [1.1150],\n",
      "        [1.0867],\n",
      "        [1.0866],\n",
      "        [1.1136],\n",
      "        [1.1124],\n",
      "        [1.0868],\n",
      "        [1.0646],\n",
      "        [1.0933],\n",
      "        [1.0873],\n",
      "        [1.0868],\n",
      "        [1.0849],\n",
      "        [1.0877],\n",
      "        [1.0992],\n",
      "        [1.1074],\n",
      "        [1.0837],\n",
      "        [1.0483],\n",
      "        [1.1007],\n",
      "        [1.1105],\n",
      "        [1.0911],\n",
      "        [1.0830],\n",
      "        [1.0473],\n",
      "        [1.0927],\n",
      "        [1.1151],\n",
      "        [1.1144],\n",
      "        [1.0933],\n",
      "        [1.0987],\n",
      "        [1.0981],\n",
      "        [1.1112],\n",
      "        [1.0784],\n",
      "        [1.0901],\n",
      "        [1.0183],\n",
      "        [1.0877],\n",
      "        [1.1005],\n",
      "        [1.0854],\n",
      "        [1.0851],\n",
      "        [1.0282],\n",
      "        [1.0940],\n",
      "        [1.0863],\n",
      "        [1.0845],\n",
      "        [1.0784],\n",
      "        [1.0764],\n",
      "        [1.1163],\n",
      "        [1.0863],\n",
      "        [1.0811],\n",
      "        [1.0975],\n",
      "        [1.1157],\n",
      "        [1.0755],\n",
      "        [1.1034],\n",
      "        [1.0542],\n",
      "        [1.1088],\n",
      "        [1.0774],\n",
      "        [1.0870],\n",
      "        [1.0898],\n",
      "        [1.1059],\n",
      "        [1.0904],\n",
      "        [1.0850],\n",
      "        [1.0926],\n",
      "        [1.0425],\n",
      "        [1.0942],\n",
      "        [1.0635],\n",
      "        [1.1019],\n",
      "        [1.1040],\n",
      "        [1.1054],\n",
      "        [1.0936],\n",
      "        [1.0913],\n",
      "        [1.0316],\n",
      "        [1.1024],\n",
      "        [1.0748],\n",
      "        [1.0862],\n",
      "        [1.0764],\n",
      "        [1.1084],\n",
      "        [1.0933],\n",
      "        [1.1070],\n",
      "        [1.0880],\n",
      "        [1.1107],\n",
      "        [1.0986],\n",
      "        [1.1111],\n",
      "        [1.1083],\n",
      "        [1.0406],\n",
      "        [1.0983],\n",
      "        [1.1147],\n",
      "        [1.0857],\n",
      "        [1.1004],\n",
      "        [1.1074],\n",
      "        [1.0783],\n",
      "        [1.1036],\n",
      "        [1.1112],\n",
      "        [1.0570],\n",
      "        [1.0767],\n",
      "        [1.0752],\n",
      "        [1.1027],\n",
      "        [1.0895],\n",
      "        [1.0806],\n",
      "        [1.0987],\n",
      "        [1.0695],\n",
      "        [1.0657],\n",
      "        [1.0999],\n",
      "        [1.0918],\n",
      "        [1.1092],\n",
      "        [1.0861],\n",
      "        [1.0907],\n",
      "        [1.0815],\n",
      "        [1.0966],\n",
      "        [1.0937],\n",
      "        [1.1072],\n",
      "        [1.1175],\n",
      "        [1.0902],\n",
      "        [1.0775],\n",
      "        [1.1135],\n",
      "        [1.0824],\n",
      "        [1.0514],\n",
      "        [1.0280],\n",
      "        [1.0996],\n",
      "        [1.0780],\n",
      "        [1.1106],\n",
      "        [1.0897],\n",
      "        [1.0846],\n",
      "        [1.1169],\n",
      "        [1.0778],\n",
      "        [1.0934],\n",
      "        [1.1104],\n",
      "        [1.0742],\n",
      "        [1.0773],\n",
      "        [1.0627]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0777],\n",
      "        [1.0816],\n",
      "        [1.1021],\n",
      "        [1.1002],\n",
      "        [1.0847],\n",
      "        [1.0976],\n",
      "        [1.1061],\n",
      "        [1.0895],\n",
      "        [1.0579],\n",
      "        [1.1012],\n",
      "        [1.1030],\n",
      "        [1.0790],\n",
      "        [1.0934],\n",
      "        [1.0835],\n",
      "        [1.0483],\n",
      "        [1.0740],\n",
      "        [1.0945],\n",
      "        [1.1149],\n",
      "        [1.1033],\n",
      "        [1.1000],\n",
      "        [1.1146],\n",
      "        [1.0987],\n",
      "        [1.0995],\n",
      "        [1.0724],\n",
      "        [1.1023],\n",
      "        [1.0954],\n",
      "        [1.1124],\n",
      "        [1.0847],\n",
      "        [1.0814],\n",
      "        [1.0929],\n",
      "        [1.0799],\n",
      "        [1.0545],\n",
      "        [1.0985],\n",
      "        [1.1173],\n",
      "        [1.0620],\n",
      "        [1.0964],\n",
      "        [1.0914],\n",
      "        [1.1091],\n",
      "        [1.0577],\n",
      "        [1.1054],\n",
      "        [1.1142],\n",
      "        [1.0870],\n",
      "        [1.0960],\n",
      "        [1.0163],\n",
      "        [1.0980],\n",
      "        [1.0840],\n",
      "        [1.1026],\n",
      "        [1.0806],\n",
      "        [1.0736],\n",
      "        [1.0795],\n",
      "        [1.1089],\n",
      "        [1.0922],\n",
      "        [1.0729],\n",
      "        [1.0552],\n",
      "        [1.1038],\n",
      "        [1.0740],\n",
      "        [1.0808],\n",
      "        [1.0897],\n",
      "        [1.0887],\n",
      "        [1.0582],\n",
      "        [1.0704],\n",
      "        [1.1001],\n",
      "        [1.0671],\n",
      "        [1.1090],\n",
      "        [1.0481],\n",
      "        [1.0437],\n",
      "        [1.0943],\n",
      "        [1.0717],\n",
      "        [1.0891],\n",
      "        [1.0808],\n",
      "        [1.0787],\n",
      "        [1.0913],\n",
      "        [1.1122],\n",
      "        [1.1016],\n",
      "        [1.0875],\n",
      "        [1.0790],\n",
      "        [1.0961],\n",
      "        [1.0558],\n",
      "        [1.0891],\n",
      "        [1.0911],\n",
      "        [1.0657],\n",
      "        [1.0868],\n",
      "        [1.0481],\n",
      "        [1.0795],\n",
      "        [1.0709],\n",
      "        [1.1116],\n",
      "        [1.0829],\n",
      "        [1.0156],\n",
      "        [1.0946],\n",
      "        [1.1146],\n",
      "        [1.1021],\n",
      "        [1.0607],\n",
      "        [1.0953],\n",
      "        [1.0937],\n",
      "        [1.0785],\n",
      "        [1.0893],\n",
      "        [1.0818],\n",
      "        [1.1114],\n",
      "        [1.0566],\n",
      "        [1.0546],\n",
      "        [1.0861],\n",
      "        [1.1033],\n",
      "        [1.1147],\n",
      "        [1.0721],\n",
      "        [1.0506],\n",
      "        [1.0296],\n",
      "        [1.0872],\n",
      "        [1.1012],\n",
      "        [1.0501],\n",
      "        [1.0981],\n",
      "        [1.0952],\n",
      "        [1.0787],\n",
      "        [1.0890],\n",
      "        [1.1004],\n",
      "        [1.0453],\n",
      "        [1.1011],\n",
      "        [1.1033],\n",
      "        [1.0986],\n",
      "        [1.0612],\n",
      "        [1.1029],\n",
      "        [1.0589],\n",
      "        [1.0515],\n",
      "        [1.0165],\n",
      "        [1.0772],\n",
      "        [1.0992],\n",
      "        [1.0874],\n",
      "        [1.1148],\n",
      "        [1.0870]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1071],\n",
      "        [1.0995],\n",
      "        [1.1024],\n",
      "        [1.1085],\n",
      "        [1.0293],\n",
      "        [1.1063],\n",
      "        [1.0749],\n",
      "        [1.0272],\n",
      "        [1.0900],\n",
      "        [1.0844],\n",
      "        [1.0808],\n",
      "        [1.1011],\n",
      "        [1.1079],\n",
      "        [1.0940],\n",
      "        [1.0794],\n",
      "        [1.0642],\n",
      "        [1.0900],\n",
      "        [1.0650],\n",
      "        [1.1101],\n",
      "        [1.0627],\n",
      "        [1.0831],\n",
      "        [1.0804],\n",
      "        [1.0974],\n",
      "        [1.1059],\n",
      "        [1.1084],\n",
      "        [1.0447],\n",
      "        [1.1142],\n",
      "        [1.1064],\n",
      "        [1.0600],\n",
      "        [1.0893],\n",
      "        [1.0885],\n",
      "        [1.1107],\n",
      "        [1.0992],\n",
      "        [1.0832],\n",
      "        [1.1137],\n",
      "        [1.0884],\n",
      "        [1.0874],\n",
      "        [1.0567],\n",
      "        [1.0863],\n",
      "        [1.1143],\n",
      "        [1.0733],\n",
      "        [1.0532],\n",
      "        [1.0855],\n",
      "        [1.0397],\n",
      "        [1.0451],\n",
      "        [1.0359],\n",
      "        [1.0702],\n",
      "        [1.0716],\n",
      "        [1.1024],\n",
      "        [1.0279],\n",
      "        [1.0752],\n",
      "        [1.0694],\n",
      "        [1.0481],\n",
      "        [1.1079],\n",
      "        [1.0628],\n",
      "        [1.1051],\n",
      "        [1.0679],\n",
      "        [1.1014],\n",
      "        [1.0903],\n",
      "        [1.0256],\n",
      "        [1.0810],\n",
      "        [1.0638],\n",
      "        [1.0888],\n",
      "        [1.1190],\n",
      "        [1.0861],\n",
      "        [1.0849],\n",
      "        [1.1024],\n",
      "        [1.0854],\n",
      "        [1.0977],\n",
      "        [1.1127],\n",
      "        [1.0643],\n",
      "        [1.1140],\n",
      "        [1.0850],\n",
      "        [1.0661],\n",
      "        [1.0791],\n",
      "        [1.0544],\n",
      "        [1.0763],\n",
      "        [1.0991],\n",
      "        [1.0797],\n",
      "        [1.0789],\n",
      "        [1.0873],\n",
      "        [1.0790],\n",
      "        [1.1002],\n",
      "        [1.1023],\n",
      "        [1.0721],\n",
      "        [1.1116],\n",
      "        [1.0114],\n",
      "        [1.0794],\n",
      "        [1.0922],\n",
      "        [1.0859],\n",
      "        [1.0711],\n",
      "        [1.0977],\n",
      "        [1.0813],\n",
      "        [1.0645],\n",
      "        [1.1137],\n",
      "        [1.1174],\n",
      "        [1.1131],\n",
      "        [1.0795],\n",
      "        [1.0568],\n",
      "        [1.0475],\n",
      "        [1.0494],\n",
      "        [1.0755],\n",
      "        [1.0852],\n",
      "        [1.0618],\n",
      "        [1.1152],\n",
      "        [1.0995],\n",
      "        [1.0972],\n",
      "        [1.0953],\n",
      "        [1.0772],\n",
      "        [1.1056],\n",
      "        [1.0968],\n",
      "        [1.1046],\n",
      "        [1.0859],\n",
      "        [1.0915],\n",
      "        [1.0949],\n",
      "        [1.0872],\n",
      "        [1.0146],\n",
      "        [1.1051],\n",
      "        [1.0912],\n",
      "        [1.0507],\n",
      "        [1.0939],\n",
      "        [1.0714],\n",
      "        [1.0791],\n",
      "        [1.0659],\n",
      "        [1.0268],\n",
      "        [1.0243],\n",
      "        [1.0966],\n",
      "        [1.0963]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1111],\n",
      "        [1.1000],\n",
      "        [1.0995],\n",
      "        [1.0802],\n",
      "        [1.1075],\n",
      "        [1.0554],\n",
      "        [1.1120],\n",
      "        [1.0485],\n",
      "        [1.0970],\n",
      "        [1.0712],\n",
      "        [1.0986],\n",
      "        [1.0673],\n",
      "        [1.0957],\n",
      "        [1.1042],\n",
      "        [1.0853],\n",
      "        [1.0854],\n",
      "        [1.1114],\n",
      "        [1.1090],\n",
      "        [1.0763],\n",
      "        [1.0881],\n",
      "        [1.0780],\n",
      "        [1.0888],\n",
      "        [1.0942],\n",
      "        [1.0904],\n",
      "        [1.0539],\n",
      "        [1.0686],\n",
      "        [1.0867],\n",
      "        [1.0774],\n",
      "        [1.0821],\n",
      "        [1.0775],\n",
      "        [1.0535],\n",
      "        [1.1160],\n",
      "        [1.1016],\n",
      "        [1.1044],\n",
      "        [1.1015],\n",
      "        [1.0941],\n",
      "        [1.0940],\n",
      "        [1.1052],\n",
      "        [1.0932],\n",
      "        [1.0524],\n",
      "        [1.0871],\n",
      "        [1.0810],\n",
      "        [1.0912],\n",
      "        [1.1045],\n",
      "        [1.0698],\n",
      "        [1.0911],\n",
      "        [1.1011],\n",
      "        [1.0738],\n",
      "        [1.1099],\n",
      "        [1.0510],\n",
      "        [0.9002],\n",
      "        [1.1022],\n",
      "        [1.1096],\n",
      "        [0.7070],\n",
      "        [1.0654],\n",
      "        [1.0774],\n",
      "        [1.0772],\n",
      "        [1.0492],\n",
      "        [1.1108],\n",
      "        [1.0714],\n",
      "        [1.0797],\n",
      "        [1.0954],\n",
      "        [1.0831],\n",
      "        [1.0603],\n",
      "        [1.0992],\n",
      "        [1.0274],\n",
      "        [1.1138],\n",
      "        [1.0966],\n",
      "        [1.0802],\n",
      "        [1.0722],\n",
      "        [1.0753],\n",
      "        [1.0725],\n",
      "        [1.1058],\n",
      "        [1.1033],\n",
      "        [1.0937],\n",
      "        [0.0676],\n",
      "        [1.0766],\n",
      "        [1.0756],\n",
      "        [1.1026],\n",
      "        [1.1052],\n",
      "        [1.0876],\n",
      "        [1.0867],\n",
      "        [1.0776],\n",
      "        [0.0281],\n",
      "        [1.1067],\n",
      "        [1.1139],\n",
      "        [1.0712],\n",
      "        [1.1092],\n",
      "        [1.0852],\n",
      "        [1.0871],\n",
      "        [1.0924],\n",
      "        [1.1035],\n",
      "        [1.1094],\n",
      "        [1.0906],\n",
      "        [1.0583],\n",
      "        [1.0603],\n",
      "        [1.0539],\n",
      "        [1.0957],\n",
      "        [1.0578],\n",
      "        [1.1145],\n",
      "        [1.0885],\n",
      "        [1.1035],\n",
      "        [1.1014],\n",
      "        [1.0839],\n",
      "        [1.0889],\n",
      "        [1.0706],\n",
      "        [1.0978],\n",
      "        [1.1020],\n",
      "        [1.0669],\n",
      "        [1.0972],\n",
      "        [1.0953],\n",
      "        [1.1053],\n",
      "        [1.0729],\n",
      "        [1.0649],\n",
      "        [1.0703],\n",
      "        [1.1127],\n",
      "        [1.0790],\n",
      "        [1.0938],\n",
      "        [1.0946],\n",
      "        [1.0926],\n",
      "        [1.0640],\n",
      "        [1.0702],\n",
      "        [1.0741],\n",
      "        [1.0424],\n",
      "        [1.1016],\n",
      "        [1.1124],\n",
      "        [1.0451],\n",
      "        [1.0753]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0821],\n",
      "        [1.1034],\n",
      "        [1.0845],\n",
      "        [1.0708],\n",
      "        [1.0912],\n",
      "        [1.0914],\n",
      "        [1.0735],\n",
      "        [1.0984],\n",
      "        [1.0692],\n",
      "        [1.0769],\n",
      "        [1.0951],\n",
      "        [1.1050],\n",
      "        [1.0994],\n",
      "        [1.0738],\n",
      "        [1.0897],\n",
      "        [1.0703],\n",
      "        [1.0885],\n",
      "        [1.1050],\n",
      "        [1.0591],\n",
      "        [1.0328],\n",
      "        [1.0038],\n",
      "        [1.1076],\n",
      "        [1.1031],\n",
      "        [1.0758],\n",
      "        [1.0536],\n",
      "        [1.0442],\n",
      "        [1.1024],\n",
      "        [1.1135],\n",
      "        [1.0759],\n",
      "        [1.0602],\n",
      "        [1.0971],\n",
      "        [1.0746],\n",
      "        [1.0562],\n",
      "        [1.0939],\n",
      "        [1.0887],\n",
      "        [1.0891],\n",
      "        [1.0837],\n",
      "        [1.0780],\n",
      "        [1.0674],\n",
      "        [1.0720],\n",
      "        [1.0860],\n",
      "        [1.0696],\n",
      "        [1.0472],\n",
      "        [1.0460],\n",
      "        [1.0601],\n",
      "        [1.0723],\n",
      "        [1.0526],\n",
      "        [1.0840],\n",
      "        [1.0285],\n",
      "        [1.0979],\n",
      "        [1.0974],\n",
      "        [1.0870],\n",
      "        [1.1028],\n",
      "        [1.0895],\n",
      "        [1.0813],\n",
      "        [1.0824],\n",
      "        [1.0107],\n",
      "        [1.0299],\n",
      "        [1.1133],\n",
      "        [1.0998],\n",
      "        [1.1058],\n",
      "        [1.0739],\n",
      "        [1.1043],\n",
      "        [1.0427],\n",
      "        [1.0837],\n",
      "        [1.1013],\n",
      "        [1.0810],\n",
      "        [1.1013],\n",
      "        [1.0933],\n",
      "        [1.1165],\n",
      "        [1.0954],\n",
      "        [1.1112],\n",
      "        [1.0690],\n",
      "        [1.0510],\n",
      "        [1.1124],\n",
      "        [1.1057],\n",
      "        [1.0819],\n",
      "        [1.0947],\n",
      "        [1.0780],\n",
      "        [1.0950],\n",
      "        [1.0896],\n",
      "        [1.1004],\n",
      "        [1.0473],\n",
      "        [1.0519],\n",
      "        [1.0852],\n",
      "        [1.1083],\n",
      "        [1.0986],\n",
      "        [1.1029],\n",
      "        [1.0651],\n",
      "        [1.0686],\n",
      "        [1.0623],\n",
      "        [1.1080],\n",
      "        [1.1134],\n",
      "        [1.1065],\n",
      "        [1.0825],\n",
      "        [1.0844],\n",
      "        [1.0971],\n",
      "        [1.0652],\n",
      "        [1.0794],\n",
      "        [1.1008],\n",
      "        [1.0897],\n",
      "        [1.0923],\n",
      "        [1.0733],\n",
      "        [1.0813],\n",
      "        [1.0918],\n",
      "        [1.0717],\n",
      "        [1.0993],\n",
      "        [1.1117],\n",
      "        [1.0771],\n",
      "        [1.1089],\n",
      "        [1.0802],\n",
      "        [1.1045],\n",
      "        [1.0699],\n",
      "        [1.0744],\n",
      "        [1.1002],\n",
      "        [1.0758],\n",
      "        [1.0834],\n",
      "        [1.0969],\n",
      "        [1.1107],\n",
      "        [1.0678],\n",
      "        [1.0989],\n",
      "        [1.1120],\n",
      "        [1.0710],\n",
      "        [1.0921],\n",
      "        [1.0765],\n",
      "        [1.1036],\n",
      "        [1.1038],\n",
      "        [1.0707]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0984],\n",
      "        [1.0955],\n",
      "        [1.0768],\n",
      "        [1.0597],\n",
      "        [1.0716],\n",
      "        [1.0920],\n",
      "        [1.0425],\n",
      "        [1.0730],\n",
      "        [1.0926],\n",
      "        [1.1023],\n",
      "        [1.0842],\n",
      "        [1.0918],\n",
      "        [1.0982],\n",
      "        [1.1061],\n",
      "        [1.0313],\n",
      "        [1.0550],\n",
      "        [1.0714],\n",
      "        [1.0803],\n",
      "        [1.1115],\n",
      "        [1.1102],\n",
      "        [1.1063],\n",
      "        [1.0504],\n",
      "        [1.0968],\n",
      "        [1.0610],\n",
      "        [1.0851],\n",
      "        [1.0728],\n",
      "        [1.0771],\n",
      "        [1.1024],\n",
      "        [1.0401],\n",
      "        [1.0978],\n",
      "        [1.1146],\n",
      "        [1.0765],\n",
      "        [1.1115],\n",
      "        [1.1014],\n",
      "        [1.0735],\n",
      "        [1.0972],\n",
      "        [1.1083],\n",
      "        [1.1131],\n",
      "        [1.1064],\n",
      "        [1.0967],\n",
      "        [1.1038],\n",
      "        [1.0893],\n",
      "        [1.0808],\n",
      "        [1.0449],\n",
      "        [1.0388],\n",
      "        [1.0778],\n",
      "        [1.0688],\n",
      "        [1.1134],\n",
      "        [1.1107],\n",
      "        [1.0941],\n",
      "        [1.1014],\n",
      "        [1.1054],\n",
      "        [1.0974],\n",
      "        [1.0974],\n",
      "        [1.1027],\n",
      "        [1.1114],\n",
      "        [1.0751],\n",
      "        [1.0498],\n",
      "        [1.1048],\n",
      "        [1.0201],\n",
      "        [1.0810],\n",
      "        [1.0866],\n",
      "        [1.0916],\n",
      "        [1.0803],\n",
      "        [1.0848],\n",
      "        [1.0462],\n",
      "        [0.4458],\n",
      "        [1.0616],\n",
      "        [1.1033],\n",
      "        [1.0717],\n",
      "        [1.1103],\n",
      "        [1.0907],\n",
      "        [1.0972],\n",
      "        [1.0155],\n",
      "        [1.0865],\n",
      "        [1.1043],\n",
      "        [1.0630],\n",
      "        [1.1005],\n",
      "        [1.0907],\n",
      "        [1.1015],\n",
      "        [1.0801],\n",
      "        [1.1040],\n",
      "        [1.0591],\n",
      "        [1.1145],\n",
      "        [1.0862],\n",
      "        [1.0794],\n",
      "        [1.0789],\n",
      "        [1.1088],\n",
      "        [1.0976],\n",
      "        [1.0882],\n",
      "        [1.1076],\n",
      "        [1.0559],\n",
      "        [1.0736],\n",
      "        [1.1000],\n",
      "        [1.1024],\n",
      "        [1.0648],\n",
      "        [1.1040],\n",
      "        [1.0844],\n",
      "        [1.0951],\n",
      "        [1.0918],\n",
      "        [1.1042],\n",
      "        [1.1031],\n",
      "        [1.0929],\n",
      "        [1.0395],\n",
      "        [1.0873],\n",
      "        [1.0638],\n",
      "        [1.1088],\n",
      "        [1.0961],\n",
      "        [1.0603],\n",
      "        [1.0713],\n",
      "        [1.0835],\n",
      "        [1.0866],\n",
      "        [1.0839],\n",
      "        [1.0924],\n",
      "        [1.0650],\n",
      "        [1.0621],\n",
      "        [0.1473],\n",
      "        [1.0739],\n",
      "        [1.0919],\n",
      "        [1.0696],\n",
      "        [1.0851],\n",
      "        [1.0923],\n",
      "        [1.0620],\n",
      "        [1.0520],\n",
      "        [1.0786],\n",
      "        [1.0807],\n",
      "        [1.0840],\n",
      "        [1.0483]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0817],\n",
      "        [1.0915],\n",
      "        [1.0543],\n",
      "        [1.0903],\n",
      "        [1.0989],\n",
      "        [1.1091],\n",
      "        [1.0670],\n",
      "        [1.1081],\n",
      "        [1.0755],\n",
      "        [1.0620],\n",
      "        [1.0313],\n",
      "        [1.1075],\n",
      "        [1.0537],\n",
      "        [1.0957],\n",
      "        [1.1153],\n",
      "        [1.0650],\n",
      "        [1.0659],\n",
      "        [1.0874],\n",
      "        [1.0750],\n",
      "        [1.1055],\n",
      "        [1.0859],\n",
      "        [1.0496],\n",
      "        [1.0946],\n",
      "        [1.0948],\n",
      "        [1.0702],\n",
      "        [1.0749],\n",
      "        [1.0539],\n",
      "        [1.0906],\n",
      "        [1.0791],\n",
      "        [1.1043],\n",
      "        [1.0619],\n",
      "        [1.0677],\n",
      "        [1.0367],\n",
      "        [1.0617],\n",
      "        [1.0742],\n",
      "        [1.0566],\n",
      "        [1.1014],\n",
      "        [1.1038],\n",
      "        [1.0862],\n",
      "        [1.0746],\n",
      "        [1.1004],\n",
      "        [1.0346],\n",
      "        [1.1021],\n",
      "        [1.0797],\n",
      "        [1.0462],\n",
      "        [1.0719],\n",
      "        [1.1129],\n",
      "        [1.0783],\n",
      "        [1.0896],\n",
      "        [1.0941],\n",
      "        [1.0323],\n",
      "        [1.0416],\n",
      "        [1.0802],\n",
      "        [1.0623],\n",
      "        [1.1107],\n",
      "        [1.0847],\n",
      "        [1.0856],\n",
      "        [1.0964],\n",
      "        [1.0847],\n",
      "        [1.0980],\n",
      "        [1.0835],\n",
      "        [1.1010],\n",
      "        [1.0898],\n",
      "        [1.0952],\n",
      "        [1.0404],\n",
      "        [1.0631],\n",
      "        [1.1006],\n",
      "        [1.0875],\n",
      "        [1.0756],\n",
      "        [1.1137],\n",
      "        [1.0890],\n",
      "        [1.1096],\n",
      "        [1.1089],\n",
      "        [1.1129],\n",
      "        [1.1128],\n",
      "        [1.1055],\n",
      "        [1.0879],\n",
      "        [1.1107],\n",
      "        [1.0604],\n",
      "        [1.1132],\n",
      "        [1.0835],\n",
      "        [1.0944],\n",
      "        [1.0937],\n",
      "        [1.0667],\n",
      "        [1.0528],\n",
      "        [1.0955],\n",
      "        [1.0736],\n",
      "        [1.0503],\n",
      "        [1.0797],\n",
      "        [1.1031],\n",
      "        [1.0357],\n",
      "        [1.0983],\n",
      "        [1.0613],\n",
      "        [1.0653],\n",
      "        [1.0923],\n",
      "        [1.0554],\n",
      "        [1.0825],\n",
      "        [1.0411],\n",
      "        [1.0916],\n",
      "        [1.1059],\n",
      "        [1.1018],\n",
      "        [1.0710],\n",
      "        [1.1091],\n",
      "        [1.1050],\n",
      "        [1.0571],\n",
      "        [1.0848],\n",
      "        [1.1035],\n",
      "        [1.0937],\n",
      "        [1.0703],\n",
      "        [1.1008],\n",
      "        [1.1113],\n",
      "        [1.1015],\n",
      "        [1.0817],\n",
      "        [1.1104],\n",
      "        [1.0745],\n",
      "        [1.0817],\n",
      "        [1.0590],\n",
      "        [1.0553],\n",
      "        [1.0894],\n",
      "        [1.0960],\n",
      "        [1.0969],\n",
      "        [1.0305],\n",
      "        [1.1071],\n",
      "        [0.0032],\n",
      "        [1.0979],\n",
      "        [1.0307],\n",
      "        [1.0556],\n",
      "        [1.0926]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0764],\n",
      "        [1.0991],\n",
      "        [1.0568],\n",
      "        [1.0962]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "| epoch  50 | lr 0.00010 train_loss 2.12943 | val_loss 2.29442 | val_rmse 1.51473\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m         f\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     52\u001b[0m     f\u001b[39m.\u001b[39mclose()\n\u001b[0;32m---> 53\u001b[0m TrainModel(CNNRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)\n",
      "Cell \u001b[0;32mIn[12], line 47\u001b[0m, in \u001b[0;36mTrainModel\u001b[0;34m(model, loss_fn, optimizer, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         min_val_loss \u001b[39m=\u001b[39m val_loss\n\u001b[1;32m     46\u001b[0m         best_model \u001b[39m=\u001b[39m model\n\u001b[0;32m---> 47\u001b[0m         torch\u001b[39m.\u001b[39;49msave(best_model\u001b[39m.\u001b[39;49mstate_dict(), \u001b[39m'\u001b[39;49m\u001b[39m./result/cnn_best_all.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     48\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./result/cnn_log.txt\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/lstm/lib/python3.10/site-packages/torch/serialization.py:379\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 379\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    380\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    381\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[0;32m~/.conda/envs/lstm/lib/python3.10/site-packages/torch/serialization.py:601\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[39m# given that we copy things around anyway, we might use storage.cpu()\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39m# this means to that to get tensors serialized, you need to implement\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# .cpu() on the underlying Storage\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m storage\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 601\u001b[0m     storage \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m    602\u001b[0m \u001b[39m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    603\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n",
      "File \u001b[0;32m~/.conda/envs/lstm/lib/python3.10/site-packages/torch/storage.py:112\u001b[0m, in \u001b[0;36m_StorageBase.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_UntypedStorage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize())\u001b[39m.\u001b[39;49mcopy_(\u001b[39mself\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "    min_val_loss = float(\"inf\")\n",
    "    log = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.\n",
    "        best_model = None\n",
    "        model.train()\n",
    "        for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            X_ori = X_ori.to(device)\n",
    "            X_mut = X_mut.to(device)\n",
    "            X_muthhb = X_muthhb.to(device)\n",
    "            X_orihhb = X_orihhb.to(device)\n",
    "            X_na = X_na.to(device)\n",
    "            y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "            print(y_preds)\n",
    "            y = y.to(device)\n",
    "            loss = loss_fn(y_preds.ravel(), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*len(X_ori)\n",
    "        total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_losses = 0.\n",
    "        with torch.no_grad():\n",
    "            for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "                X_ori = X_ori.to(device)\n",
    "                X_mut = X_mut.to(device)\n",
    "                X_muthhb = X_muthhb.to(device)\n",
    "                X_orihhb = X_orihhb.to(device)\n",
    "                X_na = X_na.to(device)\n",
    "                y = y.to(device)\n",
    "                preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "                val_loss = loss_fn(preds.ravel(), y)\n",
    "                val_losses += val_loss.item()*len(X_ori)\n",
    "        val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "        log.append([epoch,total_mse,val_mse])\n",
    "        print('| epoch {:3d} | lr {:02.5f} '\n",
    "                      'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "                      format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "        if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "            min_val_loss = val_loss\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), './result/cnn_best_all.pth')\n",
    "        scheduler.step()\n",
    "    f = open('./result/cnn_log.txt','w')\n",
    "    for i in log:\n",
    "        f.write(str(i)+'\\n')\n",
    "    f.close()\n",
    "TrainModel(CNNRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350],\n",
      "        [1.1350]], device='cuda:2', grad_fn=<AddmmBackward0>)\n",
      "1.1187809604218082\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_mse = 0.\n",
    "test_result = []\n",
    "model = CNNRegressor\n",
    "model.load_state_dict(torch.load('result/cnn_best_all.pth'))\n",
    "model.eval()\n",
    "for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "    X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "    X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "    X_na = X_na.to(device)\n",
    "    y = y.to(device)\n",
    "    preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na)\n",
    "    print(preds)\n",
    "    loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "    test_result.append(y.tolist())\n",
    "    test_result.append(preds.tolist())\n",
    "    test_result.append(loss.tolist())\n",
    "    test_mse += loss.item()*len(X_ori)\n",
    "test_mse = test_mse/len(test_dataset)\n",
    "test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "file_name = 'result/cnn_test_result.txt'\n",
    "f = open(file_name,'w')\n",
    "for i in test_result:\n",
    "    f.write(str(i)+'\\n')\n",
    "f.close()\n",
    "print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liangjs/.conda/envs/lstm/lib/python3.10/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMRegressor(\n",
       "  (lstm_ori): LSTM(20, 256, dropout=0.1)\n",
       "  (lstm_mut): LSTM(20, 256, dropout=0.1)\n",
       "  (lstm_orihhb): LSTM(30, 256, dropout=0.1)\n",
       "  (lstm_muthhb): LSTM(30, 256, dropout=0.1)\n",
       "  (lstm_na): LSTM(4, 256, dropout=0.1)\n",
       "  (linear1): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (linear3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (linear4): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (linear5): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (act): ReLU()\n",
       "  (linear6): Linear(in_features=41000, out_features=8192, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear7): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  (linear8): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (linear9): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (linearout): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "LSTMRegressor = LSTMRegressor().to(device)\n",
    "\n",
    "optimizer = Adam(LSTMRegressor.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "LSTMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | lr 0.00100 train_loss 21.35763 | val_loss 3.20652 | val_rmse 1.79068\n",
      "| epoch   2 | lr 0.00100 train_loss 2.37638 | val_loss 2.58102 | val_rmse 1.60656\n",
      "| epoch   3 | lr 0.00100 train_loss 2.36255 | val_loss 2.10985 | val_rmse 1.45253\n",
      "| epoch   4 | lr 0.00100 train_loss 1.76393 | val_loss 2.02138 | val_rmse 1.42175\n",
      "| epoch   5 | lr 0.00100 train_loss 1.64985 | val_loss 1.94418 | val_rmse 1.39434\n",
      "| epoch   6 | lr 0.00100 train_loss 1.52684 | val_loss 2.00181 | val_rmse 1.41485\n",
      "| epoch   7 | lr 0.00100 train_loss 1.45396 | val_loss 1.96440 | val_rmse 1.40157\n",
      "| epoch   8 | lr 0.00100 train_loss 1.35043 | val_loss 2.10766 | val_rmse 1.45178\n",
      "| epoch   9 | lr 0.00100 train_loss 1.56370 | val_loss 1.94879 | val_rmse 1.39599\n",
      "| epoch  10 | lr 0.00100 train_loss 1.35339 | val_loss 2.36777 | val_rmse 1.53876\n",
      "| epoch  11 | lr 0.00100 train_loss 1.46831 | val_loss 1.89338 | val_rmse 1.37600\n",
      "| epoch  12 | lr 0.00100 train_loss 1.22209 | val_loss 1.98759 | val_rmse 1.40982\n",
      "| epoch  13 | lr 0.00100 train_loss 1.14893 | val_loss 1.88859 | val_rmse 1.37426\n",
      "| epoch  14 | lr 0.00100 train_loss 1.03515 | val_loss 1.80973 | val_rmse 1.34526\n",
      "| epoch  15 | lr 0.00100 train_loss 0.99156 | val_loss 1.93489 | val_rmse 1.39100\n",
      "| epoch  16 | lr 0.00100 train_loss 0.91695 | val_loss 1.94882 | val_rmse 1.39600\n",
      "| epoch  17 | lr 0.00100 train_loss 1.01774 | val_loss 1.73985 | val_rmse 1.31903\n",
      "| epoch  18 | lr 0.00100 train_loss 0.88278 | val_loss 2.03175 | val_rmse 1.42540\n",
      "| epoch  19 | lr 0.00100 train_loss 0.83439 | val_loss 1.86025 | val_rmse 1.36391\n",
      "| epoch  20 | lr 0.00100 train_loss 0.79833 | val_loss 1.70502 | val_rmse 1.30577\n",
      "| epoch  21 | lr 0.00100 train_loss 0.79414 | val_loss 1.73285 | val_rmse 1.31638\n",
      "| epoch  22 | lr 0.00100 train_loss 0.92910 | val_loss 1.87496 | val_rmse 1.36929\n",
      "| epoch  23 | lr 0.00100 train_loss 0.82712 | val_loss 1.94324 | val_rmse 1.39400\n",
      "| epoch  24 | lr 0.00100 train_loss 0.84907 | val_loss 1.95811 | val_rmse 1.39933\n",
      "| epoch  25 | lr 0.00100 train_loss 0.97255 | val_loss 2.05842 | val_rmse 1.43472\n",
      "| epoch  26 | lr 0.00100 train_loss 0.85142 | val_loss 2.08272 | val_rmse 1.44316\n",
      "| epoch  27 | lr 0.00100 train_loss 0.78490 | val_loss 1.88833 | val_rmse 1.37417\n",
      "| epoch  28 | lr 0.00100 train_loss 0.75051 | val_loss 2.00106 | val_rmse 1.41459\n",
      "| epoch  29 | lr 0.00100 train_loss 0.73926 | val_loss 1.98442 | val_rmse 1.40870\n",
      "| epoch  30 | lr 0.00100 train_loss 0.76591 | val_loss 2.00251 | val_rmse 1.41510\n",
      "| epoch  31 | lr 0.00100 train_loss 0.73309 | val_loss 1.76841 | val_rmse 1.32982\n",
      "| epoch  32 | lr 0.00100 train_loss 0.72883 | val_loss 1.62718 | val_rmse 1.27561\n",
      "| epoch  33 | lr 0.00100 train_loss 0.70113 | val_loss 1.93646 | val_rmse 1.39157\n",
      "| epoch  34 | lr 0.00100 train_loss 0.72896 | val_loss 1.78830 | val_rmse 1.33727\n",
      "| epoch  35 | lr 0.00100 train_loss 0.68398 | val_loss 1.74823 | val_rmse 1.32221\n",
      "| epoch  36 | lr 0.00100 train_loss 0.69973 | val_loss 1.82957 | val_rmse 1.35262\n",
      "| epoch  37 | lr 0.00100 train_loss 0.71976 | val_loss 1.81684 | val_rmse 1.34790\n",
      "| epoch  38 | lr 0.00100 train_loss 0.67308 | val_loss 1.75165 | val_rmse 1.32350\n",
      "| epoch  39 | lr 0.00100 train_loss 0.69447 | val_loss 1.80229 | val_rmse 1.34249\n",
      "| epoch  40 | lr 0.00100 train_loss 0.74271 | val_loss 1.85049 | val_rmse 1.36033\n",
      "| epoch  41 | lr 0.00100 train_loss 0.73268 | val_loss 1.70149 | val_rmse 1.30441\n",
      "| epoch  42 | lr 0.00100 train_loss 0.67024 | val_loss 1.89704 | val_rmse 1.37733\n",
      "| epoch  43 | lr 0.00100 train_loss 0.64146 | val_loss 1.72456 | val_rmse 1.31322\n",
      "| epoch  44 | lr 0.00100 train_loss 0.62807 | val_loss 1.65523 | val_rmse 1.28656\n",
      "| epoch  45 | lr 0.00100 train_loss 0.63332 | val_loss 1.84758 | val_rmse 1.35926\n",
      "| epoch  46 | lr 0.00100 train_loss 0.66965 | val_loss 1.94851 | val_rmse 1.39589\n",
      "| epoch  47 | lr 0.00100 train_loss 0.65347 | val_loss 1.98213 | val_rmse 1.40788\n",
      "| epoch  48 | lr 0.00100 train_loss 0.63695 | val_loss 1.76647 | val_rmse 1.32908\n",
      "| epoch  49 | lr 0.00100 train_loss 0.61937 | val_loss 1.62852 | val_rmse 1.27613\n",
      "| epoch  50 | lr 0.00100 train_loss 0.68904 | val_loss 1.64546 | val_rmse 1.28276\n",
      "| epoch  51 | lr 0.00010 train_loss 0.62221 | val_loss 1.68544 | val_rmse 1.29824\n",
      "| epoch  52 | lr 0.00010 train_loss 0.59410 | val_loss 1.67135 | val_rmse 1.29281\n",
      "| epoch  53 | lr 0.00010 train_loss 0.59032 | val_loss 1.61794 | val_rmse 1.27198\n",
      "| epoch  54 | lr 0.00010 train_loss 0.57128 | val_loss 1.66856 | val_rmse 1.29173\n",
      "| epoch  55 | lr 0.00010 train_loss 0.57026 | val_loss 1.63330 | val_rmse 1.27801\n",
      "| epoch  56 | lr 0.00010 train_loss 0.56360 | val_loss 1.66634 | val_rmse 1.29087\n",
      "| epoch  57 | lr 0.00010 train_loss 0.57331 | val_loss 1.71533 | val_rmse 1.30971\n",
      "| epoch  58 | lr 0.00010 train_loss 0.57455 | val_loss 1.62847 | val_rmse 1.27611\n",
      "| epoch  59 | lr 0.00010 train_loss 0.55812 | val_loss 1.62794 | val_rmse 1.27591\n",
      "| epoch  60 | lr 0.00010 train_loss 0.58256 | val_loss 1.65758 | val_rmse 1.28747\n",
      "| epoch  61 | lr 0.00010 train_loss 0.58157 | val_loss 1.68139 | val_rmse 1.29668\n",
      "| epoch  62 | lr 0.00010 train_loss 0.55672 | val_loss 1.67642 | val_rmse 1.29477\n",
      "| epoch  63 | lr 0.00010 train_loss 0.56166 | val_loss 1.62059 | val_rmse 1.27303\n",
      "| epoch  64 | lr 0.00010 train_loss 0.55271 | val_loss 1.61754 | val_rmse 1.27183\n",
      "| epoch  65 | lr 0.00010 train_loss 0.53992 | val_loss 1.66540 | val_rmse 1.29050\n",
      "| epoch  66 | lr 0.00010 train_loss 0.55594 | val_loss 1.69431 | val_rmse 1.30166\n",
      "| epoch  67 | lr 0.00010 train_loss 0.55891 | val_loss 1.65662 | val_rmse 1.28710\n",
      "| epoch  68 | lr 0.00010 train_loss 0.55038 | val_loss 1.61052 | val_rmse 1.26906\n",
      "| epoch  69 | lr 0.00010 train_loss 0.54109 | val_loss 1.62817 | val_rmse 1.27600\n",
      "| epoch  70 | lr 0.00010 train_loss 0.54863 | val_loss 1.66074 | val_rmse 1.28870\n",
      "| epoch  71 | lr 0.00010 train_loss 0.55748 | val_loss 1.65874 | val_rmse 1.28792\n",
      "| epoch  72 | lr 0.00010 train_loss 0.54341 | val_loss 1.63079 | val_rmse 1.27702\n",
      "| epoch  73 | lr 0.00010 train_loss 0.54497 | val_loss 1.69742 | val_rmse 1.30285\n",
      "| epoch  74 | lr 0.00010 train_loss 0.54623 | val_loss 1.72731 | val_rmse 1.31427\n",
      "| epoch  75 | lr 0.00010 train_loss 0.53864 | val_loss 1.70396 | val_rmse 1.30536\n",
      "| epoch  76 | lr 0.00010 train_loss 0.55838 | val_loss 1.69681 | val_rmse 1.30262\n",
      "| epoch  77 | lr 0.00010 train_loss 0.53434 | val_loss 1.71443 | val_rmse 1.30936\n",
      "| epoch  78 | lr 0.00010 train_loss 0.54386 | val_loss 1.79169 | val_rmse 1.33854\n",
      "| epoch  79 | lr 0.00010 train_loss 0.52947 | val_loss 1.74558 | val_rmse 1.32120\n",
      "| epoch  80 | lr 0.00010 train_loss 0.54182 | val_loss 1.72445 | val_rmse 1.31318\n",
      "| epoch  81 | lr 0.00010 train_loss 0.52515 | val_loss 1.74645 | val_rmse 1.32153\n",
      "| epoch  82 | lr 0.00010 train_loss 0.53658 | val_loss 1.76039 | val_rmse 1.32680\n",
      "| epoch  83 | lr 0.00010 train_loss 0.53125 | val_loss 1.74596 | val_rmse 1.32135\n",
      "| epoch  84 | lr 0.00010 train_loss 0.52624 | val_loss 1.76200 | val_rmse 1.32740\n",
      "| epoch  85 | lr 0.00010 train_loss 0.53370 | val_loss 1.69451 | val_rmse 1.30173\n",
      "| epoch  86 | lr 0.00010 train_loss 0.51966 | val_loss 1.68650 | val_rmse 1.29865\n",
      "| epoch  87 | lr 0.00010 train_loss 0.54305 | val_loss 1.72802 | val_rmse 1.31454\n",
      "| epoch  88 | lr 0.00010 train_loss 0.53403 | val_loss 1.72665 | val_rmse 1.31402\n",
      "| epoch  89 | lr 0.00010 train_loss 0.52316 | val_loss 1.74637 | val_rmse 1.32150\n",
      "| epoch  90 | lr 0.00010 train_loss 0.52827 | val_loss 1.75426 | val_rmse 1.32449\n",
      "| epoch  91 | lr 0.00010 train_loss 0.52044 | val_loss 1.74413 | val_rmse 1.32066\n",
      "| epoch  92 | lr 0.00010 train_loss 0.52122 | val_loss 1.72663 | val_rmse 1.31401\n",
      "| epoch  93 | lr 0.00010 train_loss 0.53294 | val_loss 1.72169 | val_rmse 1.31213\n",
      "| epoch  94 | lr 0.00010 train_loss 0.52117 | val_loss 1.70984 | val_rmse 1.30761\n",
      "| epoch  95 | lr 0.00010 train_loss 0.52322 | val_loss 1.75853 | val_rmse 1.32610\n",
      "| epoch  96 | lr 0.00010 train_loss 0.52264 | val_loss 1.74979 | val_rmse 1.32280\n",
      "| epoch  97 | lr 0.00010 train_loss 0.52937 | val_loss 1.75053 | val_rmse 1.32307\n",
      "| epoch  98 | lr 0.00010 train_loss 0.53090 | val_loss 1.78955 | val_rmse 1.33774\n",
      "| epoch  99 | lr 0.00010 train_loss 0.51678 | val_loss 1.80535 | val_rmse 1.34363\n",
      "| epoch 100 | lr 0.00010 train_loss 0.53067 | val_loss 1.74836 | val_rmse 1.32225\n",
      "| epoch 101 | lr 0.00010 train_loss 0.54106 | val_loss 1.76519 | val_rmse 1.32861\n",
      "| epoch 102 | lr 0.00010 train_loss 0.51561 | val_loss 1.73828 | val_rmse 1.31844\n",
      "| epoch 103 | lr 0.00010 train_loss 0.51224 | val_loss 1.71429 | val_rmse 1.30931\n",
      "| epoch 104 | lr 0.00010 train_loss 0.51869 | val_loss 1.71926 | val_rmse 1.31121\n",
      "| epoch 105 | lr 0.00010 train_loss 0.54907 | val_loss 1.70283 | val_rmse 1.30493\n",
      "| epoch 106 | lr 0.00010 train_loss 0.54235 | val_loss 1.74452 | val_rmse 1.32080\n",
      "| epoch 107 | lr 0.00010 train_loss 0.52575 | val_loss 1.72611 | val_rmse 1.31381\n",
      "| epoch 108 | lr 0.00010 train_loss 0.53613 | val_loss 1.72516 | val_rmse 1.31345\n",
      "| epoch 109 | lr 0.00010 train_loss 0.52358 | val_loss 1.70603 | val_rmse 1.30615\n",
      "| epoch 110 | lr 0.00010 train_loss 0.50632 | val_loss 1.74281 | val_rmse 1.32016\n",
      "| epoch 111 | lr 0.00010 train_loss 0.51319 | val_loss 1.79437 | val_rmse 1.33954\n",
      "| epoch 112 | lr 0.00010 train_loss 0.51962 | val_loss 1.82503 | val_rmse 1.35094\n",
      "| epoch 113 | lr 0.00010 train_loss 0.51248 | val_loss 1.74253 | val_rmse 1.32005\n",
      "| epoch 114 | lr 0.00010 train_loss 0.51137 | val_loss 1.74197 | val_rmse 1.31984\n",
      "| epoch 115 | lr 0.00010 train_loss 0.50661 | val_loss 1.73949 | val_rmse 1.31890\n",
      "| epoch 116 | lr 0.00010 train_loss 0.51149 | val_loss 1.75258 | val_rmse 1.32385\n",
      "| epoch 117 | lr 0.00010 train_loss 0.51061 | val_loss 1.73128 | val_rmse 1.31578\n",
      "| epoch 118 | lr 0.00010 train_loss 0.52185 | val_loss 1.76416 | val_rmse 1.32822\n",
      "| epoch 119 | lr 0.00010 train_loss 0.52079 | val_loss 1.74279 | val_rmse 1.32015\n",
      "| epoch 120 | lr 0.00010 train_loss 0.52636 | val_loss 1.67182 | val_rmse 1.29299\n",
      "| epoch 121 | lr 0.00010 train_loss 0.51419 | val_loss 1.69184 | val_rmse 1.30071\n",
      "| epoch 122 | lr 0.00010 train_loss 0.51725 | val_loss 1.66428 | val_rmse 1.29007\n",
      "| epoch 123 | lr 0.00010 train_loss 0.51547 | val_loss 1.66372 | val_rmse 1.28985\n",
      "| epoch 124 | lr 0.00010 train_loss 0.51627 | val_loss 1.68095 | val_rmse 1.29651\n",
      "| epoch 125 | lr 0.00010 train_loss 0.51200 | val_loss 1.68994 | val_rmse 1.29998\n",
      "| epoch 126 | lr 0.00010 train_loss 0.49776 | val_loss 1.70228 | val_rmse 1.30471\n",
      "| epoch 127 | lr 0.00010 train_loss 0.51816 | val_loss 1.76855 | val_rmse 1.32987\n",
      "| epoch 128 | lr 0.00010 train_loss 0.52201 | val_loss 1.66931 | val_rmse 1.29202\n",
      "| epoch 129 | lr 0.00010 train_loss 0.50928 | val_loss 1.65466 | val_rmse 1.28633\n",
      "| epoch 130 | lr 0.00010 train_loss 0.50328 | val_loss 1.62631 | val_rmse 1.27527\n",
      "| epoch 131 | lr 0.00010 train_loss 0.51025 | val_loss 1.62866 | val_rmse 1.27619\n",
      "| epoch 132 | lr 0.00010 train_loss 0.49916 | val_loss 1.68643 | val_rmse 1.29863\n",
      "| epoch 133 | lr 0.00010 train_loss 0.49666 | val_loss 1.66966 | val_rmse 1.29215\n",
      "| epoch 134 | lr 0.00010 train_loss 0.49360 | val_loss 1.69028 | val_rmse 1.30011\n",
      "| epoch 135 | lr 0.00010 train_loss 0.49774 | val_loss 1.67489 | val_rmse 1.29418\n",
      "| epoch 136 | lr 0.00010 train_loss 0.50685 | val_loss 1.71688 | val_rmse 1.31030\n",
      "| epoch 137 | lr 0.00010 train_loss 0.51396 | val_loss 1.68209 | val_rmse 1.29695\n",
      "| epoch 138 | lr 0.00010 train_loss 0.51832 | val_loss 1.65211 | val_rmse 1.28534\n",
      "| epoch 139 | lr 0.00010 train_loss 0.51917 | val_loss 1.65713 | val_rmse 1.28730\n",
      "| epoch 140 | lr 0.00010 train_loss 0.50893 | val_loss 1.69540 | val_rmse 1.30207\n",
      "| epoch 141 | lr 0.00010 train_loss 0.49541 | val_loss 1.68491 | val_rmse 1.29804\n",
      "| epoch 142 | lr 0.00010 train_loss 0.50000 | val_loss 1.68189 | val_rmse 1.29688\n",
      "| epoch 143 | lr 0.00010 train_loss 0.48929 | val_loss 1.83144 | val_rmse 1.35331\n",
      "| epoch 144 | lr 0.00010 train_loss 0.50194 | val_loss 1.73907 | val_rmse 1.31874\n",
      "| epoch 145 | lr 0.00010 train_loss 0.49481 | val_loss 1.72914 | val_rmse 1.31497\n",
      "| epoch 146 | lr 0.00010 train_loss 0.51279 | val_loss 1.69691 | val_rmse 1.30266\n",
      "| epoch 147 | lr 0.00010 train_loss 0.48817 | val_loss 1.74792 | val_rmse 1.32209\n",
      "| epoch 148 | lr 0.00010 train_loss 0.50799 | val_loss 1.71399 | val_rmse 1.30919\n",
      "| epoch 149 | lr 0.00010 train_loss 0.50350 | val_loss 1.69723 | val_rmse 1.30278\n",
      "| epoch 150 | lr 0.00010 train_loss 0.50288 | val_loss 1.63909 | val_rmse 1.28027\n",
      "| epoch 151 | lr 0.00010 train_loss 0.48765 | val_loss 1.68788 | val_rmse 1.29918\n",
      "| epoch 152 | lr 0.00010 train_loss 0.48742 | val_loss 1.72614 | val_rmse 1.31382\n",
      "| epoch 153 | lr 0.00010 train_loss 0.49975 | val_loss 1.78886 | val_rmse 1.33748\n",
      "| epoch 154 | lr 0.00010 train_loss 0.49439 | val_loss 1.69242 | val_rmse 1.30093\n",
      "| epoch 155 | lr 0.00010 train_loss 0.49810 | val_loss 1.75266 | val_rmse 1.32388\n",
      "| epoch 156 | lr 0.00010 train_loss 0.49819 | val_loss 1.64758 | val_rmse 1.28358\n",
      "| epoch 157 | lr 0.00010 train_loss 0.50178 | val_loss 1.70920 | val_rmse 1.30736\n",
      "| epoch 158 | lr 0.00010 train_loss 0.49971 | val_loss 1.65719 | val_rmse 1.28732\n",
      "| epoch 159 | lr 0.00010 train_loss 0.52354 | val_loss 1.69582 | val_rmse 1.30224\n",
      "| epoch 160 | lr 0.00010 train_loss 0.49236 | val_loss 1.68925 | val_rmse 1.29971\n",
      "| epoch 161 | lr 0.00010 train_loss 0.50787 | val_loss 1.67042 | val_rmse 1.29245\n",
      "| epoch 162 | lr 0.00010 train_loss 0.50532 | val_loss 1.65205 | val_rmse 1.28532\n",
      "| epoch 163 | lr 0.00010 train_loss 0.49413 | val_loss 1.60969 | val_rmse 1.26874\n",
      "| epoch 164 | lr 0.00010 train_loss 0.49513 | val_loss 1.68692 | val_rmse 1.29881\n",
      "| epoch 165 | lr 0.00010 train_loss 0.50918 | val_loss 1.74212 | val_rmse 1.31989\n",
      "| epoch 166 | lr 0.00010 train_loss 0.49457 | val_loss 1.78077 | val_rmse 1.33446\n",
      "| epoch 167 | lr 0.00010 train_loss 0.48556 | val_loss 1.70527 | val_rmse 1.30586\n",
      "| epoch 168 | lr 0.00010 train_loss 0.50327 | val_loss 1.75901 | val_rmse 1.32628\n",
      "| epoch 169 | lr 0.00010 train_loss 0.49475 | val_loss 1.72264 | val_rmse 1.31250\n",
      "| epoch 170 | lr 0.00010 train_loss 0.50265 | val_loss 1.73176 | val_rmse 1.31596\n",
      "| epoch 171 | lr 0.00010 train_loss 0.48896 | val_loss 1.71339 | val_rmse 1.30896\n",
      "| epoch 172 | lr 0.00010 train_loss 0.48949 | val_loss 1.70575 | val_rmse 1.30604\n",
      "| epoch 173 | lr 0.00010 train_loss 0.49006 | val_loss 1.74267 | val_rmse 1.32010\n",
      "| epoch 174 | lr 0.00010 train_loss 0.47803 | val_loss 1.71827 | val_rmse 1.31083\n",
      "| epoch 175 | lr 0.00010 train_loss 0.48174 | val_loss 1.67497 | val_rmse 1.29421\n",
      "| epoch 176 | lr 0.00010 train_loss 0.47763 | val_loss 1.71413 | val_rmse 1.30925\n",
      "| epoch 177 | lr 0.00010 train_loss 0.48266 | val_loss 1.74840 | val_rmse 1.32227\n",
      "| epoch 178 | lr 0.00010 train_loss 0.48473 | val_loss 1.68812 | val_rmse 1.29928\n",
      "| epoch 179 | lr 0.00010 train_loss 0.48650 | val_loss 1.71846 | val_rmse 1.31090\n",
      "| epoch 180 | lr 0.00010 train_loss 0.48141 | val_loss 1.74354 | val_rmse 1.32043\n",
      "| epoch 181 | lr 0.00010 train_loss 0.49538 | val_loss 1.69722 | val_rmse 1.30277\n",
      "| epoch 182 | lr 0.00010 train_loss 0.47786 | val_loss 1.70987 | val_rmse 1.30762\n",
      "| epoch 183 | lr 0.00010 train_loss 0.47643 | val_loss 1.71951 | val_rmse 1.31130\n",
      "| epoch 184 | lr 0.00010 train_loss 0.47993 | val_loss 1.71842 | val_rmse 1.31088\n",
      "| epoch 185 | lr 0.00010 train_loss 0.47580 | val_loss 1.67459 | val_rmse 1.29406\n",
      "| epoch 186 | lr 0.00010 train_loss 0.46783 | val_loss 1.62464 | val_rmse 1.27461\n",
      "| epoch 187 | lr 0.00010 train_loss 0.47230 | val_loss 1.67435 | val_rmse 1.29397\n",
      "| epoch 188 | lr 0.00010 train_loss 0.48140 | val_loss 1.67184 | val_rmse 1.29300\n",
      "| epoch 189 | lr 0.00010 train_loss 0.48308 | val_loss 1.63346 | val_rmse 1.27807\n",
      "| epoch 190 | lr 0.00010 train_loss 0.47004 | val_loss 1.63633 | val_rmse 1.27919\n",
      "| epoch 191 | lr 0.00010 train_loss 0.47986 | val_loss 1.72950 | val_rmse 1.31510\n",
      "| epoch 192 | lr 0.00010 train_loss 0.46509 | val_loss 1.67697 | val_rmse 1.29498\n",
      "| epoch 193 | lr 0.00010 train_loss 0.47413 | val_loss 1.68679 | val_rmse 1.29877\n",
      "| epoch 194 | lr 0.00010 train_loss 0.47080 | val_loss 1.69540 | val_rmse 1.30208\n",
      "| epoch 195 | lr 0.00010 train_loss 0.47547 | val_loss 1.67672 | val_rmse 1.29488\n",
      "| epoch 196 | lr 0.00010 train_loss 0.46950 | val_loss 1.74238 | val_rmse 1.31999\n",
      "| epoch 197 | lr 0.00010 train_loss 0.47405 | val_loss 1.72567 | val_rmse 1.31365\n",
      "| epoch 198 | lr 0.00010 train_loss 0.47410 | val_loss 1.74245 | val_rmse 1.32002\n",
      "| epoch 199 | lr 0.00010 train_loss 0.46450 | val_loss 1.71962 | val_rmse 1.31134\n",
      "| epoch 200 | lr 0.00010 train_loss 0.46533 | val_loss 1.70991 | val_rmse 1.30763\n",
      "| epoch 201 | lr 0.00010 train_loss 0.46243 | val_loss 1.73648 | val_rmse 1.31776\n",
      "| epoch 202 | lr 0.00010 train_loss 0.47584 | val_loss 1.68025 | val_rmse 1.29624\n",
      "| epoch 203 | lr 0.00010 train_loss 0.47934 | val_loss 1.72737 | val_rmse 1.31430\n",
      "| epoch 204 | lr 0.00010 train_loss 0.46028 | val_loss 1.72372 | val_rmse 1.31290\n",
      "| epoch 205 | lr 0.00010 train_loss 0.45869 | val_loss 1.73053 | val_rmse 1.31550\n",
      "| epoch 206 | lr 0.00010 train_loss 0.46481 | val_loss 1.70671 | val_rmse 1.30641\n",
      "| epoch 207 | lr 0.00010 train_loss 0.46074 | val_loss 1.75914 | val_rmse 1.32633\n",
      "| epoch 208 | lr 0.00010 train_loss 0.46681 | val_loss 1.67908 | val_rmse 1.29579\n",
      "| epoch 209 | lr 0.00010 train_loss 0.46931 | val_loss 1.74959 | val_rmse 1.32272\n",
      "| epoch 210 | lr 0.00010 train_loss 0.46257 | val_loss 1.71806 | val_rmse 1.31075\n",
      "| epoch 211 | lr 0.00010 train_loss 0.47702 | val_loss 1.72824 | val_rmse 1.31462\n",
      "| epoch 212 | lr 0.00010 train_loss 0.47195 | val_loss 1.64920 | val_rmse 1.28421\n",
      "| epoch 213 | lr 0.00010 train_loss 0.45379 | val_loss 1.60155 | val_rmse 1.26552\n",
      "| epoch 214 | lr 0.00010 train_loss 0.46721 | val_loss 1.65241 | val_rmse 1.28546\n",
      "| epoch 215 | lr 0.00010 train_loss 0.46049 | val_loss 1.63179 | val_rmse 1.27742\n",
      "| epoch 216 | lr 0.00010 train_loss 0.45627 | val_loss 1.66763 | val_rmse 1.29137\n",
      "| epoch 217 | lr 0.00010 train_loss 0.46294 | val_loss 1.61621 | val_rmse 1.27130\n",
      "| epoch 218 | lr 0.00010 train_loss 0.46246 | val_loss 1.64236 | val_rmse 1.28155\n",
      "| epoch 219 | lr 0.00010 train_loss 0.45319 | val_loss 1.66377 | val_rmse 1.28987\n",
      "| epoch 220 | lr 0.00010 train_loss 0.45151 | val_loss 1.68933 | val_rmse 1.29974\n",
      "| epoch 221 | lr 0.00010 train_loss 0.45686 | val_loss 1.70919 | val_rmse 1.30736\n",
      "| epoch 222 | lr 0.00010 train_loss 0.46895 | val_loss 1.71359 | val_rmse 1.30904\n",
      "| epoch 223 | lr 0.00010 train_loss 0.45497 | val_loss 1.67024 | val_rmse 1.29238\n",
      "| epoch 224 | lr 0.00010 train_loss 0.45934 | val_loss 1.70587 | val_rmse 1.30609\n",
      "| epoch 225 | lr 0.00010 train_loss 0.45690 | val_loss 1.65051 | val_rmse 1.28472\n",
      "| epoch 226 | lr 0.00010 train_loss 0.44725 | val_loss 1.61445 | val_rmse 1.27061\n",
      "| epoch 227 | lr 0.00010 train_loss 0.44850 | val_loss 1.61070 | val_rmse 1.26913\n",
      "| epoch 228 | lr 0.00010 train_loss 0.44830 | val_loss 1.62619 | val_rmse 1.27522\n",
      "| epoch 229 | lr 0.00010 train_loss 0.45436 | val_loss 1.70294 | val_rmse 1.30497\n",
      "| epoch 230 | lr 0.00010 train_loss 0.45269 | val_loss 1.73053 | val_rmse 1.31550\n",
      "| epoch 231 | lr 0.00010 train_loss 0.44392 | val_loss 1.65553 | val_rmse 1.28667\n",
      "| epoch 232 | lr 0.00010 train_loss 0.44952 | val_loss 1.70588 | val_rmse 1.30609\n",
      "| epoch 233 | lr 0.00010 train_loss 0.45542 | val_loss 1.63394 | val_rmse 1.27826\n",
      "| epoch 234 | lr 0.00010 train_loss 0.44426 | val_loss 1.63012 | val_rmse 1.27676\n",
      "| epoch 235 | lr 0.00010 train_loss 0.43928 | val_loss 1.69599 | val_rmse 1.30230\n",
      "| epoch 236 | lr 0.00010 train_loss 0.43814 | val_loss 1.66862 | val_rmse 1.29175\n",
      "| epoch 237 | lr 0.00010 train_loss 0.43887 | val_loss 1.67646 | val_rmse 1.29478\n",
      "| epoch 238 | lr 0.00010 train_loss 0.44521 | val_loss 1.65128 | val_rmse 1.28502\n",
      "| epoch 239 | lr 0.00010 train_loss 0.43845 | val_loss 1.65288 | val_rmse 1.28564\n",
      "| epoch 240 | lr 0.00010 train_loss 0.44171 | val_loss 1.66567 | val_rmse 1.29061\n",
      "| epoch 241 | lr 0.00010 train_loss 0.45438 | val_loss 1.70976 | val_rmse 1.30758\n",
      "| epoch 242 | lr 0.00010 train_loss 0.42918 | val_loss 1.68221 | val_rmse 1.29700\n",
      "| epoch 243 | lr 0.00010 train_loss 0.44054 | val_loss 1.68239 | val_rmse 1.29707\n",
      "| epoch 244 | lr 0.00010 train_loss 0.42703 | val_loss 1.66194 | val_rmse 1.28916\n",
      "| epoch 245 | lr 0.00010 train_loss 0.42102 | val_loss 1.71053 | val_rmse 1.30787\n",
      "| epoch 246 | lr 0.00010 train_loss 0.43523 | val_loss 1.69793 | val_rmse 1.30305\n",
      "| epoch 247 | lr 0.00010 train_loss 0.46362 | val_loss 1.69615 | val_rmse 1.30236\n",
      "| epoch 248 | lr 0.00010 train_loss 0.45571 | val_loss 1.65728 | val_rmse 1.28735\n",
      "| epoch 249 | lr 0.00010 train_loss 0.44624 | val_loss 1.74901 | val_rmse 1.32250\n",
      "| epoch 250 | lr 0.00010 train_loss 0.43563 | val_loss 1.76892 | val_rmse 1.33001\n",
      "| epoch 251 | lr 0.00010 train_loss 0.43913 | val_loss 1.74126 | val_rmse 1.31957\n",
      "| epoch 252 | lr 0.00010 train_loss 0.43308 | val_loss 1.67822 | val_rmse 1.29546\n",
      "| epoch 253 | lr 0.00010 train_loss 0.42155 | val_loss 1.70371 | val_rmse 1.30526\n",
      "| epoch 254 | lr 0.00010 train_loss 0.42869 | val_loss 1.71383 | val_rmse 1.30913\n",
      "| epoch 255 | lr 0.00010 train_loss 0.42777 | val_loss 1.67370 | val_rmse 1.29372\n",
      "| epoch 256 | lr 0.00010 train_loss 0.41863 | val_loss 1.62322 | val_rmse 1.27406\n",
      "| epoch 257 | lr 0.00010 train_loss 0.41869 | val_loss 1.63127 | val_rmse 1.27721\n",
      "| epoch 258 | lr 0.00010 train_loss 0.41617 | val_loss 1.65114 | val_rmse 1.28497\n",
      "| epoch 259 | lr 0.00010 train_loss 0.42807 | val_loss 1.64776 | val_rmse 1.28365\n",
      "| epoch 260 | lr 0.00010 train_loss 0.42354 | val_loss 1.65580 | val_rmse 1.28678\n",
      "| epoch 261 | lr 0.00010 train_loss 0.45228 | val_loss 1.60272 | val_rmse 1.26598\n",
      "| epoch 262 | lr 0.00010 train_loss 0.41411 | val_loss 1.60638 | val_rmse 1.26743\n",
      "| epoch 263 | lr 0.00010 train_loss 0.42576 | val_loss 1.64515 | val_rmse 1.28263\n",
      "| epoch 264 | lr 0.00010 train_loss 0.41460 | val_loss 1.65598 | val_rmse 1.28685\n",
      "| epoch 265 | lr 0.00010 train_loss 0.41557 | val_loss 1.60283 | val_rmse 1.26603\n",
      "| epoch 266 | lr 0.00010 train_loss 0.41536 | val_loss 1.58534 | val_rmse 1.25910\n",
      "| epoch 267 | lr 0.00010 train_loss 0.41031 | val_loss 1.64674 | val_rmse 1.28325\n",
      "| epoch 268 | lr 0.00010 train_loss 0.41233 | val_loss 1.59139 | val_rmse 1.26150\n",
      "| epoch 269 | lr 0.00010 train_loss 0.40043 | val_loss 1.63548 | val_rmse 1.27886\n",
      "| epoch 270 | lr 0.00010 train_loss 0.38938 | val_loss 1.67467 | val_rmse 1.29409\n",
      "| epoch 271 | lr 0.00010 train_loss 0.40477 | val_loss 1.64195 | val_rmse 1.28138\n",
      "| epoch 272 | lr 0.00010 train_loss 0.41033 | val_loss 1.63566 | val_rmse 1.27893\n",
      "| epoch 273 | lr 0.00010 train_loss 0.42649 | val_loss 1.57344 | val_rmse 1.25437\n",
      "| epoch 274 | lr 0.00010 train_loss 0.41940 | val_loss 1.63841 | val_rmse 1.28000\n",
      "| epoch 275 | lr 0.00010 train_loss 0.40073 | val_loss 1.57068 | val_rmse 1.25327\n",
      "| epoch 276 | lr 0.00010 train_loss 0.41848 | val_loss 1.62200 | val_rmse 1.27358\n",
      "| epoch 277 | lr 0.00010 train_loss 0.42263 | val_loss 1.64352 | val_rmse 1.28200\n",
      "| epoch 278 | lr 0.00010 train_loss 0.42539 | val_loss 1.69495 | val_rmse 1.30190\n",
      "| epoch 279 | lr 0.00010 train_loss 0.40859 | val_loss 1.69080 | val_rmse 1.30031\n",
      "| epoch 280 | lr 0.00010 train_loss 0.40706 | val_loss 1.64290 | val_rmse 1.28176\n",
      "| epoch 281 | lr 0.00010 train_loss 0.42685 | val_loss 1.70695 | val_rmse 1.30650\n",
      "| epoch 282 | lr 0.00010 train_loss 0.40309 | val_loss 1.63727 | val_rmse 1.27956\n",
      "| epoch 283 | lr 0.00010 train_loss 0.40021 | val_loss 1.67555 | val_rmse 1.29443\n",
      "| epoch 284 | lr 0.00010 train_loss 0.38693 | val_loss 1.64881 | val_rmse 1.28406\n",
      "| epoch 285 | lr 0.00010 train_loss 0.40026 | val_loss 1.67970 | val_rmse 1.29603\n",
      "| epoch 286 | lr 0.00010 train_loss 0.39304 | val_loss 1.58887 | val_rmse 1.26050\n",
      "| epoch 287 | lr 0.00010 train_loss 0.39759 | val_loss 1.65461 | val_rmse 1.28632\n",
      "| epoch 288 | lr 0.00010 train_loss 0.40489 | val_loss 1.57599 | val_rmse 1.25538\n",
      "| epoch 289 | lr 0.00010 train_loss 0.40203 | val_loss 1.67398 | val_rmse 1.29382\n",
      "| epoch 290 | lr 0.00010 train_loss 0.40449 | val_loss 1.59216 | val_rmse 1.26181\n",
      "| epoch 291 | lr 0.00010 train_loss 0.39378 | val_loss 1.65574 | val_rmse 1.28676\n",
      "| epoch 292 | lr 0.00010 train_loss 0.39987 | val_loss 1.64670 | val_rmse 1.28324\n",
      "| epoch 293 | lr 0.00010 train_loss 0.39901 | val_loss 1.62716 | val_rmse 1.27560\n",
      "| epoch 294 | lr 0.00010 train_loss 0.39723 | val_loss 1.60162 | val_rmse 1.26555\n",
      "| epoch 295 | lr 0.00010 train_loss 0.39687 | val_loss 1.60346 | val_rmse 1.26628\n",
      "| epoch 296 | lr 0.00010 train_loss 0.39076 | val_loss 1.62263 | val_rmse 1.27382\n",
      "| epoch 297 | lr 0.00010 train_loss 0.38557 | val_loss 1.61727 | val_rmse 1.27172\n",
      "| epoch 298 | lr 0.00010 train_loss 0.40112 | val_loss 1.63285 | val_rmse 1.27783\n",
      "| epoch 299 | lr 0.00010 train_loss 0.39280 | val_loss 1.61035 | val_rmse 1.26899\n",
      "| epoch 300 | lr 0.00010 train_loss 0.40540 | val_loss 1.62438 | val_rmse 1.27451\n",
      "| epoch 301 | lr 0.00010 train_loss 0.40083 | val_loss 1.64368 | val_rmse 1.28206\n",
      "| epoch 302 | lr 0.00010 train_loss 0.40795 | val_loss 1.70482 | val_rmse 1.30569\n",
      "| epoch 303 | lr 0.00010 train_loss 0.40502 | val_loss 1.63478 | val_rmse 1.27859\n",
      "| epoch 304 | lr 0.00010 train_loss 0.40647 | val_loss 1.66439 | val_rmse 1.29011\n",
      "| epoch 305 | lr 0.00010 train_loss 0.38462 | val_loss 1.61763 | val_rmse 1.27186\n",
      "| epoch 306 | lr 0.00010 train_loss 0.39265 | val_loss 1.58695 | val_rmse 1.25974\n",
      "| epoch 307 | lr 0.00010 train_loss 0.38421 | val_loss 1.58570 | val_rmse 1.25925\n",
      "| epoch 308 | lr 0.00010 train_loss 0.39464 | val_loss 1.60923 | val_rmse 1.26856\n",
      "| epoch 309 | lr 0.00010 train_loss 0.38811 | val_loss 1.59118 | val_rmse 1.26142\n",
      "| epoch 310 | lr 0.00010 train_loss 0.39940 | val_loss 1.59274 | val_rmse 1.26204\n",
      "| epoch 311 | lr 0.00010 train_loss 0.38543 | val_loss 1.57498 | val_rmse 1.25498\n",
      "| epoch 312 | lr 0.00010 train_loss 0.38828 | val_loss 1.58282 | val_rmse 1.25810\n",
      "| epoch 313 | lr 0.00010 train_loss 0.38974 | val_loss 1.55447 | val_rmse 1.24678\n",
      "| epoch 314 | lr 0.00010 train_loss 0.40053 | val_loss 1.59380 | val_rmse 1.26246\n",
      "| epoch 315 | lr 0.00010 train_loss 0.38562 | val_loss 1.61090 | val_rmse 1.26921\n",
      "| epoch 316 | lr 0.00010 train_loss 0.39480 | val_loss 1.60525 | val_rmse 1.26698\n",
      "| epoch 317 | lr 0.00010 train_loss 0.37915 | val_loss 1.62525 | val_rmse 1.27485\n",
      "| epoch 318 | lr 0.00010 train_loss 0.39830 | val_loss 1.54764 | val_rmse 1.24404\n",
      "| epoch 319 | lr 0.00010 train_loss 0.39566 | val_loss 1.55448 | val_rmse 1.24679\n",
      "| epoch 320 | lr 0.00010 train_loss 0.39374 | val_loss 1.62027 | val_rmse 1.27290\n",
      "| epoch 321 | lr 0.00010 train_loss 0.39229 | val_loss 1.58425 | val_rmse 1.25867\n",
      "| epoch 322 | lr 0.00010 train_loss 0.36881 | val_loss 1.56072 | val_rmse 1.24929\n",
      "| epoch 323 | lr 0.00010 train_loss 0.38399 | val_loss 1.63581 | val_rmse 1.27899\n",
      "| epoch 324 | lr 0.00010 train_loss 0.40379 | val_loss 1.59062 | val_rmse 1.26120\n",
      "| epoch 325 | lr 0.00010 train_loss 0.38503 | val_loss 1.56107 | val_rmse 1.24943\n",
      "| epoch 326 | lr 0.00010 train_loss 0.38563 | val_loss 1.53965 | val_rmse 1.24083\n",
      "| epoch 327 | lr 0.00010 train_loss 0.39423 | val_loss 1.59426 | val_rmse 1.26264\n",
      "| epoch 328 | lr 0.00010 train_loss 0.40077 | val_loss 1.61335 | val_rmse 1.27018\n",
      "| epoch 329 | lr 0.00010 train_loss 0.37293 | val_loss 1.59185 | val_rmse 1.26168\n",
      "| epoch 330 | lr 0.00010 train_loss 0.37487 | val_loss 1.65054 | val_rmse 1.28473\n",
      "| epoch 331 | lr 0.00010 train_loss 0.37523 | val_loss 1.58346 | val_rmse 1.25836\n",
      "| epoch 332 | lr 0.00010 train_loss 0.38099 | val_loss 1.57929 | val_rmse 1.25670\n",
      "| epoch 333 | lr 0.00010 train_loss 0.37023 | val_loss 1.56649 | val_rmse 1.25160\n",
      "| epoch 334 | lr 0.00010 train_loss 0.37643 | val_loss 1.59596 | val_rmse 1.26331\n",
      "| epoch 335 | lr 0.00010 train_loss 0.37896 | val_loss 1.65793 | val_rmse 1.28761\n",
      "| epoch 336 | lr 0.00010 train_loss 0.40371 | val_loss 1.67360 | val_rmse 1.29368\n",
      "| epoch 337 | lr 0.00010 train_loss 0.39509 | val_loss 1.71327 | val_rmse 1.30892\n",
      "| epoch 338 | lr 0.00010 train_loss 0.39339 | val_loss 1.63040 | val_rmse 1.27687\n",
      "| epoch 339 | lr 0.00010 train_loss 0.38027 | val_loss 1.62551 | val_rmse 1.27496\n",
      "| epoch 340 | lr 0.00010 train_loss 0.38465 | val_loss 1.55784 | val_rmse 1.24813\n",
      "| epoch 341 | lr 0.00010 train_loss 0.36801 | val_loss 1.55185 | val_rmse 1.24573\n",
      "| epoch 342 | lr 0.00010 train_loss 0.37515 | val_loss 1.60735 | val_rmse 1.26781\n",
      "| epoch 343 | lr 0.00010 train_loss 0.36470 | val_loss 1.61657 | val_rmse 1.27144\n",
      "| epoch 344 | lr 0.00010 train_loss 0.36298 | val_loss 1.62557 | val_rmse 1.27498\n",
      "| epoch 345 | lr 0.00010 train_loss 0.36320 | val_loss 1.60735 | val_rmse 1.26781\n",
      "| epoch 346 | lr 0.00010 train_loss 0.37804 | val_loss 1.64483 | val_rmse 1.28251\n",
      "| epoch 347 | lr 0.00010 train_loss 0.37720 | val_loss 1.61237 | val_rmse 1.26979\n",
      "| epoch 348 | lr 0.00010 train_loss 0.38403 | val_loss 1.66450 | val_rmse 1.29016\n",
      "| epoch 349 | lr 0.00010 train_loss 0.36864 | val_loss 1.54716 | val_rmse 1.24385\n",
      "| epoch 350 | lr 0.00010 train_loss 0.36409 | val_loss 1.63918 | val_rmse 1.28031\n",
      "| epoch 351 | lr 0.00010 train_loss 0.38031 | val_loss 1.60602 | val_rmse 1.26729\n",
      "| epoch 352 | lr 0.00010 train_loss 0.37086 | val_loss 1.56743 | val_rmse 1.25197\n",
      "| epoch 353 | lr 0.00010 train_loss 0.38259 | val_loss 1.62257 | val_rmse 1.27380\n",
      "| epoch 354 | lr 0.00010 train_loss 0.39096 | val_loss 1.63270 | val_rmse 1.27777\n",
      "| epoch 355 | lr 0.00010 train_loss 0.38062 | val_loss 1.60495 | val_rmse 1.26686\n",
      "| epoch 356 | lr 0.00010 train_loss 0.38671 | val_loss 1.59503 | val_rmse 1.26294\n",
      "| epoch 357 | lr 0.00010 train_loss 0.38117 | val_loss 1.69064 | val_rmse 1.30025\n",
      "| epoch 358 | lr 0.00010 train_loss 0.37375 | val_loss 1.64772 | val_rmse 1.28364\n",
      "| epoch 359 | lr 0.00010 train_loss 0.37839 | val_loss 1.68878 | val_rmse 1.29953\n",
      "| epoch 360 | lr 0.00010 train_loss 0.37638 | val_loss 1.61881 | val_rmse 1.27232\n",
      "| epoch 361 | lr 0.00010 train_loss 0.37915 | val_loss 1.60148 | val_rmse 1.26549\n",
      "| epoch 362 | lr 0.00010 train_loss 0.37054 | val_loss 1.67779 | val_rmse 1.29530\n",
      "| epoch 363 | lr 0.00010 train_loss 0.37767 | val_loss 1.65123 | val_rmse 1.28500\n",
      "| epoch 364 | lr 0.00010 train_loss 0.36846 | val_loss 1.60870 | val_rmse 1.26834\n",
      "| epoch 365 | lr 0.00010 train_loss 0.36081 | val_loss 1.66302 | val_rmse 1.28958\n",
      "| epoch 366 | lr 0.00010 train_loss 0.36275 | val_loss 1.62819 | val_rmse 1.27600\n",
      "| epoch 367 | lr 0.00010 train_loss 0.37111 | val_loss 1.58880 | val_rmse 1.26047\n",
      "| epoch 368 | lr 0.00010 train_loss 0.36960 | val_loss 1.59159 | val_rmse 1.26158\n",
      "| epoch 369 | lr 0.00010 train_loss 0.36920 | val_loss 1.62269 | val_rmse 1.27385\n",
      "| epoch 370 | lr 0.00010 train_loss 0.37603 | val_loss 1.64294 | val_rmse 1.28177\n",
      "| epoch 371 | lr 0.00010 train_loss 0.36655 | val_loss 1.61865 | val_rmse 1.27226\n",
      "| epoch 372 | lr 0.00010 train_loss 0.34770 | val_loss 1.66437 | val_rmse 1.29010\n",
      "| epoch 373 | lr 0.00010 train_loss 0.36218 | val_loss 1.65405 | val_rmse 1.28610\n",
      "| epoch 374 | lr 0.00010 train_loss 0.35532 | val_loss 1.66880 | val_rmse 1.29182\n",
      "| epoch 375 | lr 0.00010 train_loss 0.36160 | val_loss 1.62539 | val_rmse 1.27491\n",
      "| epoch 376 | lr 0.00010 train_loss 0.38173 | val_loss 1.65196 | val_rmse 1.28529\n",
      "| epoch 377 | lr 0.00010 train_loss 0.35399 | val_loss 1.64805 | val_rmse 1.28376\n",
      "| epoch 378 | lr 0.00010 train_loss 0.36802 | val_loss 1.62477 | val_rmse 1.27467\n",
      "| epoch 379 | lr 0.00010 train_loss 0.37179 | val_loss 1.54125 | val_rmse 1.24147\n",
      "| epoch 380 | lr 0.00010 train_loss 0.36458 | val_loss 1.61080 | val_rmse 1.26917\n",
      "| epoch 381 | lr 0.00010 train_loss 0.35462 | val_loss 1.63828 | val_rmse 1.27995\n",
      "| epoch 382 | lr 0.00010 train_loss 0.35308 | val_loss 1.60171 | val_rmse 1.26559\n",
      "| epoch 383 | lr 0.00010 train_loss 0.36422 | val_loss 1.69478 | val_rmse 1.30184\n",
      "| epoch 384 | lr 0.00010 train_loss 0.34878 | val_loss 1.62401 | val_rmse 1.27436\n",
      "| epoch 385 | lr 0.00010 train_loss 0.38348 | val_loss 1.67159 | val_rmse 1.29290\n",
      "| epoch 386 | lr 0.00010 train_loss 0.38776 | val_loss 1.65100 | val_rmse 1.28491\n",
      "| epoch 387 | lr 0.00010 train_loss 0.36085 | val_loss 1.68359 | val_rmse 1.29753\n",
      "| epoch 388 | lr 0.00010 train_loss 0.36948 | val_loss 1.74036 | val_rmse 1.31923\n",
      "| epoch 389 | lr 0.00010 train_loss 0.36879 | val_loss 1.76088 | val_rmse 1.32698\n",
      "| epoch 390 | lr 0.00010 train_loss 0.37244 | val_loss 1.69597 | val_rmse 1.30229\n",
      "| epoch 391 | lr 0.00010 train_loss 0.37108 | val_loss 1.53479 | val_rmse 1.23886\n",
      "| epoch 392 | lr 0.00010 train_loss 0.37551 | val_loss 1.57205 | val_rmse 1.25381\n",
      "| epoch 393 | lr 0.00010 train_loss 0.39524 | val_loss 1.60620 | val_rmse 1.26736\n",
      "| epoch 394 | lr 0.00010 train_loss 0.38897 | val_loss 1.53471 | val_rmse 1.23883\n",
      "| epoch 395 | lr 0.00010 train_loss 0.37170 | val_loss 1.63894 | val_rmse 1.28021\n",
      "| epoch 396 | lr 0.00010 train_loss 0.37878 | val_loss 1.62771 | val_rmse 1.27582\n",
      "| epoch 397 | lr 0.00010 train_loss 0.36389 | val_loss 1.62375 | val_rmse 1.27426\n",
      "| epoch 398 | lr 0.00010 train_loss 0.38167 | val_loss 1.66744 | val_rmse 1.29129\n",
      "| epoch 399 | lr 0.00010 train_loss 0.37543 | val_loss 1.66059 | val_rmse 1.28864\n",
      "| epoch 400 | lr 0.00010 train_loss 0.36600 | val_loss 1.60058 | val_rmse 1.26514\n",
      "| epoch 401 | lr 0.00010 train_loss 0.38568 | val_loss 1.61293 | val_rmse 1.27001\n",
      "| epoch 402 | lr 0.00010 train_loss 0.36418 | val_loss 1.67281 | val_rmse 1.29337\n",
      "| epoch 403 | lr 0.00010 train_loss 0.37339 | val_loss 1.65840 | val_rmse 1.28779\n",
      "| epoch 404 | lr 0.00010 train_loss 0.35542 | val_loss 1.59043 | val_rmse 1.26112\n",
      "| epoch 405 | lr 0.00010 train_loss 0.36178 | val_loss 1.58824 | val_rmse 1.26026\n",
      "| epoch 406 | lr 0.00010 train_loss 0.36509 | val_loss 1.66071 | val_rmse 1.28869\n",
      "| epoch 407 | lr 0.00010 train_loss 0.36822 | val_loss 1.62475 | val_rmse 1.27465\n",
      "| epoch 408 | lr 0.00010 train_loss 0.35375 | val_loss 1.65482 | val_rmse 1.28640\n",
      "| epoch 409 | lr 0.00010 train_loss 0.35081 | val_loss 1.65737 | val_rmse 1.28739\n",
      "| epoch 410 | lr 0.00010 train_loss 0.34688 | val_loss 1.72219 | val_rmse 1.31232\n",
      "| epoch 411 | lr 0.00010 train_loss 0.36817 | val_loss 1.65007 | val_rmse 1.28455\n",
      "| epoch 412 | lr 0.00010 train_loss 0.36689 | val_loss 1.64320 | val_rmse 1.28188\n",
      "| epoch 413 | lr 0.00010 train_loss 0.36301 | val_loss 1.59589 | val_rmse 1.26328\n",
      "| epoch 414 | lr 0.00010 train_loss 0.35828 | val_loss 1.60501 | val_rmse 1.26689\n",
      "| epoch 415 | lr 0.00010 train_loss 0.35378 | val_loss 1.57793 | val_rmse 1.25616\n",
      "| epoch 416 | lr 0.00010 train_loss 0.34697 | val_loss 1.58308 | val_rmse 1.25821\n",
      "| epoch 417 | lr 0.00010 train_loss 0.34020 | val_loss 1.64713 | val_rmse 1.28341\n",
      "| epoch 418 | lr 0.00010 train_loss 0.34026 | val_loss 1.60334 | val_rmse 1.26623\n",
      "| epoch 419 | lr 0.00010 train_loss 0.34993 | val_loss 1.57643 | val_rmse 1.25556\n",
      "| epoch 420 | lr 0.00010 train_loss 0.36420 | val_loss 1.58678 | val_rmse 1.25967\n",
      "| epoch 421 | lr 0.00010 train_loss 0.35887 | val_loss 1.47606 | val_rmse 1.21493\n",
      "| epoch 422 | lr 0.00010 train_loss 0.35742 | val_loss 1.56220 | val_rmse 1.24988\n",
      "| epoch 423 | lr 0.00010 train_loss 0.33935 | val_loss 1.52622 | val_rmse 1.23540\n",
      "| epoch 424 | lr 0.00010 train_loss 0.35628 | val_loss 1.54134 | val_rmse 1.24151\n",
      "| epoch 425 | lr 0.00010 train_loss 0.34726 | val_loss 1.53683 | val_rmse 1.23969\n",
      "| epoch 426 | lr 0.00010 train_loss 0.36388 | val_loss 1.61972 | val_rmse 1.27268\n",
      "| epoch 427 | lr 0.00010 train_loss 0.34161 | val_loss 1.71791 | val_rmse 1.31069\n",
      "| epoch 428 | lr 0.00010 train_loss 0.34209 | val_loss 1.67692 | val_rmse 1.29496\n",
      "| epoch 429 | lr 0.00010 train_loss 0.35229 | val_loss 1.73250 | val_rmse 1.31625\n",
      "| epoch 430 | lr 0.00010 train_loss 0.35039 | val_loss 1.64832 | val_rmse 1.28387\n",
      "| epoch 431 | lr 0.00010 train_loss 0.32986 | val_loss 1.66785 | val_rmse 1.29145\n",
      "| epoch 432 | lr 0.00010 train_loss 0.35810 | val_loss 1.63903 | val_rmse 1.28025\n",
      "| epoch 433 | lr 0.00010 train_loss 0.35993 | val_loss 1.65584 | val_rmse 1.28680\n",
      "| epoch 434 | lr 0.00010 train_loss 0.34535 | val_loss 1.64511 | val_rmse 1.28262\n",
      "| epoch 435 | lr 0.00010 train_loss 0.35082 | val_loss 1.64607 | val_rmse 1.28299\n",
      "| epoch 436 | lr 0.00010 train_loss 0.34600 | val_loss 1.63141 | val_rmse 1.27727\n",
      "| epoch 437 | lr 0.00010 train_loss 0.33933 | val_loss 1.67604 | val_rmse 1.29462\n",
      "| epoch 438 | lr 0.00010 train_loss 0.34342 | val_loss 1.61675 | val_rmse 1.27152\n",
      "| epoch 439 | lr 0.00010 train_loss 0.35160 | val_loss 1.59977 | val_rmse 1.26482\n",
      "| epoch 440 | lr 0.00010 train_loss 0.35752 | val_loss 1.68472 | val_rmse 1.29797\n",
      "| epoch 441 | lr 0.00010 train_loss 0.37560 | val_loss 1.64175 | val_rmse 1.28131\n",
      "| epoch 442 | lr 0.00010 train_loss 0.35385 | val_loss 1.58724 | val_rmse 1.25986\n",
      "| epoch 443 | lr 0.00010 train_loss 0.36260 | val_loss 1.62207 | val_rmse 1.27360\n",
      "| epoch 444 | lr 0.00010 train_loss 0.36025 | val_loss 1.65492 | val_rmse 1.28644\n",
      "| epoch 445 | lr 0.00010 train_loss 0.35221 | val_loss 1.61333 | val_rmse 1.27017\n",
      "| epoch 446 | lr 0.00010 train_loss 0.34871 | val_loss 1.63984 | val_rmse 1.28056\n",
      "| epoch 447 | lr 0.00010 train_loss 0.33936 | val_loss 1.59838 | val_rmse 1.26427\n",
      "| epoch 448 | lr 0.00010 train_loss 0.35581 | val_loss 1.67933 | val_rmse 1.29589\n",
      "| epoch 449 | lr 0.00010 train_loss 0.40200 | val_loss 1.58865 | val_rmse 1.26042\n",
      "| epoch 450 | lr 0.00010 train_loss 0.35417 | val_loss 1.66241 | val_rmse 1.28935\n",
      "| epoch 451 | lr 0.00010 train_loss 0.35300 | val_loss 1.64689 | val_rmse 1.28331\n",
      "| epoch 452 | lr 0.00010 train_loss 0.35528 | val_loss 1.65272 | val_rmse 1.28558\n",
      "| epoch 453 | lr 0.00010 train_loss 0.34063 | val_loss 1.63139 | val_rmse 1.27726\n",
      "| epoch 454 | lr 0.00010 train_loss 0.33627 | val_loss 1.61624 | val_rmse 1.27131\n",
      "| epoch 455 | lr 0.00010 train_loss 0.33827 | val_loss 1.60031 | val_rmse 1.26503\n",
      "| epoch 456 | lr 0.00010 train_loss 0.36477 | val_loss 1.61788 | val_rmse 1.27196\n",
      "| epoch 457 | lr 0.00010 train_loss 0.35071 | val_loss 1.59059 | val_rmse 1.26119\n",
      "| epoch 458 | lr 0.00010 train_loss 0.33544 | val_loss 1.65064 | val_rmse 1.28477\n",
      "| epoch 459 | lr 0.00010 train_loss 0.35142 | val_loss 1.62999 | val_rmse 1.27671\n",
      "| epoch 460 | lr 0.00010 train_loss 0.34411 | val_loss 1.61318 | val_rmse 1.27011\n",
      "| epoch 461 | lr 0.00010 train_loss 0.36465 | val_loss 1.63379 | val_rmse 1.27820\n",
      "| epoch 462 | lr 0.00010 train_loss 0.34260 | val_loss 1.61935 | val_rmse 1.27254\n",
      "| epoch 463 | lr 0.00010 train_loss 0.32625 | val_loss 1.66176 | val_rmse 1.28909\n",
      "| epoch 464 | lr 0.00010 train_loss 0.32617 | val_loss 1.63091 | val_rmse 1.27707\n",
      "| epoch 465 | lr 0.00010 train_loss 0.33471 | val_loss 1.64438 | val_rmse 1.28233\n",
      "| epoch 466 | lr 0.00010 train_loss 0.33209 | val_loss 1.68788 | val_rmse 1.29918\n",
      "| epoch 467 | lr 0.00010 train_loss 0.32156 | val_loss 1.75440 | val_rmse 1.32454\n",
      "| epoch 468 | lr 0.00010 train_loss 0.33375 | val_loss 1.79127 | val_rmse 1.33838\n",
      "| epoch 469 | lr 0.00010 train_loss 0.37146 | val_loss 1.71436 | val_rmse 1.30934\n",
      "| epoch 470 | lr 0.00010 train_loss 0.37530 | val_loss 1.68741 | val_rmse 1.29901\n",
      "| epoch 471 | lr 0.00010 train_loss 0.35263 | val_loss 1.63869 | val_rmse 1.28011\n",
      "| epoch 472 | lr 0.00010 train_loss 0.34298 | val_loss 1.60459 | val_rmse 1.26672\n",
      "| epoch 473 | lr 0.00010 train_loss 0.33980 | val_loss 1.68314 | val_rmse 1.29736\n",
      "| epoch 474 | lr 0.00010 train_loss 0.33880 | val_loss 1.63061 | val_rmse 1.27695\n",
      "| epoch 475 | lr 0.00010 train_loss 0.34179 | val_loss 1.59856 | val_rmse 1.26434\n",
      "| epoch 476 | lr 0.00010 train_loss 0.32369 | val_loss 1.62202 | val_rmse 1.27359\n",
      "| epoch 477 | lr 0.00010 train_loss 0.32929 | val_loss 1.64355 | val_rmse 1.28201\n",
      "| epoch 478 | lr 0.00010 train_loss 0.31695 | val_loss 1.64560 | val_rmse 1.28281\n",
      "| epoch 479 | lr 0.00010 train_loss 0.32467 | val_loss 1.74294 | val_rmse 1.32020\n",
      "| epoch 480 | lr 0.00010 train_loss 0.34833 | val_loss 1.78400 | val_rmse 1.33566\n",
      "| epoch 481 | lr 0.00010 train_loss 0.32456 | val_loss 1.77748 | val_rmse 1.33322\n",
      "| epoch 482 | lr 0.00010 train_loss 0.32806 | val_loss 1.66520 | val_rmse 1.29043\n",
      "| epoch 483 | lr 0.00010 train_loss 0.31777 | val_loss 1.73936 | val_rmse 1.31885\n",
      "| epoch 484 | lr 0.00010 train_loss 0.32425 | val_loss 1.63246 | val_rmse 1.27768\n",
      "| epoch 485 | lr 0.00010 train_loss 0.32810 | val_loss 1.69472 | val_rmse 1.30181\n",
      "| epoch 486 | lr 0.00010 train_loss 0.32823 | val_loss 1.66436 | val_rmse 1.29010\n",
      "| epoch 487 | lr 0.00010 train_loss 0.33007 | val_loss 1.75222 | val_rmse 1.32372\n",
      "| epoch 488 | lr 0.00010 train_loss 0.32166 | val_loss 1.75765 | val_rmse 1.32576\n",
      "| epoch 489 | lr 0.00010 train_loss 0.34855 | val_loss 1.73491 | val_rmse 1.31716\n",
      "| epoch 490 | lr 0.00010 train_loss 0.37048 | val_loss 1.71046 | val_rmse 1.30785\n",
      "| epoch 491 | lr 0.00010 train_loss 0.33305 | val_loss 1.68441 | val_rmse 1.29785\n",
      "| epoch 492 | lr 0.00010 train_loss 0.34551 | val_loss 1.59889 | val_rmse 1.26447\n",
      "| epoch 493 | lr 0.00010 train_loss 0.32976 | val_loss 1.58426 | val_rmse 1.25867\n",
      "| epoch 494 | lr 0.00010 train_loss 0.32796 | val_loss 1.61875 | val_rmse 1.27230\n",
      "| epoch 495 | lr 0.00010 train_loss 0.32995 | val_loss 1.67816 | val_rmse 1.29544\n",
      "| epoch 496 | lr 0.00010 train_loss 0.34231 | val_loss 1.73003 | val_rmse 1.31531\n",
      "| epoch 497 | lr 0.00010 train_loss 0.31294 | val_loss 1.69572 | val_rmse 1.30220\n",
      "| epoch 498 | lr 0.00010 train_loss 0.31646 | val_loss 1.69283 | val_rmse 1.30109\n",
      "| epoch 499 | lr 0.00010 train_loss 0.32584 | val_loss 1.67043 | val_rmse 1.29245\n",
      "| epoch 500 | lr 0.00010 train_loss 0.31393 | val_loss 1.61107 | val_rmse 1.26928\n"
     ]
    }
   ],
   "source": [
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "    min_val_loss = float(\"inf\")\n",
    "    log = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.\n",
    "        best_model = None\n",
    "        model.train()\n",
    "        for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            X_ori = X_ori.to(device)\n",
    "            X_mut = X_mut.to(device)\n",
    "            X_muthhb = X_muthhb.to(device)\n",
    "            X_orihhb = X_orihhb.to(device)\n",
    "            X_na = X_na.to(device)\n",
    "            y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "            y = y.to(device)\n",
    "            loss = loss_fn(y_preds.ravel(), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*len(X_ori)\n",
    "        total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_losses = 0.\n",
    "        with torch.no_grad():\n",
    "            for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "                X_ori = X_ori.to(device)\n",
    "                X_mut = X_mut.to(device)\n",
    "                X_muthhb = X_muthhb.to(device)\n",
    "                X_orihhb = X_orihhb.to(device)\n",
    "                X_na = X_na.to(device)\n",
    "                y = y.to(device)\n",
    "                preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "                val_loss = loss_fn(preds.ravel(), y)\n",
    "                val_losses += val_loss.item()*len(X_ori)\n",
    "        val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "        log.append([epoch,total_mse,val_mse])\n",
    "        print('| epoch {:3d} | lr {:02.5f} '\n",
    "                      'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "                      format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "        if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "            min_val_loss = val_loss\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), 'result/lstm_best_all.pth')\n",
    "        scheduler.step()\n",
    "    f = open('result/lstm_log.txt','w')\n",
    "    for i in log:\n",
    "        f.write(str(i)+'\\n')\n",
    "    f.close()\n",
    "TrainModel(LSTMRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102504828791502\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_mse = 0.\n",
    "test_result = []\n",
    "model = LSTMRegressor\n",
    "model.load_state_dict(torch.load('result/lstm_best_all.pth'))\n",
    "model.eval()\n",
    "for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "    X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "    X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "    X_na = X_na.to(device)\n",
    "    y = y.to(device)\n",
    "    preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "    loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "    test_result.append(y.tolist())\n",
    "    test_result.append(preds.tolist())\n",
    "    test_result.append(loss.tolist())\n",
    "    test_mse += loss.item()*len(X_ori)\n",
    "test_mse = test_mse/len(test_dataset)\n",
    "test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "file_name = 'result/lstm_test_result.txt'\n",
    "f = open(file_name,'w')\n",
    "for i in test_result:\n",
    "    f.write(str(i)+'\\n')\n",
    "f.close()\n",
    "print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLSTMRegressor(\n",
       "  (lstm_mut): LSTM(20, 256, dropout=0.1, bidirectional=True)\n",
       "  (lstm_ori): LSTM(20, 256, dropout=0.1, bidirectional=True)\n",
       "  (lstm_muthhb): LSTM(30, 256, dropout=0.1, bidirectional=True)\n",
       "  (lstm_orihhb): LSTM(30, 256, dropout=0.1, bidirectional=True)\n",
       "  (lstm_na): LSTM(4, 256, dropout=0.1, bidirectional=True)\n",
       "  (linear1): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (linear3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (linear4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (linear5): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (act): ReLU()\n",
       "  (linear6): Linear(in_features=41000, out_features=8192, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear7): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  (linear8): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (linear9): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (linearout): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "BLSTMRegressor = BLSTMRegressor().to(device)\n",
    "\n",
    "optimizer = Adam(BLSTMRegressor.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "BLSTMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | lr 0.00100 train_loss 49.45978 | val_loss 3.43837 | val_rmse 1.85428\n",
      "| epoch   2 | lr 0.00100 train_loss 2.42842 | val_loss 2.19490 | val_rmse 1.48152\n",
      "| epoch   3 | lr 0.00100 train_loss 1.96696 | val_loss 2.61455 | val_rmse 1.61696\n",
      "| epoch   4 | lr 0.00100 train_loss 2.11748 | val_loss 2.11026 | val_rmse 1.45267\n",
      "| epoch   5 | lr 0.00100 train_loss 1.70838 | val_loss 1.91446 | val_rmse 1.38364\n",
      "| epoch   6 | lr 0.00100 train_loss 1.53655 | val_loss 1.91029 | val_rmse 1.38213\n",
      "| epoch   7 | lr 0.00100 train_loss 1.29872 | val_loss 1.92765 | val_rmse 1.38840\n",
      "| epoch   8 | lr 0.00100 train_loss 1.27451 | val_loss 1.97948 | val_rmse 1.40694\n",
      "| epoch   9 | lr 0.00100 train_loss 1.35941 | val_loss 1.91423 | val_rmse 1.38356\n",
      "| epoch  10 | lr 0.00100 train_loss 1.13704 | val_loss 1.95198 | val_rmse 1.39713\n",
      "| epoch  11 | lr 0.00100 train_loss 1.03687 | val_loss 2.13880 | val_rmse 1.46246\n",
      "| epoch  12 | lr 0.00100 train_loss 0.98158 | val_loss 2.24553 | val_rmse 1.49851\n",
      "| epoch  13 | lr 0.00100 train_loss 1.00444 | val_loss 1.96901 | val_rmse 1.40321\n",
      "| epoch  14 | lr 0.00100 train_loss 0.78903 | val_loss 1.97238 | val_rmse 1.40441\n",
      "| epoch  15 | lr 0.00100 train_loss 0.78880 | val_loss 1.93883 | val_rmse 1.39242\n",
      "| epoch  16 | lr 0.00100 train_loss 0.74184 | val_loss 2.05922 | val_rmse 1.43500\n",
      "| epoch  17 | lr 0.00100 train_loss 0.71937 | val_loss 2.06138 | val_rmse 1.43575\n",
      "| epoch  18 | lr 0.00100 train_loss 0.73453 | val_loss 2.13006 | val_rmse 1.45947\n",
      "| epoch  19 | lr 0.00100 train_loss 0.78890 | val_loss 1.94128 | val_rmse 1.39330\n",
      "| epoch  20 | lr 0.00100 train_loss 0.80122 | val_loss 1.83468 | val_rmse 1.35450\n",
      "| epoch  21 | lr 0.00100 train_loss 0.76376 | val_loss 1.95301 | val_rmse 1.39750\n",
      "| epoch  22 | lr 0.00100 train_loss 0.74781 | val_loss 1.85779 | val_rmse 1.36301\n",
      "| epoch  23 | lr 0.00100 train_loss 0.74336 | val_loss 1.90288 | val_rmse 1.37945\n",
      "| epoch  24 | lr 0.00100 train_loss 0.74081 | val_loss 2.45536 | val_rmse 1.56696\n",
      "| epoch  25 | lr 0.00100 train_loss 0.85098 | val_loss 2.10737 | val_rmse 1.45168\n",
      "| epoch  26 | lr 0.00100 train_loss 0.70181 | val_loss 2.10117 | val_rmse 1.44954\n",
      "| epoch  27 | lr 0.00100 train_loss 0.68411 | val_loss 1.94848 | val_rmse 1.39588\n",
      "| epoch  28 | lr 0.00100 train_loss 0.67784 | val_loss 1.99406 | val_rmse 1.41211\n",
      "| epoch  29 | lr 0.00100 train_loss 0.80161 | val_loss 2.08636 | val_rmse 1.44442\n",
      "| epoch  30 | lr 0.00100 train_loss 0.80953 | val_loss 1.95350 | val_rmse 1.39768\n",
      "| epoch  31 | lr 0.00100 train_loss 0.71534 | val_loss 2.04365 | val_rmse 1.42956\n",
      "| epoch  32 | lr 0.00100 train_loss 0.67401 | val_loss 2.01257 | val_rmse 1.41865\n",
      "| epoch  33 | lr 0.00100 train_loss 0.65406 | val_loss 2.03379 | val_rmse 1.42611\n",
      "| epoch  34 | lr 0.00100 train_loss 0.65904 | val_loss 1.99276 | val_rmse 1.41165\n",
      "| epoch  35 | lr 0.00100 train_loss 0.60998 | val_loss 1.90090 | val_rmse 1.37873\n",
      "| epoch  36 | lr 0.00100 train_loss 0.63303 | val_loss 2.04273 | val_rmse 1.42924\n",
      "| epoch  37 | lr 0.00100 train_loss 0.73059 | val_loss 2.13249 | val_rmse 1.46030\n",
      "| epoch  38 | lr 0.00100 train_loss 0.66556 | val_loss 2.05794 | val_rmse 1.43455\n",
      "| epoch  39 | lr 0.00100 train_loss 0.67168 | val_loss 1.91468 | val_rmse 1.38372\n",
      "| epoch  40 | lr 0.00100 train_loss 0.59035 | val_loss 1.90342 | val_rmse 1.37965\n",
      "| epoch  41 | lr 0.00100 train_loss 0.58713 | val_loss 2.06046 | val_rmse 1.43543\n",
      "| epoch  42 | lr 0.00100 train_loss 0.64239 | val_loss 2.00560 | val_rmse 1.41619\n",
      "| epoch  43 | lr 0.00100 train_loss 0.59035 | val_loss 2.11326 | val_rmse 1.45371\n",
      "| epoch  44 | lr 0.00100 train_loss 0.60387 | val_loss 2.01393 | val_rmse 1.41913\n",
      "| epoch  45 | lr 0.00100 train_loss 0.67619 | val_loss 2.37614 | val_rmse 1.54147\n",
      "| epoch  46 | lr 0.00100 train_loss 0.74516 | val_loss 2.01055 | val_rmse 1.41794\n",
      "| epoch  47 | lr 0.00100 train_loss 0.65583 | val_loss 2.09761 | val_rmse 1.44831\n",
      "| epoch  48 | lr 0.00100 train_loss 0.60033 | val_loss 2.03178 | val_rmse 1.42541\n",
      "| epoch  49 | lr 0.00100 train_loss 0.60734 | val_loss 1.99806 | val_rmse 1.41353\n",
      "| epoch  50 | lr 0.00100 train_loss 0.64950 | val_loss 1.92765 | val_rmse 1.38840\n",
      "| epoch  51 | lr 0.00010 train_loss 0.56926 | val_loss 1.95512 | val_rmse 1.39826\n",
      "| epoch  52 | lr 0.00010 train_loss 0.56081 | val_loss 1.87045 | val_rmse 1.36764\n",
      "| epoch  53 | lr 0.00010 train_loss 0.56142 | val_loss 1.88106 | val_rmse 1.37152\n",
      "| epoch  54 | lr 0.00010 train_loss 0.55812 | val_loss 1.88678 | val_rmse 1.37360\n",
      "| epoch  55 | lr 0.00010 train_loss 0.54956 | val_loss 1.92795 | val_rmse 1.38851\n",
      "| epoch  56 | lr 0.00010 train_loss 0.54134 | val_loss 1.93844 | val_rmse 1.39228\n",
      "| epoch  57 | lr 0.00010 train_loss 0.54383 | val_loss 1.91768 | val_rmse 1.38480\n",
      "| epoch  58 | lr 0.00010 train_loss 0.54874 | val_loss 1.93628 | val_rmse 1.39150\n",
      "| epoch  59 | lr 0.00010 train_loss 0.54119 | val_loss 1.94156 | val_rmse 1.39340\n",
      "| epoch  60 | lr 0.00010 train_loss 0.53670 | val_loss 1.93567 | val_rmse 1.39128\n",
      "| epoch  61 | lr 0.00010 train_loss 0.54243 | val_loss 1.97491 | val_rmse 1.40531\n",
      "| epoch  62 | lr 0.00010 train_loss 0.54013 | val_loss 1.90756 | val_rmse 1.38114\n",
      "| epoch  63 | lr 0.00010 train_loss 0.52638 | val_loss 1.95513 | val_rmse 1.39826\n",
      "| epoch  64 | lr 0.00010 train_loss 0.52884 | val_loss 1.95949 | val_rmse 1.39982\n",
      "| epoch  65 | lr 0.00010 train_loss 0.53191 | val_loss 1.96551 | val_rmse 1.40196\n",
      "| epoch  66 | lr 0.00010 train_loss 0.52813 | val_loss 1.94686 | val_rmse 1.39530\n",
      "| epoch  67 | lr 0.00010 train_loss 0.53302 | val_loss 1.96488 | val_rmse 1.40174\n",
      "| epoch  68 | lr 0.00010 train_loss 0.53078 | val_loss 1.96788 | val_rmse 1.40281\n",
      "| epoch  69 | lr 0.00010 train_loss 0.53330 | val_loss 1.98796 | val_rmse 1.40995\n",
      "| epoch  70 | lr 0.00010 train_loss 0.53440 | val_loss 1.98953 | val_rmse 1.41051\n",
      "| epoch  71 | lr 0.00010 train_loss 0.53858 | val_loss 1.97669 | val_rmse 1.40595\n",
      "| epoch  72 | lr 0.00010 train_loss 0.52409 | val_loss 1.98839 | val_rmse 1.41010\n",
      "| epoch  73 | lr 0.00010 train_loss 0.53032 | val_loss 2.00328 | val_rmse 1.41537\n",
      "| epoch  74 | lr 0.00010 train_loss 0.52185 | val_loss 1.95114 | val_rmse 1.39683\n",
      "| epoch  75 | lr 0.00010 train_loss 0.52059 | val_loss 2.00052 | val_rmse 1.41440\n",
      "| epoch  76 | lr 0.00010 train_loss 0.53046 | val_loss 1.98515 | val_rmse 1.40895\n",
      "| epoch  77 | lr 0.00010 train_loss 0.53080 | val_loss 1.98310 | val_rmse 1.40823\n",
      "| epoch  78 | lr 0.00010 train_loss 0.51748 | val_loss 1.94216 | val_rmse 1.39361\n",
      "| epoch  79 | lr 0.00010 train_loss 0.54367 | val_loss 2.00293 | val_rmse 1.41525\n",
      "| epoch  80 | lr 0.00010 train_loss 0.52624 | val_loss 1.98447 | val_rmse 1.40871\n",
      "| epoch  81 | lr 0.00010 train_loss 0.52527 | val_loss 1.94025 | val_rmse 1.39293\n",
      "| epoch  82 | lr 0.00010 train_loss 0.52691 | val_loss 1.93491 | val_rmse 1.39101\n",
      "| epoch  83 | lr 0.00010 train_loss 0.52639 | val_loss 1.97454 | val_rmse 1.40518\n",
      "| epoch  84 | lr 0.00010 train_loss 0.51267 | val_loss 1.94647 | val_rmse 1.39516\n",
      "| epoch  85 | lr 0.00010 train_loss 0.52168 | val_loss 1.90507 | val_rmse 1.38024\n",
      "| epoch  86 | lr 0.00010 train_loss 0.52736 | val_loss 1.92979 | val_rmse 1.38917\n",
      "| epoch  87 | lr 0.00010 train_loss 0.52701 | val_loss 1.93243 | val_rmse 1.39012\n",
      "| epoch  88 | lr 0.00010 train_loss 0.52484 | val_loss 2.01330 | val_rmse 1.41891\n",
      "| epoch  89 | lr 0.00010 train_loss 0.50660 | val_loss 1.96452 | val_rmse 1.40161\n",
      "| epoch  90 | lr 0.00010 train_loss 0.49295 | val_loss 2.00774 | val_rmse 1.41695\n",
      "| epoch  91 | lr 0.00010 train_loss 0.50542 | val_loss 1.95253 | val_rmse 1.39733\n",
      "| epoch  92 | lr 0.00010 train_loss 0.51421 | val_loss 1.98085 | val_rmse 1.40743\n",
      "| epoch  93 | lr 0.00010 train_loss 0.51697 | val_loss 1.97110 | val_rmse 1.40396\n",
      "| epoch  94 | lr 0.00010 train_loss 0.51252 | val_loss 1.95155 | val_rmse 1.39698\n",
      "| epoch  95 | lr 0.00010 train_loss 0.50907 | val_loss 1.97261 | val_rmse 1.40450\n",
      "| epoch  96 | lr 0.00010 train_loss 0.50932 | val_loss 1.93580 | val_rmse 1.39133\n",
      "| epoch  97 | lr 0.00010 train_loss 0.52361 | val_loss 2.05969 | val_rmse 1.43516\n",
      "| epoch  98 | lr 0.00010 train_loss 0.51701 | val_loss 2.03027 | val_rmse 1.42488\n",
      "| epoch  99 | lr 0.00010 train_loss 0.50965 | val_loss 1.99865 | val_rmse 1.41373\n",
      "| epoch 100 | lr 0.00010 train_loss 0.51408 | val_loss 1.96367 | val_rmse 1.40131\n",
      "| epoch 101 | lr 0.00010 train_loss 0.51833 | val_loss 2.06000 | val_rmse 1.43527\n",
      "| epoch 102 | lr 0.00010 train_loss 0.53722 | val_loss 1.99735 | val_rmse 1.41328\n",
      "| epoch 103 | lr 0.00010 train_loss 0.51495 | val_loss 2.00668 | val_rmse 1.41657\n",
      "| epoch 104 | lr 0.00010 train_loss 0.51374 | val_loss 2.04325 | val_rmse 1.42942\n",
      "| epoch 105 | lr 0.00010 train_loss 0.52469 | val_loss 2.01556 | val_rmse 1.41971\n",
      "| epoch 106 | lr 0.00010 train_loss 0.52256 | val_loss 2.00018 | val_rmse 1.41428\n",
      "| epoch 107 | lr 0.00010 train_loss 0.51110 | val_loss 1.94289 | val_rmse 1.39388\n",
      "| epoch 108 | lr 0.00010 train_loss 0.51044 | val_loss 1.90728 | val_rmse 1.38104\n",
      "| epoch 109 | lr 0.00010 train_loss 0.51010 | val_loss 1.99564 | val_rmse 1.41267\n",
      "| epoch 110 | lr 0.00010 train_loss 0.49965 | val_loss 2.02612 | val_rmse 1.42342\n",
      "| epoch 111 | lr 0.00010 train_loss 0.50326 | val_loss 1.99908 | val_rmse 1.41389\n",
      "| epoch 112 | lr 0.00010 train_loss 0.50814 | val_loss 2.06244 | val_rmse 1.43612\n",
      "| epoch 113 | lr 0.00010 train_loss 0.50131 | val_loss 1.97320 | val_rmse 1.40471\n",
      "| epoch 114 | lr 0.00010 train_loss 0.50775 | val_loss 2.00009 | val_rmse 1.41425\n",
      "| epoch 115 | lr 0.00010 train_loss 0.49775 | val_loss 1.96162 | val_rmse 1.40058\n",
      "| epoch 116 | lr 0.00010 train_loss 0.50439 | val_loss 1.96736 | val_rmse 1.40263\n",
      "| epoch 117 | lr 0.00010 train_loss 0.50798 | val_loss 1.99271 | val_rmse 1.41163\n",
      "| epoch 118 | lr 0.00010 train_loss 0.48660 | val_loss 2.02663 | val_rmse 1.42360\n",
      "| epoch 119 | lr 0.00010 train_loss 0.49797 | val_loss 2.03107 | val_rmse 1.42516\n",
      "| epoch 120 | lr 0.00010 train_loss 0.49505 | val_loss 1.98639 | val_rmse 1.40939\n",
      "| epoch 121 | lr 0.00010 train_loss 0.50763 | val_loss 1.95666 | val_rmse 1.39881\n",
      "| epoch 122 | lr 0.00010 train_loss 0.50498 | val_loss 2.01231 | val_rmse 1.41856\n",
      "| epoch 123 | lr 0.00010 train_loss 0.50497 | val_loss 1.92367 | val_rmse 1.38697\n",
      "| epoch 124 | lr 0.00010 train_loss 0.49302 | val_loss 1.98932 | val_rmse 1.41043\n",
      "| epoch 125 | lr 0.00010 train_loss 0.50335 | val_loss 2.01329 | val_rmse 1.41891\n",
      "| epoch 126 | lr 0.00010 train_loss 0.50427 | val_loss 2.01648 | val_rmse 1.42003\n",
      "| epoch 127 | lr 0.00010 train_loss 0.49515 | val_loss 1.93326 | val_rmse 1.39042\n",
      "| epoch 128 | lr 0.00010 train_loss 0.50596 | val_loss 1.94655 | val_rmse 1.39519\n",
      "| epoch 129 | lr 0.00010 train_loss 0.49854 | val_loss 1.97453 | val_rmse 1.40518\n",
      "| epoch 130 | lr 0.00010 train_loss 0.49612 | val_loss 2.02314 | val_rmse 1.42237\n",
      "| epoch 131 | lr 0.00010 train_loss 0.50408 | val_loss 2.00069 | val_rmse 1.41446\n",
      "| epoch 132 | lr 0.00010 train_loss 0.50297 | val_loss 1.97052 | val_rmse 1.40375\n",
      "| epoch 133 | lr 0.00010 train_loss 0.50500 | val_loss 1.94372 | val_rmse 1.39417\n",
      "| epoch 134 | lr 0.00010 train_loss 0.49453 | val_loss 2.01522 | val_rmse 1.41958\n",
      "| epoch 135 | lr 0.00010 train_loss 0.49032 | val_loss 2.01183 | val_rmse 1.41839\n",
      "| epoch 136 | lr 0.00010 train_loss 0.49800 | val_loss 1.99140 | val_rmse 1.41117\n",
      "| epoch 137 | lr 0.00010 train_loss 0.49346 | val_loss 1.96942 | val_rmse 1.40336\n",
      "| epoch 138 | lr 0.00010 train_loss 0.49064 | val_loss 2.02537 | val_rmse 1.42316\n",
      "| epoch 139 | lr 0.00010 train_loss 0.49727 | val_loss 2.00414 | val_rmse 1.41568\n",
      "| epoch 140 | lr 0.00010 train_loss 0.48356 | val_loss 2.02034 | val_rmse 1.42139\n",
      "| epoch 141 | lr 0.00010 train_loss 0.49648 | val_loss 1.99641 | val_rmse 1.41294\n",
      "| epoch 142 | lr 0.00010 train_loss 0.48844 | val_loss 2.01093 | val_rmse 1.41807\n",
      "| epoch 143 | lr 0.00010 train_loss 0.50231 | val_loss 2.02233 | val_rmse 1.42209\n",
      "| epoch 144 | lr 0.00010 train_loss 0.49835 | val_loss 2.01872 | val_rmse 1.42082\n",
      "| epoch 145 | lr 0.00010 train_loss 0.49920 | val_loss 1.99796 | val_rmse 1.41349\n",
      "| epoch 146 | lr 0.00010 train_loss 0.49598 | val_loss 1.98156 | val_rmse 1.40768\n",
      "| epoch 147 | lr 0.00010 train_loss 0.50295 | val_loss 1.98466 | val_rmse 1.40878\n",
      "| epoch 148 | lr 0.00010 train_loss 0.48493 | val_loss 1.94879 | val_rmse 1.39599\n",
      "| epoch 149 | lr 0.00010 train_loss 0.50610 | val_loss 1.98460 | val_rmse 1.40876\n",
      "| epoch 150 | lr 0.00010 train_loss 0.49524 | val_loss 2.00099 | val_rmse 1.41457\n",
      "| epoch 151 | lr 0.00010 train_loss 0.49031 | val_loss 1.96264 | val_rmse 1.40094\n",
      "| epoch 152 | lr 0.00010 train_loss 0.48298 | val_loss 2.01885 | val_rmse 1.42086\n",
      "| epoch 153 | lr 0.00010 train_loss 0.49919 | val_loss 2.00383 | val_rmse 1.41557\n",
      "| epoch 154 | lr 0.00010 train_loss 0.48819 | val_loss 1.98824 | val_rmse 1.41005\n",
      "| epoch 155 | lr 0.00010 train_loss 0.49811 | val_loss 2.03913 | val_rmse 1.42798\n",
      "| epoch 156 | lr 0.00010 train_loss 0.49021 | val_loss 2.07822 | val_rmse 1.44160\n",
      "| epoch 157 | lr 0.00010 train_loss 0.48974 | val_loss 2.03277 | val_rmse 1.42575\n",
      "| epoch 158 | lr 0.00010 train_loss 0.47187 | val_loss 2.01290 | val_rmse 1.41877\n",
      "| epoch 159 | lr 0.00010 train_loss 0.48684 | val_loss 2.01108 | val_rmse 1.41813\n",
      "| epoch 160 | lr 0.00010 train_loss 0.48899 | val_loss 1.99113 | val_rmse 1.41107\n",
      "| epoch 161 | lr 0.00010 train_loss 0.48981 | val_loss 2.00111 | val_rmse 1.41461\n",
      "| epoch 162 | lr 0.00010 train_loss 0.47377 | val_loss 1.97175 | val_rmse 1.40419\n",
      "| epoch 163 | lr 0.00010 train_loss 0.47949 | val_loss 1.99481 | val_rmse 1.41238\n",
      "| epoch 164 | lr 0.00010 train_loss 0.48399 | val_loss 1.96614 | val_rmse 1.40219\n",
      "| epoch 165 | lr 0.00010 train_loss 0.48864 | val_loss 2.00323 | val_rmse 1.41536\n",
      "| epoch 166 | lr 0.00010 train_loss 0.49742 | val_loss 2.00285 | val_rmse 1.41522\n",
      "| epoch 167 | lr 0.00010 train_loss 0.48817 | val_loss 1.94547 | val_rmse 1.39480\n",
      "| epoch 168 | lr 0.00010 train_loss 0.50177 | val_loss 1.98205 | val_rmse 1.40785\n",
      "| epoch 169 | lr 0.00010 train_loss 0.49441 | val_loss 1.99775 | val_rmse 1.41342\n",
      "| epoch 170 | lr 0.00010 train_loss 0.49636 | val_loss 2.01201 | val_rmse 1.41845\n",
      "| epoch 171 | lr 0.00010 train_loss 0.47909 | val_loss 2.02772 | val_rmse 1.42398\n",
      "| epoch 172 | lr 0.00010 train_loss 0.47873 | val_loss 2.03139 | val_rmse 1.42527\n",
      "| epoch 173 | lr 0.00010 train_loss 0.48500 | val_loss 2.03205 | val_rmse 1.42550\n",
      "| epoch 174 | lr 0.00010 train_loss 0.48094 | val_loss 2.02033 | val_rmse 1.42138\n",
      "| epoch 175 | lr 0.00010 train_loss 0.48316 | val_loss 2.00377 | val_rmse 1.41555\n",
      "| epoch 176 | lr 0.00010 train_loss 0.47910 | val_loss 2.04552 | val_rmse 1.43022\n",
      "| epoch 177 | lr 0.00010 train_loss 0.47520 | val_loss 2.06031 | val_rmse 1.43538\n",
      "| epoch 178 | lr 0.00010 train_loss 0.47120 | val_loss 1.98281 | val_rmse 1.40812\n",
      "| epoch 179 | lr 0.00010 train_loss 0.47831 | val_loss 2.01972 | val_rmse 1.42117\n",
      "| epoch 180 | lr 0.00010 train_loss 0.48893 | val_loss 2.02017 | val_rmse 1.42133\n",
      "| epoch 181 | lr 0.00010 train_loss 0.47945 | val_loss 2.00590 | val_rmse 1.41630\n",
      "| epoch 182 | lr 0.00010 train_loss 0.46639 | val_loss 1.95683 | val_rmse 1.39887\n",
      "| epoch 183 | lr 0.00010 train_loss 0.47000 | val_loss 1.98670 | val_rmse 1.40950\n",
      "| epoch 184 | lr 0.00010 train_loss 0.48014 | val_loss 1.96235 | val_rmse 1.40084\n",
      "| epoch 185 | lr 0.00010 train_loss 0.46740 | val_loss 1.90290 | val_rmse 1.37946\n",
      "| epoch 186 | lr 0.00010 train_loss 0.47099 | val_loss 1.93936 | val_rmse 1.39261\n",
      "| epoch 187 | lr 0.00010 train_loss 0.47491 | val_loss 1.95241 | val_rmse 1.39729\n",
      "| epoch 188 | lr 0.00010 train_loss 0.47404 | val_loss 1.94609 | val_rmse 1.39502\n",
      "| epoch 189 | lr 0.00010 train_loss 0.47172 | val_loss 1.96951 | val_rmse 1.40339\n",
      "| epoch 190 | lr 0.00010 train_loss 0.47308 | val_loss 1.97077 | val_rmse 1.40384\n",
      "| epoch 191 | lr 0.00010 train_loss 0.48126 | val_loss 1.98077 | val_rmse 1.40740\n",
      "| epoch 192 | lr 0.00010 train_loss 0.47621 | val_loss 1.95336 | val_rmse 1.39763\n",
      "| epoch 193 | lr 0.00010 train_loss 0.47306 | val_loss 1.97849 | val_rmse 1.40659\n",
      "| epoch 194 | lr 0.00010 train_loss 0.47557 | val_loss 2.00322 | val_rmse 1.41535\n",
      "| epoch 195 | lr 0.00010 train_loss 0.46219 | val_loss 1.99807 | val_rmse 1.41353\n",
      "| epoch 196 | lr 0.00010 train_loss 0.46975 | val_loss 1.97684 | val_rmse 1.40600\n",
      "| epoch 197 | lr 0.00010 train_loss 0.46412 | val_loss 1.97822 | val_rmse 1.40649\n",
      "| epoch 198 | lr 0.00010 train_loss 0.47022 | val_loss 2.00091 | val_rmse 1.41453\n",
      "| epoch 199 | lr 0.00010 train_loss 0.46274 | val_loss 2.01724 | val_rmse 1.42030\n",
      "| epoch 200 | lr 0.00010 train_loss 0.46427 | val_loss 1.97520 | val_rmse 1.40542\n",
      "| epoch 201 | lr 0.00010 train_loss 0.46628 | val_loss 1.97152 | val_rmse 1.40411\n",
      "| epoch 202 | lr 0.00010 train_loss 0.46528 | val_loss 1.97459 | val_rmse 1.40520\n",
      "| epoch 203 | lr 0.00010 train_loss 0.47342 | val_loss 1.99015 | val_rmse 1.41073\n",
      "| epoch 204 | lr 0.00010 train_loss 0.46366 | val_loss 1.93584 | val_rmse 1.39134\n",
      "| epoch 205 | lr 0.00010 train_loss 0.46222 | val_loss 1.93246 | val_rmse 1.39013\n",
      "| epoch 206 | lr 0.00010 train_loss 0.46876 | val_loss 1.98163 | val_rmse 1.40770\n",
      "| epoch 207 | lr 0.00010 train_loss 0.46279 | val_loss 1.95502 | val_rmse 1.39822\n",
      "| epoch 208 | lr 0.00010 train_loss 0.47072 | val_loss 1.99378 | val_rmse 1.41201\n",
      "| epoch 209 | lr 0.00010 train_loss 0.46429 | val_loss 2.06676 | val_rmse 1.43762\n",
      "| epoch 210 | lr 0.00010 train_loss 0.46814 | val_loss 2.05294 | val_rmse 1.43281\n",
      "| epoch 211 | lr 0.00010 train_loss 0.46294 | val_loss 2.06153 | val_rmse 1.43580\n",
      "| epoch 212 | lr 0.00010 train_loss 0.45826 | val_loss 2.12699 | val_rmse 1.45842\n",
      "| epoch 213 | lr 0.00010 train_loss 0.45617 | val_loss 2.07256 | val_rmse 1.43964\n",
      "| epoch 214 | lr 0.00010 train_loss 0.45381 | val_loss 2.08369 | val_rmse 1.44350\n",
      "| epoch 215 | lr 0.00010 train_loss 0.46326 | val_loss 2.01840 | val_rmse 1.42070\n",
      "| epoch 216 | lr 0.00010 train_loss 0.46840 | val_loss 2.00108 | val_rmse 1.41460\n",
      "| epoch 217 | lr 0.00010 train_loss 0.45860 | val_loss 2.08471 | val_rmse 1.44385\n",
      "| epoch 218 | lr 0.00010 train_loss 0.46334 | val_loss 2.12558 | val_rmse 1.45794\n",
      "| epoch 219 | lr 0.00010 train_loss 0.45864 | val_loss 2.03003 | val_rmse 1.42479\n",
      "| epoch 220 | lr 0.00010 train_loss 0.46966 | val_loss 2.00381 | val_rmse 1.41556\n",
      "| epoch 221 | lr 0.00010 train_loss 0.46754 | val_loss 1.98944 | val_rmse 1.41047\n",
      "| epoch 222 | lr 0.00010 train_loss 0.46721 | val_loss 2.03903 | val_rmse 1.42794\n",
      "| epoch 223 | lr 0.00010 train_loss 0.46798 | val_loss 2.10492 | val_rmse 1.45083\n",
      "| epoch 224 | lr 0.00010 train_loss 0.46700 | val_loss 2.01225 | val_rmse 1.41854\n",
      "| epoch 225 | lr 0.00010 train_loss 0.46762 | val_loss 1.99083 | val_rmse 1.41097\n",
      "| epoch 226 | lr 0.00010 train_loss 0.47068 | val_loss 1.98240 | val_rmse 1.40798\n",
      "| epoch 227 | lr 0.00010 train_loss 0.45855 | val_loss 1.94924 | val_rmse 1.39615\n",
      "| epoch 228 | lr 0.00010 train_loss 0.46446 | val_loss 1.94660 | val_rmse 1.39521\n",
      "| epoch 229 | lr 0.00010 train_loss 0.46187 | val_loss 2.03489 | val_rmse 1.42650\n",
      "| epoch 230 | lr 0.00010 train_loss 0.47809 | val_loss 2.03337 | val_rmse 1.42596\n",
      "| epoch 231 | lr 0.00010 train_loss 0.46425 | val_loss 2.03051 | val_rmse 1.42496\n",
      "| epoch 232 | lr 0.00010 train_loss 0.46908 | val_loss 2.00229 | val_rmse 1.41502\n",
      "| epoch 233 | lr 0.00010 train_loss 0.45959 | val_loss 2.00098 | val_rmse 1.41456\n",
      "| epoch 234 | lr 0.00010 train_loss 0.45756 | val_loss 2.04686 | val_rmse 1.43069\n",
      "| epoch 235 | lr 0.00010 train_loss 0.46003 | val_loss 2.01542 | val_rmse 1.41965\n",
      "| epoch 236 | lr 0.00010 train_loss 0.45741 | val_loss 2.00940 | val_rmse 1.41753\n",
      "| epoch 237 | lr 0.00010 train_loss 0.46490 | val_loss 2.05442 | val_rmse 1.43332\n",
      "| epoch 238 | lr 0.00010 train_loss 0.46582 | val_loss 2.02038 | val_rmse 1.42140\n",
      "| epoch 239 | lr 0.00010 train_loss 0.45257 | val_loss 2.06933 | val_rmse 1.43852\n",
      "| epoch 240 | lr 0.00010 train_loss 0.48502 | val_loss 2.11079 | val_rmse 1.45285\n",
      "| epoch 241 | lr 0.00010 train_loss 0.46169 | val_loss 2.14078 | val_rmse 1.46314\n",
      "| epoch 242 | lr 0.00010 train_loss 0.46435 | val_loss 2.05470 | val_rmse 1.43342\n",
      "| epoch 243 | lr 0.00010 train_loss 0.46102 | val_loss 2.08189 | val_rmse 1.44287\n",
      "| epoch 244 | lr 0.00010 train_loss 0.46186 | val_loss 2.05765 | val_rmse 1.43445\n",
      "| epoch 245 | lr 0.00010 train_loss 0.45712 | val_loss 2.04360 | val_rmse 1.42954\n",
      "| epoch 246 | lr 0.00010 train_loss 0.44751 | val_loss 2.00868 | val_rmse 1.41728\n",
      "| epoch 247 | lr 0.00010 train_loss 0.45609 | val_loss 2.03412 | val_rmse 1.42623\n",
      "| epoch 248 | lr 0.00010 train_loss 0.45791 | val_loss 2.06454 | val_rmse 1.43685\n",
      "| epoch 249 | lr 0.00010 train_loss 0.46793 | val_loss 2.02369 | val_rmse 1.42257\n",
      "| epoch 250 | lr 0.00010 train_loss 0.45174 | val_loss 2.02128 | val_rmse 1.42172\n",
      "| epoch 251 | lr 0.00010 train_loss 0.45314 | val_loss 2.06493 | val_rmse 1.43699\n",
      "| epoch 252 | lr 0.00010 train_loss 0.45122 | val_loss 2.03088 | val_rmse 1.42509\n",
      "| epoch 253 | lr 0.00010 train_loss 0.45648 | val_loss 2.00445 | val_rmse 1.41579\n",
      "| epoch 254 | lr 0.00010 train_loss 0.44873 | val_loss 2.03287 | val_rmse 1.42579\n",
      "| epoch 255 | lr 0.00010 train_loss 0.45107 | val_loss 2.07349 | val_rmse 1.43996\n",
      "| epoch 256 | lr 0.00010 train_loss 0.45664 | val_loss 2.01853 | val_rmse 1.42075\n",
      "| epoch 257 | lr 0.00010 train_loss 0.44678 | val_loss 2.02424 | val_rmse 1.42276\n",
      "| epoch 258 | lr 0.00010 train_loss 0.44806 | val_loss 2.04464 | val_rmse 1.42991\n",
      "| epoch 259 | lr 0.00010 train_loss 0.45166 | val_loss 2.06543 | val_rmse 1.43716\n",
      "| epoch 260 | lr 0.00010 train_loss 0.44786 | val_loss 2.05636 | val_rmse 1.43400\n",
      "| epoch 261 | lr 0.00010 train_loss 0.46062 | val_loss 2.06797 | val_rmse 1.43804\n",
      "| epoch 262 | lr 0.00010 train_loss 0.45635 | val_loss 2.06233 | val_rmse 1.43608\n",
      "| epoch 263 | lr 0.00010 train_loss 0.45647 | val_loss 2.04056 | val_rmse 1.42848\n",
      "| epoch 264 | lr 0.00010 train_loss 0.44894 | val_loss 2.03395 | val_rmse 1.42617\n",
      "| epoch 265 | lr 0.00010 train_loss 0.44566 | val_loss 2.02722 | val_rmse 1.42380\n",
      "| epoch 266 | lr 0.00010 train_loss 0.45231 | val_loss 2.02447 | val_rmse 1.42284\n",
      "| epoch 267 | lr 0.00010 train_loss 0.45272 | val_loss 2.03345 | val_rmse 1.42599\n",
      "| epoch 268 | lr 0.00010 train_loss 0.43261 | val_loss 2.00341 | val_rmse 1.41542\n",
      "| epoch 269 | lr 0.00010 train_loss 0.44364 | val_loss 2.06008 | val_rmse 1.43530\n",
      "| epoch 270 | lr 0.00010 train_loss 0.44633 | val_loss 2.04125 | val_rmse 1.42872\n",
      "| epoch 271 | lr 0.00010 train_loss 0.45366 | val_loss 2.01961 | val_rmse 1.42113\n",
      "| epoch 272 | lr 0.00010 train_loss 0.44502 | val_loss 2.04109 | val_rmse 1.42867\n",
      "| epoch 273 | lr 0.00010 train_loss 0.44615 | val_loss 1.97063 | val_rmse 1.40379\n",
      "| epoch 274 | lr 0.00010 train_loss 0.44670 | val_loss 1.96732 | val_rmse 1.40261\n",
      "| epoch 275 | lr 0.00010 train_loss 0.45363 | val_loss 1.98344 | val_rmse 1.40835\n",
      "| epoch 276 | lr 0.00010 train_loss 0.45057 | val_loss 2.05050 | val_rmse 1.43196\n",
      "| epoch 277 | lr 0.00010 train_loss 0.46176 | val_loss 2.01612 | val_rmse 1.41990\n",
      "| epoch 278 | lr 0.00010 train_loss 0.44930 | val_loss 2.07471 | val_rmse 1.44039\n",
      "| epoch 279 | lr 0.00010 train_loss 0.46415 | val_loss 2.05833 | val_rmse 1.43469\n",
      "| epoch 280 | lr 0.00010 train_loss 0.45839 | val_loss 2.01041 | val_rmse 1.41789\n",
      "| epoch 281 | lr 0.00010 train_loss 0.44728 | val_loss 2.00350 | val_rmse 1.41545\n",
      "| epoch 282 | lr 0.00010 train_loss 0.44783 | val_loss 2.01926 | val_rmse 1.42101\n",
      "| epoch 283 | lr 0.00010 train_loss 0.44943 | val_loss 2.00709 | val_rmse 1.41672\n",
      "| epoch 284 | lr 0.00010 train_loss 0.45005 | val_loss 2.06925 | val_rmse 1.43849\n",
      "| epoch 285 | lr 0.00010 train_loss 0.45562 | val_loss 2.01468 | val_rmse 1.41939\n",
      "| epoch 286 | lr 0.00010 train_loss 0.45261 | val_loss 2.05402 | val_rmse 1.43318\n",
      "| epoch 287 | lr 0.00010 train_loss 0.44626 | val_loss 2.04337 | val_rmse 1.42946\n",
      "| epoch 288 | lr 0.00010 train_loss 0.44036 | val_loss 2.05905 | val_rmse 1.43494\n",
      "| epoch 289 | lr 0.00010 train_loss 0.44454 | val_loss 2.06969 | val_rmse 1.43864\n",
      "| epoch 290 | lr 0.00010 train_loss 0.43365 | val_loss 2.03122 | val_rmse 1.42521\n",
      "| epoch 291 | lr 0.00010 train_loss 0.44126 | val_loss 2.02606 | val_rmse 1.42340\n",
      "| epoch 292 | lr 0.00010 train_loss 0.44892 | val_loss 2.00674 | val_rmse 1.41660\n",
      "| epoch 293 | lr 0.00010 train_loss 0.45555 | val_loss 2.01212 | val_rmse 1.41849\n",
      "| epoch 294 | lr 0.00010 train_loss 0.44604 | val_loss 2.04541 | val_rmse 1.43018\n",
      "| epoch 295 | lr 0.00010 train_loss 0.44150 | val_loss 2.02604 | val_rmse 1.42339\n",
      "| epoch 296 | lr 0.00010 train_loss 0.44905 | val_loss 1.99809 | val_rmse 1.41354\n",
      "| epoch 297 | lr 0.00010 train_loss 0.44847 | val_loss 2.04472 | val_rmse 1.42994\n",
      "| epoch 298 | lr 0.00010 train_loss 0.44660 | val_loss 2.01288 | val_rmse 1.41876\n",
      "| epoch 299 | lr 0.00010 train_loss 0.45645 | val_loss 2.05973 | val_rmse 1.43518\n",
      "| epoch 300 | lr 0.00010 train_loss 0.44555 | val_loss 2.04238 | val_rmse 1.42912\n",
      "| epoch 301 | lr 0.00010 train_loss 0.45576 | val_loss 2.02464 | val_rmse 1.42290\n",
      "| epoch 302 | lr 0.00010 train_loss 0.45000 | val_loss 2.01699 | val_rmse 1.42021\n",
      "| epoch 303 | lr 0.00010 train_loss 0.44810 | val_loss 2.06464 | val_rmse 1.43688\n",
      "| epoch 304 | lr 0.00010 train_loss 0.43671 | val_loss 2.02971 | val_rmse 1.42468\n",
      "| epoch 305 | lr 0.00010 train_loss 0.43883 | val_loss 2.04559 | val_rmse 1.43024\n",
      "| epoch 306 | lr 0.00010 train_loss 0.44636 | val_loss 2.07120 | val_rmse 1.43917\n",
      "| epoch 307 | lr 0.00010 train_loss 0.45308 | val_loss 1.99090 | val_rmse 1.41099\n",
      "| epoch 308 | lr 0.00010 train_loss 0.44203 | val_loss 2.02037 | val_rmse 1.42140\n",
      "| epoch 309 | lr 0.00010 train_loss 0.44499 | val_loss 2.01530 | val_rmse 1.41961\n",
      "| epoch 310 | lr 0.00010 train_loss 0.44776 | val_loss 2.04041 | val_rmse 1.42843\n",
      "| epoch 311 | lr 0.00010 train_loss 0.43705 | val_loss 1.96374 | val_rmse 1.40133\n",
      "| epoch 312 | lr 0.00010 train_loss 0.44603 | val_loss 2.01202 | val_rmse 1.41846\n",
      "| epoch 313 | lr 0.00010 train_loss 0.43556 | val_loss 2.07636 | val_rmse 1.44096\n",
      "| epoch 314 | lr 0.00010 train_loss 0.43461 | val_loss 2.06645 | val_rmse 1.43751\n",
      "| epoch 315 | lr 0.00010 train_loss 0.43587 | val_loss 2.00829 | val_rmse 1.41714\n",
      "| epoch 316 | lr 0.00010 train_loss 0.42983 | val_loss 2.02409 | val_rmse 1.42270\n",
      "| epoch 317 | lr 0.00010 train_loss 0.44214 | val_loss 2.05220 | val_rmse 1.43255\n",
      "| epoch 318 | lr 0.00010 train_loss 0.44276 | val_loss 2.06347 | val_rmse 1.43648\n",
      "| epoch 319 | lr 0.00010 train_loss 0.44559 | val_loss 2.17218 | val_rmse 1.47383\n",
      "| epoch 320 | lr 0.00010 train_loss 0.45457 | val_loss 2.12053 | val_rmse 1.45620\n",
      "| epoch 321 | lr 0.00010 train_loss 0.43351 | val_loss 2.10986 | val_rmse 1.45253\n",
      "| epoch 322 | lr 0.00010 train_loss 0.43868 | val_loss 2.11719 | val_rmse 1.45506\n",
      "| epoch 323 | lr 0.00010 train_loss 0.43349 | val_loss 2.05820 | val_rmse 1.43464\n",
      "| epoch 324 | lr 0.00010 train_loss 0.43663 | val_loss 2.05856 | val_rmse 1.43477\n",
      "| epoch 325 | lr 0.00010 train_loss 0.44468 | val_loss 2.00017 | val_rmse 1.41427\n",
      "| epoch 326 | lr 0.00010 train_loss 0.43777 | val_loss 1.99349 | val_rmse 1.41191\n",
      "| epoch 327 | lr 0.00010 train_loss 0.44697 | val_loss 1.98162 | val_rmse 1.40770\n",
      "| epoch 328 | lr 0.00010 train_loss 0.44341 | val_loss 2.02131 | val_rmse 1.42173\n",
      "| epoch 329 | lr 0.00010 train_loss 0.43778 | val_loss 2.02408 | val_rmse 1.42270\n",
      "| epoch 330 | lr 0.00010 train_loss 0.44031 | val_loss 2.03903 | val_rmse 1.42795\n",
      "| epoch 331 | lr 0.00010 train_loss 0.43735 | val_loss 2.01940 | val_rmse 1.42106\n",
      "| epoch 332 | lr 0.00010 train_loss 0.44736 | val_loss 2.03253 | val_rmse 1.42567\n",
      "| epoch 333 | lr 0.00010 train_loss 0.44443 | val_loss 1.99414 | val_rmse 1.41214\n",
      "| epoch 334 | lr 0.00010 train_loss 0.44726 | val_loss 1.99769 | val_rmse 1.41340\n",
      "| epoch 335 | lr 0.00010 train_loss 0.43363 | val_loss 1.96100 | val_rmse 1.40036\n",
      "| epoch 336 | lr 0.00010 train_loss 0.43605 | val_loss 2.01095 | val_rmse 1.41808\n",
      "| epoch 337 | lr 0.00010 train_loss 0.43479 | val_loss 1.98688 | val_rmse 1.40957\n",
      "| epoch 338 | lr 0.00010 train_loss 0.45164 | val_loss 1.99291 | val_rmse 1.41170\n",
      "| epoch 339 | lr 0.00010 train_loss 0.43307 | val_loss 1.99289 | val_rmse 1.41170\n",
      "| epoch 340 | lr 0.00010 train_loss 0.44003 | val_loss 1.94268 | val_rmse 1.39380\n",
      "| epoch 341 | lr 0.00010 train_loss 0.44255 | val_loss 1.98949 | val_rmse 1.41049\n",
      "| epoch 342 | lr 0.00010 train_loss 0.43100 | val_loss 2.00201 | val_rmse 1.41493\n",
      "| epoch 343 | lr 0.00010 train_loss 0.44151 | val_loss 2.03643 | val_rmse 1.42704\n",
      "| epoch 344 | lr 0.00010 train_loss 0.42479 | val_loss 2.01312 | val_rmse 1.41885\n",
      "| epoch 345 | lr 0.00010 train_loss 0.43298 | val_loss 2.00620 | val_rmse 1.41640\n",
      "| epoch 346 | lr 0.00010 train_loss 0.43451 | val_loss 1.99475 | val_rmse 1.41235\n",
      "| epoch 347 | lr 0.00010 train_loss 0.43122 | val_loss 1.96041 | val_rmse 1.40015\n",
      "| epoch 348 | lr 0.00010 train_loss 0.44358 | val_loss 1.94217 | val_rmse 1.39362\n",
      "| epoch 349 | lr 0.00010 train_loss 0.45715 | val_loss 1.95331 | val_rmse 1.39761\n",
      "| epoch 350 | lr 0.00010 train_loss 0.43787 | val_loss 1.91595 | val_rmse 1.38418\n",
      "| epoch 351 | lr 0.00010 train_loss 0.42315 | val_loss 1.96929 | val_rmse 1.40331\n",
      "| epoch 352 | lr 0.00010 train_loss 0.43289 | val_loss 1.98667 | val_rmse 1.40949\n",
      "| epoch 353 | lr 0.00010 train_loss 0.42479 | val_loss 2.02249 | val_rmse 1.42214\n",
      "| epoch 354 | lr 0.00010 train_loss 0.41503 | val_loss 1.95828 | val_rmse 1.39939\n",
      "| epoch 355 | lr 0.00010 train_loss 0.42810 | val_loss 1.99045 | val_rmse 1.41083\n",
      "| epoch 356 | lr 0.00010 train_loss 0.41899 | val_loss 1.99919 | val_rmse 1.41393\n",
      "| epoch 357 | lr 0.00010 train_loss 0.42989 | val_loss 1.94532 | val_rmse 1.39475\n",
      "| epoch 358 | lr 0.00010 train_loss 0.41915 | val_loss 1.99362 | val_rmse 1.41196\n",
      "| epoch 359 | lr 0.00010 train_loss 0.40822 | val_loss 1.97508 | val_rmse 1.40538\n",
      "| epoch 360 | lr 0.00010 train_loss 0.40211 | val_loss 2.01023 | val_rmse 1.41783\n",
      "| epoch 361 | lr 0.00010 train_loss 0.40629 | val_loss 1.97401 | val_rmse 1.40499\n",
      "| epoch 362 | lr 0.00010 train_loss 0.41114 | val_loss 1.91233 | val_rmse 1.38287\n",
      "| epoch 363 | lr 0.00010 train_loss 0.40488 | val_loss 1.97881 | val_rmse 1.40670\n",
      "| epoch 364 | lr 0.00010 train_loss 0.40454 | val_loss 1.93160 | val_rmse 1.38982\n",
      "| epoch 365 | lr 0.00010 train_loss 0.41010 | val_loss 1.96048 | val_rmse 1.40017\n",
      "| epoch 366 | lr 0.00010 train_loss 0.39627 | val_loss 1.95187 | val_rmse 1.39709\n",
      "| epoch 367 | lr 0.00010 train_loss 0.39681 | val_loss 1.92146 | val_rmse 1.38617\n",
      "| epoch 368 | lr 0.00010 train_loss 0.39768 | val_loss 1.94801 | val_rmse 1.39571\n",
      "| epoch 369 | lr 0.00010 train_loss 0.39820 | val_loss 1.96242 | val_rmse 1.40086\n",
      "| epoch 370 | lr 0.00010 train_loss 0.38669 | val_loss 1.98257 | val_rmse 1.40804\n",
      "| epoch 371 | lr 0.00010 train_loss 0.40518 | val_loss 2.01440 | val_rmse 1.41929\n",
      "| epoch 372 | lr 0.00010 train_loss 0.39720 | val_loss 2.03780 | val_rmse 1.42751\n",
      "| epoch 373 | lr 0.00010 train_loss 0.40968 | val_loss 1.97604 | val_rmse 1.40572\n",
      "| epoch 374 | lr 0.00010 train_loss 0.40973 | val_loss 1.92355 | val_rmse 1.38692\n",
      "| epoch 375 | lr 0.00010 train_loss 0.41928 | val_loss 1.89555 | val_rmse 1.37679\n",
      "| epoch 376 | lr 0.00010 train_loss 0.41755 | val_loss 1.95860 | val_rmse 1.39950\n",
      "| epoch 377 | lr 0.00010 train_loss 0.39866 | val_loss 1.86804 | val_rmse 1.36676\n",
      "| epoch 378 | lr 0.00010 train_loss 0.40790 | val_loss 1.95196 | val_rmse 1.39712\n",
      "| epoch 379 | lr 0.00010 train_loss 0.38225 | val_loss 1.92165 | val_rmse 1.38624\n",
      "| epoch 380 | lr 0.00010 train_loss 0.38295 | val_loss 1.87933 | val_rmse 1.37089\n",
      "| epoch 381 | lr 0.00010 train_loss 0.38995 | val_loss 1.95509 | val_rmse 1.39824\n",
      "| epoch 382 | lr 0.00010 train_loss 0.38383 | val_loss 1.93337 | val_rmse 1.39046\n",
      "| epoch 383 | lr 0.00010 train_loss 0.38143 | val_loss 1.97621 | val_rmse 1.40578\n",
      "| epoch 384 | lr 0.00010 train_loss 0.38309 | val_loss 1.96408 | val_rmse 1.40145\n",
      "| epoch 385 | lr 0.00010 train_loss 0.38183 | val_loss 1.95693 | val_rmse 1.39890\n",
      "| epoch 386 | lr 0.00010 train_loss 0.37734 | val_loss 1.92435 | val_rmse 1.38721\n",
      "| epoch 387 | lr 0.00010 train_loss 0.38483 | val_loss 1.96768 | val_rmse 1.40274\n",
      "| epoch 388 | lr 0.00010 train_loss 0.38127 | val_loss 1.96042 | val_rmse 1.40015\n",
      "| epoch 389 | lr 0.00010 train_loss 0.37958 | val_loss 1.92390 | val_rmse 1.38705\n",
      "| epoch 390 | lr 0.00010 train_loss 0.37028 | val_loss 1.97348 | val_rmse 1.40481\n",
      "| epoch 391 | lr 0.00010 train_loss 0.45876 | val_loss 1.95159 | val_rmse 1.39699\n",
      "| epoch 392 | lr 0.00010 train_loss 0.38920 | val_loss 1.96033 | val_rmse 1.40012\n",
      "| epoch 393 | lr 0.00010 train_loss 0.38895 | val_loss 1.95253 | val_rmse 1.39733\n",
      "| epoch 394 | lr 0.00010 train_loss 0.40564 | val_loss 1.90863 | val_rmse 1.38153\n",
      "| epoch 395 | lr 0.00010 train_loss 0.39896 | val_loss 1.94902 | val_rmse 1.39607\n",
      "| epoch 396 | lr 0.00010 train_loss 0.37633 | val_loss 1.92190 | val_rmse 1.38633\n",
      "| epoch 397 | lr 0.00010 train_loss 0.39282 | val_loss 1.96455 | val_rmse 1.40162\n",
      "| epoch 398 | lr 0.00010 train_loss 0.38106 | val_loss 1.89152 | val_rmse 1.37532\n",
      "| epoch 399 | lr 0.00010 train_loss 0.39280 | val_loss 1.92955 | val_rmse 1.38908\n",
      "| epoch 400 | lr 0.00010 train_loss 0.38303 | val_loss 1.90052 | val_rmse 1.37859\n",
      "| epoch 401 | lr 0.00010 train_loss 0.37426 | val_loss 1.89880 | val_rmse 1.37797\n",
      "| epoch 402 | lr 0.00010 train_loss 0.36345 | val_loss 1.88479 | val_rmse 1.37288\n",
      "| epoch 403 | lr 0.00010 train_loss 0.36967 | val_loss 1.90508 | val_rmse 1.38025\n",
      "| epoch 404 | lr 0.00010 train_loss 0.37729 | val_loss 1.89506 | val_rmse 1.37661\n",
      "| epoch 405 | lr 0.00010 train_loss 0.39510 | val_loss 1.91668 | val_rmse 1.38444\n",
      "| epoch 406 | lr 0.00010 train_loss 0.40474 | val_loss 1.82793 | val_rmse 1.35201\n",
      "| epoch 407 | lr 0.00010 train_loss 0.37341 | val_loss 1.83093 | val_rmse 1.35312\n",
      "| epoch 408 | lr 0.00010 train_loss 0.37908 | val_loss 1.87282 | val_rmse 1.36851\n",
      "| epoch 409 | lr 0.00010 train_loss 0.39316 | val_loss 1.89911 | val_rmse 1.37808\n",
      "| epoch 410 | lr 0.00010 train_loss 0.38326 | val_loss 1.86342 | val_rmse 1.36507\n",
      "| epoch 411 | lr 0.00010 train_loss 0.37545 | val_loss 1.85247 | val_rmse 1.36106\n",
      "| epoch 412 | lr 0.00010 train_loss 0.37166 | val_loss 1.88483 | val_rmse 1.37289\n",
      "| epoch 413 | lr 0.00010 train_loss 0.37766 | val_loss 1.90423 | val_rmse 1.37994\n",
      "| epoch 414 | lr 0.00010 train_loss 0.35851 | val_loss 1.85174 | val_rmse 1.36079\n",
      "| epoch 415 | lr 0.00010 train_loss 0.37197 | val_loss 1.87093 | val_rmse 1.36782\n",
      "| epoch 416 | lr 0.00010 train_loss 0.36170 | val_loss 1.91828 | val_rmse 1.38502\n",
      "| epoch 417 | lr 0.00010 train_loss 0.38041 | val_loss 1.90780 | val_rmse 1.38123\n",
      "| epoch 418 | lr 0.00010 train_loss 0.36648 | val_loss 1.89935 | val_rmse 1.37817\n",
      "| epoch 419 | lr 0.00010 train_loss 0.36582 | val_loss 1.89662 | val_rmse 1.37718\n",
      "| epoch 420 | lr 0.00010 train_loss 0.37279 | val_loss 1.96400 | val_rmse 1.40143\n",
      "| epoch 421 | lr 0.00010 train_loss 0.37246 | val_loss 1.91093 | val_rmse 1.38236\n",
      "| epoch 422 | lr 0.00010 train_loss 0.36988 | val_loss 1.90236 | val_rmse 1.37926\n",
      "| epoch 423 | lr 0.00010 train_loss 0.38034 | val_loss 1.94990 | val_rmse 1.39639\n",
      "| epoch 424 | lr 0.00010 train_loss 0.37587 | val_loss 1.92264 | val_rmse 1.38659\n",
      "| epoch 425 | lr 0.00010 train_loss 0.36694 | val_loss 1.91315 | val_rmse 1.38317\n",
      "| epoch 426 | lr 0.00010 train_loss 0.36243 | val_loss 1.91680 | val_rmse 1.38449\n",
      "| epoch 427 | lr 0.00010 train_loss 0.37331 | val_loss 1.89440 | val_rmse 1.37637\n",
      "| epoch 428 | lr 0.00010 train_loss 0.36255 | val_loss 1.88514 | val_rmse 1.37300\n",
      "| epoch 429 | lr 0.00010 train_loss 0.34375 | val_loss 1.85225 | val_rmse 1.36097\n",
      "| epoch 430 | lr 0.00010 train_loss 0.36797 | val_loss 1.92654 | val_rmse 1.38800\n",
      "| epoch 431 | lr 0.00010 train_loss 0.35892 | val_loss 1.87594 | val_rmse 1.36965\n",
      "| epoch 432 | lr 0.00010 train_loss 0.36957 | val_loss 1.90233 | val_rmse 1.37925\n",
      "| epoch 433 | lr 0.00010 train_loss 0.36628 | val_loss 1.90289 | val_rmse 1.37945\n",
      "| epoch 434 | lr 0.00010 train_loss 0.35381 | val_loss 1.86771 | val_rmse 1.36664\n",
      "| epoch 435 | lr 0.00010 train_loss 0.35095 | val_loss 1.87672 | val_rmse 1.36993\n",
      "| epoch 436 | lr 0.00010 train_loss 0.36262 | val_loss 1.90418 | val_rmse 1.37992\n",
      "| epoch 437 | lr 0.00010 train_loss 0.36082 | val_loss 1.92515 | val_rmse 1.38750\n",
      "| epoch 438 | lr 0.00010 train_loss 0.36037 | val_loss 1.94029 | val_rmse 1.39294\n",
      "| epoch 439 | lr 0.00010 train_loss 0.36609 | val_loss 1.89697 | val_rmse 1.37730\n",
      "| epoch 440 | lr 0.00010 train_loss 0.37571 | val_loss 1.90853 | val_rmse 1.38150\n",
      "| epoch 441 | lr 0.00010 train_loss 0.35825 | val_loss 1.93667 | val_rmse 1.39164\n",
      "| epoch 442 | lr 0.00010 train_loss 0.35159 | val_loss 1.87241 | val_rmse 1.36836\n",
      "| epoch 443 | lr 0.00010 train_loss 0.36301 | val_loss 1.84103 | val_rmse 1.35684\n",
      "| epoch 444 | lr 0.00010 train_loss 0.35997 | val_loss 1.88756 | val_rmse 1.37389\n",
      "| epoch 445 | lr 0.00010 train_loss 0.35359 | val_loss 1.88420 | val_rmse 1.37266\n",
      "| epoch 446 | lr 0.00010 train_loss 0.35451 | val_loss 1.86503 | val_rmse 1.36566\n",
      "| epoch 447 | lr 0.00010 train_loss 0.35674 | val_loss 1.82607 | val_rmse 1.35132\n",
      "| epoch 448 | lr 0.00010 train_loss 0.36665 | val_loss 1.92574 | val_rmse 1.38771\n",
      "| epoch 449 | lr 0.00010 train_loss 0.35922 | val_loss 1.92007 | val_rmse 1.38567\n",
      "| epoch 450 | lr 0.00010 train_loss 0.35407 | val_loss 1.90626 | val_rmse 1.38067\n",
      "| epoch 451 | lr 0.00010 train_loss 0.35499 | val_loss 1.86736 | val_rmse 1.36651\n",
      "| epoch 452 | lr 0.00010 train_loss 0.40497 | val_loss 1.90014 | val_rmse 1.37846\n",
      "| epoch 453 | lr 0.00010 train_loss 0.39950 | val_loss 1.88316 | val_rmse 1.37228\n",
      "| epoch 454 | lr 0.00010 train_loss 0.39355 | val_loss 1.86342 | val_rmse 1.36507\n",
      "| epoch 455 | lr 0.00010 train_loss 0.38269 | val_loss 1.87274 | val_rmse 1.36848\n",
      "| epoch 456 | lr 0.00010 train_loss 0.36924 | val_loss 1.86476 | val_rmse 1.36556\n",
      "| epoch 457 | lr 0.00010 train_loss 0.36472 | val_loss 1.86494 | val_rmse 1.36563\n",
      "| epoch 458 | lr 0.00010 train_loss 0.35147 | val_loss 1.86526 | val_rmse 1.36575\n",
      "| epoch 459 | lr 0.00010 train_loss 0.36433 | val_loss 1.88246 | val_rmse 1.37203\n",
      "| epoch 460 | lr 0.00010 train_loss 0.36012 | val_loss 1.98329 | val_rmse 1.40829\n",
      "| epoch 461 | lr 0.00010 train_loss 0.36573 | val_loss 1.89631 | val_rmse 1.37707\n",
      "| epoch 462 | lr 0.00010 train_loss 0.37079 | val_loss 1.84045 | val_rmse 1.35663\n",
      "| epoch 463 | lr 0.00010 train_loss 0.35929 | val_loss 1.87678 | val_rmse 1.36995\n",
      "| epoch 464 | lr 0.00010 train_loss 0.36945 | val_loss 1.83621 | val_rmse 1.35507\n",
      "| epoch 465 | lr 0.00010 train_loss 0.36347 | val_loss 1.85441 | val_rmse 1.36177\n",
      "| epoch 466 | lr 0.00010 train_loss 0.34879 | val_loss 1.83486 | val_rmse 1.35457\n",
      "| epoch 467 | lr 0.00010 train_loss 0.35733 | val_loss 1.87403 | val_rmse 1.36895\n",
      "| epoch 468 | lr 0.00010 train_loss 0.35549 | val_loss 1.88926 | val_rmse 1.37451\n",
      "| epoch 469 | lr 0.00010 train_loss 0.36699 | val_loss 1.92875 | val_rmse 1.38880\n",
      "| epoch 470 | lr 0.00010 train_loss 0.35218 | val_loss 1.90264 | val_rmse 1.37936\n",
      "| epoch 471 | lr 0.00010 train_loss 0.35127 | val_loss 1.90886 | val_rmse 1.38162\n",
      "| epoch 472 | lr 0.00010 train_loss 0.36274 | val_loss 1.92672 | val_rmse 1.38806\n",
      "| epoch 473 | lr 0.00010 train_loss 0.36333 | val_loss 1.90798 | val_rmse 1.38130\n",
      "| epoch 474 | lr 0.00010 train_loss 0.36214 | val_loss 1.94339 | val_rmse 1.39405\n",
      "| epoch 475 | lr 0.00010 train_loss 0.35732 | val_loss 1.96470 | val_rmse 1.40168\n",
      "| epoch 476 | lr 0.00010 train_loss 0.34207 | val_loss 1.96948 | val_rmse 1.40338\n",
      "| epoch 477 | lr 0.00010 train_loss 0.34739 | val_loss 1.95373 | val_rmse 1.39776\n",
      "| epoch 478 | lr 0.00010 train_loss 0.34657 | val_loss 1.91158 | val_rmse 1.38260\n",
      "| epoch 479 | lr 0.00010 train_loss 0.35263 | val_loss 1.92541 | val_rmse 1.38759\n",
      "| epoch 480 | lr 0.00010 train_loss 0.35218 | val_loss 1.88266 | val_rmse 1.37210\n",
      "| epoch 481 | lr 0.00010 train_loss 0.37523 | val_loss 1.87260 | val_rmse 1.36843\n",
      "| epoch 482 | lr 0.00010 train_loss 0.36975 | val_loss 1.86525 | val_rmse 1.36574\n",
      "| epoch 483 | lr 0.00010 train_loss 0.36459 | val_loss 1.87514 | val_rmse 1.36936\n",
      "| epoch 484 | lr 0.00010 train_loss 0.34443 | val_loss 1.86511 | val_rmse 1.36569\n",
      "| epoch 485 | lr 0.00010 train_loss 0.35597 | val_loss 1.85628 | val_rmse 1.36245\n",
      "| epoch 486 | lr 0.00010 train_loss 0.34681 | val_loss 1.89933 | val_rmse 1.37816\n",
      "| epoch 487 | lr 0.00010 train_loss 0.35221 | val_loss 1.87447 | val_rmse 1.36911\n",
      "| epoch 488 | lr 0.00010 train_loss 0.34185 | val_loss 1.82904 | val_rmse 1.35242\n",
      "| epoch 489 | lr 0.00010 train_loss 0.34891 | val_loss 1.89918 | val_rmse 1.37811\n",
      "| epoch 490 | lr 0.00010 train_loss 0.34769 | val_loss 1.94761 | val_rmse 1.39557\n",
      "| epoch 491 | lr 0.00010 train_loss 0.33642 | val_loss 1.90459 | val_rmse 1.38007\n",
      "| epoch 492 | lr 0.00010 train_loss 0.33419 | val_loss 1.90321 | val_rmse 1.37957\n",
      "| epoch 493 | lr 0.00010 train_loss 0.34541 | val_loss 1.91425 | val_rmse 1.38356\n",
      "| epoch 494 | lr 0.00010 train_loss 0.33960 | val_loss 1.91412 | val_rmse 1.38352\n",
      "| epoch 495 | lr 0.00010 train_loss 0.34515 | val_loss 1.92005 | val_rmse 1.38566\n",
      "| epoch 496 | lr 0.00010 train_loss 0.33272 | val_loss 1.92718 | val_rmse 1.38823\n",
      "| epoch 497 | lr 0.00010 train_loss 0.33337 | val_loss 1.91479 | val_rmse 1.38376\n",
      "| epoch 498 | lr 0.00010 train_loss 0.33875 | val_loss 1.96814 | val_rmse 1.40290\n",
      "| epoch 499 | lr 0.00010 train_loss 0.33032 | val_loss 1.94477 | val_rmse 1.39455\n",
      "| epoch 500 | lr 0.00010 train_loss 0.33531 | val_loss 1.90954 | val_rmse 1.38186\n"
     ]
    }
   ],
   "source": [
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "    min_val_loss = float(\"inf\")\n",
    "    log = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.\n",
    "        best_model = None\n",
    "        model.train()\n",
    "        for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            X_ori = X_ori.to(device)\n",
    "            X_mut = X_mut.to(device)\n",
    "            X_muthhb = X_muthhb.to(device)\n",
    "            X_orihhb = X_orihhb.to(device)\n",
    "            X_na = X_na.to(device)\n",
    "            y_preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "            y = y.to(device)\n",
    "            loss = loss_fn(y_preds.ravel(), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*len(X_ori)\n",
    "        total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "        # validate\n",
    "        model.eval()\n",
    "        val_losses = 0.\n",
    "        with torch.no_grad():\n",
    "            for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "                X_ori = X_ori.to(device)\n",
    "                X_mut = X_mut.to(device)\n",
    "                X_muthhb = X_muthhb.to(device)\n",
    "                X_orihhb = X_orihhb.to(device)\n",
    "                X_na = X_na.to(device)\n",
    "                y = y.to(device)\n",
    "                preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "                val_loss = loss_fn(preds.ravel(), y)\n",
    "                val_losses += val_loss.item()*len(X_ori)\n",
    "        val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "        log.append([epoch,total_mse,val_mse])\n",
    "        print('| epoch {:3d} | lr {:02.5f} '\n",
    "                      'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "                      format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "        if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "            min_val_loss = val_loss\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), 'result/blstm_best_all.pth')\n",
    "        scheduler.step()\n",
    "    f = open('result/blstm_log.txt','w')\n",
    "    for i in log:\n",
    "        f.write(str(i)+'\\n')\n",
    "    f.close()\n",
    "TrainModel(BLSTMRegressor, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871100818357419\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_mse = 0.\n",
    "test_result = []\n",
    "model = BLSTMRegressor.to(device)\n",
    "model.load_state_dict(torch.load('result/blstm_best_all.pth'))\n",
    "model.eval()\n",
    "for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "    X_mut = X_mut.to(device); X_muthhb = X_muthhb.to(device)\n",
    "    X_ori = X_ori.to(device); X_orihhb = X_orihhb.to(device)\n",
    "    X_na = X_na.to(device)\n",
    "    y = y.to(device)\n",
    "    preds = model(X_ori, X_mut, X_orihhb, X_muthhb, X_na, device)\n",
    "    loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "    test_result.append(y.tolist())\n",
    "    test_result.append(preds.tolist())\n",
    "    test_result.append(loss.tolist())\n",
    "    test_mse += loss.item()*len(X_ori)\n",
    "test_mse = test_mse/len(test_dataset)\n",
    "test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "file_name = 'result/blstm_test_result.txt'\n",
    "f = open(file_name,'w')\n",
    "for i in test_result:\n",
    "    f.write(str(i)+'\\n')\n",
    "f.close()\n",
    "print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# Trans = Trans1().to(device)\n",
    "\n",
    "# optimizer = Adam(Trans.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "# Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "#     min_val_loss = float(\"inf\")\n",
    "#     log = []\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         total_loss = 0.\n",
    "#         best_model = None\n",
    "#         model.train()\n",
    "#         for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             X_ori = X_ori.to(device)\n",
    "#             X_mut = X_mut.to(device)\n",
    "#             # X_muthhb = X_muthhb.to(device)\n",
    "#             # X_orihhb = X_orihhb.to(device)\n",
    "#             X_na = X_na.to(device)\n",
    "#             y_preds = model(X_ori, X_mut, X_na, device)\n",
    "#             y = y.to(device)\n",
    "#             loss = loss_fn(y_preds.ravel(), y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()*len(X_ori)\n",
    "#         total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "#         # validate\n",
    "#         model.eval()\n",
    "#         val_losses = 0.\n",
    "#         with torch.no_grad():\n",
    "#             for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "#                 X_ori = X_ori.to(device)\n",
    "#                 X_mut = X_mut.to(device)\n",
    "#                 # X_muthhb = X_muthhb.to(device)\n",
    "#                 # X_orihhb = X_orihhb.to(device)\n",
    "#                 X_na = X_na.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 preds = model(X_ori, X_mut, X_na, device)\n",
    "#                 val_loss = loss_fn(preds.ravel(), y)\n",
    "#                 val_losses += val_loss.item()*len(X_ori)\n",
    "#         val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "#         log.append([epoch,total_mse,val_mse])\n",
    "#         print('| epoch {:3d} | lr {:02.5f} '\n",
    "#                       'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "#                       format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "#         if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "#             min_val_loss = val_loss\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), 'result/trans1_best_all.pth')\n",
    "#         scheduler.step()\n",
    "#     f = open('result/trans1_log.txt','w')\n",
    "#     for i in log:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#     f.close()\n",
    "# TrainModel(Trans, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# test_mse = 0.\n",
    "# test_result = []\n",
    "# model = Trans\n",
    "# model.load_state_dict(torch.load('result/trans1_best_all.pth'))\n",
    "# model.eval()\n",
    "# for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "#     X_mut = X_mut.to(device)\n",
    "#     X_ori = X_ori.to(device)\n",
    "#     # X_orihhb = X_orihhb.to(device)\n",
    "#     # X_muthhb = X_muthhb.to(device)\n",
    "#     X_na = X_na.to(device)\n",
    "#     y = y.to(device)\n",
    "#     preds = model(X_ori, X_mut, X_na, device)\n",
    "#     loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "#     test_result.append(y.tolist())\n",
    "#     test_result.append(preds.tolist())\n",
    "#     test_result.append(loss.tolist())\n",
    "#     test_mse += loss.item()*len(X_ori)\n",
    "# test_mse = test_mse/len(test_dataset)\n",
    "# test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "# file_name = 'result/trans1_test_result.txt'\n",
    "# f = open(file_name,'w')\n",
    "# for i in test_result:\n",
    "#     f.write(str(i)+'\\n')\n",
    "# f.close()\n",
    "# print(test_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# Trans = Trans2().to(device)\n",
    "\n",
    "# optimizer = Adam(Trans.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
    "# Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=epochs):\n",
    "#     min_val_loss = float(\"inf\")\n",
    "#     log = []\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         total_loss = 0.\n",
    "#         best_model = None\n",
    "#         model.train()\n",
    "#         for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             # X_ori = X_ori.to(device)\n",
    "#             # X_mut = X_mut.to(device)\n",
    "#             X_muthhb = X_muthhb.to(device)\n",
    "#             X_orihhb = X_orihhb.to(device)\n",
    "#             X_na = X_na.to(device)\n",
    "#             y_preds = model(X_orihhb, X_muthhb, X_na, device)\n",
    "#             y = y.to(device)\n",
    "#             loss = loss_fn(y_preds.ravel(), y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()*len(X_ori)\n",
    "#         total_mse = total_loss/len(train_dataset)\n",
    "\n",
    "#         # validate\n",
    "#         model.eval()\n",
    "#         val_losses = 0.\n",
    "#         with torch.no_grad():\n",
    "#             for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in val_loader:\n",
    "#                 # X_ori = X_ori.to(device)\n",
    "#                 # X_mut = X_mut.to(device)\n",
    "#                 X_muthhb = X_muthhb.to(device)\n",
    "#                 X_orihhb = X_orihhb.to(device)\n",
    "#                 X_na = X_na.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 preds = model(X_orihhb, X_muthhb, X_na, device)\n",
    "#                 val_loss = loss_fn(preds.ravel(), y)\n",
    "#                 val_losses += val_loss.item()*len(X_ori)\n",
    "#         val_mse = val_losses/len(val_dataset)\n",
    "\n",
    "#         log.append([epoch,total_mse,val_mse])\n",
    "#         print('| epoch {:3d} | lr {:02.5f} '\n",
    "#                       'train_loss {:5.5f} | val_loss {:5.5f} | val_rmse {:5.5f}'.\n",
    "#                       format(epoch, scheduler.get_last_lr()[0],total_mse, val_mse, math.sqrt(val_mse)))\n",
    "#         if (epoch >= 50) and (val_mse < min_val_loss):\n",
    "#             min_val_loss = val_loss\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), 'result/trans2_best_all.pth')\n",
    "#         scheduler.step()\n",
    "#     f = open('result/trans2_log.txt','w')\n",
    "#     for i in log:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#     f.close()\n",
    "# TrainModel(Trans, loss_fn, optimizer, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# test_mse = 0.\n",
    "# test_result = []\n",
    "# model = Trans\n",
    "# model.load_state_dict(torch.load('result/trans2_best_all.pth'))\n",
    "# model.eval()\n",
    "# for X_ori, X_mut, X_orihhb, X_muthhb, X_na, y in test_loader:\n",
    "#     # X_mut = X_mut.to(device)\n",
    "#     # X_ori = X_ori.to(device)\n",
    "#     X_orihhb = X_orihhb.to(device)\n",
    "#     X_muthhb = X_muthhb.to(device)\n",
    "#     X_na = X_na.to(device)\n",
    "#     y = y.to(device)\n",
    "#     preds = model(X_orihhb, X_muthhb, X_na, device)\n",
    "#     loss = loss_fn(preds.ravel(), y)\n",
    "    \n",
    "#     test_result.append(y.tolist())\n",
    "#     test_result.append(preds.tolist())\n",
    "#     test_result.append(loss.tolist())\n",
    "#     test_mse += loss.item()*len(X_ori)\n",
    "# test_mse = test_mse/len(test_dataset)\n",
    "# test_rmse = math.sqrt(test_mse)\n",
    "\n",
    "# file_name = 'result/trans2_test_result.txt'\n",
    "# f = open(file_name,'w')\n",
    "# for i in test_result:\n",
    "#     f.write(str(i)+'\\n')\n",
    "# f.close()\n",
    "# print(test_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cea085641e72410502974b25165e6310c4e74f3895213c724f4183725c7e9270"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
